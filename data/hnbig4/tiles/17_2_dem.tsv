id	label	hovertext	author	x	y	type	relevance	size	year	umap1d
33082469	Just a note that LiteFS isn't a dist	"Just a note that LiteFS isn't a distributed filesystem; despite the name, it's not a filesystem at all, but rather just a filesystem proxy. It does essentially the same thing that the VFS layer in SQLite itself does, but it does it with a FUSE filesystem, so you don't have to change SQLite's configuration in your application. As for the ""distributed"" part of it: LiteFS has a single-writer multi-reader architecture; it's the same strategy you'd use to scale out Postgres.It's a little ironic to see LiteFS brought up in relation to a SQLite fork, since the premise of LiteFS is not changing the SQLite code you link into your application. Much of the work in LiteFS is about cooperating with standard SQLite.At any rate: it seems somewhat unlikely that a hard fork of SQLite is going to succeed, i"	tptacek	13.5807085	-5.5186834	comment	3.0	19.0	1664899913	9.817041
33082558	Has sqlite been forked before? This 	"Has sqlite been forked before? This is the first true fork and re-license attempt that's caught my eye. The others I've seen are ""ports"" and ""modifications"", but always pointing people back upstream.It's possible that the appetite for a SQLite fork is there, but nobody has provided it."	mmastrac	13.637389	-5.5849047	comment	3.0	14.0	1664900218	9.857884
33082275	Whether or not this succeeds, I thin	Whether or not this succeeds, I think it's a great effort. SQLite not taking any outside contributions is of course their prerogative. But it would also be cool to see what could happen with a more open development model. And their (libsql) plans around io_uring and Rust for future code both sound like a good start.The way they're going about this fork (described in the repo [0] readme) seems healthy enough for both projects as well.Maybe the biggest challenge though is recreating SQLite's private/proprietary test suite [1].[0] https://github.com/libsql/libsql[1] https://www.sqlite.org/th3.html	eatonphil	13.626904	-5.6206474	comment	3.0	14.0	1664899101	9.824693
33082806	SITUATION: there are too many compet	SITUATION: there are too many competing SQLite forks...	johnboiles	13.621481	-5.5712295	comment	3.0	11.0	1664901189	9.823777
33099767	I mean.  I was definitely unfamiliar	"I mean.  I was definitely unfamiliar with their ""Code of Ethics"" [0] until I read it and I cannot say that I'm a tremendous fan.  But also, it's the absolute last thing mentioned in the readme, so unless you have additional information that I don't, I don't know why you think that's the main reason they forked, especially when they tell you all the reasons they forked and that isn't really one of them.[0] https://sqlite.org/codeofethics.html"	anoonmoose	13.655977	-5.592798	comment	3.0	21.0	1664996014	9.813531
33145874	> Uses SQLite, and no external depen	> Uses SQLite, and no external dependencies except Python 3.10+I don't know if it's the way it's been written, but it reads to me that only python is needed, no libraries.I'm assuming this isn't true though: I can see a lot of libraries: https://github.com/tsileo/microblog.pub/blob/v2/pyproject.to...	cetra3	13.632639	-5.6197047	comment	3.0	17.0	1665354170	9.81324
33198315	"Is ""ported"" the right term here? It "	"Is ""ported"" the right term here? It know the repo's README says ""CGo-free port"", but this is the C version of TCL transpiled from C to Go (see the ~13MB .go files per platform in the ""lib"" directory). Which is a very cool idea, and the author has done the same thing with SQLite, to avoid CGo (https://gitlab.com/cznic/sqlite).Here's a link to his C to Go translator: https://gitlab.com/cznic/ccgo"	benhoyt	13.620952	-5.6682343	comment	3.0	15.0	1665707714	9.959114
33199693	This seems to not be entirely reason	This seems to not be entirely reasonable.[edit: apparently the author is a deno employee but did not choose to disclose such? If so then that throws any moral position they have out the window. The below however is still accurate to my reading of the complaints.]First up is the FFI test. On the one hand I think that this is a legitimate complaint, changing an existing benchmark for your comparisons is always suspect. That said I can see technically legitimate reasons for the change - for example if bun's ffi interface doesn't actually handle byte arrays as well as other runtimes. But in such a case that should be explicitly called out as a caveat.The sqlite complaint is not reasonable, if sqlite is being used as a demonstration of wasm performance there is nothing at all wrong with this te	olliej	13.661211	-5.6206627	comment	3.0	10.0	1665722459	9.836576
33206541	Shameless plug of my mvSQLite [1] pr	Shameless plug of my mvSQLite [1] project here! It's basically another distributed SQLite (that is API-compatible with libsqlite3), but with support for everything expected from a proper distributed database: synchronous replication, strictly serializable transactions, + scalable reads and writes w/ multiple concurrent writers.[1] https://github.com/losfair/mvsqlite	losfair	13.547748	-5.466661	comment	3.0	16.0	1665768940	9.748718
33329795	"""This bug is an array-bounds overflo"	"""This bug is an array-bounds overflow. The bug is only accessible when using some of the C-language APIs provided by SQLite. The bug cannot be reached using SQL nor can it be reached by providing SQLite with a corrupt database file. The bug only comes up when very long string inputs (greater than 2 billion bytes in length) are provided as arguments to a few specific C-language interfaces, and even then only under special circumstances.""Source: https://www.sqlite.org/cves.html#status_of_recent_sqlite_cve..."	harryvederci	13.626432	-5.5937304	comment	3.0	17.0	1666702271	9.909591
33330238	> The bug is only accessible when us	> The bug is only accessible when using some of the C-language APIs provided by SQLite.I assume the SQLite CLI (sqlite3) uses these APIs. Could the bug be triggered indirectly by input to sqlite3? The article doesn't appear to address this question.	chmaynard	13.666387	-5.6325693	comment	3.0	12.0	1666704778	9.903456
33331841	SQLite is used in places that Rust h	SQLite is used in places that Rust has no compiler for and that no other language has a compiler for.One severe CVE in about 20 years is no reason to rewrite in another language and remove support for some platforms.	ghoward	13.640592	-5.6722307	comment	3.0	12.0	1666711440	9.824645
33378660	> It has to be downloaded and JIT co	> It has to be downloaded and JIT compiled separately for every site that uses itI don't really see the problem with that. Looking at the sql.js demo[1] the WASM binary is 610K (305K compressed/transferred), and it seems to run pretty fast even on my slow laptop.> Maybe if half the sites on the web start using itMost websites have no reason to use it; simple key/value localStorage is enough for many sites or apps that need some sort of storage. It's kind of a niche thing. Many regular desktop applications have no need SQLite, either.	Beltalowda	13.572202	-5.546751	comment	3.0	12.0	1666995335	-5.243189
33379069	See, that's the insanity: why would 	"See, that's the insanity: why would we need an independent implementation? sqlite has authoritative libraries, that everyone uses, and sqlite3 has been stable for literally over a decade. For all that time, the world could have benefited from ""just bloody expose it"" as opposed to ""but there's no API-equivalent alternative implementations!""."	TheRealPomax	13.590679	-5.5655484	comment	3.0	17.0	1666998072	9.898419
33388919	Is this example too large or about t	Is this example too large or about the right size for you? https://github.com/simonw/sqlite-utils/commit/ab8d4aad0c42f9...	simonw	13.615002	-5.581488	comment	3.0	19.0	1667085360	9.8557825
26581192	I've built a complex CRM that handle	I've built a complex CRM that handles 2.1 million USD in transactions every year. It is running sqlite with a simple in-memory lru cache (just a dict) that gets purged when a mutating query (INSERT, UPDATE or DELETE) is executed. It is very simple and more than fast enough.Friendly reminder that you shouldn't spend time fine tuning your horizontal autoscaler in k8s before making money.	michaelmcmillan	13.528908	-5.4234276	comment	3.0	28.0	1616684928	9.76019
26581414	The article addresses this.  Basical	"The article addresses this.  Basically, you can have any number of concurrent readers, but only a single writer.  Writing and reading can happen concurrently just fine.  So the question is -- how many users does a website need before having only a single concurrent writer becomes a bottleneck?That number will obviously depend on the read/write ratio of any given website; but it's hard to imagine any website where [EDIT the number maximum number of concurrent users] is actually ""1"".  And for many, that will be in the thousands or hundreds of thousands.FWIW the webapp I use to help organize my community's conference has almost 0 cpu utilization with 50 users.  Using sqlite rather than a separate database greatly simplifies administration and deployment."	gwd	13.560353	-5.496779	comment	3.0	17.0	1616685960	9.7477865
26581421	While this makes things easy, you sh	While this makes things easy, you should not do this for any application file format where you except your users to share files. This is because opening a SQLite database file makes the SQLite library execute any arbitrary code that may be stored in that file. [0] Therefore, SQLite is really only suitable for local-only file formats, such as configuration files, and not for files that users will e-mail to each other.[0] https://media.ccc.de/v/36c3-10701-select_code_execution_from...	indigo945	13.578719	-5.5708523	comment	3.0	11.0	1616685989	9.842953
26583128	> then what's the reason people aren	"> then what's the reason people aren't using it for websites?I'd guess the reason to be that people keep hearing things like ""don't use SQLite for websites"" and thus don't even try.> Why do you say it works for ""small"" websites but presumably not large ones?Not the GP, but the main reason I wouldn't use SQLite for a large website is that SQLite itself doesn't offer much re: failover/replication (i.e. multiple servers, one database), and I haven't used RQLite enough (or at all; I should fix that) to be comfortable with it in production.  Because of that, I'm more likely to reach for / recommend PostgreSQL instead.That being said, if your website has crazy ""web scale"" FAANGesque needs and you're at the point where you need to write your own replicated datastore, using SQLite as a base and bu"	yellowapple	13.568578	-5.5040345	comment	3.0	13.0	1616693976	9.802998
26674671	Just SQLite - two tables, one for th	Just SQLite - two tables, one for the nodes, one for edges + some fancy constraints and queries. I was tempted to make a custom binary format, but that's a big task, and it seems to work fine as it is.As for the syncing, that would be really nice, but I haven't come up with an elegant way to do it yet. Suggestions welcome, if anyone has ideas!	climech	13.575526	-5.51758	comment	3.0	15.0	1617389722	9.812601
26685384	One of the things I really like abou	One of the things I really like about SQLite is the fact that it is in the public domain.But most third-party extensions, like this one, aren't. (This extension is MIT licensed.) If you think SQLite being in the public domain is a positive, then that's a positive these extensions lack.(Or a public domain near-equivalent license like Unlicense or CC0, which contains an ultra-permissive copyright license for those jurisdictions which don't allow one to voluntarily put stuff in the public domain.)	skissane	13.626616	-5.579222	comment	3.0	20.0	1617489528	9.911662
26693582	I'm seriously starting to think that	"I'm seriously starting to think that selling UUIDs of virtual things could really take off. I'd call them ""Green Carbon Tokens"" because despite their carbon print being negligible, 50% of the profits would be used for carbon capture.My database would be a text file that anyone could download and verify.Edit: I mean plain UUIDs, so you could create billions with the same carbon used to create a NFT, and the signed text file counts as distributed because anyone can have a copy, I couldn't tamper with it and not be caught."	ASalazarMX	13.98201	-5.212019	comment	3.0	10.0	1617577259	-13.67789
26694560	The percentage of breaches in this d	The percentage of breaches in this database which is “Mongdo DB instance exposed to internet without a password”... yikes. Why on earth is no password the default?	bottled_poe	13.728352	-5.23988	comment	3.0	10.0	1617587606	9.953728
26770324	Sequential is still bad if you don’t	Sequential is still bad if you don’t want to disclose the size of your customer base or other commercially sensitive information.Also see the German Tank Problem[1].1. https://en.m.wikipedia.org/wiki/German_tank_problem	yardstick	13.904574	-5.1879745	comment	3.0	16.0	1618148588	-13.613032
26773909	> Personally, I'm a fan of giving ev	> Personally, I'm a fan of giving everything a random UUID, because it's more flexibleUnless of course, you're using a relational database like OP and incur a performance hit from using a UUID as your primary key. Additionally, they're not sortable like autoinc id's.I've always wanted to try out Twitter's Snowflake ID [1] algorithm to get around this, but it requires requires using something like Zookeeper. I've seen some people on the net talk about UUIDv6 being sortable by time, but there's still the potential performance hit of index size.While I'm bringing this up I've never actually tested how slow PK UUIDv1's are and at what magnitude their performance hit becomes noticeable.[1] https://blog.twitter.com/engineering/en_us/a/2010/announcing...	yukinon	13.977954	-5.215154	comment	3.0	19.0	1618178776	-13.646134
26817129	I wish someone would write a set of 	"I wish someone would write a set of shell scripts that overcome the hardships when dealing with SQLite databases.For example, deleting a column is a pain in the ass.A single purpose script ""rename_column.sh"" would be nice, which combines all necessary steps and gives some guidance regarding edge cases."	TicklishTiger	13.592685	-5.576733	comment	3.0	13.0	1618471314	9.841931
26817386	> I use Gitea(Github clone) locally 	> I use Gitea(Github clone) locally with SQLite running on ZFS where I can take atomic snapshots of both the SQLite database and git repositories.ZFS snapshots may not result in a consistent databases backup of sqlite. You should use VACUUM INTO and then do a snapshot or use the sqlite Backup API.See my other comment: https://www.sqlite.org/backup.htmlEssentially, while you have a proper atomic snapshot of changes on disk the in flight transactions won't be there and you will be on the mercy of having a sucessful recovery from the journal/wal if you have that.	mulander	13.520727	-5.4472704	comment	3.0	18.0	1618473168	9.735559
26817503	So if SQLite is typically run embedd	So if SQLite is typically run embedded in the client application, does this mean it's not supported to have multiple clients operating on the same SQLite DB concurrently, or is there some support for this?	skohan	13.582756	-5.525764	comment	3.0	13.0	1618474252	9.806305
26817876	We've been using SQLite as our princ	We've been using SQLite as our principal data store for 6 years. Our application services potentially hundreds of simultaneous users at once, each pushing 1-15 megabytes of business state to/from disk 1-2 times per second.We have not had a single incident involving performance or data integrity issues throughout this time. The trick to this success is as follows:- Use a single SqliteConnection instance per physical database file and share it responsibly within your application. I have seen some incorrect comments in this thread already regarding the best way to extract performance from SQLite using multiple connections. SQLite (by default for most distributions) is built with serialized mode enabled, so it would be very counterproductive to throw a Parallel.ForEach against one of these.- U	bob1029	13.549247	-5.504604	comment	3.0	19.0	1618476848	9.817728
37595838	How is (a) wrong? Pg doesn't horizon	How is (a) wrong? Pg doesn't horizontally scale like Mongo does	seedless-sensat	13.530356	-5.238406	comment	3.0	21.0	1695293430	9.751008
37595854	At least in my experience it is all 	At least in my experience it is all still the case today.If you are dealing exclusively with documents I find MongoDB to be faster, better and easier to use. If my data model is hybrid or purely relational then I would use PostgreSQL.After all these years I am still waiting for an horizontal scalability solution for PostgreSQL that is up to the level of a modern database. It's 2023 and for many of us in enterprise environments it's a mandatory NFR.But it seems like you're not interested in a having an actual technical discussion.	threeseed	13.603723	-5.3525615	comment	3.0	13.0	1695293590	9.857476
37595936	Because just about no one cares and 	Because just about no one cares and I want to burn down a backlog quickly and often mongo enables that. Developer productivity is far more valuable that open source purity.	nemo44x	13.66017	-5.274739	comment	3.0	12.0	1695294379	9.830154
37614347	Author here. Cool to see the post ma	Author here. Cool to see the post make it up on HN again. I'm still as excited as ever about the SQLite space. So much great work going on from rqlite, cr-sqlite, & Turso, and we're still plugging away on LiteFS. I'm happy to answer any questions about the post.	benbjohnson	13.621477	-5.579109	comment	3.0	13.0	1695401316	9.835131
37614644	I recently wrote a production system	I recently wrote a production system that uses SQLite as the main backend.  SQLite is in memory in this case and its entire state gets rebuilt from Kafka on start.  The DB receives about 2 updates a second, wrapped with rest api aiohttp and odata filters.  It has been able to handle close to 9k requests/second ands it’s a primary system in a financial institution.  So yes SQLite is fully capable prod db.	meitham	13.58263	-5.5178046	comment	3.0	12.0	1695402568	9.793949
37614666	What separate DB server? I was talki	What separate DB server? I was talking about installing the RDBMS on localhost, right inside the server where your application runs. No other EC2 instance, no extra charges. Preferably connect to it over a Unix domain socket instead of TCP. That's the only way to compare SQLite performance with an RDBMS in an apples-to-apples way.The point about operational overhead makes sense, though, and IMO it's the only point in this unnecessarily long article that's actually worth considering. I do have a couple of other apps running on SQLite, so I appreciate the simplicity.	kijin	13.5342245	-5.4722743	comment	3.0	10.0	1695402655	9.795535
37614742	I’m bullish on SQLite, and this is m	I’m bullish on SQLite, and this is mostly a great article, but this kind of stuff is flat-out misleading:> When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds.As if postgres and others don’t have a way to run application logic at the database. I like the SQLite way of doing it — you pretty much freely choose your own host language — anything with a decent SQLite client will work. While in postgres, for example, you’ll probably end up with pgplsql (there are others, but there are constraints). So this isn’t about latency, as the whole section of the article suggests.There’s actually a relative weakness in SQLite here, since it doesn’t include a built-in protocol to support running application logic separate from the database. That’	jmull	13.561312	-5.489959	comment	3.0	34.0	1695403035	9.791325
37615063	Any self respecting e-commerce site 	Any self respecting e-commerce site would want fault tolerance and strong consistency even with potential network partitions, so definitely not SQLite as described in article	endisneigh	13.582697	-5.5135746	comment	3.0	30.0	1695404332	9.804049
37678497	I dug into the internals of the loca	"I dug into the internals of the local, SQLite version of this just now and wrote up some notes here: https://til.simonwillison.net/deno/deno-kv#user-content-deno...The most interesting detail is probably the schema they're using for that:    CREATE TABLE queue (
      ts integer not null,
      id text not null,
      data blob not null,
      backoff_schedule text not null,
      keys_if_undelivered blob not null,
      primary key (ts, id)
    );
    CREATE TABLE queue_running(
      deadline integer not null,
      id text not null,
      data blob not null,
      backoff_schedule text not null,
      keys_if_undelivered blob not null,
      primary key (deadline, id)
    );
    CREATE INDEX kv_expiration_ms_idx on kv (expiration_ms);"	simonw	13.533118	-5.5309615	comment	3.0	18.0	1695837427	-11.0869255
37712135	I use ULID  a lot too and It’s frust	I use ULID  a lot too and It’s frustrating how close the new spec UUIDs are to it without actually being the same… so I’ve got a bunch of code to modify once Postgres supports generation of the new UUIDs server side without extensions or stored procedures. Relatively painless work, but frustrating since it could have been avoided.	techdragon	13.967348	-5.22298	comment	3.0	11.0	1696038518	-13.662242
37733558	What are the benefits of using the P	What are the benefits of using the Postgres uuid type (versus using TEXT or VARCHAR)?	perfmode	13.99603	-5.2189426	comment	3.0	12.0	1696216591	-13.651495
37733802	It seems insane to me to “validate” 	It seems insane to me to “validate” GUIDs/UUIDs.Half the point of these things is that they’re treated as opaque identifiers.	jiggawatts	13.973661	-5.2039237	comment	3.0	16.0	1696218930	-13.66229
37734485	Is there a way to encrypt 122 bits -	Is there a way to encrypt 122 bits -> 122 bits? If so – do that and set version to 4.Alternatively, just say it's a random string ID and not an UUID.	notpushkin	13.98482	-5.2098646	comment	3.0	15.0	1696226472	-13.694979
37734682	Similar to the old situation in the 	Similar to the old situation in the article, we are using sequential 64 bit primary keys, but we use an additional random 64 bit key for external usage (instead of 128 bit).The external key is base64 encoded for use in URLs which results in an 11 byte string.This hides any information about the size of the data, the creation date of customer accounts (which would be sort of visible with UUIDv7) and prevents anyone from attempting to enumerate data by changing the integer in URLs.I thought about using UUIDs as external keys but the only compelling use case seems to be the ability to generate keys from many decoupled sources that have to be merged later.64 bit should be enough for most things https://youtu.be/gocwRvLhDf8?si=QBheJCG21bAAV0Z7	dajonker	13.9660845	-5.217564	comment	3.0	11.0	1696228717	-13.658293
37733316	And you can use it today with Postgr	And you can use it today with Postgres uuid type. Postgres doesn’t care what you store in it as long as it has the correct length. So you can generate a uuidv7 and store it natively	pyrolistical	13.982834	-5.218905	comment	3.0	17.0	1696214026	-13.6847
37733648	UUIDs are 128-bits, not characters. 	UUIDs are 128-bits, not characters. The string representation is just for humans.	chewbacha	13.977433	-5.214547	comment	3.0	11.0	1696217372	-13.65611
37734980	Why not just use the AES-128 result 	Why not just use the AES-128 result as the UUID then? What's the benefit of the internal structure at all?If AES-128 is an acceptable external UUID (and likely an acceptable internal one), then you might as well just stick with a faster RNG.	dragontamer	13.986458	-5.212239	comment	3.0	20.0	1696232155	-13.70756
37735247	Reading their docs: No real benefits	"Reading their docs: No real benefits, just misconceptions.1. Collision resistance / ""weak"" PRGNs used to generate UUIDv4. Firstly, these are properties of the implementation, not the spec. Secondly, the source for calling the browser `Crypto.getRandomValues()` insecure is an issue that has been fixed back in 2016. I would not trust the developers of this implementation to do a better job than current browsers.2. ""Not URL or name friendly"": Fair, but not very strong argument.3. ""Horizontally scalable"" and ""offline-capable"": No argument given for why UUIDv4 does not meet these requirements, apart from point 1 above.4. ""Too fast"": No argument given for why having a slower algorithm to generate random ids is more secure. Both UUIDv4 and Cuid2 use a similar number of random bits (122-124). When"	matharmin	13.989937	-5.2142787	comment	3.0	10.0	1696234301	-13.668467
37737760	Unless you have specific needs, the 	Unless you have specific needs, the only type of UUID you should care about is v4.v1: mac address + time + randomv4: completely randomv5: input + seed (consistent, derived from input)v7: time + random (distributed sortable ids)	ricardobeat	13.986483	-5.2104015	comment	3.0	20.0	1696253129	-13.6744585
37738098	As someone who only cares about v4, 	As someone who only cares about v4, I periodically wonder why don't I just use fully random 128-bit identifiers instead (without the version information).	kozak	13.98192	-5.2040353	comment	3.0	16.0	1696254698	-13.697306
37769900	Why not use UUIDs?People never enter	Why not use UUIDs?People never enter ISBNs manually, anyways. So it might as well be longer string. Or a QR code.	amelius	13.980602	-5.207952	comment	3.0	14.0	1696445687	-13.659123
37819200	People needing to query huge amounts	People needing to query huge amounts of data discovering technology that's been developed over the past 45 years for querying huge amounts of data efficiently; news at 11.Seems all these shops starting out with MongoDB or the like always need to do a huge, complicated migration to a /proper/ optimized data store, when they could have started with a sane design in the first place...	porbelm	13.556988	-5.3076653	comment	3.0	10.0	1696850605	9.855596
37918251	If you care about compressability, y	If you care about compressability, you can simply use a different way of generating UUIDs, instead of switching to another type. For example initializing a 128-bit counter when starting the process and incrementing it for each number generated. This should compress almost as well as sequential integers, while still being collision resistant without coordination or persistent state.	CodesInChaos	13.974036	-5.219214	comment	3.0	16.0	1697562850	-13.646688
37919687	> how expensive UUIDs areI don't qui	> how expensive UUIDs areI don't quite get it. The normal string encoding of a UUID (d92b13b6-6780-4b98-82cc-d469dcdd42ab) clearly requires more bytes (36B) than the actual UUID itself (16B). The string encoding is for showing to users, it's not what you store in your DB, or your CRDT -- for that, you use the actual 16-byte value.>  Not only will your UUIDs take up 2x the space of a 64bit integer, they'll compress horribly by comparison. Integer compression is so good these days you can compress integers such that they basically end up taking up ~1/2 a byte instead of 8. Doing that with UUID v4s is fundamentally not going to work.Yes, UUIDs are 128 bits, and 64 bit integers are 64 bits, but in both cases you're storing them as raw bytes -- or, maybe, integers, sure. Whatever compression wo	kiitos	13.97587	-5.215559	comment	3.0	13.0	1697568287	-13.672709
14712495	Any criticism of MongoDB that does n	Any criticism of MongoDB that does not acknowledge WiredTiger and the plethora of positive changes that made MongoDB much, much better in the 3.0, 3.2 and 3.4 releases is criticism that is not fully thought out.It's like complaining getting graphic cards working because of drivers is difficult on Ubuntu, based on experience with linux in 2005.	diziet	13.704167	-5.290614	comment	3.0	10.0	1499364726	9.921488
14712769	I think Enterprise folks do not appr	I think Enterprise folks do not appreciate the flexibility afforded by NoSQL .  For my startup I started off on PostGres SQL with Hibernate and it worked great ... until we first met our paying customers. They needed data elements that I had not envisioned and so we ended up doing Schema updates.. again and again .  Since we used ORM (hibernate), that also meant new hibernate code generation .  After a while this became very tedious.I have a background in enterprise s/w development; we always lock down on most of our requirements before we start writing code. RDBMS is fantastic in this scenarios. In my startup, we build something light and show it to bunch of prospects and iterate. MongoDB fits this mode of s/w development for us. Sure there are gotchas and other issues  but they have not 	manishsharan	13.551637	-5.4052825	comment	3.0	10.0	1499366407	9.805035
14723131	When I started building my first app	When I started building my first app in 2011 MongoDB was the rage. So I build the back-end using the futuristic 'No-SQL' technology. It turned out to be slow (~1 min Query time), inconsistent, and missing an RDBMS layer. Move the thing to PHP/Mysql problems were gone. I still have not found a use case outside of web (comments/discussion) sites where the high integration with Javascript actually makes sense.	jsemrau	13.632744	-5.3955207	comment	3.0	20.0	1499470915	9.860089
14788687	I've really gotta get on testing thi	I've really gotta get on testing this with my product.  It has a bunch of features i'm really looking forward to (gist index support for enums and uuids are the main ones for me).This is a huge release.  Been following the development for years on the mailing list, it's always interesting seeing how it plays out and the features come to life.  It's one of the best collaborations i've seen.	Tostino	13.978071	-5.208716	comment	3.0	10.0	1500301179	-13.656131
14804765	(I’m the author of this series)Eliot	(I’m the author of this series)Eliot Horowitz (HN: @ehwizard), MongoDB’s current and founding CTO, reached out after my last post - and spent two hours providing feedback last week in Palo Alto. It was an expansive discussion, and Eliot was reflective and eager to understand the perspectives I had heard. He noted how much it mattered to him what HN thought.I left with tremendous empathy for the challenges of building a venture-backed database company - while we also disagreed in a few key areas. As engineers, I hope we continue to have thoughtful, if spirited discussions, like Eliot and I had - where we both are open to being wrong and have a desire to understand differing viewpoints.In the interest of length, I didn’t write the whole interview into my series, but wanted to share key parts	nemild	13.662863	-5.2964106	comment	3.0	10.0	1500476474	1.676113
14805586	> Some databases might be easier to 	> Some databases might be easier to understand than others, but I feel MongoDB is on the 'easier' end here. YMMV.I agree with most of this, relational databases have a lot of moving parts that many developers (myself included) don't fully understand.However, I believe relational databases (Postgres is what I have experience with) has defaults that are basically correct, and unlikely to cause significant issues, whereas in my experience MongoDB did not have this. MongoDB might be easier to understand on the surface, but I think that's deceptive.	danpalmer	13.645255	-5.3479238	comment	3.0	10.0	1500482377	9.858233
14805812	You definitely can but MongoDB provi	You definitely can but MongoDB provides convenience over storing and managing JSON files on you filesystem by your own efforts.	mrtksn	13.628657	-5.377688	comment	3.0	16.0	1500483823	9.826699
14805599	I feel the best thing to come out of	I feel the best thing to come out of MongoDB is that Postgres now handles JSON.	pryelluw	13.596596	-5.3984346	comment	3.0	14.0	1500482470	9.842163
14812658	I wonder if they improved Cluster se	I wonder if they improved Cluster setup with this release. If you tried without DC/OS, it was painful experience. Arangodb Starter was definitely a step in right direction.	princetman	13.649298	-5.267412	comment	3.0	12.0	1500560462	9.958568
14950404	I was looking really hard at using C	I was looking really hard at using CouchDB 2.0 for an offline-first progressive web app.  The biggest asset in my opinion of CouchDB is actually PouchDB [1]  PouchDB is really great and nicely designed.However, the showstopper that I hit was that CouchDB still does not support permissions on a per-user basis (even though PouchDB encourages this explicitly [2])What this means is that if you have a typical system with users and logins, who can only access their own data, and you require some sort of aggregated view where you can view all users data behind some sort of permissions (admin user, etc), you are forced to create a new db for each user in Couch, and then run replication for those users to a separate master.Think for example if you wanted to store images in CouchDB, and then have so	tarr11	13.593726	-5.2013774	comment	3.0	12.0	1502133759	9.673029
14973439	CockroachDB does many thing really w	CockroachDB does many thing really well but please for the love social acceptance please change the name.	knodi	13.720655	-5.1893187	comment	3.0	14.0	1502311713	-4.549011
15020401	"Or there is middle ground""Allow easy"	"Or there is middle ground""Allow easy access with no password or username, but only from localhost""Not foolproof, but as far as I know both this and mongo did the ""bind to all ports AND allow access with no password"". It was the combo that really killed it."	brianwawok	13.73201	-5.2499638	comment	3.0	10.0	1502818578	9.9567
15025106	>their market just isnt big enoughth	>their market just isnt big enoughthe database market is one of the biggest software markets out there, if not the biggest.>their losing a lot of steam as of lateat least according ot google trends, mongodb is more popular than ever.>last effort cash out sort of deal to methey're hiring like crazy and looking to grow a ton in the next year, so I don't think that's the case.	patrickfreed	13.659305	-5.3090262	comment	3.0	11.0	1502860652	9.915369
12544187	CouchDB is eventually consistent and	CouchDB is eventually consistent and does not guarantee consistency. Would a Jepsen test make sense?	robinson_k	13.621882	-5.21643	comment	3.0	10.0	1474413593	9.629685
12543892	Sad to not see Jepsen tests ran on t	Sad to not see Jepsen tests ran on this at least by the developers when releasing a new clustering piece.The folks working on cockroachdb recently did this[1] and it was a good read.[1] https://www.cockroachlabs.com/blog/diy-jepsen-testing-cockro...	SEJeff	13.618707	-5.2042785	comment	3.0	17.0	1474410191	9.86849
12578723	> Do people agree with this?I don't.	> Do people agree with this?I don't. I've corrupted SQLite DBs enough to not have warm and fuzzy feelings about it like I used to have.I think it's only a good choice when you just need a database for your app that will barely be using it, and if you didn't use it you'd be writing to a file instead. And, that's basically what the SQLite docs say.However, even then, I think it can be short-sighted. I've used webapps before that used SQLite and I thought to myself: if they'd only used MySQL or PostgreSQL and then provided access to it, I could have used it.Be aware though, if you decide to use a scalable DB like PostgreSQL, it will require a port to be open for the DB, even if only locally. If you're trying to minimize how people can access your data, you don't want a port open/an extra port	watermoose	13.56899	-5.5219855	comment	3.0	13.0	1474855269	9.822729
12584030	DBHub.io: SQLite database storage “i	DBHub.io: SQLite database storage “in the cloud”	justinclift	13.534585	-5.4318857	story	3.0	16.0	1474912593	9.791812
12590042	I work on PouchDB, in terms of those	"I work on PouchDB, in terms of those points:""great client-side performance"": PouchDB is more than fast enough for most use cases, its just a wrapper over indexedDB. (there are areas we can improve, particularly performance of map reduce / mango queries).""native models that are extremely easy to use"": Not sure what that means, PouchDB and CouchDB use json, its native and easy to use in JavaScript""conflict-free sync (not conflict resolution!)"": Certainly going to have to take a look at this, any conflict free sync protocol I have seen put a lot of limitations on how data within your application is structured but conflict resolution certainly is something that can be improved within Pouch / Couch.I do think there is a bunch we can (and are) improving in PouchDB and its great to see alternativ"	daleharvey	13.531214	-5.216578	comment	3.0	13.0	1474988231	9.666845
12644717	The deal-breaker for me with couchba	The deal-breaker for me with couchbase is that the community edition lags (in terms of bug fixes, security updates, etc) 8-10 months behind their commercially licensed offering.	tepidandroid	13.6211815	-5.205262	comment	3.0	11.0	1475681665	9.665549
12649464	A shame that a company like mongo ca	A shame that a company like mongo can exist while a company like rethink folds.	joneholland	13.708307	-5.2817383	comment	3.0	48.0	1475717603	9.9075
12649483	MongoDB is like the Microsoft of ope	MongoDB is like the Microsoft of operating systems.  Well promoted and easy to get going with.  Hopefully they use the money they have to rewrite MongoDB to be better.	bhouston	13.684665	-5.30005	comment	3.0	32.0	1475717806	9.907369
12649543	Because having the better product (o	Because having the better product (often) doesn't matter:  see Windows vs Apple in the early days.Mongo has a strong community, which translates into a plethora of articles/blog-posts/tutorials/etc that secures its niche.  From there it's possible to make money with things like consulting fees to help fix the problems it created in the first place.It's all about execution.  Case and point:  I know what (purportedly) makes MongoDB special.  I have no idea what RethinkDB is supposed to do, other than store data.  Yes, I could check their site, but the point is I'm already familiar with Mongo's reputation.  All of this contributes to a lesser product winning over a better one.	omginternets	13.705916	-5.296216	comment	3.0	15.0	1475718285	9.891333
12649812	"Not sales. Marketing.
In today's wor"	"Not sales. Marketing.
In today's world having someone push a new database for a hefty price is not going to work. I would need to be able to test it against mongo and decide myself that it is better... but how would I know it's even an option?"	ronreiter	13.662418	-5.3199573	comment	3.0	16.0	1475721638	9.888833
12649851	> Postgres is a tough database to co	> Postgres is a tough database to contend with and it's mature and open source.Presumably, that's in part why CockroachDB decided to be more-or-less Postgres-compatible on the wire, and embraced SQL.	erichocean	13.572532	-5.2911973	comment	3.0	11.0	1475722089	9.78964
12649476	I hope this isn't true. Having worke	I hope this isn't true. Having worked at/on multiple competitors I have nothing but respect and admiration for the work the RethinkDB team has done to make a great database and development platform.This was real technology! I'm truly sad that the environment is such that great work like this can't continue to be funded.Thanks for showing everyone how to write amazing documentation, caring about the fundamentals, and for the incrediblly snazzy admin panel.	tbrock	13.657641	-5.2837543	comment	3.0	37.0	1475717718	-12.825497
12656419	I have to agree here a bit.  However	"I have to agree here a bit.  However, there was nothing stoping Rethink from building their own service and promoting it as the ""official"" RethinkDB service.  They have the unique opportunity of making it better than any other service by:-Updating the service the day new versions go GA-Faster turn around on breaking changes-Ability to provide authentic expert support-Ability to provide additional functionality power users would pay for and 3rd parties like compose would not implementThey wouldn't capture the entire market but they could be the leader in it.The open source business model is hard enough.  It becomes very difficult when every other Cloud simply wants to offer your product and you capture none of that.  And then the project dies and no one wins.Open source companies need to be"	nemo44x	13.613057	-5.1974473	comment	3.0	17.0	1475790597	-12.724024
12664015	RethinkDB's niche is allowing a serv	"RethinkDB's niche is allowing a service to listen for changes to a dataset. As in, your Node application could listen for published events by Rethink, rather than your Node application long-polling the dataset for changes. ""Real Time"" data analytics can then be performed."	alexbanks	13.595025	-5.3085756	comment	3.0	30.0	1475875437	-12.803992
12724430	I was surprised to hear that Rethink	I was surprised to hear that RethinkDB was shutting down, since everyone that used it seemed to like it.I looked into their business model a bit more... and it was like, super difficult to figure out how to actually pay them for anything. Seems like having a push-button managed DB option on AWS/Google Cloud/Generic would've been awesome for them? The company just didn't seem like it was set up to make money even though people liked the product.I know, hindsight and everything... but without going to a page linked from a random github issue that I found via Google I couldn't even find a page talking about pricing. To build a business you have to not only make something people love... you also have to let them pay you for it.	mej10	13.66019	-5.250434	comment	3.0	31.0	1476707493	-12.806292
12733425	NoSQL Data Modeling Techniques	NoSQL Data Modeling Techniques	victorbojica	13.529431	-5.344094	story	3.0	157.0	1476789329	9.85717
12740834	"Thanks for asking!Re: ""SQLite can be"	"Thanks for asking!Re: ""SQLite can be beat really easily by the client/server systems since each SQLite instance only supports one concurrent writer"" -- That's not actually true, sqlite supports concurrent writers via their page-locking branch (and changesets allow for effectively row-level locks).  But none of that matters, because single-threaded replication means any multi-threaded write capability is irrelevant.  Regardless, when we add multi-threaded replication (on the way), we'll take advantage of SQLite's multi-thread write capabilities.Re: MySQL's replication.  What specifically are you referring to?  It's distributed transaction features are actually quite new -- and I think were developed after Bedrock was already in production for years.  Furthermore, MySQL doesn't support autom"	quinthar	13.562602	-5.4841447	comment	3.0	15.0	1476847687	9.770472
27512631	You can still mandate a spec, and if	You can still mandate a spec, and if everybody ends up picking SQLite to implement it, so what?	int_19h	13.617719	-5.576913	comment	3.0	15.0	1623745345	9.8312
27542962	So... what is wrong with them? I've 	So... what is wrong with them? I've only had very good experience with ArangoDB.	dkarras	13.670195	-5.2589393	comment	3.0	12.0	1623955257	9.93543
27551641	Codd was pretty adamant in his origi	Codd was pretty adamant in his original papers that keys should be made up from data rather than a unique integer, and his example of converting from a hierarchical database schemas to a relational database schema shows how compound, natural keys are important to represent relationships. But we don’t usually do it that way today, partly because it isn’t that practical with our current databases and ORMs. It has some theoretical advantages and disadvantages, but using IDs seems to work well enough that we’re not investing in a new paradigm.	dnlhg	13.638162	-5.441747	comment	3.0	11.0	1624031534	-13.628073
27565587	This post is about a new feature in 	This post is about a new feature in my sqlite-utils tool, which is a combination CLI utility and Python library for productively working with SQLite database files: https://sqlite-utils.datasette.io/en/latest/changelog.html#v...	simonw	13.600263	-5.583103	comment	3.0	14.0	1624145988	9.840653
27568537	We use SQLite in-memory databases fo	We use SQLite in-memory databases for executing 100% of our business logic these days.  Letting the business write all the rules in SQL is the biggest win of my career so far.Also, if you think SQLite might be too constrained for your business case, you can expose any arbitrary application function to it. E.g.:https://docs.microsoft.com/en-us/dotnet/standard/data/sqlite...The very first thing we did was pipe DateTime into SQLite as a UDF. Imagine instantly having the full power of .NET6 available from inside SQLite.Note that these functions do NOT necessarily have to avoid side effects either. You can use a procedural DSL via SELECT statements that invokes any arbitrary business method with whatever parameters from the domain data.The process is so simple I am actually disappointed that we	bob1029	13.568005	-5.560941	comment	3.0	16.0	1624182160	9.842656
27590826	Show HN: Convert data exports from v	Show HN: Convert data exports from various services to a single SQLite database	sevazhidkov	13.560926	-5.550218	story	3.0	7.0	1624365061	9.839686
27670540	I don't know why this is being downv	"I don't know why this is being downvoted.  Multiple overlapping layers of security would have given newsblur a backup in case of accidental ""footguns"".Unauthenticated mongodb instances are a pretty common problem - it's why a 
""script kiddie"" was so successful."	mdellavo	13.697025	-5.2911716	comment	3.0	14.0	1624929654	9.9128065
27671593	There was no perimeter security here	There was no perimeter security here. The attacker did not first enter a private network and then pivot to MongoDB; he dialed MongoDB right from the internet. Had Mongo been un-authenticated on a private network it still might have been owned, but the bar would have been a lot higher.Side note: everything that’s ever existed is “flawed,” it’s a weird word to use in the context of something you want to discredit, because then your alternative had better be “flawless” and it obviously isn’t.	closeparen	13.721102	-5.2302017	comment	3.0	10.0	1624939023	9.958401
27673759	I see everyone discussing how much D	I see everyone discussing how much Docker is at fault, how much Mongo DB is at fault, how much NewsBlur should have had better settings, and I do agree to some extent.However, the much worse problem seems to be the fact that NewsBlur didn't test their network connectivity with something as basic as a port scan. This wasn't some complex attack based on some complex code injection jumping through legitimate ports or anything: their machine had the Mongo port open when they thought it should be closed. This is the kind of thing that absolutely shouldn't make it past basic testing.	simiones	13.707216	-5.2876754	comment	3.0	11.0	1624959929	9.930346
27675019	I used WordPress as my datastore for	I used WordPress as my datastore for a while on personal projects. I could wrestle it mostly into shape and use the built-in rest api. WP is my day job so I know it well and like it, but I'm not a backender, so it was a bit clunky and time consuming to get things the way I wanted.Then I needed to host that WP instance somewhere. That was also a pain.I decided last year to try and use Node/Express/Mongo for my backend instead and stay fully in JS land.  But now I need to host a Mongo db. Instead of that, I tried Atlas for hosted mongo, but ....it feels like it's from corporate America circa 2004.Then came Supabase.I randomly came across it, gave it a try, and it's heaven. It's absolutely dead simple to get working (for my simple needs). It can work as a regular DB or as a realtime thing lik	saltcod	13.64855	-5.310856	comment	3.0	12.0	1624970680	9.871352
27719332	I’d love it if Dr Hipp created a cli	I’d love it if Dr Hipp created a client/server db. He could call it SQLMajor instead of SQLite :)	alberth	13.61224	-5.5829363	comment	3.0	16.0	1625286197	-4.485831
27719545	Couple things:* immutable* built in 	"Couple things:* immutable* built in first-class ticketing systemHappens to use SQLite as its storage engine too (SQLInception?), which brings at least a couple (off the top of my head) features:* SQL is used to query things, which is very powerful* the repository is a single SQLite file. Easy to store, copy, and…* one can checkout multiple working copies into various directories.
Or, in other words, I can have three discrete, independent workflows happening simultaneously, but only one copy of the repository backing them all.It’s also got a built-in server that you can use locally or publish for remote people to access via their web browser that’s essentially GitHub-in-a-box.Also… (kidding. I’m just going to stop here).Edit: formatting"	bch	13.555552	-5.4989176	comment	3.0	14.0	1625289599	-11.802646
27721629	I run a self hosted notes applicatio	I run a self hosted notes application[1] on raspberry pi at home. I have been thinking about moving from .md files to sql. Both seem to have their own pros/cons. With SQLLite, I get easy search, tagging while with .md files I get easy editing and viewing by mapping networked drive.[1]: https://github.com/quaintdev/pinotes	quaintdev	13.590868	-5.578132	comment	3.0	13.0	1625320384	9.818108
27721883	I enjoyed this episode. I knew about	"I enjoyed this episode. I knew about all the tests before, but what came clear in this interview is that Sqlite inc is using their tests as a unique way to keep contracts on Sqlite development flowing. Since they can test it so much better than anyone else, it would be crazy not to hire them, rather than hiring someone else to develop a patch.While they're keeping those tests proprietary, and relatedly have a closed development model, this strikes me as still better than typical open core strategies for monetizing free software, or at least pointing in better directions.Agbell, since you're here, could I ask you add a standard link to the RSS feed for your podcast?<link rel=""alternate"" title=""Corecursive"" type=""application/rss+xml"" href=""https://link.chtbl.com/corecursive?platform=rss"" />"	joeyh	13.63846	-5.602572	comment	3.0	10.0	1625323151	8.094242
27731966	Writing a SQLite clone from scratch 	Writing a SQLite clone from scratch in C (2017)	rubyn00bie	13.620149	-5.6013856	story	3.0	210.0	1625426567	9.884825
35210345	SQLite is great for datasets that fi	SQLite is great for datasets that fit comfortably into memory, but otherwise it starts to struggle.	philwelch	13.571885	-5.5012712	comment	3.0	14.0	1679156436	9.8237705
35238570	> Building a model of the SQL type s	> Building a model of the SQL type system within the Rust type system is very impressive work. It also leads to really annoying problems, because the Diesel types are so complex.Oh man have I felt this pain, trying to do anything mildly complex with Diesel's types is so ridiculously difficult. I once (foolishly) tried to write a generic repository implementation for database entities which could either have sqlite or postgres as a backend. I thought this would be very convenient for testing, being able to just keep all of the code the same safe for using a sqlite backed repository instead of a Postgres one.I gave up after about ~10 hours of battling incomprehensible error messages.	Pepe1vo	13.534587	-5.720515	comment	3.0	14.0	1679345842	9.768742
35247799	rqlite[1] creator here. This offerin	rqlite[1] creator here. This offering is completely new to me. Welcome to the party, that's what I say. I started doing what they are doing about 10 years ago. :-)https://www.philipotoole.com/9-years-of-open-source-database...https://www.philipotoole.com/replicating-sqlite-using-raft-c...https://www.philipotoole.com/rqlite-v3-0-1-globally-replicat...The post makes a fairly big point of the shortcomings of statement-based replication (like what rqlite does).What they state is correct -- non-deterministic SQL will be a problem, but it's not a difficult problem to solve. Just parse and rewrite the SQL statement before sending it to Raft. It's exactly what rqlite does[2] (though there is more to do). However they claim that there are	otoolep	13.521816	-5.4501433	comment	3.0	14.0	1679413314	9.728968
35361312	Why would anyone use this as opposed	Why would anyone use this as opposed to using Postgres? The value prop of run-anywhere applies to Postgres as well. I see column store and index advisor as the two features but if I don't need these, is there any reason?	TheTaO	13.534003	-5.3792114	comment	3.0	13.0	1680114854	9.791377
35382037	This looks great! I will give it a s	This looks great! I will give it a spin> e.g. transactions don't work on a single nodeany Mongo has this restriction	avinassh	13.695767	-5.3313804	comment	3.0	10.0	1680232452	9.905619
35415383	The schema:    CREATE TABLE IF NOT E	"The schema:    CREATE TABLE IF NOT EXISTS users (
        id BLOB PRIMARY KEY NOT NULL,
        created_at TEXT NOT NULL,
        username TEXT NOT NULL
    );


The data:    let user = User {
        id: uuid::Uuid::new_v4(),
        created_at: chrono::Utc::now(),
        username: String::from(""Hello""),
    };


If you can't insert 15,000 of these records per second then there's something wrong with your database.  I'm aware that people are all on the SQLite hype train, but this kind of stuff is table-stakes.I really like SQLite.  But this blog isn't any kind of great performance indicator for it."	VWWHFSfQ	13.594352	-5.5558295	comment	3.0	15.0	1680470642	9.786599
35454460	An up-to-date list of SQLite related	An up-to-date list of SQLite related news from all over the World	marcobambini	13.604968	-5.5818005	story	3.0	3.0	1680703574	-11.040956
35490178	What’s the point of something like t	What’s the point of something like this instead of just using SQLite? Seriously, “foo but in bar!” is not exactly the sort of thing that solves real problems for most people.	eschaton	13.621106	-5.5808315	comment	3.0	13.0	1680923939	9.858922
22367850	Is it simple, though? I mean, readin	Is it simple, though? I mean, reading about how they test it[1] leads me to believe it is not simple. Maybe it's simple compared to Oracle, and maybe using it is simple, but the actual implementation is definitely not simple.[1] https://www.sqlite.org/testing.html	umvi	13.6226425	-5.608504	comment	3.0	22.0	1582133957	9.866488
22368542	We used SQLite at my company to allo	We used SQLite at my company to allow users to write SQL queries against their db. When we hit the limit of it, we had to switch to Postgres. That migration is quite difficult and I wish we had used Postgres from the start. 20/20 hindsight but that was my first thought.	joshdance	13.540737	-5.4643555	comment	3.0	20.0	1582137472	9.8052025
22412999	> But other cases (CockroachDB is on	> But other cases (CockroachDB is one) I think people go overboard with getting offended at names.But with this name there is a 0.1% chance in any enterprise setting that managers would accept usage of such a DB. At least as long as it's not as mainstream as maybe Redis or MongoDB. (If something is popular enough, the name is to be accepted)	blablabla123	13.612853	-5.2272	comment	3.0	11.0	1582637393	-4.601724
22414543	Interesting. I'm familiar with the m	"Interesting. I'm familiar with the meta as it relates to gaming (I follow SC2 pretty closely, though I basically never play anymore). I am curious to explore what the meta is as it relates to building web apps, or building software systems.
I guess in web apps, the meta has evolved away from stateful and towards stateless applications, rigid to ephemeral infrastructure, and away from big kitchen sink frameworks towards smaller tools built for specific purposes (here I'm thinking like netlify, react-cli / vue-cli, serverless and aws lambda compatible frameworks and languages). In database land, I think there's a bit of reversal towards a happy medium between Relational and No SQL with the whole NewSQL trend (though I think most people just end up using whatever they're comfortable with).I t"	mangoman	13.555807	-5.4214497	comment	3.0	15.0	1582648484	9.856921
22426431	CouchDB is awesome, full stop.While 	"CouchDB is awesome, full stop.While it's missing some popularity from MongoDB and having wide adoption of things like mongoose in lots of open source CMS-type projects, it wins for the (i believe) unique take on map / reduce and writing custom javascript view functions that run on every document, letting you really customize the way you can query slice and access parts of your data...Example: I'm building a document analysis app that does topic + keyword frequency vectorization of a corpus of documents, only a few thousand for now.I end up with a bunch of documents that have ""text"": ""here is my document text..."" and ""vector"": [ array of floating point values ...].What I can do with couchdb is store that 20d vector and emit integers of it as a query key:    var intVectors = doc.vector.map(f"	splatcollision	13.607673	-5.251484	comment	3.0	26.0	1582745764	9.762266
22440889	It's weird to me that we haven't set	It's weird to me that we haven't settled on a common, stable, purpose-built high-level language specifically for business logic. Stuff that doesn't change much, that doesn't need to concern itself with the platform, only the business. That code should be portable to whatever shiny new underlying system gets invented; why does it keep having to be re-expressed every few years?The situation is much better (though still far from ideal) when it comes to data. Everything knows how to use CSVs. Relational databases, from a schematic perspective, really haven't changed terribly much in decades. NoSQL came around but that was really just an alternative option; you don't see everyone scrambling to migrate their SQL data to Mongo. SQL isn't quite a standard, but it would be dramatically easier to mi	_bxg1	13.571882	-5.407522	comment	3.0	11.0	1582870719	9.897429
22502939	Great example of how to introduce a 	Great example of how to introduce a sql/mongo query injection in your code.The string interpolation in findById will open up your whole database to the world, possibly even allowing remote command execution.Same for the other functions that access MongoDB.Do not copy / paste random code until you fully understand it.	st3fan	13.667922	-5.357223	comment	3.0	11.0	1583496311	9.879119
22524720	Hmm, a lot of effort to make documen	Hmm, a lot of effort to make documents small, but then storing it in mongodb?!?!If size and performance are a focus, just store them in a normal sorted table with compression (e.g. leveldb, or mysql using rocksdb).This means all these small documents can be compressed with repetition between games and not just within each game.And probably much much faster and simpler etc.Basically, the size taken by the database should be at the same kind of level as you get by just having a text file with one line per game, and gzipping the whole thing.  I'd expect it to be an order of magnitude smaller than per-document compression.	willvarfar	13.557297	-5.3473864	comment	3.0	12.0	1583755809	9.849942
15125735	I have a Node server that restarts o	I have a Node server that restarts once a day. On start it reads the state of the app (which is just one big JSON) from MongoDB into a JavaScript variable. When something changes it updates the variable in the Node process and fires an event to update the field in MongoDB. In other word it only ever reads from MongoDB on server start. This has worked very good so far but with all the negative comments I'm thinking there must be some kind of drawback or reason I should switch to Postgre JSON instead.One problem I see is that I need to overwrite the whole thing when saving with Postgre when you can easily just set one field in MongoDB. If I need to overwrite I may as well just save the whole state to a file instead.Forgot to add that it does the same for users. Users are one collection which	Kiro	13.584083	-5.422173	comment	3.0	16.0	1504026120	9.822823
15127007	Here's my personal version of the st	Here's my personal version of the story:With SQL DBs (Oracle, SQLServer and MySQL):1. SQL database migrations where killing us. Going back and forward in a dev environment was impossible. No hot deploy in production.2. Could not work well with application user-defined fields: adding columns adhoc to the database, indexing them, normalizing and denormalizing, performance issues, everything was a problem.3. Blobs holding logging data got unmanageable quickly.4. Joins where very hard to optimize even though the team had a lot of DBA experience fine tuning databases.5. Had to build a very complex architecture around the database for a product that was not that complex: cache, search, database, blob store, distributed, etc.And with all our 1990s and 2000s previous experiences in data warehousin	rgo	13.556286	-5.347558	comment	3.0	18.0	1504035538	9.862445
15127058	I agree that Postgres trumps Mongo f	I agree that Postgres trumps Mongo for most use cases, but if ORM is the answer, you might be asking the wrong question.I love that Fowler discusses[1] how to avoid ORMs and offers only two possibilities:> Either you use the relational model in memory, or you don't use it in the database.He clearly has a blind spot. The correct answer, at least in some cases, is don't use objects in the first place.[1]: https://www.martinfowler.com/bliki/OrmHate.html	macintux	13.609131	-5.4104023	comment	3.0	25.0	1504035967	9.948546
15127212	> 2. Understood what NoSQL meant and	> 2. Understood what NoSQL meant and forgot about joins altogether.How would you represent a simple invoicing system in MongoDB (e.g. Customers + Products + Orders + OrderLineItems )? NoSQL-for-everything advocates posit two solutions: either denormalize the data by embedding Customer information within an Order document, which also contains an array of OrderLineItems, or use a UUID as a kind-of foreign key and maintain separate relationships. Both approaches have serious problems (data-duplication and inevitable inconsistency in the first, and lack of referential integrity in the second, besides ending-up abusing a NoSQL database as an RDBMS). Is there a better way? Or would you agree that certain classes of problems are best left to RDBMS' domain?	DaiPlusPlus	13.537763	-5.405974	comment	3.0	15.0	1504037285	9.793755
15127614	The example you've used (invoices) i	"The example you've used (invoices) is actually quite instructive for demonstrating the benefits of a ""document store."" An invoice, historically, was a literal printed piece of paper. Invoices are actually really annoying to implement in an RDBMS because of so-called ""referential integrity"" -- an invoice should be a ""snapshot in time"" of everything that happened when the order was processed, so ideally, when a user views their invoices from the past 2 years, they look the same every time.Except, oops, your user got married and moved, now your precious ""referential integrity"" means jack because the generated invoice is flat-out wrong. Product removed from the store? Too bad, needs to stay in the database forever for historical purposes. Prices need to change? Better design the database to ha"	rmrfrmrf	13.592936	-5.355542	comment	3.0	12.0	1504040881	9.855776
15169092	Following with interest. I would als	Following with interest. I would also LOVE to see a SQLite clone in pure Go. That would be amazing.	DLA	13.623779	-5.5945406	comment	3.0	14.0	1504541157	9.845047
15169450	Is there anything even close to SQLi	Is there anything even close to SQLite in terms of reliability?  Its pretty much the standard for embedded systems.	karmicthreat	13.600935	-5.559517	comment	3.0	10.0	1504544555	9.810335
15171018	Isn't SQLite an application calling 	Isn't SQLite an application calling for a clean implementation in Rust?	std_throwaway	13.658072	-5.66488	comment	3.0	15.0	1504561140	9.834037
15171389	Still waiting for SQLite4 with it's 	Still waiting for SQLite4 with it's awesome LSM engine :P (shameless plug I ported the engine over to windows https://github.com/maxpert/lsm-windows and it works :D). I wish somebody can do a detailed architecture about SQLite4, that kind of knowledge is scares and valuable.	maxpert	13.600302	-5.5970435	comment	3.0	10.0	1504566461	9.848853
15227486	This isn't about UUIDs. I think the 	This isn't about UUIDs. I think the project creator in the OP was just learning lower level things like working with randomness and bytes... I don't see the problem. Experimenting is fun. Leave them alone.	artursapek	13.988363	-5.212546	comment	3.0	17.0	1505226307	-13.661939
15226027	what about uuid, a well researched a	what about uuid, a well researched and established standard?	ijustdontcare	14.002485	-5.2137003	comment	3.0	12.0	1505210390	-13.641098
15256412	>  Rethink is no longer commercially	>  Rethink is no longer commercially maintained.Just wondering, seeing as am not a Postgress user - is Postgress commercially maintained? Or is it pure open source (like I believe RethinkDB is currently)?	cyberferret	13.66002	-5.2814584	comment	3.0	13.0	1505477356	8.8260975
15303840	I have but I'd say that SQLite is no	I have but I'd say that SQLite is not intended for use in that scenario. It's an in-process library for persisting data to disk in a generally relational format with a SQL interface. It starts to degrade under highly concurrent read and write workloads that you can experience in client-server applications. At that point, a typical RDBMS with more robust concurrency support starts to be a better choice. I experienced that when using SQLite and we eventually moved the application to a full RDBMS which was more complex but also performed and scaled much better.Note that this is very much in line with their recommendations from the docs (http://sqlite.org/whentouse.html):>>SQLite is not directly comparable to client/server SQL database engines such as MySQL, Oracle, PostgreSQL, or SQL Server s	dhd415	13.575408	-5.517686	comment	3.0	15.0	1506004666	9.811619
15304369	Fossil-SCM.I've always wondered why 	Fossil-SCM.I've always wondered why the creator of SQLite (who's also the creator of Fossil SCM) will state that SQLite is not meant for client/server scenarios ... yet his Fossil SCM (which is client/server) uses SQLite.https://www.fossil-scm.org	tiffanyh	13.6068	-5.583385	comment	3.0	10.0	1506007506	9.825028
15308500	I've been using and relying on Mongo	"I've been using and relying on MongoDB for years (since 2010). It's pleasant to develop for, the query interface is awesome, and the library / ORM support is top notch (Mongoid on ruby, and Mongoose on node).I also use Postgres regularly so I can compare the 2. And in my experience, I always enjoy working with Mongo more.Many people don't care about the developer experience and rather focus on Mongo's lack of features like joins and transactions. There's definitely  tradeoffs to choosing Mongo and I wouldn't criticize anyone for picking Postgres over Mongo, however the amount of belly-aching about how Mongo is ""the worst"" was always pretty ridiculous."	jacquesc	13.631003	-5.342615	comment	3.0	11.0	1506040693	9.895068
15308932	Mongo is quick and dirty. If you're 	Mongo is quick and dirty. If you're writing NodeJS, chances are you don't care about `what's best`.	arrty88	13.671277	-5.330159	comment	3.0	15.0	1506046373	9.888749
15366619	I'm curious what would be their moti	I'm curious what would be their motivation for investing so much in MariaDB when they already have their own? Hedging bets? Encouraging competition?	smaili	13.522224	-5.4267716	comment	3.0	16.0	1506701995	9.883012
15410918	Native partitioning, as well as the 	Native partitioning, as well as the advancements on the replication and scaling side of things look like good first steps for a distributed SQL system.Can anyone speak to how much closer this brings Postgres to being able to work like Spanner/CockroachDB? Partitioning is great but having to define my own partitions ahead of time isn’t a great solution for us folks who want to be able to spin up new databases on the fly (without the overhead of assigning new ranges for the tables on these new instances.)Obviously CockroachDB has a long way to go before it works as well as a single instance Postgres DB. But how far does Postgres have before it works as well as a multi-instance Cockroach DB?	lwansbrough	13.542016	-5.2526994	comment	3.0	19.0	1507224827	9.813091
15510442	>it's an unlikely success story that	>it's an unlikely success story that deserves admirationWell, it's a success story due to marketing, smart marketing, clever marketing, and more marketing, not due to lots of technical merits.And it was not the first document store to appear, just the most successful. For starters, CouchDB was previous to MongoDB.	flavio81	13.621026	-5.2406754	comment	3.0	12.0	1508438315	-1.6384563
15510499	Ah, right, like RethinkDB?As much as	Ah, right, like RethinkDB?As much as I'd love this to be true, the #1 measure of success is if people even know you exist and #2 is if you solve enough of a customer's problems that it's worth using your product. MongoDB hit these two points hard right out of the gate and are now very successful because of it.	jameskilton	13.653757	-5.3179736	comment	3.0	18.0	1508438655	9.896508
15511332	I'm continuously amazed when I hear 	I'm continuously amazed when I hear about mongodb in use. Not over say postgres, I get that there are nosql advantages, but over literally any other nosql option.https://en.wikipedia.org/wiki/Poe%27s_law is the term you're looking for...	Jach	13.567742	-5.3670454	comment	3.0	54.0	1508445250	9.840855
15511806	I second this. Mongo clusters are ea	I second this. Mongo clusters are easy to manage, and the aggregation pipeline or MapReduce engines do wonders on a sharded cluster with tons of data. That's the selling point of mongo for me.	fermuch	13.563308	-5.28866	comment	3.0	11.0	1508449564	9.839694
15527181	Entirely disabling synchronous is in	"Entirely disabling synchronous is incredibly dangerous. Use ""pragma journal_mode=wal"" for a safe performance boost."	Scaevolus	13.541885	-5.381907	comment	3.0	12.0	1508685736	9.666904
15556601	These performance figures cited in t	"These performance figures cited in the article are utterly meaningless:
12 billion transactions a day and 1000 NoSQL databases.What does that even mean? I'm sure even modest x86 hardware can spin up 1000 MongoDB instances, and perform 12 billion transactions in a day."	adamtulinius	13.60498	-5.3353066	comment	3.0	10.0	1508996053	9.864863
15649199	I'm jealous you got to hear Dr. Hipp	I'm jealous you got to hear Dr. Hipp, that sounds cool. Would love to hear more about the circumstances :)Regarding the LSM engine, you can find all the relevant implementation details here: https://sqlite.org/src4/doc/trunk/www/lsm.wiki#summary> The in-memory tree is an append-only red-black tree structure used to stage user data that has not yet flushed into the database file by the system. Under normal circumstances, the in-memory tree is not allowed to grow very large.	coleifer	13.559609	-5.575763	comment	3.0	20.0	1510102952	9.636188
15649854	> your normal dB driving some web-ba	> your normal dB driving some web-based CRUD appThat can totally be handled with SQLite.	hasenj	13.560849	-5.5270114	comment	3.0	18.0	1510114165	9.826728
15670190	Until WebSQL gets a full spec, I per	"Until WebSQL gets a full spec, I personally am completely against it.Right now it's defined as ""What SQLite does"", which is not a way to implement a standard.Not to mention that even if they did create a full ""specification"" for the SQL that it uses, it seems like way too much to force onto a browser to develop for not all that much benefit.Safari and Chrome both support it, but it's not going to get any major updates and only exists in the browser today because it was added at one point."	Klathmon	13.572003	-5.553982	comment	3.0	15.0	1510325497	9.820981
15712763	Unfortunately, no. Some friends of m	Unfortunately, no. Some friends of mine picked another nonrel database (not Mongo) for their new company, which prompted this article. I still have to give this advice quite often.	StavrosK	13.70988	-5.3015184	comment	3.0	17.0	1510842162	9.916322
15712754	I feel like MongoDB/NoSQL is a horse	I feel like MongoDB/NoSQL is a horse that's been beaten so much in the last few years that no one is actually making that choice nowadays. Hasn't everyone already learned to stick with Postgres?	elvinyung	13.59	-5.3576846	comment	3.0	29.0	1510842073	9.857644
15712802	Exactly. This article typifies prema	Exactly. This article typifies premature optimisation. If MongoDB lets you prototype faster, then use it until you have enough paying customers to warrant a refactor.	izolate	13.696253	-5.3139887	comment	3.0	12.0	1510842478	9.952157
37958712	On the topic of PostgreSQL and git. 	"On the topic of PostgreSQL and git. As crazy as this sounds, I once entertained the idea of writing a VCS that used PostgreSQL's large object facility for storing the data. I always have PostgreSQL installed on my personal devices so communication would be through Unix Domain Sockets anyway (or through a gigabit LAN in worst case). And the transactions and SQL interface (for metadata) were just that tempting.But I realized pg_largeobject (1) chunks data to around 2kB per chunk, and (2) stores each chunk on its own row, and (3) each row uses ""oid"" type as identifier, which is just 32 bit long. It's probably large enough for anything I would ever need, but for some reason I don't feel comfortable with only 32 bits as primary key."	quectophoton	13.520357	-5.2975626	comment	3.0	10.0	1697821569	-13.266526
37964778	the max order_id is not always the l	the max order_id is not always the latest idalthough it would seem to be so by design, however design is only as robust as the thousands of individuals building on the system :)	hackernewds	13.696334	-5.373796	comment	3.0	20.0	1697872642	-13.600698
38037814	> Also, column types are not checked	> Also, column types are not checked and you can easily insert a string into numeric column.This is only true if you don't use strict tables (implemented end of 2021): https://www.sqlite.org/stricttables.htmlIf you define a table as strict, the data is coerced, and if not successful an error is thrown.	Timon3	13.616133	-5.603193	comment	3.0	10.0	1698411436	9.866687
38037918	I'm a huge fan of SQLite!  My org's 	I'm a huge fan of SQLite!  My org's apps use it heavily, often via this simple key-value interface built on sqlite: https://github.com/aaviator42/StorXHandles tens of thousands of requests a day very smoothly! :)As an aside, has anyone tried using a RAM-disk as the storage medium for SQLite DB files? We've started experimenting with it lately and results have been promising!	aaviator42	13.546728	-5.519096	comment	3.0	13.0	1698412051	9.807568
38039292	Funny this article would pop up for 	Funny this article would pop up for me today, as I'm currently migrating my web app from sqlite to mysql.I got jazzed up on articles like this, only to figure out the hard way that it's ill-suited to apps where concurrency matters.Sqlite is an incredible piece of software, but it doesn't do scalable, concurrent things well.	frithsun	13.56933	-5.509569	comment	3.0	11.0	1698418512	9.765162
38038467	Why you should not use SQLite:Does n	Why you should not use SQLite:Does not handle concurrent writers	miohtama	13.604399	-5.5551324	comment	3.0	10.0	1698415023	9.7915
38095815	Is there any chance SQLite will some	Is there any chance SQLite will sometime work stored under CIFS/SMB shares? I wanted to store all my container /config directories under NAS but can't with the ones using SQLite.	karolist	13.568489	-5.5318193	comment	3.0	10.0	1698827439	9.826821
38100672	SQLite 3.44.0	SQLite 3.44.0	justinclift	13.626447	-5.5910196	story	3.0	92.0	1698856122	9.87397
38258886	> Can’t I just use a Database?> In t	> Can’t I just use a Database?> In theory you could write a pretty simple SQL query, and sure, Big Tech companies have giant data warehouses where you can easily do this sort of thing. But for the scope of a coding interview, you wouldn’t want to. Since this is not a distributed systems problem and the data fits in memory, why introduce the additional complexity and dependencies of a database for something that you can solve with 20 lines of simple code?My first thought on an actual implementation was, if this is a one-off request, to import it into sqlite.  No need to set up a big system, and I think it would be easier/faster than writing those 20 lines of code.  Also a hell of a lot easier to iterate on minor spec tweaks like the unique pages overall vs per day clarification.  And probab	Izkata	13.612882	-5.5689454	comment	3.0	10.0	1699933846	9.810714
38285056	> SQLite4 was an experimental rewrit	> SQLite4 was an experimental rewrite of SQLite that was active from 2012 through 2014. All development work on SQLite4 has ended. Lessons learned from SQLite4 have been folded into the main SQLite3 product. SQLite4 was never released. There are no plans to revive it. You should be using SQLite3.	meepmorp	13.628037	-5.592271	comment	3.0	11.0	1700099955	9.852489
38417933	Actually I'm a bit disappointed that	"Actually I'm a bit disappointed that it can't format 128 bit integers or byte arrays. That would allow formatting UUIDs. I'm not a huge fan of public facing integer IDs. There is always the risk of leaking some kind of critical information with ascending IDs.So I will probably keep Base64URL formatting my UUIDs to make them shorter for URLs, QR Codes and so on.Quick example:  20b30b32-d421-4cfb-bdbc-9a4e0475abea
  =>
  MguzICHU-0y9vJpOBHWr6g

It's important to keep in mind that there are different ways to convert an UUID to a byte array (little/big endian, order of segments, ..)"	andix	13.975157	-5.2145095	comment	3.0	11.0	1700956322	-13.662264
38420830	I've come across Novu in the past an	I've come across Novu in the past and it looks like a solid piece of software. The need to bring MongoDB into my stack is a deal breaker though. Anyone aware of something similar that works on a Postgres database?	Rodeoclash	13.61511	-5.325028	comment	3.0	20.0	1700998084	9.835002
38419833	I appreciate that the author clearly	"I appreciate that the author clearly states that security, i.e., output can't be reversed back to the input, is a non-requirement. We can't criticize the author too much for that either, because, as a rule, ""random-looking id generator"" algorithms will always be either not secure, or not short, or not collision-free.  Or they'll be a key-value database.A secure ""random-looking id generator"" is called a block cipher. Block ciphers with less than 128 bits of output are widely considered insecure: this corresponds to about 22 base64 characters.Going further, you probably do want to use a secure algorithm. History is full of people thinking ""we don't need this to be secure, it's not used for security-sensitive things"" and later regretting it. Some case studies at [1].[1] https://www.schneier.c"	notfed	13.955814	-5.197191	comment	3.0	13.0	1700983272	-13.637194
38438048	"> don't know how you could see ""mong"	"> don't know how you could see ""mongoDB"" and not think it is techI disagree with the author in that I would be comfortable wearing a mongodb shirt in public. Mongoloid is a slur, and at least in Norway it's often shortened to ""mongo""."	matsemann	13.719013	-5.3039746	comment	3.0	13.0	1701118121	-4.43406
38480741	SQLite has five types, documented he	"SQLite has five types, documented here: https://www.sqlite.org/datatype3.html    null, integer, real, text, blob

It has a historically cavalier attitude to enforcing them (which I believe it inherited from TCL) but that changed in November 2021 with the release of strict table mode in version 3.37.0: https://www.sqlite.org/stricttables.html"	simonw	13.608882	-5.5946045	comment	3.0	10.0	1701386862	9.867214
26884180	Cool project but I have to admit I s	Cool project but I have to admit I sure wish this was written on top of SQLite, rather than just mentioned it, implementing a query language shim for MongoDB on SQLite would be an amazing project. In the absence of such a project though, this is a pretty great alternative to have.	hardwaresofton	13.613937	-5.4856715	comment	3.0	14.0	1618967075	9.859768
26888390	"""Mongita"" is a misspelling according"	"""Mongita"" is a misspelling according to the DLE; the standard spelling is ""monjita"".  Literally, the word means ""little nun"", but is the common name for flycatchers of the genus Xolmis.  https://dle.rae.es/?formList=form&w=monjita# https://es.wikipedia.org/wiki/Xolmis_rubetraUnfortunately every time I see the misspelling in this thread I involuntarily cringe.  I suppose ""MongoDB"" is named after a slur used to insult people with Down syndrome, so maybe calling this project the Spanish equivalent of ""Magolia"", ""Mamalian"", or ""Meercat"" is a clever reversal of the insult into a form of self-deprecation on the part of the author, who is wittily feigning illiteracy?  Or perhaps it is intended to ridicule the speling of Spainards and other speekers of Spansh?  Or programmers who decided to yoke t"	kragen	13.710978	-5.2890706	comment	3.0	12.0	1619005999	-4.543908
26923731	>  This is also the reason why seria	">  This is also the reason why serial IDs are way better than UUIDs for internal IDs.There are three core problems with that:  a) Serial IDs are a nightmare for database merges, clustering or anything like that
  b) Serial IDs won't scale
  c) Serial IDs require management, whilst UUIDs can be produced anywhere (in DB, in frontend etc)

There is the KSUID[1] if people want a time-sortable thing that is near-enough to a UUID.[1] https://github.com/segmentio/ksuid"	traceroute66	13.950932	-5.2124104	comment	3.0	13.0	1619258897	-13.646995
26981276	Author here.I discovered Litestream 	Author here.I discovered Litestream here on HN after benbjohnson shared it here a few months back.[0] I wasn't interested at first because I don't ever use SQLite, but it stuck with me. I eventually realized it's a great way to achieve vendor flexibility in hosting apps, so I used Litestream to build a pastebin-style service for my app and wanted to share what I learned.Happy to answer any questions or hear any feedback about this post.[0] https://news.ycombinator.com/item?id=26103776	mtlynch	13.567313	-5.5021405	comment	3.0	14.0	1619704945	9.749328
26996677	"if C is a ""child entity"" of C then i"	"if C is a ""child entity"" of C then it's primary key should have the primary key of B as a prefix.This is how I design all my table schema. and it make database partitioning easier too."	skyde	13.624378	-5.4696054	comment	3.0	15.0	1619804357	-13.629765
27017950	Right but that is an artificially cr	Right but that is an artificially created demo by the author to justify the solution being presented (no offense). The question is how common are ~GB large SQLite databases in the real world relative to databases that are ~MB large?In my experience SQLite databases of millions of rows of raw tabular data tend to compress very well into dozens of megabytes. Indeed SQLite is often touted as a file format for applications.	CyberRabbi	13.577628	-5.538186	comment	3.0	17.0	1619982491	9.781431
27018194	Have you actually read the article? 	Have you actually read the article? SQLite is unmodified, and thinks it runs on a virtual file system, which fetches file chunks via HTTP range headers.It's REALLY impressive that you only need to read 54 KB out of 700 MB, to fetch the records.	watermelon0	13.559611	-5.5281405	comment	3.0	20.0	1619983820	9.804903
27022115	As everyone else has been saying, th	As everyone else has been saying, this is amazing work. It sounds like the biggest issue with loading the page is the initial sql.js download - it's about 1.2MB, is that right?Might it be feasible to easily strip down SQLite so that it only compiles the parts for read-only use? The browser version is obviously somewhat read-only but that's because of the sandbox. I'm talking about excluding the code for CREATE, UPDATE, INSERT and everything else which is just for writing. The aim here would be to produce a significantly smaller WASM binary.I'm guessing that the answer is no, there's no easy way of doing this without significant rewrites of SQLite's core, but... I can't be the only one to think of this, surely?	yoz	13.583939	-5.5547132	comment	3.0	11.0	1620022103	9.869748
27030807	Sortable IDs have pleasant propertie	Sortable IDs have pleasant properties on insertion in traditional btree indexes as all the new values are on one edge of the tree. Truly random IDs end up with random I/O on the index tree.With a database like postgres with full page writes enabled, it can blow out quite quickly at scale.	koolba	13.826702	-5.2372065	comment	3.0	10.0	1620076779	-13.670176
27032271	Umm.. 12 bytes of randomness has 7*1	"Umm.. 12 bytes of randomness has 7*10^28 unique uuid per second. We generally take order of square root of this due to birthday paradox which means that if you generate less than 
 something like 10^10 UUID per second you couldn't get collision."	YetAnotherNick	13.973341	-5.2020144	comment	3.0	16.0	1620084813	-13.656595
27032694	The collision risk depends on the ap	The collision risk depends on the application and use case. In sufficiently large real systems, a probabilistic pseudo-UUID with only 96 bits of entropy has a collision probability that is very small but not so small that you can treat it as effectively zero if avoiding collisions is critical. I’ve seen multiple systems that generate unique identifiers at rates > 10^9 per second. The 128-bit size has a lot of advantages, but probabilistic identifiers are expressly disallowed for some applications and contracts because of the collision tail risk. Making the identifier larger than 128-bits has other significant costs so that generally is not an option either.That aside, generating probabilistic UUIDs at the rates where this is an issue is a bad idea regardless for performance reasons.	jandrewrogers	13.97893	-5.2121344	comment	3.0	11.0	1620088178	-13.665388
27171553	What sort of systems are you buildin	What sort of systems are you building ? I’m guessing some variation of CMS, shopping cart or simple crud backoffice reporting systems.I’ve spent 14 years working for a small agency building these sorts of systems. I kept up with all the cool new stuff that’s come out and played with it but all we ever needed was 2 load balanced app servers with a single instance Postgres database and we ran some pretty chunky systems.I’m now looking for a new position and this attitude has come up to bite me. I’ve always been dismissive of the new dangled complexity but turns out there are systems out there that churn through so much data that mongodb makes sense, and large teams of devs where splitting systems into separate services and writing reusable components is required which is where frameworks and	taotau	13.58585	-5.2938404	comment	3.0	16.0	1621145067	9.844494
27224683	Does this mean we can use sqlite nat	Does this mean we can use sqlite natively on the browser now?	philipyoungg	13.60666	-5.5708895	comment	3.0	11.0	1621533579	9.831422
27250192	Really? Oracle actually makes a lot 	Really? Oracle actually makes a lot of sense to me for a database name (in the 'source of truth' sense, not in the prophet sense).Mongo, on the other hand, has definitely always had the racist/ablist slur as the first connotation for me.	zdragnar	13.671717	-5.294921	comment	3.0	15.0	1621716946	-4.4894567
27249943	Cockroach is the worst brand for a d	Cockroach is the worst brand for a database ever.Even Croach would be a massive branding improvement.This is similar to how gimp is a terrible brand.	gogopuppygogo	13.691668	-5.196129	comment	3.0	22.0	1621714861	10.003012
27346149	The main advantage with UUIDs (and w	The main advantage with UUIDs (and why I now use them widely everywhere) is with relations, foreign keys, multi-region setups, replication, backups, and the ease of restoring those backups.With sequential IDs, the database state is pretty rigid and cannot easily be restored while still in continuous use, because you can relatively easily run into primary key collisions/violations that can make it incredibly difficult to backup and restore data without taking the whole database offline for writes. Things like scaling out to multi-region and sharding also can get pretty quickly problematic - you end up with duplicate IDs that makes it impossible to easily move data between regions - unless you use a centralized unique ID service (see Twitter's Snowflake for an example). UUIDs just avoids thi	vlucas	13.972363	-5.216924	comment	3.0	14.0	1622481063	-13.657233
27346584	It's not like the only two choices y	"It's not like the only two choices you have in the world are UUIDs and auto-incrementing sequential IDs.There are many better alternatives to UUID for the general case in which UUIDv4 is used, that provide some of the following advantages (based on the implementation):
- Simpler spec and implementation
- Easier to enforce compatibility across implementations (no ambiguity about letter case, order or hyphenation)
- Smaller size and better readability
- Lexicographically sortable based on time of generation
- Deterministic uniqueness guaranteeUUID is too much of a jack-of-all-trades-master-of-none. It originally defined many versions (which should have been called ""formats"") for flexibility, but nowadays only UUIDv4 (and less often UUIDv1) seem to be in use. UUIDv3 and UUIDv5 rely on the ins"	unscaled	13.979375	-5.2145205	comment	3.0	11.0	1622483702	-13.661691
27346919	That’s the UUID approach, but worse.	That’s the UUID approach, but worse. According to the birthday problem[1], you’re 50% likely to get a collision in 65 bit numbers after about 5 billion insertions. That’s not an awful lot. Replace that with a 128-bit UUID and you’d have to insert 22,000,000,000,000,000,000 rows to get a 50% chance. That’s probably less likely than a cosmic ray flipping a random bit in RAM and corrupting the index that way.[1] https://en.wikipedia.org/wiki/Birthday_problem#Probability_t...	kstrauser	13.890987	-5.1920905	comment	3.0	16.0	1622486064	-13.640865
27348473	Caveat programmer: this could be pro	"Caveat programmer: this could be problematic, not in the sense it doesn't work, but in the sense that someone working on backend code may have a preconceived expectation that UUIDs are also effectively a keyspace i.e. they're hard to guess.  The validity of that is already challenged by variants defining  temporal or logical order, and evaporates completely if you let clients declare their own that you accept at face value.  Applications may have potentially guessable/gameable object identifiers sloshing around inside as a consequence, which is modestly ironic given that one benefit many folks expect from adopting UUIDs in the first place is hardening up the attack surface of trivially enumerable sequences.There are a few mitigations but my favourite is the ""casino chips"" approach: pregene"	inopinatus	13.984995	-5.21362	comment	3.0	17.0	1622498397	-13.668986
33459330	Show HN: SnowId – A Decentralized, K	Show HN: SnowId – A Decentralized, K-Ordered, 128-bit UUID library in C	beyonddream	13.953208	-5.2169843	story	3.0	15.0	1667517634	-13.657981
33485094	i love sqlite like as much as anybod	i love sqlite like as much as anybody else, but i'm really curious : why would you want to build a web api on top it ?	bsaul	13.566078	-5.557481	comment	3.0	12.0	1667678703	9.827841
33513225	SQLite integrates nicely with .Net a	SQLite integrates nicely with .Net and EF Core.  Would there be any reason to use this over SQLite with a JSON field?	PaulWaldman	13.525916	-5.595593	comment	3.0	18.0	1667858810	9.790195
33559838	For me an important caveat is the ty	For me an important caveat is the typing. With all respect for the original author of SQLite -- he has done an outstanding job-- I think he underestimates the value of a good typing system. I have seen some databases that had all kinds of messy data. Back in the day MySQL was also quite loose with regards to checking data. Undoing the damage is in most cases not possible. For a business data is more important than code, so be strict up front.I know, SQLite has added the option to enforce type checking. The authors still don´t believe in the value of it and the available types are quite limited and thus loose. I think this is something that pgsql got quite right, where you can have your domain types on the database level.On the other hand, if you keep this as a replacement for your config f	exceptione	13.557819	-5.5088744	comment	3.0	11.0	1668168931	9.858407
33559454	The very problem of SQLite: Single u	The very problem of SQLite: Single user only. Although SQLite does have WAL but it still doesn't allow you to do concurrent write unless you want to see file corruption.This means SQLite is very much locked to things that works with one specific purpose and almost nothing else. Sure, you can be read-only, but you have to run alongside the app in the specific node, too.Another problem (although without solving the single user mindset this wouldn't be a problem at all) is high availability. You want to make sure that your database won't get lost do you.Things like Litestream [1] attempts to solve the SQLite backup problem it by continuously saving the database state and pack t up to S3-compatibles or file system but its just half the story. You want to make sure your operation not stopping. 	stevefan1999	13.560639	-5.4772043	comment	3.0	24.0	1668166375	9.78975
33611110	There are a lot of features being de	"There are a lot of features being developed for SQLite now. 
Are they mostly standalone external ""patches/extensions""
or being rolled into the official release?I am hoping it does not get into the official releases.
At least not for a couple of years."	ThinkBeat	13.632504	-5.6047816	comment	3.0	11.0	1668529099	9.824759
33621496	Having a web3 startup is just as ina	Having a web3 startup is just as inane as having a mongodb startup. Those technologies don‘t make anything possible that wasn‘t possible before.In any case: We are talking about this buzzwords for ~8 years now. Is there a list of useful web3 offerings by now? Any heavy hitters, killer applications? Anything besides wacky money making schemes like virtual sneakers?	Traubenfuchs	13.642799	-5.321136	comment	3.0	10.0	1668597898	9.875426
33656157	An idea that pops up more and more o	"An idea that pops up more and more often in my head is to create a SQLite wrapper library that basically treats SQLite like Datalog.I know way too little about Datalog, but it goes something like this:1.
create helper functions to create/alter/drop tables.2.
create helper functions for insert/select/update/delete queries, etc. Probably with the same syntax as in Datomic / Asami / etc.3.
each table its name would be a Datalog ""attribute"", and would have 2 columns: the ""id"" and the ""value"". ""id"" would be indexed, ""value"" would be a value or a foreign key to another table.I guess writes would be slow if everything you insert into the DB is indexed, not sure what the other downsides would be."	harryvederci	13.54358	-5.519967	comment	3.0	17.0	1668785571	0.35269406
33699624	I think the author forgets that whil	I think the author forgets that while you may (potentially) be able to generate quintillions of UUID’s per second, there is no way you’ll be able to validate that they’re correct at the same speed.At least, I don’t feel bad saying my server would melt if it had to serve that many requests.	Aeolun	13.975179	-5.2101817	comment	3.0	11.0	1669073044	-13.6647415
33700055	I've never understood why UUIDs are.	"I've never understood why UUIDs are... a thing. I understand how it can useful to have a name for different kinds of identifiers, but what is the purpose of adding variant/version bits and unifying different kinds of IDs into a single thing called a UUID? The article for instance never did anything with the ""UUID-ness"" of the IDs so they might as well have started with ""random 128-bit integers"".Can anyone explain this?"	edflsafoiewq	13.983797	-5.2132287	comment	3.0	23.0	1669075913	11.433555
33700067	I made a comparison list with the mo	I made a comparison list with the most known uuids out there, a couple of days ago, it was quite fun discovering all the different kinds of uid and their pros/cons.https://adileo.github.io/awesome-identifiers/	adileo	13.983588	-5.209974	comment	3.0	11.0	1669075996	-13.659564
33700595	> There's probably a non-trivial amo	"> There's probably a non-trivial amount of folks that equate a UUID with ""unguessable"" given their appearance.That's near enough to true for anyone not operating at ""web scale"".FAANG/BAT engineers need to care. My systems with 10s or 100s of thousands of users (or, you know, a few thousand users tops) are without doubt going to be re-written (probably several times) well before I have to worry about having so many UUIDs in the wild that this becomes a reasonable thing to worry about.For me, at the scale of systems I run (or will conceivably run in the medium term future), I think the simplicity/understandability of code that uses native language UUID functions is ""the right thing"". Whoever does the next big rewrite to support a few million MAU will be thankful they don't have to work out W"	bigiain	13.9763565	-5.2040806	comment	3.0	14.0	1669079967	-13.664121
33700813	IMO, this is bad math and why you pr	"IMO, this is bad math and why you probably need to be more cautious. I actually went through similar math with my team last year.* It's long been know that UUID should never be used as a security mechanism. While the math is interesting, the fact they're using it as justification for moving away from UUIDs is concerning. It'd be like publishing a post titled ""we're moving away from MD5""* If you're using these tokens for human-entered purposes, you should implement account based rate limiting. It's nearly impossible for a brute force attack if a single account can only have, say 100 attempts per day before contacting support. There are very very use cases where a human-based token will ever need more than 20 attempts per day.* Use long, high-character count tokens if they're intended to be "	SkyPuncher	13.986498	-5.1947894	comment	3.0	11.0	1669082155	-13.661833
33700838	Something I don't understand: how ar	Something I don't understand: how are UUIDs not safe given that they are probably better than 99.9999% of passwords generated by users?	human	13.984152	-5.207174	comment	3.0	18.0	1669082370	-13.666719
33700361	The reason to use UUIDs as primary k	The reason to use UUIDs as primary keys is to allow creating records including primary keys outside of the database before posting them, especially in distributed systems.UUIDs are sortable, but don’t give you creation-order sorting (of course, its abusing bigint PKs to rely on them for that, too.) If you want creation-order sorting, storing a creation timestamp and sorting on that works, and I’ve never had a db that had a business requirement for creation order sorting and didn’t also have one for actual creation time.	dragonwriter	13.961188	-5.2245994	comment	3.0	11.0	1669078041	-13.6620655
33704610	So there's nothing actually wrong wi	"So there's nothing actually wrong with UUIDs as secrets, if you know what you're doing and how to mitigate the risks?So pretty much the same as every other damn thing in software that gets an ""X Considered Harmful"" article? :-D"	Gordonjcp	13.985131	-5.2067127	comment	3.0	11.0	1669116660	-13.688947
33705362	I'm getting down votes, presumably b	I'm getting down votes, presumably because people think what I said is incorrect. Would anybody care to explain how UUIDs can have lower probability of collision than just random bits? (Apart from using a central coordinator for handing them out of course, which would defate the whole point.)	vanviegen	13.98722	-5.209198	comment	3.0	13.0	1669122737	-13.6502
33752870	If I/O was the bottleneck, paralleli	If I/O was the bottleneck, parallelizing it won't help, your SSD/network link/database won't get magically faster.If I/O wasn't the bottleneck, I guess you can parallelize reading, but what are you gaining?If you're writing to files, most of the time the parallism will be hard to implement correctly. SQLite doesn't support parallel writes for example.	plonk	13.567118	-5.5144877	comment	3.0	10.0	1669472725	9.798704
33788651	> Native access to SQLite databasesI	> Native access to SQLite databasesI'm excited for this. May there be a nice database CRUD mode in the future.	Tomte	13.522779	-5.506447	comment	3.0	12.0	1669735400	9.821071
33845615	In the mid-2010s I worked at a compa	"In the mid-2010s I worked at a company that switched from using raw ints to refer to database rows to using (in C# terms) ""Id<FooTable>"".Across the entire codebase, we discovered an entire class of bugs that only never cause any issues because all the important rows in all the important tables had Id 1 (e.g. Currency 1 was USD and Country 1 was USA) - so in a few places where the ints got mixed up, the correct row was still accidentally looked up in the wrong table)."	ThePadawan	13.844026	-5.288523	comment	3.0	12.0	1670090433	-13.622644
33851278	While UUID4 can be good for UserID. 	While UUID4 can be good for UserID. Sometimes, to avoid having a second index in the DB, ULID is another good option; As not only it supports some of the features of UUID4 of uniqueness, it is also sortable.	mardix	13.968487	-5.2177715	comment	3.0	14.0	1670136714	-13.66301
33853509	Emacs: Using SQLite as a Data Source	Emacs: Using SQLite as a Data Source	tosh	13.597018	-5.578971	story	3.0	101.0	1670160356	9.864479
33897337	> doesn't support multi-coreCan you 	> doesn't support multi-coreCan you expand on that? I thought it supported multiple readers, but only a single writer. They do all have to be on the same host, though.Since you mentioned Django - I think there are some complexities where the Python driver can't really do concurrent access if using threads instead of processes, but this is due to Python/GIL limitations, not sqlite limitations.	cldellow	13.586947	-5.5280056	comment	3.0	13.0	1670434473	9.797036
33897276	AFAIK, sqlite3 doesn't support multi	AFAIK, sqlite3 doesn't support multi-core, so you can only do vertical scaling. In cloud, people rather do horizontal scaling. That being said, I ran a django based webapp for internal users and we saw core being pegged by sqlite3 when the queries were complex. However, under normal usage, it was fine for about 100 concurrent users including machine API calls.	aynyc	13.585348	-5.487903	comment	3.0	18.0	1670434203	9.797519
33897490	It doesn't strike me as the best lan	It doesn't strike me as the best language for embedding SQLite given the need to constantly cross the Cgo boundary. But I'm sure it still works fine.	simscitizen	13.60979	-5.5887084	comment	3.0	11.0	1670435011	9.850458
33898056	I suggest you run some simple load t	I suggest you run some simple load tests that do inserts, you'll find WAL is not sufficient for concurrency. Multiple reader, single writers handle this well though.	marktangotango	13.53416	-5.4334855	comment	3.0	19.0	1670437534	9.754916
33906690	I wonder how performance would chang	I wonder how performance would change if using SQLite instead. You would get those range trees and indexes for free (hence much simpler implementation). Plus persistent storage, some guarantees, etc.	janjones	13.561104	-5.553751	comment	3.0	11.0	1670498209	-8.253463
33945603	There are great bits of discussion a	There are great bits of discussion about SQLite being maintained and enhanced by a very small team - three people.While I very much appreciate the safety of being a very small cog in a larger machine, I also wonder how my career might be more enjoyable and satisfying if I had chosen to limit my options to small teams where every single person on the team had a critical impact on the success of a project.	clusterhacks	13.578265	-5.528112	comment	3.0	12.0	1670781811	9.88409
33946081	Even though SQLite bugs are rare, th	Even though SQLite bugs are rare, those can be found occasionally.I remember a bug finder took the sqlite documentation off their website. Collected all their keywords, made up millions of jumbled up queries of random combination between keywords and then ran those overnight to find 10 bugs where the engine crashed. And yes those were also reported and fixed quickly.	habibur	13.636608	-5.5994043	comment	3.0	15.0	1670784438	9.879551
33953521	UUID type for a database Primary Key	UUID type for a database Primary Key	sun_bear	13.964693	-5.23032	story	3.0	19.0	1670844519	-13.660662
33975635	The idea that SQLite shouldn't be us	The idea that SQLite shouldn't be use for web applications is about a decade out-of-date at this point.But... actual guidance as to how to use it there is still pretty thin on the ground!Short version: use WAL mode (which is not the default). Only send writes from a single process (maybe via a queue). Run your own load tests before you go live. Don't use it if you're going to want to horizontally scale to handle more than 1,000 requests/second or so (though vertically scaling will probably work really well).I'd love to see more useful written material about this. I hope to provide more myself at some point.Here are some notes I wrote a few months ago: https://simonwillison.net/2022/Oct/23/datasette-gunicorn/	simonw	13.587314	-5.5004454	comment	3.0	16.0	1670964918	9.776842
17924956	">Where possible avoid simply using """	">Where possible avoid simply using ""id"" as the primary identifier for the table.I wonder what is the reasoning behind this? To escape the ambiguity during joins?>Designs to avoid>EAV (Entity Attribute Value) tables—use a specialist product intended for handling such schema-less data instead.What if you have to use the data in some complex join-heavy query? Make a copy of the data needed in the relational database and hope that the data doesn't get unsynchronised?"	ainar-g	13.723999	-5.4240556	comment	3.0	10.0	1536226265	-13.590047
17926779	RC1 ArangoDB 3.4 – What’s new?	RC1 ArangoDB 3.4 – What’s new?	rubbercasing	13.647967	-5.2797475	story	3.0	60.0	1536246237	9.940621
17958829	Yeah :/ There used to be this thing 	Yeah :/ There used to be this thing called Web SQL (which really… was SQLite)… but… people didn't like it and it didn't catch on. So on the web, Watermelon uses LokiJS, which isn't perfect, but still works well.	radex	13.6194315	-5.56965	comment	3.0	17.0	1536666710	9.827458
17964588	"This probably needs a rename, ""SQLit"	"This probably needs a rename, ""SQLite: View Ticket"" is not a terribly descriptive title.That said, it's a little surprising to see a bug of this type in SQLite which generally has such solid test coverage... Oh well, nothing is bug free after all."	yoklov	13.640214	-5.6005974	comment	3.0	24.0	1536711472	9.904833
18962363	MongoDB didn't become a public compa	MongoDB didn't become a public company through innovations in fundamental distributed database technology or even through good engineering.  They became a public company because once Javascript became adequate for building client software, there was a strong incentive to build MVPs using the same data structures from client to server to DB, and once you build an MVP that gets adoption there's a strong incentive not to switch databases.That's the sort of shift in the environment that the grandparent is talking about.  Fundamental CS tech was arguably better in the 1970s and 1980s, because it moved more slowly and you had time to get the details right.   That doesn't matter if you're building say a mobile Ethereum wallet in 2018, because you're building for the user expectations of today, th	nostrademons	13.663489	-5.3222866	comment	3.0	15.0	1548095689	9.925508
19085720	https://en.wikipedia.org/wiki/Univer	https://en.wikipedia.org/wiki/Universally_unique_identifier#...V4 UUIDs are supposed to be random.	whack	13.982827	-5.2009263	comment	3.0	15.0	1549378301	-13.66852
19086238	Aha, UUID v1!  The author really wan	"Aha, UUID v1!  The author really wanted/expected a UUIDv4 there probably. It's confusing that we talk about ""UUIDs"", when there are a variety of different kinds -- called ""versions"" but they're not really ""versions"" in the sense of updated/replaced algorithms, just different approaches.I don't know if MySQL has built-in UUIDv4 though. pg does."	jrochkind1	13.989958	-5.215662	comment	3.0	16.0	1549381218	-13.659463
19159462	Not sure I understand the MongoDB ha	Not sure I understand the MongoDB hate here. Migrations and denomalization is not somthing you have to deal with in MongoDB.	hartator	13.699399	-5.3164153	comment	3.0	13.0	1550115944	9.90486
19159888	Yup this.People don't realize just h	Yup this.People don't realize just how performant SQLite can be. If you are running just 1 server and won't probably need more than SQLite is more than enough.2 application servers and up is where PostgreSQL can come into play.https://www.sqlite.org/whentouse.htmlAfter reading the SQLite when-to-use document I transitioned some smaller marketing sites over from Postgres because it was overkill for the specific situation. Other multi-app server applications or ones that scale, SQLite might not be the best use, but it still has it's cases. Like copying over a subset of the original data and running queries locally instead of hitting a production database	skunkworker	13.575839	-5.5055475	comment	3.0	15.0	1550123368	9.786828
19170072	Oh FireDAC is no longer available fo	"Oh FireDAC is no longer available for Professional version either? Geez.. really not going to lay down $3k for an EE.How is that ""professional"" if you cannot even read/write to sqlite."	wila	13.640547	-5.6098943	comment	3.0	11.0	1550230782	9.856399
19251558	Fairly off topic ;), but any idea if	"Fairly off topic ;), but any idea if SQLite is used on any of the rovers, spacecraft, etc?Mostly from idle curiosity.  Was wondering a few days ago and guessing ""probably yes"", but no idea who to ask.So, taking the opportunity (heh) now. :)"	justinclift	13.617045	-5.5830336	comment	3.0	13.0	1551148671	9.866121
15795743	I believe the authors point is that 	I believe the authors point is that you have to use SQLAlchemy for that experience. Natively, the experience is much harder and that's why ORMs (like SQLALchemy) have been built. In MongoDB, the driver matches the command line interface 1-1, there is no need for a higher level wrapper so that you can use your database.	TruffleMuffin	13.54569	-5.5723066	comment	3.0	12.0	1511862104	9.920346
15815479	So, you would rather have your prima	So, you would rather have your primary keys be a 36 character UUID string instead of a 4-8 byte integer?This is for every single row in your database and will increase the size of your database substantially.	tkyjonathan	13.966632	-5.217718	comment	3.0	13.0	1512048227	-13.652451
15815654	The article doesn't mention them but	The article doesn't mention them but there are incremental only UUIDs (NEWSEQUENTIALID in TSQL) that solve that problem. Or you can prefix it with a timestamp.	cm2187	13.966918	-5.2182994	comment	3.0	11.0	1512049872	-13.670352
15898241	Not everyone jumped on the NoSQL ban	Not everyone jumped on the NoSQL bandwagon. Software development is a horrible gaping maw of fad-driven, ill-thought-out crap.	dunk010	13.532173	-5.428128	comment	3.0	26.0	1513011142	9.850781
15998228	This is a common case? Besides educa	This is a common case? Besides educational exercises, why? I would have guessed most printed integers are random ID numbers, prices, database foreign keys, etc.	blt	13.870501	-5.213658	comment	3.0	12.0	1514095429	-13.620169
16050330	On Postgres I prefer to use a single	"On Postgres I prefer to use a single sequence to generate ids across all tables. This reduces the chance of accidents (eg accidentally deleting the wrong thing with id #123) and reduces information leakage (""oh, I see I'm customer #5, you must only have 4 other customers"")."	stickfigure	13.932028	-5.222736	comment	3.0	14.0	1514875334	-13.636473
16051784	I disagree that UUIDs are generally 	I disagree that UUIDs are generally preferable over integers. For one, they take up more space (on disk and in memory). And for something like a key, it is likely that there will be multiple copies of that value stored, since it will exist in the table itself, at least one index (possibly more) and foreign keys. More space means fewer records per page on disk, more I/O and more memory usage (potentially leading to more I/O). I would wager that for most users (including this case), the cost of this additional I/O is far greater than some theoretical scalability limitation on generating IDs.Most database vendors make sequence generation (whether through explicit SEQUENCE objects or auto-incrementing columns) performant by making a few compromises:* Numbers may not always be sequential (you m	adambatkin	13.957734	-5.219479	comment	3.0	15.0	1514900804	-13.648552
16052722	After a decade of large systems rely	After a decade of large systems relying on RDBMs, we now use 64-bit integers for all primary keys with a global Hi/Lo id generation system (app reserves a range of numbers on startup to assign to records automatically).This means plenty of ID space, maintains rough numeric ordering, allows ID creation without a roundtrip for every insert, is easily portable across different databases, and produces unique IDs for every row in the database which greatly simplifies everything from caching to replication.	manigandham	13.927166	-5.2305384	comment	3.0	26.0	1514909722	-13.638761
16877793	This is great news!Unfortunately it 	This is great news!Unfortunately it looks like they striped out some important things, notably the storage engine (there's now a sqlite fallback).Edit: Apparently it was always sqlite as per replies bellow.	arthursilva	13.637073	-5.5818753	comment	3.0	12.0	1524158312	9.861167
16878126	Honest question, does MongoDB not wo	Honest question, does MongoDB not work for this?	julien_c	13.686373	-5.323888	comment	3.0	17.0	1524159874	9.890083
16878579	It doesn't look like Apple open-sour	It doesn't look like Apple open-sourced the Document Layer, which is a slight bummer. But I echo what Dave said below: what we got is incredible, let's not get greedy!Also TBH now that I don't have commercial reasons to push interop, if I write another document database on top of FDB, I doubt I'd make it Mongo compatible. That API is gnarly.	wwilson	13.672279	-5.299755	comment	3.0	12.0	1524162209	9.848021
16933370	It seems like what Paul is describin	It seems like what Paul is describing, is the niche filled by libraries/frameworks.When you have a website to build, you reach for an existing web framework, because it has already done the bottom-up steps for you.The same could be said of choosing a language, OS, hardware, etc.Existing technologies allow for increased productivity, at the cost of it becoming increasingly difficult to understand the bigger picture. The 'bottom-up' part at this point, is choosing which Ruby/Java/Python/etc libraries to use. The productivity bar has been set high, leaving little time for bottom-up decision making or education. Hence MongoDB and the never-ending tales of mediocre solutions gaining adoption due to marketing hype.Curiously enough - academia isn't able to solve this problem well, because they're	alexashka	13.653154	-5.324755	comment	3.0	11.0	1524760204	9.881404
16947242	UUID are the way, GUID for those in 	UUID are the way, GUID for those in Microsoft's lands.Not only will you never run out but you don't need a round trip to the keymaster, horizontal scaling, clustering and vertical sharding even are all way easier due to that. This removes a single point of failure entirely when the keymaster is no longer needed.Using ints for keys for profiles/users and many other things were needed way back when processing/db/disk/memory and performance from that were a problem, no longer.Do your part, join the UUID revolution. Also, if you were a piece of data, would you not want to be unique across all the databases, storage and services? You've heard of Roko's Basilisk right? Do not disappoint.	drawkbox	13.97316	-5.220079	comment	3.0	12.0	1524916434	-13.665248
16961316	So one of the issues here is using a	So one of the issues here is using an externally visible ID (or a transformation of such) as an internal ID. Why not create a random int64 at account creation time which is invisibly linked to the public username (eg, email address). So now you've got a proper join key, you can restrict access to the map, and it's easy to delete the map entry when the user unsubscribes.(There can still be good reasons to apply one-way hashing to the random internal UUID, as well: for example, to provide different levels of logs access to different internal users. People who make dashboards get hashed ids, and people who debug logging get raw ids.)The problem of entropy allowing individual user identification even with all IDs scrubbed is still very real, though, and non-trivial to undertake. One can start 	sdenton4	13.976506	-5.207695	comment	3.0	24.0	1525115368	-13.659048
16988530	> make our UI update immediately in 	> make our UI update immediately in order to reflect user actions, instead of traditionally waiting for the backend's success responseSo, a user on a slow network thinks that the request went through and closes the tab. Boom! You've got yourself the first version of MongoDB on the client side!	egeozcan	13.709316	-5.313785	comment	3.0	15.0	1525372480	9.89419
17043773	I'd love it the SQLite page wrapped 	I'd love it the SQLite page wrapped content in a div of a reasonable max-width. Text running edge-to-edge is hard to read.Anyone know if the site is hosted on GitHub?	bmpafa	13.569354	-5.5525966	comment	3.0	11.0	1525994901	9.83541
17111278	Is Coinbase still using MongoDB as t	Is Coinbase still using MongoDB as their primary database? Article talks about moving deliberately and fixing things but then talks about double transaction problems that weren’t fixed for weeks, something that would be easy to make impossible in an actual mature database solution.	shalmanese	13.685164	-5.316123	comment	3.0	14.0	1526791552	9.890493
17122461	My first impression looking at their	"My first impression looking at their schema was, ""what the fuck? if they wanted MongoDB why the fuck didnt they just go with MongoDB?""Thanks to Magento I can add ""someone tried to turn MySQL into a typeless K-V document store"" to the list of crazy things that I've seen."	tomc1985	13.58577	-5.359552	comment	3.0	14.0	1526942608	9.870418
17135847	> Is there anyone who can go a littl	"> Is there anyone who can go a little bit more in detail?* UUIDs are way more painful than serials to recognise, remember, input or transmit especially if you're not dealing with huge tables. ""18574"" is easy to read/grok, ""21caeffa-0fca-4f4e-b845-46ef0576e42a"" is not.* UUID are 128 bit instead of 32 for most serial PKs by default, this may or may not matter. Note that this doesn't just impact the table itself (lowering data locality and thus performanes: less stuff fits into caches) but also any FK as well as wire transmission (where the size explodes as you're going to transmit a hex version of the UUID so always at least 32 bytes, a decimalised u32 maxes out at 10 bytes).* because UUID are random data they're intrinsically non-ordered (as opposed to serial ids which… are), this means you"	masklinn	13.97736	-5.2208753	comment	3.0	13.0	1527095388	-13.66075
17162354	I wonder why sqlite? Isn't quite lim	I wonder why sqlite? Isn't quite limiting for a client-server app?	wiradikusuma	13.585079	-5.532321	comment	3.0	22.0	1527346491	9.8300085
21041810	No. MongoDB has a track record of lo	No. MongoDB has a track record of losing data and not actually providing durability. It is considered a joke in the professional community.	madhadron	13.694912	-5.3085933	comment	3.0	13.0	1569166363	9.895782
21137504	Couchbase really is the best of both	Couchbase really is the best of both worlds, in one product. Store in memory first (memcached) and disk later, on 0 or more cluster nodes. From the calling API, you can choose whether to block or not for the disk commit.Edit: typos	beamatronic	13.55494	-5.194057	comment	3.0	14.0	1570030183	9.682489
21138279	This is what I found in my experienc	This is what I found in my experience as well. I founded a startup in 2013 (and ran it for 3 years) and used Couchbase as our primary data store (a saas that integrates with web sites as customers that received tens of millions DAU). With no dev ops person, running it was easy, and we've never had performance or outage issues. I know you can't compare a document store/kv store with a relational DB like PG or Mysql, but I have wondered why couchbase is not as popular as say Mongo.	godot	13.613874	-5.2786293	comment	3.0	10.0	1570033845	4.08621
21164237	sqlite can be handy but it's not a s	sqlite can be handy but it's not a substitute for testing against a staging instance of another database platform. It ignores a lot of mistakes in column types and size limits and sometimes even foreign keys. If anything, I would want tests to be more strict than prod.	erik_seaberg	13.588697	-5.6131735	comment	3.0	10.0	1570260183	9.818462
22834761	If you picked mongodb and you are us	If you picked mongodb and you are using joins, you've picked a wrong tool for a job.	tasubotadas	13.695996	-5.334265	comment	3.0	16.0	1586537105	9.885333
22834872	This was quite the lopsided comparis	This was quite the lopsided comparison - a document store just doesn't get fair competition in a relational setting. Additionally, both the SQL and the MongoDB queries appear unnecessarily complicated (or inefficient) for the examples they illustrate.	daneel_w	13.606696	-5.334147	comment	3.0	12.0	1586537748	9.801031
22854239	Note that neither CockroachDB or TiD	Note that neither CockroachDB or TiDB use Golang for their actual storage engine, which is in both cases written in C (RocksDB). They do use Golang for SQL parsing though, which is what this post was mostly about.	orhanhh	13.628462	-5.2699237	comment	3.0	10.0	1586768955	9.930599
23034548	To be completely frank, I'm seeing l	To be completely frank, I'm seeing less and less reason to use traditional sql databases. MongoDB offers the ability to make sql queries and even has Acid transactions. Everything SQL can do, it does without slowing down when dealing with big data. The only thing it doesn't offer an efficient solution for is something SQL can't do either, and that's advanced search engine capabilities like Elasticsearch provides.Some people will argue that PostGreSQL is better in certain ways, but the argument really always comes down to 2 factors. Are you going to hit the cost efficiency performance limits of traditional SQL servers, and do you require advanced searching capabilities like graph queries or synonym matching. Even if both answers are No, I'd still argue for Mongo because it makes it easier t	tikiman163	13.608389	-5.3626986	comment	3.0	16.0	1588272427	9.859481
23064965	Sqlite is battle-tested though, it h	Sqlite is battle-tested though, it has one of the most comprehensive test suite and is used on billions of devices already.What systemd is doing with this log storage system is reinventing sqlite, because systemd has a fairly new and not battle-tested database implementation, it has shortcomings.I would argue that either they use plain text logs like before or use sqlite but they should not reinvent a new db.	realusername	13.628032	-5.5816846	comment	3.0	15.0	1588571723	9.844738
23196184	I usually describe MongoDB as a data	"I usually describe MongoDB as a database designed for applications where the data doesn't matter very much.This might sound disparaging, and we all like to think our own data matters to the Nth degree, but consider: how important is that banner that displays at the bottom of the Amazon or Ebay page, ""people who looked at this thing bought this stuff""? It has to be there, but how accurate does it have to be? Are you willing to wait an extra five seconds for it to be right?In the overwhelming majority of places where you might want a database to help you manage the data involved, the majority if the data does not need to be 100% right if it would make the main operations slower. For those parts of the job, MongoDB in its default configuration with default options is good enough.Many of us wi"	ncmncm	13.64621	-5.3446145	comment	3.0	17.0	1589570077	9.86914
23201581	I agree that MongoDB marketing overs	I agree that MongoDB marketing oversells the product.The stock market demands that the product have all the same stickers on as everybody else. But nobody is obliged to believe them. It may take quite a lot before anybody does, again.The people working on the product are very smart and hard-working, but the problem they have set themselves is extremely complex, and possibly not solvable; or, even if ever solved, maybe not demonstrably so.And, anyway, it is not what the customers actually want, although they might often need to convince their own management that they are getting it.	ncmncm	13.727461	-5.271768	comment	3.0	12.0	1589618225	9.9239435
23271068	That's my attitude as well. RethinkD	"That's my attitude as well. RethinkDB, in comparison, had a much better attitude of ""reliable first, fast later"". Unfortunately, it turned out that when you're a database, it doesn't matter how much data you lose, only how fast you are while losing it."	StavrosK	13.640813	-5.30185	comment	3.0	14.0	1590148047	-12.782548
23271457	There is a very recent Jepsen report	There is a very recent Jepsen report on MongoDB. http://jepsen.io/analyses/mongodb-4.2.6> Jepsen evaluated MongoDB version 4.2.6, and found that even at the strongest levels of read and write concern, it failed to preserve snapshot isolation. Instead, Jepsen observed read skew, cyclic information flow, duplicate writes, and internal consistency violations. Weak defaults meant that transactions could lose writes and allow dirty reads, even downgrading requested safety levels at the database and collection level.	dreur	13.604092	-5.2994556	comment	3.0	14.0	1590151755	9.832758
23271556	Yep, just regret and misery.Back in 	Yep, just regret and misery.Back in 2010 when the MongoDB hype was high, the well-known company where I was working at the time decided to build the next version of the product using MongoDB. I was on the analytics team and had to code a whole bunch of intricate map-reduce jobs to extract summary data out of Mongo. I'd repeatedly head to the product team and ask them to explain the edge cases I was seeing in the data and they would not be able to give me an answer because the data was on the third or fourth version of their mentally-stored schema and no one knew anymore. All in all, misery.	heliodor	13.70662	-5.332671	comment	3.0	19.0	1590152529	9.908974
23272426	> We're not going to be migrating te	> We're not going to be migrating terabytes of dataYou may have dramatically less 'real data' than mongo makes you think you do. I migrated one of our mid sized database out of mongo and into PG a couple years ago. The reduction in size was massive. One table in particular that was storing a small number of numeric fields per doc went from ~10GB to ~50MB. I wouldn't expect this with all datasets of course, but mongo's document + key storage overhead can be massive in some use cases.	mbell	13.678549	-5.323568	comment	3.0	16.0	1590157648	9.946369
23282785	I love sqlite, but just a wonder on 	I love sqlite, but just a wonder on how big you are going?I regularly see 50TB total of databases on SQL Server, and scaling up to thousands of clients.	hobs	13.587016	-5.527326	comment	3.0	13.0	1590240787	9.8195505
23285388	"From the jepsen report:""""""Curiously,"	"From the jepsen report:""""""Curiously, MongoDB omitted any mention of these findings in their MongoDB and Jepsen page. Instead, that page discusses only passing results, makes no mention of read or write concern, buries the actual report in a footnote, and goes on to claim:> MongoDB offers among the strongest data consistency, correctness, and safety guarantees of any database available today.We encourage MongoDB to report Jepsen findings in context: while MongoDB did appear to offer per-document linearizability and causal consistency with the strongest settings, it also failed to offer those properties in most configurations.""""""This is a really professional to tell someone to stop their nonsense."	naked-ferret	13.681444	-5.3090487	comment	3.0	25.0	1590259784	9.890132
23285638	[repost - asking for help] I am disa	[repost - asking for help] I am disappointed with the direction that MongoDB took this past few years. Going ACID shows in benchmarks [1] and it’s not advisable if you are using MongoDB for stats and queue. (No one uses MongoDB for financial transactions despite the changes.)And the recent change to a restrictive license is worrisome as well. I have been thinking of forking 3.4 and make it back to “true” open source and awesome performance. (If any C++ devs want to help out, reach out to me! username @gmail.com)[1] https://link.medium.com/PXIeZfhhH6	hartator	13.661903	-5.3041506	comment	3.0	33.0	1590261906	9.895017
23286124	MySQL and PG are not truly consisten	MySQL and PG are not truly consistent per default, they don't fsync every writes.MongoDB explains that pretty well: https://www.mongodb.com/faq and https://docs.mongodb.com/manual/core/causal-consistency-read...	Thaxll	13.616868	-5.2925415	comment	3.0	14.0	1590265781	9.808717
23286151	MongoDB: the Snapchat of databases.	MongoDB: the Snapchat of databases.	MrBuddyCasino	13.625274	-5.3369565	comment	3.0	14.0	1590265974	9.839029
23287363	How is Cassandra as an alternative t	How is Cassandra as an alternative to MongoDB?	therealdrag0	13.526796	-5.228494	comment	3.0	10.0	1590274742	9.747731
23291263	MongoDB is horrible, I get it.What d	"MongoDB is horrible, I get it.What do I use in this situation:1) I need to store 100,000,000+ json files in a database2) query the data in these json files3) json files come from thousands upon thousands of different sources, each with their own drastically different ""schema""4) constantly adding more json files from constantly new sources5) no time to figure out the schema prior to adding into the database6) don't care if a json file is lost once in awhile7) only 1 table, no relational tables needed8) easy replication and sharding across servers sought after9) don't actually require json, so long as data can be easily mapped from json to database format and back10) can self host, no cloud only lock-inRecommendations?"	crazybit	13.546707	-5.299768	comment	3.0	10.0	1590326071	9.819227
23291628	Is Postgres what most people would s	Is Postgres what most people would suggest as a MongoDB replacement?Anyone have any suggestions for a true non-MongoDB jsonDocument based noSql option?	ep103	13.582475	-5.407231	comment	3.0	11.0	1590329489	9.839159
23291174	"Mongo has been related to ""perpetual"	"Mongo has been related to ""perpetual irritation"" up to ""major production issue"" at all three of my last companies.For as easy as it is to use jsonb in Postgres, or Redis, or RocksDB/SQLite, or whatever else depending on your use case - I can't find any reason to advocate its use these days. In my anecdotal experience, the success stories never happen, and nearly developer I know has an unpleasant experience they can share.Big thanks to aphyr and the Jepsen suite (and unrelated blog posts like Hexing the Interview) for inspiring me to do thorough engineering."	lllr_finger	13.670236	-5.3376102	comment	3.0	19.0	1590325069	9.883985
23291361	If you work for Mongo and are readin	"If you work for Mongo and are reading this. Please just fix it. I don't need to win and I don't care about being ""right"".I just don't want to be called to the office on a weekend anymore for this sort of BS.Production incidents with MongoDB last year: 15
Production instances with redis, elasticsearch and mysql combined last year: 2 (and with much less severity)Edit: just to add: I didn't pick Mongo, I was just the engineer called to clean that mess. I created enough of my own messes to not resent the person who made that shot for it. We are constantly on the verge of rewriting the MongoDB stuff since a database that small (~250GB) should really not have these many issues (In previous workplaces I ran ~10TB PostgreSQL deployments with much more complicated schemas and queries with far fewer"	inglor	13.674519	-5.2959237	comment	3.0	18.0	1590326963	9.901803
23292263	I like to keep in mind that MongoDB'	I like to keep in mind that MongoDB's existing feature set is maturing--occasional regressions may happen, but by and large they're making progress. The problems in this analysis were in a transaction system that's only been around for a couple years, so it's had less time to have rough edges sanded off.	aphyr	13.731672	-5.287923	comment	3.0	11.0	1590334766	9.90779
23361804	Anyone here use Patroni for automate	Anyone here use Patroni for automated high availability with postgres? Does it “just work” or do you need a lot of housekeeping?	yardstick	13.530389	-5.288491	comment	3.0	14.0	1590852542	9.815632
23363284	SQLite Turns 20	SQLite Turns 20	nikbackm	13.642639	-5.5819497	story	3.0	22.0	1590862498	9.851068
28013222	It's the same trick that was describ	It's the same trick that was described here - it's absolutely brilliant: https://phiresky.github.io/blog/2021/hosting-sqlite-database...	simonw	13.603306	-5.5457907	comment	3.0	25.0	1627684345	9.846991
28017397	SQLite not being in browsers instead	SQLite not being in browsers instead of indexdb saddens me today still.I designed a system 15 years ago that released dimensional star schemas for specific reports as sqllite databases into Adobe Air (or whatever the prerelease name was) for a large retailer in the UK. We would query the data warehouse, build the sqlite db file (I can't remember the exact db sizes but they weren't too big - 15mb or so) and the computational performance we got from using sqlite as our crunching layer when building the dimensional reports with drilldown was just astounding.	goeiedaggoeie	13.538621	-5.5032496	comment	3.0	18.0	1627733515	9.817468
28050435	> A small, cool fact about SQLite is	> A small, cool fact about SQLite is that its columns are flexibly typedI don't think that's cool - I think it's horrible.	hans_castorp	13.592256	-5.5793867	comment	3.0	11.0	1628004875	9.8764105
28068706	>Lots of databases support the type 	">Lots of databases support the type conversion behavior, but SQLite can’t do the conversion it powers through and writes the bytes anyways.oh god. So if I write ""a"" to an int column it turns into 97? or does it just return a text instead next time, which the first example seems to imply?both are kind of horrible"	asddubs	13.618818	-5.6177516	comment	3.0	16.0	1628127254	9.874575
28069171	But it is dynamic typing. The type i	But it is dynamic typing. The type in sqlite is associated with the value. For example you can have a number column, but actually store a string in it.Proper shocked now?	anyfoo	13.615514	-5.608092	comment	3.0	11.0	1628131256	9.88191
28069196	I learnt this the hard way when I de	I learnt this the hard way when I decided to go for SQLite for a hobby project for 'simplicity'.Depending on how you store your values you could have a column with both floats and ints where a simple query like 'number < 10' will result in weird results.On the performance side I wonder how much of an effect this has as the DB can't guarantee the size of any given column/row.I'd also love to know why it was designed this way; I don't see a single advantage to be honest...	koyote	13.60957	-5.589692	comment	3.0	19.0	1628131494	9.845007
28070129	> Before rendering judgment, please 	"> Before rendering judgment, please read SQLite's own page on the subject. I think you will see that the choice wasn't sloppy but thoughtfully designed, https://sqlite.org/datatype3.htmlI've read the whole page. It's an excellent piece of documentation and reference, but it says nothing about the reasoning behind that design choice, nor show that it was a design choice at all (rather than being e.g. a TCL legacy as some other commenters have hypothesized).The introduction says ""However, the dynamic typing in SQLite allows it to do things which are not possible in traditional rigidly typed databases"", but it doesn't say what those things are, or explain why they're considered a good trade-off against the well-known footguns of implicit type coercion. (Indeed, if SQLite had rigid static typi"	piaste	13.616002	-5.6013584	comment	3.0	25.0	1628140473	9.867635
28076709	>  they don't even live in the same 	">  they don't even live in the same problem space despite both having ""SQL"" in their names.That's true in theory, but I do find that they end up competing in practice when you're looking for something in between the two extremes.I often seem to find myself in a position where I need a database, but it's only for one day's data, which is not huge but not tiny (say 100's of MB). It may be helpful to have a couple of processes accessing it, but probably only one will be a writer, and it's very likely (but not certain) that those processes will be on the same computer. It useful to have that data in a single file for archiving. Those are situations where you currently face a geniune choice between PostgreSQL and SQLite - more because both of them are a bit wrong, rather than because they're bo"	quietbritishjim	13.531695	-5.455575	comment	3.0	16.0	1628184032	9.78374
28089935	See ulid for similar prior art. We g	See ulid for similar prior art. We generate Ulids in code and then store them in uuid columns in Postgres to realize the compact (binary) size benefits.https://github.com/ulid/spec	ComputerGuru	13.969292	-5.221973	comment	3.0	17.0	1628269317	-13.666665
28090582	"To clarify, are those ""plus some ran"	"To clarify, are those ""plus some random bits"" parts intended to be randomly generated for each individual UUID that is created, or randomly generated once per machine or startup?I ask because a common newbie bug is to use a UUID as a secure token, but currently only v4 UUIDs with a cryptographically secure PRNG can be used this way. Separately, even if not used as a token, using UUIDs with randomness for object IDs can help mitigate IDOR vulnerabilities if there are other bugs in code that aren't adequately checking object permissions."	hn_throwaway_99	13.995064	-5.2070546	comment	3.0	18.0	1628272102	-13.65735
28090315	Hi! One of the authors here. We're u	Hi! One of the authors here. We're using MongoDB to store caches A/B test results (among other things), which are deeply nested JSON objects. MongoDB let us develop features really quickly so its been a great choice so far for us. We're willing to add support for another data store if there's a lot of demand for it.	jrdorn	13.524043	-5.4471946	comment	3.0	13.0	1628270902	9.828828
28091263	Thanks. To be honest then, that last	"Thanks. To be honest then, that last bit, ""this RFC recommends using the entirely random UUID4 for anything that's meant to be used in a security-related context, presumably with a CSPRNG."" makes me think this RFC could cause some problems.v6 UUIDs only have 48 bits of randomness, which means that some newbies will think that's ""good enough"" for security, when in reality it's not.I still like these new UUID types because I would use them as DB primary keys now (benefit of being time sorted but also globally unique and offers some protection against IDOR bugs), but important to know where not to use them."	hn_throwaway_99	13.987349	-5.211763	comment	3.0	11.0	1628275321	-13.665493
28091853	I'm not worried about collisions and	I'm not worried about collisions and I agree that being able to put metadata in the UUID is a big meh of a feature. The problem with v4 is what happens when people try using them as database keys: the random sort order can really hurt performance. You might argue that the fix for this is to simply not use UUIDs as database keys... but so many people are already doing this, and will continue to do it, that they should probably be given better standard options.	pjscott	13.981768	-5.21754	comment	3.0	16.0	1628278788	-13.648584
28093055	> First rule of database design: You	> First rule of database design: Your unique IDs should not have a real-world meaning.Well, this is an opinion.  I would definitely push back on making it a rule.  Especially the first one.Natural keys exist, make perfectly good unique identifiers, and have inherent meaning.When using synthetic keys it is difficult (read: requires making trade-offs) to guarantee they were created in order and/or that they increase monotonically.  But if you make those trade-offs (or just align expectations) you can still associate real world meaning to them.These new UUIDs standardize more of those trade-offs.	mulmen	13.929877	-5.2313466	comment	3.0	23.0	1628285923	-13.642769
28095111	> Natural keys exist, make perfectly	"> Natural keys exist, make perfectly good unique identifiers, and have inherent meaning.Most of the ""natural"" things you think are going to be good Primary Keys aren't. You quickly get into one of those ""Falsehoods Programmers Believe About X"" lists.I remember some years ago running into the Experian team who were designing a system to uniquely identify people and they'd got it all figured out for the US market. See, Americans have Social Security Numbers, so you can just use those to key off. Alas, as hopefully anybody here who actually deals with Social Security Numbers knows, they aren't unique. Perhaps you could argue they should be unique, but that's not useful in practice, because in practice they aren't. They seemed really disappointed about that. I doubt they fixed it though.It's f"	tialaramex	13.904137	-5.2380886	comment	3.0	18.0	1628303045	-13.646795
28159595	> and nobody was working on rewritin	> and nobody was working on rewriting SQLite from scratch.One could also have embedded a trimmed-down PostgreSQL or MariaDB into browsers.	mschuster91	13.595233	-5.5699954	comment	3.0	10.0	1628792177	9.884375
28195833	Mongodb should write a book on marke	Mongodb should write a book on marketing to nerds.	ddorian43	13.69744	-5.3022785	comment	3.0	10.0	1629099743	9.907999
28216081	>  Why not a type for even numbers? 	">  Why not a type for even numbers? Odd, prime, not-prime, etc?Those are not mathematical entities in the same way as are the sets W (whole numbers) or N (natural numbers, indices).  It is reasonable to specify your domain closely, otherwise you end up with sqlite.""Why not a type for datetimes or complex numbers?"" would be a better question, as those are different kinds of things but not quite so frequently used in programming."	tuatoru	13.574763	-5.6340475	comment	3.0	11.0	1629243853	9.88839
28225587	The best B-tree resource is SQLite3'	The best B-tree resource is SQLite3's documentation of its B-tree on-disk format.	cryptonector	13.560156	-5.573422	comment	3.0	15.0	1629312792	9.703895
28262290	That's hardly unique to SQLite. I'm 	That's hardly unique to SQLite. I'm a huge fanboy of SQLite, though I have to use MySQL in pretty much all of my client work since I more often get hired to work on existing projects than start new ones. There's three common ways to store timestamps in MySQL and they all stink;- Use an integer column with a Unix timestamp. Not human-readable and no sub-second accuracy if you need it (unless you store the time in milliseconds instead of full seconds, requiring larger int columns, or just get completely crazy and use a float field of some sort.- Use a `datetime` field. Human-readable, supports milliseconds natively, and supports any time between years 1000 and 10,000, but doesn't store a time zone - so if you define the column with something like `'created' TIMESTAMP NOT NULL DEFAULT current	Cyberdog	13.616528	-5.585807	comment	3.0	14.0	1629598378	9.872032
28279218	New UUID Formats	New UUID Formats	dimfeld	14.001266	-5.2087593	story	3.0	36.0	1629739769	-13.670661
28279603	Presumably people would want to rewr	Presumably people would want to rewrite sqlite into Rust. But it's still a database, a low level, high performance software system. Even if you write it in rust, some percentage of the code will be unsafe rust or rust that calls a library written in C. It will be safer, but still not a panacea. It would be more viable in my opinion to improve the safety of the C code that currently makes up sqlite.	eloff	13.627072	-5.6639132	comment	3.0	26.0	1629741529	9.848652
28279806	I don't think a rust version of sqli	"I don't think a rust version of sqlite would make sense, rewriting a very mature and well tested library rarely makes sense.Only if either:- there are anyway some major changes comming- or major problems/improvements in maintainability and better external dev commitment/supportcould rewriting it make sense IMHO.Lets be honest many (most?) of the ""recent"" (~3years) security bugs sqlite had would most likely not have been prevented by using rust, go or similar.EDIT:I guess the biggest drawback of C is that it keeps contributors away, but I also might keep some of the contributors projects like sqlite might not want to have away. So depending on the maintainer it might be seen as a benefit not a drawback."	dathinab	13.627463	-5.674939	comment	3.0	21.0	1629742382	9.809814
28279841	sqlite is renowned as a project that	sqlite is renowned as a project that tests meticulously; they claim 100% branch test coverage, to the point where a reason they reject current Rust is that they can't achieve similar coverage against the branches the compiler itself inserts as safety checks (that is: they can't use Rust because they can't test safety checks that don't even exist in the language they use today).And the track record of that approach is, well, right there for you to see.The idea that what's needed for sqlite's C to be safe is more of the approach sqlite already uses seems pre-falsified, doesn't it?	tptacek	13.652146	-5.6400175	comment	3.0	10.0	1629742563	9.878527
28297734	> But these two camps of databases a	> But these two camps of databases are slowly converging too, with JSON datatype support in MySQL and PostgreSQL, and pseudo-JOINs and transactions in MongoDB.That's not enough to justify 'Oh I guess SQL vs NoSQL isn't about relational vs non-relational anymore'. It is 100% about relational vs non-relational. That SQL databases now support JSON is besides the point: nobody is saying to model your data as JSON documents just because SQL databases now support JSON. Similarly I don't believe that MongoDB is saying to model your data in a normalized relational fashion just because it supports 'pseudo joins' (are they even efficient?). The relational model is powerful because it stores data in a query agnostic way, and NoSQL databases are very much not that. If they were, they'd be SQL database	SPBS	13.550249	-5.44217	comment	3.0	32.0	1629861785	-4.3140497
28327056	Someone on Reddit suggested stored p	Someone on Reddit suggested stored procedures, which seems like a good alternative.Alas, SQLite doesn't have them, so query building it is.	genericlemon24	13.586116	-5.572677	comment	3.0	21.0	1630068115	9.8484
28330207	We wanted to use the same setup for 	We wanted to use the same setup for all experiments, so we had to choose for an on-disk DB for SQLite, because TPC-DS SF100 catalog_sales does not fit in 16GB memory.	lnkuiper	13.559886	-5.5086565	comment	3.0	12.0	1630083503	-9.020553
28429236	MongoDB: Stashing unstructured JSON 	MongoDB: Stashing unstructured JSON data that you don't really know how you might want to query later.Also, getting up and running with an investor demo ASAP with zero technical fuss, because you have a startup idea but you're broke and can't pay your next month's rent unless you either (A) finish this demo and get that investor money next week, or (B) quit working on your idea and take the Google offer. (Yes, I've actually been there.)	dheera	13.553662	-5.4354825	comment	3.0	10.0	1630889848	9.852811
28434653	Hi, one of the developers here, ther	Hi, one of the developers here, there was no specific reason why we went mongo at the start, but there have been talks to move to a different database if needed. Currently mongodb is fine for us.	Zomatree	13.674194	-5.313208	comment	3.0	35.0	1630942185	9.889158
28568353	MongoDB and Twilio have both done re	MongoDB and Twilio have both done reasonably well haven't they?Which developer tools have not done well?	statictype	13.660417	-5.3211784	comment	3.0	17.0	1631900089	9.898604
27848461	Thank you for uncovering this edge c	"Thank you for uncovering this edge case. To summarize, Postgres reserves a batch of 32 serial numbers from its sequence objects. Then, in the case of a crash, or the promotion of a ""follower"", that batch is lost.I consider ID numbers somewhat opaque, like GUIDs but maybe not that opaque. Fretting about gaps in ID numbers can cause hair loss. This is just one of many ways gaps can happen.It is just an artifact of ""sequences"", the database object in Postgres that autogenerates the ""next"" ID number for a column --- automatically set up if you declare a column of type ""serial"", but that's all a serial column is. Serial just means: make the column of type integer, and create a sequence for it, and set the column's default value to nextval(sequence).You can mitigate gaps somewhat, like if you're"	combatentropy	13.726749	-5.2983274	comment	3.0	10.0	1626374603	-13.644441
27868419	CockroachDB is a terrible technology	CockroachDB is a terrible technology that causes almost guaranteed data corruption due to its lack of ACID guarantees and is written in a language with a GC which contirbutes to GC pauses. The dev team refuses to listen to feedback to port their code to C ;(.	bobthebuilders	13.654109	-5.211729	comment	3.0	18.0	1626552586	9.937033
27875319	As a Rust developer (that's up to th	As a Rust developer (that's up to their neck in Rust projects) I'm really looking forward to a functioning sqlite clone. To the best of my knowledge, Sqlrite (https://github.com/joaoh82/rust_sqlite) was supposed to be that but it ended up diverging from sqlite. It'll make cross platform Rust builds easier.	netsec_burn	13.619565	-5.6929746	comment	3.0	29.0	1626633583	9.789186
27997886	Race: Setting up CockroachCloud Free	Race: Setting up CockroachCloud Free vs. cooking ramen	occupy_paul_st	13.663973	-5.194523	story	3.0	8.0	1627573599	9.954351
12043912	To use another technical analogy...I	To use another technical analogy...I teach data analysis using SQLite...the purpose of the course is for students (most of who have never actually programmed) to be introduced to SQL, but more fundamentally, the concepts of databases and data joins. Ignoring the profound differences in database architecture...SQLite follows most of the SQL standard [0]...but I think there are enough syntax differences between it and Postgres that the gulf might be roughly comparable to at least the disparity in vendor prefixes on the browser side. As for SQLite vs. MySQL...well, I used to teach lessons that allowed the use of either SQLite and MySQL, and gave that up after a year.In addition to being SQLite focused, I tell students to just use one open-source, cross-platform client: http://sqlitebrowser.or	danso	13.552353	-5.4878836	comment	3.0	13.0	1467820678	-12.178719
12044040	I understand what you're saying, but	I understand what you're saying, but I think you're confusing tools and deliverables.If I hired someone to do data analysis, and they delivered accurate results using SQLite, I could not fault them since the deliverable is correct, whether they used SQLite or PG.If I hired someone to build a web application, and then found out that it only worked in Chrome, that's a broken deliverable.The specific tool (SQLite/PG/etc or Chrome/FF/Lynx/etc) used for creating each deliverable doesn't matter.	nathancahill	13.578307	-5.534285	comment	3.0	10.0	1467821658	9.817735
12113303	My experience says that the issue is	My experience says that the issue is not differences, but bad architectural decisions. Most applications out there are glorified CRUDs. They are perfectly serviced by SQL databases. NoSQL fits a smaller set of systems whose scope is mostly passing data around. PostgreSQL now supports JSON as a datatype and allows querying it. Works beautifully. No need for MongoDb at all.	asimuvPR	13.581643	-5.409377	comment	3.0	18.0	1468818347	9.825007
12123954	Ask HN: Should I migrate my MongoDB 	Ask HN: Should I migrate my MongoDB to a more reliable DB before launch?	daphinz	13.619493	-5.36077	story	3.0	3.0	1468954732	9.852648
12159231	I thought CouchDB was abandoned year	I thought CouchDB was abandoned years ago?	gwbas1c	13.625588	-5.2057204	comment	3.0	12.0	1469459816	9.66867
12159478	Primarily merging the changes that C	Primarily merging the changes that Cloudant (now an IBM product) made to Couch to turn a fairly simple implementation of NoSQL / MapReduce into a first-class datastore.Things like:* Native Lucene search, which you had to build as a weird add-on for Couch. Now it's full-featured out of the box.* Geospatial queries, also a weird add-on which only kind of worked in Couch, is also cooked in and is pretty strong now.* True node clustering and data sharding; Couch has always had really really easy replication between nodes, and getting master-master replication is essentially creating a document on each node. However, you had to store your entire data set on every node, which would grow out of control in a hurry.* A better auto-compactor. Couch 1.6 does fairly well but it's still a weird cron-ba	mark242	13.5591135	-5.1918683	comment	3.0	13.0	1469461978	9.691723
12180075	Explanation: Ayende is a well known 	Explanation: Ayende is a well known programmer in the .NET community. Among other things he works on RavenDB (open-source NoSql db for .NET) and is currently working on a new storage engine for it called Voron. In this post he discusses Uber's blog post about Postgres and MySQL and compares the low level workings of both with what his team is doing with RavenDB and Voron.	codeulike	13.5360985	-5.3624096	comment	3.0	10.0	1469713026	9.837947
12201494	Yes, I have a lot more respect for t	Yes, I have a lot more respect for this than say MongoDb which claims to be great at everything.	collyw	13.6713085	-5.3242316	comment	3.0	88.0	1470049812	9.891803
12251090	Read SQLite's FAQ on that. Given, mo	Read SQLite's FAQ on that. Given, most projects aren't as amazing as SQLite.	qwertyuiop924	13.612053	-5.5789146	comment	3.0	10.0	1470692643	9.849448
12290906	> I would likely not use it as a mai	> I would likely not use it as a main source of truth for any application but for a lot of things, it's a good database.I really don't understand this. In what case is it every acceptable for a data store to lose data? And that's not even MongoDB's only problem: it memory leaks!	devishard	13.60589	-5.3340325	comment	3.0	20.0	1471273578	9.876228
12290948	I have to say that I did not experie	I have to say that I did not experience a single data loss that was a result of the database misbehaving.Memory leaks weren't a huge issue for us as well. After stabilizing the setup I have to say it was basically a fire and forget part of the stack for us.The role of MongoDB was to act as a fast-insert and aggregation framework for other parts of the system.So, we would insert BIG amounts of data at a time and aggregate it into a K/V store where we pulled the data from.After a while, the setup became to expensive to run, at this point we turned it off for a cheaper solution, but in terms of functionality, it functioned pretty well.	avitzurel	13.691619	-5.307492	comment	3.0	14.0	1471273841	9.860269
12291086	While not a fan of mongoDB for many 	While not a fan of mongoDB for many reasons, any sufficiently large scale application will have denormalization. Caching layers cause all sorts of cache invalidation bugs because of this exact problem. Indexes, while often managed by the DB, are essentially denormalization. One could even argue that syncing data between a client and server is a class of the same problem.My point is that we deal with these problems out of necessity. If you don't get a ton of traffic, then sticking with a normalized RDBMS is probably best. However, large scale systems will have redundant logic. Generic solutions (letting the normalized DB do the work) will often be slower than specific ones (denormalizing your schema and moving logic into the application layer). These are pretty simple principles that I've s	phamilton	13.552509	-5.3424177	comment	3.0	22.0	1471274896	9.852369
12291153	This is a problem I've had to explai	This is a problem I've had to explain to too many developers recently. It's not faster just because you throw away data modeling practices and jam bits of info all over the place.If you have semi normalized data relationships, Mongo really doesn't fit the bill that well as your primary data store.Where it shines is when you've got computed pieces of data to display (parts of a user data feed for example, data for a live graph, etc), you want to quickly store some data to be processed later (analytics, event processing), or you just use it as an object cache for expensive queries.I have found that with a decently tuned DB, and I mean barely tuned, a decent data model, and sane fetching strategies (don't eager load everything always), a database can be good enough for quite a while, if not f	manyxcxi	13.571602	-5.3530574	comment	3.0	17.0	1471275583	9.879367
12297666	I agree... but at this point, it's t	I agree... but at this point, it's tough to see with all the ink that's been spilled on these issues for years how you could think anything else.  Maybe I read HN too much, but the manifold problems with MongoDB have been widely publicized for the past 6 years... it seems pretty close to conventional wisdom that you're going to have those problems if you decide to use Mongo.	dccoolgai	13.6537485	-5.341806	comment	3.0	23.0	1471357698	9.923739
12474201	I would not want to be the one on-ca	I would not want to be the one on-call for a million row SQLite database!	matt_wulfeck	13.584525	-5.561593	comment	3.0	17.0	1473612326	9.872555
12529638	I thought about trying out MongoDB. 	I thought about trying out MongoDB. Which NoSQL are better in your opinion?	ralfd	13.537238	-5.356007	comment	3.0	13.0	1474270918	9.831144
12949230	Reminds me of the SQLite developers 	Reminds me of the SQLite developers who got overwhelmed:https://github.com/mackyle/sqlite/blob/3cf493d4018042c70a4db...	Tomte	13.604926	-5.5744724	comment	3.0	37.0	1479124737	9.8443165
12962672	CockroachDB performance is just awfu	CockroachDB performance is just awful. Most of the members in its Team are arrogant just like the Go community. They just keep defending their statements without any evidence.	anonymous7777	13.673703	-5.2114663	comment	3.0	15.0	1479247252	10.009194
12977091	Ask HN: What to use after SQLite?	Ask HN: What to use after SQLite?	tiffanyh	13.560183	-5.5252123	story	3.0	4.0	1479388160	9.815652
13031301	Looks like they were planning to Jep	Looks like they were planning to Jepsen test later this year [0]. But it looks like they're preparing to run it themselves [1]?[0]: https://www.arangodb.com/2016/05/getting-closer-arangodb-3-0...[1]: https://github.com/arangodb/jepsen/commit/2b79809df73ca6c755...	iamed2	13.653725	-5.2732306	comment	3.0	11.0	1480006918	9.957678
13063415	Why MongoDB for what is pretty much 	Why MongoDB for what is pretty much a front-end :( What's wrong with SQLite?	StavrosK	13.626398	-5.4867883	comment	3.0	12.0	1480431907	9.858151
13118806	I've been working on a closely relat	I've been working on a closely related problem of universal identification in distributed computing for a few years now.  It's now in standards review and hopefully publishable soon.We came to the conclusion that universal ids should represent identity only, and explicitly not have 'metadata'.  What is the use of 48 bites of time?  It reduces the overall entropy, for what?  If time is important then why not make the id literally time (i.e. UnixNano), if it isn't they why not make all bits rand?Also, while I think speak-ability is actually very important (many disagree), I'd assert that capitalization is better addressed from the opposite direction (i.e. UI).  Instead of removing capital letters from the ID itself affecting all cases, address the human factors in the few cases it comes up.I	joshuak	13.969675	-5.1927524	comment	3.0	13.0	1481062775	-13.646074
13203291	My theory: everybody knows sqlite ca	"My theory: everybody knows sqlite can be distributed as a single-file library that you can happily embed.  However, it's a pretty complex beast compared to the rest of the list and maybe it's outside the vision of the list altogether, which features much simpler projects.Edit: to be even clearer, sqlite is 100+ .c files.  Yes, you can make it one ""amalgamated"" .c file, but no developer works on that file; they work on the 100+ smaller .c files."	idm	13.591487	-5.578818	comment	3.0	10.0	1482016267	9.819203
13226095	Vacuuming your profile might help:  	"Vacuuming your profile might help:    #!/bin/bash
    killall firefox
    for file in ~/.mozilla/firefox/*.default/*.sqlite; do
        echo sqlite3 ""$file"" VACUUM
        sqlite3 ""$file"" VACUUM
    done

I do it in my once-a-month cleanup script."	mixmastamyk	13.578739	-5.529451	comment	3.0	11.0	1482283965	9.814986
13303993	Ten-year-old severe SQLite bug fixed	Ten-year-old severe SQLite bug fixed	turrini	13.630436	-5.5894794	story	3.0	36.0	1483387607	9.864014
13317329	It's fascinating that someone instal	"It's fascinating that someone installs and configures MongoDB and doesn't stop to think: ""Hey, maybe this shouldn't be exposed directly to the internet"". I mean you wouldn't do that with something like MySQL.Some sort of analysis of the purpose of these directly exposed MongoDB instances could be interesting. Are they being used as a backend for JavaScript applications?"	mrweasel	13.657249	-5.3112626	comment	3.0	14.0	1483529327	9.878059
13317386	I also have been affected by the sam	"I also have been affected by the same ""hack"".
Turns out I have simply forgot to start mongod with --auth option, even through the I had created users for different databases, including the admin! 
Looks like in ""non secure mode"" it allows logins with existing users as well as non-authorized.I understand why the authentication is disabled by default, but it should fail to start with a DB that has users with roles and stuff."	SillentTroll	13.717694	-5.2533107	comment	3.0	18.0	1483529870	9.933658
13349072	" ""hackers have now hit around 10,500"	" ""hackers have now hit around 10,500 MongoDB servers. That's about 25% of all MongoDB databases accessible via the Internet. The attacks don't target all MongoDB databases, but only those left accessible via the Internet and without a password on the administrator account.""25% of mongodb installs externally accessible lack a fucking password on the admin account.They deserve it. Maybe it will teach them something."	gnarbarian	13.71239	-5.2266154	comment	3.0	14.0	1483868985	9.935204
13423567	I really appreciate the deep introsp	"I really appreciate the deep introspection in this post. We can all learn a lot from it. I'm one of the (possible minority) of HN users that doesn't care about startups and business, so for me the takeaway was about how choosing quality and correctness over speed works out in the real world. It seems that you really can't take the idealist approach to quality that RethinkDB took. The world just isn't willing to wait, and it's not willing to take the time to understand a system and to see how clearly it distinguishes itself from the alternatives. Our decisions are driven by speed. Our culture is ""always be shipping."" But part of the result of this is that all our software is riddled with bugs and usability issues. Even the most basic functionality of our computers fail all the time, all the"	Perceptes	13.664183	-5.281567	comment	3.0	15.0	1484707469	1.6230338
13424821	Hello HN , sorry for the early leak.	"Hello HN , sorry for the early leak. I posted as I've discovered on github after looking around rethinkdb progress.RethinkDB as a product is  not dead.The community and one of ex RethinkDB senior developer  are still maintaining it. Since it is fully Opensourced , we are welcoming  contributors , lets make RethinkDB great , together!https://github.com/rethinkdb/rethinkdbHere are current rehtinkdb plans :
https://docs.google.com/document/d/1f8qODp7voKIqwioQ3si69q3-...Most of ex RethinkDB developers are going to keep contributing rethinkdb, after things got settled down a bit.https://docs.google.com/document/d/1c27S3Ij2WLB_JiUmpIGkbwJO...Please try out rethinkdb , and if there any questions we are activly answering at :
<a href=""https:&#"	v3ss0n	13.669866	-5.2835903	comment	3.0	13.0	1484726034	-12.808048
13424558	This was a really interesting post. 	This was a really interesting post. Thanks for writing it.First with MySQL and then with MongoDB, a pattern is emerging. There's a popular open-source database. Its feature set is awesome and the ecosystem of software on top of it is good because lots of people are using it, but it's buggy and unreliable. So it's controversial. Since it's popular, it keeps being developed, and over time, it slowly gets more reliable.To me this post is a reminder that, just because I can see clear flaws with a competing product, it doesn't mean those flaws are exploitable. Better to focus on what your own customers are demanding than on criticisms of your competitor.	lacker	13.645334	-5.314473	comment	3.0	12.0	1484721603	9.8699465
13439589	It looks like you are trying to repl	It looks like you are trying to replicate the MongoDB Inc. business model (regardless of major differences in the actual product being offered).MongoDB offers a commercial version of their product with enterprise features (encryption at rest, LDAP auth, etc) and support - MongoDB Enterprise.Additionally they also offer managed, cloud hosted MongoDB deployments - MongoDB Atlas.Over the last few years the valuation of MongoDB, Inc. has been slashed by institutional investors such as Fidelity and BlackRock. While they haven't had mass layoffs or some other negative corporate event, they have clearly had some difficulty making their (and apparently your) business model work.Do you agree that this is a fair comparison? And what do you makes CockroachLabs more likely to succeed with this busines	hendzen	13.707412	-5.2006664	comment	3.0	13.0	1484860726	9.901888
13440596	Do you think there's something diffe	Do you think there's something different that Cockroach could do? Or do you think that the database market as it exists today leaves them without a path to building a lasting business?Personally I believe that latter. I don't see how they're going to get people to pay for Cockroach with all the options that are already out there. I think they might have an even more difficulty than RethinkDB did because their interface is SQL which means that migrating to things like Postgres or RDS is a lot easier.	jdoliner	13.661505	-5.204736	comment	3.0	18.0	1484870340	9.886218
13461657	What are the most popular ways to ru	What are the most popular ways to run external MongoDB databases now?	sply	13.649808	-5.328697	poll	3.0	10.0	1485174050	-11.122902
13494103	I don't think an offer amount was ma	I don't think an offer amount was made. As far as I can tell there is no significant money or even organization in the group of people that are doing their best to manage the project. They're still looking for a way to formalize. I would read this as that stakeholders have not been eager to donate the RethinkDB IP to a foundation, so perhaps there either are commercial parties interested in the IP, or the stakeholders think there might be.This is all conjecture though, unfortunately besides these meeting notes there is no record of interactions with the RethinkDB stakeholders.	tinco	13.723177	-5.260622	comment	3.0	12.0	1485456702	-12.812475
13507569	"Curious where ""to Replace SQLite"" ca"	"Curious where ""to Replace SQLite"" came from in the title.It doesn't appear to support SQL.  The word ""SQLite"" isn't anywhere on the repo.  And, this is a client side browser database...sqlite is not."	tyingq	13.617818	-5.585928	comment	3.0	10.0	1485624787	9.866321
13524318	I have written this reply and starte	I have written this reply and started over 3 times -- hopefully this one sticks.I really feel like the author boxed himself into a solution by faulty reasoning.1) Cron jobs are not hard to set up. Being able to control these things on one or more server is just part of proper server deployment.2) If it is not part of the application but seems to have to do with information about users who used the application in trial then maybe it should be part of the application? If you are deploying a application and you require to know information about users who trials are going to end I sure would bet that is part of the application and should be a trigger coded into the application itself.3) I am shocked that you are already did not have a central spot for running time interval code and maintenance	mbrumlow	13.693237	-5.3112454	comment	3.0	13.0	1485805286	9.912549
13579781	Hey everyone, thanks to the rest of 	Hey everyone, thanks to the rest of the RethinkDB leadership team and the CNCF for their hard work! This wouldn't have been possible without a lot of effort from our dedicated community.You can read the announcement on RethinkDB's blog to find out about the project's next steps: https://rethinkdb.com/blog/rethinkdb-joins-linux-foundation/We've had a lot of folks ask if they can donate to support the project. Stripe has generously offered to match up to $25k in donations (which will help fund server costs and future development.) You can learn how to contribute to the project with OSS contributions or donations here: https://rethinkdb.com/contribute	mglukhovsky	13.693287	-5.285802	comment	3.0	13.0	1486392095	-12.810177
13581389	Bryan Cantrill posted his thoughts o	Bryan Cantrill posted his thoughts on the CNCF's decision to donate RethinkDB to The Linux Foundation here: https://news.ycombinator.com/item?id=13579544We wanted to share RethinkDB's next steps in our new home with The Linux Foundation.We've also had a lot of folks ask if they can donate to support the project. Stripe has generously offered to match up to $25k in donations (which will help fund server costs and future development.) You can learn how to contribute to the project with OSS contributions or donations here: https://rethinkdb.com/contribute	mglukhovsky	13.687972	-5.27061	comment	3.0	15.0	1486400297	-12.829858
13582211	Linux foundation are collecting quit	"Linux foundation are collecting quite a lot ""failed"" projects and turn them to gold these days? I sometimes feel it is acting like a software goodwill store partially. Whatever that is, hope RethinkDB will do well in the future."	ausjke	13.672873	-5.2777014	comment	3.0	14.0	1486404592	-12.794649
13591337	In the same NoSql space as mongo db?	"In the same NoSql space as mongo db?
I can't remember not even one that passed fully jepsen test.
Can you post some links to the better NoSql options?"	tigershark	13.610152	-5.340625	comment	3.0	20.0	1486491526	9.872063
13590884	Bigger news is that Jepsen tests are	Bigger news is that Jepsen tests are now part of the MongoDB continuous integration suite: https://evergreen.mongodb.com/build/mongodb_mongo_master_ubu...Open and available for everyone to see, for every build of MongoDB. Is there another database that has this much transparency? (for every build)	jasondc	13.647228	-5.287716	comment	3.0	84.0	1486488219	9.877875
13591513	Not the OP, but RethinkDB is superio	Not the OP, but RethinkDB is superior in many ways including stability, integrity and the feature set for pretty much every use case you would consider using MongoDB.But with Jespen tests MongoDB can finally be considered a contender. Its not like competent teams were using it in production. Right?	ralfn	13.625254	-5.3203526	comment	3.0	31.0	1486493036	9.842026
13591668	Right out of the box? Mongodb has be	Right out of the box? Mongodb has been trying to get it right for 10 years now. Kyle says the storage engine they've used for most of that lifetime is fundamentally flawed, and they've only now, a decade on, managed to write something without known bugs to replace it. And maybe this time it's ok. Maybe this time there aren't any more layers of buggy crap in mongo yet to be found and fixed.Maybe. But you'd have lost that bet if you made it any day in the last 10 years. And in those 10 years mongodb has demonstrated again and again that they aren't up to the task of writing a reliable database. Even with their new storage engine they couldn't find the bugs alone.I think using mongo today for any mission critical data is an irresponsible choice. I'd seriously question the judgement of any sen	josephg	13.668491	-5.31417	comment	3.0	27.0	1486494126	9.891928
13593062	These 'from the ground up' totally a	"These 'from the ground up' totally all-new-code approaches to DBs are just a scary proposition. Think of the thousands of man-years of effort that went into building MySQL, testing its codebase, and perfecting it's robustness (fail-proof-ness). What does MongoDB bring that couldn't have 'built on top' of MySQL codebase, and used MySQL transational layer as it's underpinnings. Sure, MongoDB gets all its performance gains from delaying writes to the DB (eventually consistent), caching in memory, and dispensing with ACID, however there is nothing about MongoDB that couldn't have been written to use the DB layer of MySQL at the point where it actually does its writes to disk. In this way, MongoDB would have revolutionized the world rather than mostly ""fragmenting"" the storage space.I guess the"	ClayFerguson	13.64784	-5.3346577	comment	3.0	16.0	1486503438	9.891829
13594071	As a sysadmin, I got tired of the de	"As a sysadmin, I got tired of the devs constantly ragging on Mongodb (the same folks that selected it before I was hired). I eventually got fed up and said: ""why do we use it if you all hate it so much. Let's replace it. What do you want to use instead, it's easy for me to set up something new"". Cue everyone going ""ah, it's not so bad, really...""MongoDB is the Nickelback of databases: a reasonable act that's not going to blow your socks off, but one where saying ""OMG I hate it!"" somehow signals membership to some cool clique of connoisseurs."	vacri	13.683652	-5.31796	comment	3.0	11.0	1486510234	9.89619
13605405	If the database is the bottleneck, w	If the database is the bottleneck, why are you using the same (MongoDB) database as Parse (and Firebase) were?The problems described in the article are quite literally are my pitch deck, which I have successfully raised from billionaires Tim Draper and Marc Benioff of Salesforce, for http://gun.js.org/ . So why did you decide to stick with MongoDB when many other databases have tackled solving those problems?	marknadal	13.5449505	-5.236997	comment	3.0	13.0	1486627499	9.870454
21259579	Here’s an algorithm which I believe 	Here’s an algorithm which I believe to be 95% accurate:If only a single user/device needs to access the data: use SQLite. In all other cases: use PostgreSQL.	jl6	13.520759	-5.4507256	comment	3.0	12.0	1571153823	9.781396
21388051	> IDs should get an _id suffix, and 	> IDs should get an _id suffix, and primary keys should be called $OBJECT_id (e.g., order_id, user_id, subscription_id, order_item_name_id).Wrong.  Be consistent.  All id's are named ID or id. Consistency is key.Most of the article is filler and style choices.	throwaway35784	13.598295	-5.528701	comment	3.0	11.0	1572362020	9.811866
21498399	SQL in CockroachDB: Mapping Table Da	SQL in CockroachDB: Mapping Table Data to Key-Value Storage (2015)	jxub	13.629465	-5.2144575	story	3.0	87.0	1573400697	9.869744
21499283	"> ""and deletion of swaths of entries"	"> ""and deletion of swaths of entries is impossible as it makes the history manager UI hang for many minutes or even hours (=essentially I always kill Firefox when I do this by mistake). I suspect the GUI constructs a view of the sqlite db using single GUI objects tied to single DB entries and therefore has maximum overhead.""I've not probed this deeply, but I have encountered it and can confirm it's a problem.   To give an idea of the magnitude of the problem, deleting 10,000 history items can easily lock up Firefox for a full hour.   I think but haven't confirmed that it might even be nonlinear.  e.g. deleting 1,000 entries 10 times in a row seems faster than deleting 10,000 entries in one go.I don't know what firefox is doing here, but it's badly broken.(My places.sqlite is 55MB)"	catalogia	13.552127	-5.495475	comment	3.0	10.0	1573409928	9.847161
21516646	CockroachDB seems to be getting a lo	CockroachDB seems to be getting a lot of attention and marketing cycles lately... What has made it the focus of late?	yRetsyM	13.701808	-5.184438	comment	3.0	13.0	1573583428	10.098533
21644275	"That ""100k hits"" figure you quoted s"	"That ""100k hits"" figure you quoted surprised me, so after going over their page, I just wanted to add here that that's ""100K hits/day"", which translates to just 1 query per second, which is unreasonably conservative.In a post [0] from last year, Expensify tell how (with some modifications) they managed to get sqlite to 4M qps on a single powerful server running 192 cores. That's 20K qps/thread for their huge table, and they got over 200K qps/thread for a table with a single row (demonstrating how little overhead sqlite has).[0] https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-q..."	falcor84	13.584644	-5.530831	comment	3.0	10.0	1574815328	9.809189
21675910	It has been a while ago so maybe thi	It has been a while ago so maybe things are better now but I have seen sqlite being a disaster when the times comes to upgrade the schema. Not all of the common operations like deleting/renaming a column are supported. Since it has been a while I don't remember exactly which ones. Then someone writes an sql script to provide this functionality. Then it turns out that a freshly created database using the latest schema is subtly different from one that was created from an older schema and then updated. Things like a column that has a default but only in one of these two cases. Lots of fun, but not really.	cjfd	13.571716	-5.588361	comment	3.0	20.0	1575214419	9.852891
39085995	This an incorrect title.Per this com	This an incorrect title.Per this comment:https://sqlite.org/forum/forumpost/b6f940e87dd28cf8> Fix your code with CASTs instead of complaining about it. You didn't follow the documentationEssentially, the person was using json incorrectly (as per documentation even prior to this release) and now this version of SQLite is causing their incorrect code to not behave as they wanted.But because SQLite doesn’t want to break backward compatibility (even for a prior unknown bug), they are considering persisting the bug as seen here:https://sqlite.org/forum/forumpost/bcec95d836ad4048	alberth	13.642866	-5.6178694	comment	3.0	12.0	1705895623	9.875444
39220305	It seems like there are a lot of ext	It seems like there are a lot of extensions that are being built for sqlite. I would like to use these extensions, but I am skeptical about their support over time. I like sqlite for how freakin stable it is. How do people feel about sqlite extensions?	breadchris	13.606559	-5.576266	comment	3.0	10.0	1706816643	9.822428
39260684	What is the use case for UUIDv4/v7 w	What is the use case for UUIDv4/v7 when bigint is faster and uses less storage space?	maxloh	13.982677	-5.2182565	comment	3.0	15.0	1707137265	-13.665341
39261051	Does this stay compatible with the o	Does this stay compatible with the old uuid column type, as uuidv7() uses the same 128 bit format as gen_random_uuid()?That would mean it's easy to update old apps, as we would only have to change the default value for the columns.	naranha	13.996656	-5.212816	comment	3.0	11.0	1707140107	-13.672426
39261374	"The problem is not ""UUID"" but ""rando"	"The problem is not ""UUID"" but ""random UUID"". The randomness makes it hard to index and query, due to missing locality. UUIDv7 is time-sortable, and so has locality. For details, see for example https://uuid7.com/ - the main reason (for me) is this part: ""Since UUIDv7 is time-sortable, database indexing mechanisms can better optimize the storage and retrieval processes...""."	thomasmg	13.982356	-5.210406	comment	3.0	22.0	1707142343	-13.67489
39261633	There are some nice features of usin	There are some nice features of using UUIDs rather than ints. It's been written about before, a few on the top of my head: Client side generation of ids. No risk of faulty joins (using the wrong ids to join 2 tables can never get any hits with UUIDs, it can with ints).Those two sucks for us right now (planning to move to UUIDs).	cjblomqvist	13.970818	-5.2225037	comment	3.0	11.0	1707143828	-13.646961
39265553	At my company we had a competitor sc	At my company we had a competitor scrape our API for various businesses. One of the fields was an bson ObjectId that represented when the customer entered our system. This unique identifier encodes a timestamp of its creation.Our competitor was able to ascertain, based on that timestamp, when our customers contract was up and was (briefly) able to poach some customers by underbidding us until we corrected this.	spamizbad	13.933341	-5.2083097	comment	3.0	14.0	1707160284	-13.660757
39274334	This makes a strong case, but I've d	This makes a strong case, but I've decided to start every new project with sqlite and not switch until absolutely necessary. If Postgres is the 90% case, then sqlite is the 80% case and is also dead simple to get going and genuinely performant. So when vertical scaling finally fails me, I know I'll be at a wonderful place with what I'm building.	prisenco	13.530704	-5.359872	comment	3.0	72.0	1707228813	-13.29799
39275265	> Postgres suffers from the n+1 prob	> Postgres suffers from the n+1 problem, while SQLite does not.?	tangjurine	13.557904	-5.560706	comment	3.0	10.0	1707233338	9.823909
39300514	Here's one that works entirely clien	Here's one that works entirely clientside via Webassembly - https://sqliteviewer.app/Upload your bloated firefox `places.sqlite` and select `moz_places` and it loads it without a hitch... if you trust the website not to steal your browsing history.Unfortunately sqliteviewer.app is not open source. This one (https://inloop.github.io/sqlite-viewer/) is, though. But it uses a JS reimplementation of sqlite rather than true sqlite in WASM.	creatonez	13.558135	-5.5360217	comment	3.0	15.0	1707389617	9.823358
39322629	But then the DB Team – if you have o	But then the DB Team – if you have one – is responsible for 50 databases, each full of their own unique problems.This will undoubtedly go over poorly, but honestly I think every data decision should be gated through the DB Team (again, if you have them). Your proposed schema isn’t normalized? Straight to jail. You don’t want to learn SQL? Also straight to jail. You want to use a UUIDv4 as a primary key? Believe it or not, jail.The most performant and referentially sound app in the world, because of jail.	sgarland	13.904022	-5.2492585	comment	3.0	16.0	1707528834	-13.6630945
39340864	Not an expert, however (lol) - even 	Not an expert, however (lol) - even if the recommendations here are solid - this doesn't feel like a particularly well-reasoned comparison.IMHO maintaining a large number of files on disk (be it 16m or 1.5b) should be a non-starter (not to mention that zipping them to slightly reduce the count removes one of the benefits of having them in the first place). A database makes sense - as does SOC between generation and distribution if it brings benefit - but immediately writing off SQLite because of write performance[1]? Similarly the arguments against pmtiles feel outdated and ignorant of the developing nature of the protocol (appreciate it's a 2yo post!).OSM deciding on a format here has potential to significantly shape things to come. Hopefully Paul has progressed his thinking a bit since t	somishere	13.54122	-5.5400286	comment	3.0	14.0	1707706329	9.767536
18039303	SQlite is very high quality software	"SQlite is very high quality software, but they use DO-178b ""inspired"" testing process. As far as I know they don't have version of software that is or can be used in safety critical parts despite their boasting.They say in their site that:> Airbus confirms that SQLite is being used in the flight software for the A350 XWB family of aircraft.Flight software does not imply safety critical parts of avionics. It can be the entertainment system or some logging that is not critical."	Nokinside	13.618048	-5.610449	comment	3.0	12.0	1537534395	9.858226
18044994	With Postgres you don't need MongoDB	With Postgres you don't need MongoDB, InfluxDB, or any other trendy thing, Postgres does it all, and better than all the wannabes.	gaius	13.584434	-5.338629	comment	3.0	30.0	1537602601	9.916999
18044733	In fairness, some of this is histori	In fairness, some of this is historical baggage that MySQL got stuck with from it's early popularity.mSQL was a free/low cost SQL database in the early 90s. Originally it was an SQL translator built on top of Postgres (that used POSTQUEL). That was too slow (because Postgres had higher system requirements), so a new lightweight engine was developed for it.. and that's what later became MySQL. The point was a lightweight SQL database that ran well on cheap early-90s computers.The compromises to make mSQL fast were inherited by MySQL, and they can't be easily changed without breaking the ecosystem that was developed around mSQL/MySQL.Postgres on the other hand, was a university project in the 80s and 90s being developed on mainframes. It was always a slow moving, cautious project. Yes, it di	rgbrenner	13.526077	-5.41855	comment	3.0	15.0	1537596437	9.860112
18101957	I think the FAQ needs another questi	I think the FAQ needs another question: when should I prefer UnQLite over SQLite? When should I prefer SQLite over UnQLite?	dfabulich	13.631937	-5.581806	comment	3.0	14.0	1538245805	9.813955
18184966	"I was hoping for something like ""don"	"I was hoping for something like ""don't use an AP NoSQL database for storing your financial transactions"". I've always wondered how and why they chose MongoDB."	strken	13.670189	-5.330875	comment	3.0	15.0	1539180568	9.881779
29725332	I'm not OP but a guess would not be 	I'm not OP but a guess would not be that it's because it is MongoDB, but because of the license MongoDB has, which will put some restrictions to your usage and also - if you are going to provide services to a 3rd party - will require legal assistance.	chrisandchris	13.741538	-5.185582	comment	3.0	12.0	1640789864	9.928336
29725342	MongoDB is web scale, not universe s	MongoDB is web scale, not universe scale.	horstmeyer	13.683167	-5.322145	comment	3.0	13.0	1640789941	9.892522
29727540	It's interesting how much contempt p	It's interesting how much contempt people have around here for one of the most successful open source oriented companies in recent memory.Most of the bad things about MongoDB are actually bad things about the NoSQL fad, and that fad was huge around here a few years ago.	api	13.702566	-5.3448377	comment	3.0	10.0	1640800721	9.895382
29728439	What would a managed sqlite even loo	What would a managed sqlite even look like?  I can't tell if this is a real response or not...	cheeselip420	13.619487	-5.578724	comment	3.0	12.0	1640804158	-4.955541
29728857	SQLite hides a ton of complexity tha	SQLite hides a ton of complexity that lives in the filesystem. It’s incredibly hard to do robust IO correctly with the APIs we have.I almost always choose SQLite for persisting to disk over JSON files. It essentially removes a large class of bugs and is robust enough that I’m not worried about introducing new problems.	klysm	13.539368	-5.5727825	comment	3.0	19.0	1640805781	9.771596
29808480	Is it really true that concerns arou	Is it really true that concerns around UUIDs as primary keys are wholly irrelevant? Maybe I'm working off outdated information but in high scale environments there are a lot of downsides primarily related to the random write patterns into B-trees causing page splitting and things like that.	hderms	13.991488	-5.216156	comment	3.0	11.0	1641388558	-13.663023
29850139	If you order the data based on the u	If you order the data based on the uuid and your uuid is randomly distributed, then you will almost always be writing the data in the middle of your table, physically. You can cut the impact somewhat by using spare tables (leaving lots of empty space) but eventually you'll be re-writing the data.SQL Server has a sequential uuid type which avoids exactly this problem.	radicalbyte	13.979835	-5.219085	comment	3.0	14.0	1641635547	-13.679051
29850295	I am very much not a database person	I am very much not a database person, so forgive me if this is a dumb question.I'm reading this article and it says that UUID are compared byte by byte, and seems to be indicating they're stored as string. Is that actually the case? I would have assumed that SQL supported 128 bit ints, but this seems to imply it does not.Another question: if a column is set to char(fixed size) do the various sequel engines really not optimise to do multi word comparisons? (e.g. 8byte at a time, then 4, 2, 1, as size requires)	olliej	13.976806	-5.2177935	comment	3.0	12.0	1641637505	-13.658103
29850479	Yeah. The main problem is people usi	Yeah. The main problem is people using them as primary keys in naïve systems like relational databases. You can't just expect a relational database to magically become a distributed system just by using UUIDs. There is a bit more work to do than that.	globular-toast	13.961539	-5.223824	comment	3.0	21.0	1641639300	-13.660423
29853271	I use crockford 32 to _represent_ my	I use crockford 32 to _represent_ my UUIDs, but they are obviously stored as binary. Is the only problem with UUIDs that sometimes they get stored as strings?The only issue I've had with UUIDs is when they don't sort in increasing chronological order. RDBMSs don't appreciate high insert loads into random points in the index. Take care of that, however, and they're a treat.	pkulak	13.980782	-5.2156024	comment	3.0	11.0	1641659767	-13.669895
29854010	This article talks about random IDs 	This article talks about random IDs leading to page thrashing, and MySQL b-tree indexes not handling them well. They are bad for _MySQL performance_.It doesn't talk about NoSQL or sharding, where random IDs usually perform much better than sequential due to a lack of hot shards.If you distribute your reads and writes at random across N machines you can get ~Nx performance vs one machine. If you make your writes sequential, you'll usually get ~1x performance because every insert goes to the same machine for this second/minute/day, then rolls to a new one for the next period. There are sharding schemes that can counter this, but they require insight into your data design before implementation.	web007	13.800295	-5.2516947	comment	3.0	24.0	1641663561	-13.669454
29855123	I never understood why people would 	I never understood why people would use sequential UUIDs. That rather defeats the purpose of a UUID. If you need something sequential then just use a much more simple number	inetknght	13.985646	-5.2126894	comment	3.0	19.0	1641669546	-13.664964
29855240	Because simple integers are not univ	Because simple integers are not universally unique, a major feature of UUIDs…	rco8786	13.989551	-5.211162	comment	3.0	16.0	1641670256	11.361083
29866097	SQLite Strict Tables	SQLite Strict Tables	cristoperb	13.640387	-5.6059065	story	3.0	46.0	1641753760	9.847896
29919302	Enhance it with the fact you can laz	Enhance it with the fact you can lazy load sqlite query using HTTP Range as demonstrated in: https://news.ycombinator.com/item?id=27016630	yonixw	13.578531	-5.5554976	comment	3.0	11.0	1642071318	9.835998
29967521	Do you have any additional resources	Do you have any additional resources about this model of thought? It's like Redux on steroids lol. I wonder if anybody has done a SQLite-as-the-Store pattern library for front end apps before. I'd use the hell out of that!	freeqaz	13.565249	-5.525082	comment	3.0	10.0	1642433449	9.810704
29975267	Your comment is borderline flamebait	Your comment is borderline flamebait with that intro, making me wonder if you're just trolling...Anyway, to start of: why would you want a connection manager Middleware for a pet project? Do you honestly expect to need hundreds/thousands of simultaneous db connections?The original replication does exactly what it was supposed to, but is not what developers often think they want, which is clearly the reason for your outrage. Clustering isn't easy, as mongodb continues to prove to day by making creation of them easy but then catastrophically fail in production under load as the countless post mortems show. I really doubt you're going to need it anyway for a pet project....	y4mi	13.595226	-5.2850423	comment	3.0	11.0	1642481629	9.871481
29989445	See also the Code of Ethics: https:/	See also the Code of Ethics: https://sqlite.org/codeofethics.html	Georgelemental	13.673259	-5.602282	comment	3.0	20.0	1642561690	-8.889039
29989711	Has anyone heard of any issues using	Has anyone heard of any issues using SQLite in jurisdictions without a concept of the public domain? The copyright page [1] seems to imply that you'd need to buy a license from Hwaci.[1] https://www.sqlite.org/copyright.html	DylanSp	13.6328335	-5.5763063	comment	3.0	23.0	1642563863	9.881801
30070499	Yes, it's pretty surprising that Mon	"Yes, it's pretty surprising that MongoDB has gotten by without change when even ""master repository"" had to go. What's seen as offensive online is very US-centric, I knew that, but I didn't know mongo wasn't a well-known slur in the US.People with Down's syndrome used to be called ""mongoloids"" because they were thought to have Asian-looking eyes (epicanthic folds), so calling someone ""mongo"" or ""mong"" is basically an extra racist way of calling someone mentally retarded."	vintermann	13.707122	-5.307439	comment	3.0	12.0	1643108733	-4.457802
30073899	Do you have any tips load-balancing 	Do you have any tips load-balancing or horizontal scaling of SQLite if you have to have a 2nd server for whatever reason?	rexreed	13.569208	-5.4606085	comment	3.0	16.0	1643128576	9.781621
30075482	I'll be honest, I would consider run	"I'll be honest, I would consider running SQLite in production, at least for my personal stuff, but the part that scares me is that there's no ""managed SQLite"" offering and I would have to manage it myself. Litestream seems like a great option for people like me, but I'd like to hear some experience report on it, especially on more complex case, and how it fails.Another problem (which Litestream might solve) is that SQLite is not compatible with Heroku, that I use since I don't have much ops/sysadmin experience. I feel like people saying that SQLite makes things easier often have already some experience in sysadmin/ops stuff, which isn't my case.This is not a criticism of SQLite in any way, just an expression of my own limitations and why it makes it harder for me to consider SQLite. I'll g"	Zababa	13.585585	-5.5410075	comment	3.0	15.0	1643134136	9.811214
30121443	I just refactored my whole app from 	I just refactored my whole app from MongoDB to DGraph... Guys I really like this idea I don't want to abandon it. What should I do: eat section 13 of Mongo's license, or try to maintain a database server myself?	danhab99	13.715905	-5.242832	comment	3.0	14.0	1643409548	9.888838
30133686	use go-sqlite3 to work with sqlite3 	use go-sqlite3 to work with sqlite3 is one choice.https://github.com/etcd-io/bbolt is another pure go option.cznic seems like an alternative to bbolt. nice to have some options.	synergy20	13.60367	-5.5944085	comment	3.0	14.0	1643513782	9.83317
30145514	Mongo for years defaulted to being o	Mongo for years defaulted to being open to the internet, with no authentication.	Sebguer	13.731072	-5.255746	comment	3.0	10.0	1643614917	10.003192
30164386	I am surprised how low postgres rank	I am surprised how low postgres ranks in those trends. I guess I have been in an echo chamber for too long, because my perception was that it was much more pervasive.	lbhdc	13.531448	-5.3646364	comment	3.0	30.0	1643731627	9.82461
30164973	Is MariaDB code base a fork of MySQL	Is MariaDB code base a fork of MySQL, seems a good business to sell something twice. I would have expected him to have a non-compete after selling it the first time. Anyone know how he pulled this off?	rr808	13.5198555	-5.420925	comment	3.0	12.0	1643733233	9.893993
30169252	"Care to elaborate on ""couchdb has fa"	"Care to elaborate on ""couchdb has fallen out of favour""? Currently evaluating it for the very case you describe"	rom99	13.619622	-5.198118	comment	3.0	10.0	1643749555	9.706454
30208963	It seems straightforward to just enu	It seems straightforward to just enumerate every setuid program that ships on the vast majority of distros and check for this issue and patch what's there. That seems like the simplest approach with no concern for breaking anything.Also, a sysctl for rejecting the call would seem reasonable.	staticassertion	13.966668	-5.2279224	comment	3.0	24.0	1643992277	-13.641545
30289405	Postgres wire compatibility does not	Postgres wire compatibility does not imply Postgres compatibility.I recently got bit by this, I wanted to convert a mail address database from MySQL Galera to CockroachDB, because CockroachDB was just a bit easier to deal with.Unfortunately, Cockroach only support UTF-8, and Postgres only supports LATIN1 for the database (compiled into code).  I believe that there are reasons for both sides to make this choice, unfortunately it turned what I hoped would be a slam dunk into a round peg in a square hole.	linsomniac	13.532463	-5.35067	comment	3.0	10.0	1644513560	9.846654
30314798	If you only care about storing data 	If you only care about storing data and not doing any complex operations or query against it why are you using something like sqlite as well?It’s not a comparison as being in sqlite makes the ability to access this data significantly easier. This is comparing apples and dogs and i don’t see the merits.	bogota	13.56864	-5.5593057	comment	3.0	27.0	1644689094	9.847733
30369175	We've been using SQLite for 100% of 	We've been using SQLite for 100% of our data persistence needs for the last ~5-6 years now. Our largest single environment is probably getting close to 500gb total size. Hundreds of concurrent users are no problem for us, even without these enhancements (we use WAL currently).The biggest single trick I learned was to use 1 sqlite connection instance for the entire lifetime of the application. You can add orders of magnitude more throughput with this path. SQLite serializes writers by default so dont duplicate the effort. You can even use the RETURNING keyword to grab insert keys without needing to lock over LastInsertRowId.We also are close to 100% of business logic being executed via SQL queries as well.	bob1029	13.542647	-5.497122	comment	3.0	21.0	1645068043	9.769253
30394468	I looked, but it seems to run on SQL	I looked, but it seems to run on SQLite. Makes me a bit concerned about scalability.	freen	13.588132	-5.5497355	comment	3.0	11.0	1645245572	9.842896
30399223	Yes, I could have used Mongo, but it	Yes, I could have used Mongo, but it would have been 100x to 1000x slower than an mmap-ed look up table.	fxtentacle	13.655006	-5.32611	comment	3.0	21.0	1645295064	9.883522
30434852	> Enhancements to date and time func	> Enhancements to date and time functions…What’s the rationale for SQLite not having a date/time data type?	tiffanyh	13.586273	-5.596548	comment	3.0	17.0	1645569361	9.889933
30438880	> why go through all the trouble of 	> why go through all the trouble of reinventing the wheel?Because now you depend on an UUID library and its attack surface.In some environments it is crucial to reduce dependencies.	danuker	13.95619	-5.2108846	comment	3.0	12.0	1645604349	-13.659259
30637778	I would just like to warn people tha	I would just like to warn people that you shouldn't use this in any production or client-facing app, it's trivial for a malicious actor to change the SQL and drop your database or whatever.If you need to access a sqlite database remotely, try https://github.com/rqlite/rqlite, it offers clustering on top of a basic SQLite database as well as a HTTP(s) API.	Cthulhu_	13.585466	-5.532415	comment	3.0	11.0	1646988738	9.833476
18273710	> Speak no useless words or words th	> Speak no useless words or words that move to laughter.Aww here goes my entire social coping strategy.That being said: this is a stab at Linux CoC? I can see the humour in it but... Seems unprofessonal for a project as SQLite?	apexalpha	13.628228	-5.5813336	comment	3.0	14.0	1540207370	9.856872
18273740	Discussion on the sqlite-users maili	"Discussion on the sqlite-users mailing list:http://sqlite.1065341.n5.nabble.com/Regarding-CoC-td104277.h...From Richard:""Yes.  Clients were encouraging me to have a code of conduct.  
(Having a CoC seems to be a trendy thing nowadays.) So I looked around and came up with what you found,  submitted the idea to the whole staff, and everybody approved."""	chippy	13.641436	-5.592938	comment	3.0	39.0	1540207619	9.868667
18284747	Mongo works well as a straight-up JS	Mongo works well as a straight-up JSON store for store-and-retrieve use cases (with no analytics). It is horizontally scalable, avoids the overhead of relational databases, has indexing capabilities, and provides a strong consistency model. The big improvement came with WiredTiger, which addressed many of the issues that plagued earlier versions of Mongo.I've seen high-speed machine data stored in Mongo for logging and visualization purposes. It's an improvement over writing csv files to disk.However, if you ever need to perform non-trivial analytics, Mongo's weaknesses quickly become obvious. For machine learning, typically you would want to first ETL the data into a dataframe-like structure (which is a structure native to SQL databases).	wenc	13.648876	-5.341968	comment	3.0	13.0	1540311753	9.87902
18284769	"db.webhooks.find({ 
  ""events"": {
  "	"db.webhooks.find({ 
  ""events"": {
    $exists: true, 
    $ne: [],
    $elemMatch: { ""links.cancelInvoice"": {$exists: true}}
  }
})What is this, I don't even. Mongo is a huge pain when it comes to searching nested arrays. And above is just an array in an object, not multiple levels of nesting. I have to re-learn the syntax every time I pick it up.Other than that, it worked great for allowing users to build completely custom forms."	madeuptempacct	13.660045	-5.361889	comment	3.0	13.0	1540311867	9.91064
18287015	> This interpretation hinges on inte	"> This interpretation hinges on interpreting successful sub-majority writes as not necessarily successful: rather, a successful response is merely a suggestion that the write has probably occurred, or might later occur, or perhaps will occur, be visible to some clients, then un-occur, or perhaps nothing will happen whatsoever.> We note that this remains MongoDB’s default level of write safety.This sounds pretty scary. How does it compare to other distributed dbs, like Riak? My understanding is that Riak lets you specify how many nodes a write must succeed on to be considered successful. Are its responses more reliable? Is this just a ""distributed computing is hard"" situation?"	nathan_long	13.588526	-5.2400956	comment	3.0	20.0	1540325701	9.844086
18301853	MongoDB made some very sketchy, undo	MongoDB made some very sketchy, undocumented (or poorly documented) technical decisions in its early years that placed data at great risk.It's better now, but very few things worry technical people more than a database that loses data. It's hard to get past that early impression.	macintux	13.644721	-5.3215756	comment	3.0	14.0	1540482760	9.863896
18313475	Are the SQLite developers monks and 	Are the SQLite developers monks and nuns?	craftyguy	13.644836	-5.5909066	comment	3.0	11.0	1540597137	-8.493607
18313543	This is sad. It is clear that the SQ	This is sad. It is clear that the SQLite creator's heart was with the previous version of the CoC, and that although the CoC was only obligatory for developers, other people from outside came and forced their politics on the owners of the project.	radiator	13.634149	-5.5870566	comment	3.0	10.0	1540598031	9.872723
18352235	Do I understand it right, that whate	Do I understand it right, that whatever a project I build using MongoDB (i.e. any website/app that uses a MongoDB instance as a backend to store data directly or via a middleware layer or has a feature of connecting to MongoDB) I must open-source it completely? This feels a way too radical if so.	qwerty456127	13.718447	-5.215099	comment	3.0	13.0	1541062869	-13.006236
18393715	This might be a stupid question, but	This might be a stupid question, but what is the advantage of this solution over an in-memory sqlite database?	moolcool	13.588938	-5.5536675	comment	3.0	13.0	1541529722	9.726406
18405996	I'd love to hear from someone who ha	I'd love to hear from someone who has done a thorough evaluation of TiDB vs CockroachDB for production purposes.Anyone out there?	the_duke	13.674801	-5.205404	comment	3.0	10.0	1541682848	10.021301
18432735	Thanks :) You're exactly right, whic	Thanks :) You're exactly right, which is why it'll support SQLite by v1.0. Again this came out of our hosted platform, so there's still plenty to do to make it easy for self-hosting. But the goal is an entirely self-contained binary -- upload it, run, and you're online.	thebaer	13.589538	-5.5441847	comment	3.0	11.0	1542032725	9.861925
18460089	Release notes here: https://access.r	Release notes here: https://access.redhat.com/documentation/en-us/red_hat_enterp...For those that matters, MongoDB is not included because it uses Server Side Public License: https://access.redhat.com/documentation/en-us/red_hat_enterp...	pksadiq	13.727832	-5.1999903	comment	3.0	35.0	1542296520	9.919022
18465042	sqlite famously squeezed out a ~40% 	sqlite famously squeezed out a ~40% performance improvement (I think from v3 to v4?) by just combining tons of micro-optimizations of this kind where it wasn't obvious if each change even made an improvement. They measured the performance with cachegrind in order to identify very small improvements that get lost in the normal measurement noise.	eloff	13.585158	-5.5451536	comment	3.0	10.0	1542328582	9.785806
18499340	> encode a unique key which points t	> encode a unique key which points to a record of the desired size in some databaseI'm sure you understand why this is not going to work the same way as reading the actual public key. Not only it needs a network, but it also is susceptible to stealing the values from the database by just generating the (short) unique keys.	nine_k	13.849655	-5.2377286	comment	3.0	11.0	1542761918	-13.619425
18556286	I was wondering, quite unrelated to 	I was wondering, quite unrelated to the article, if anyone knows if CockroachDB would be suited for small databases (and comparably modest computing/memory resources). I very much like its distributed properties, but only have a simple table of usernames and corresponding cryptographic material. Is CRDB easy to run and manage?	Confiks	13.646184	-5.2076855	comment	3.0	12.0	1543444225	9.90895
18611078	> If they got their clustering story	> If they got their clustering story to be as easy as MongoDB's was 5 years agoYou must have been using a different mongodb than I did.	chmod775	13.690231	-5.3125954	comment	3.0	10.0	1544035023	9.914411
18685610	Maybe related to https://www.sqlite.	Maybe related to https://www.sqlite.org/src/info/8576ccb479fc4b76 ?Edit: Yes, this is probably it.	testplzignore	13.6269045	-5.5821743	comment	3.0	10.0	1544827679	9.849533
18686695	Right.  The actual standard is calle	"Right.  The actual standard is called ""modified condition/decison coverage"" or MC/DC.  In languages like C, MC/DC and branch coverage, though not exactly the same, are very close.Achieving 100% MC/DC does not prove that you always get the right answer.  All it means is that your tests are so extensive that you managed to get every machine-code branch to go in both directions at least once.  It is a high standard and is difficult to achieve.  It does not mean that the software is perfect.But it does help. A lot. When I was young, I used to think I could right flawless code.  Then I wrote SQLite, and it got picked up and used by lots of applications.  It will amaze you how many problems will crop up when your code runs on in millions of application on billions of devices.I was getting a stea"	SQLite	13.646945	-5.6227508	comment	3.0	12.0	1544841518	9.859744
18686305	It is very likely that this bug only	It is very likely that this bug only affects systems which accept and run arbitrary SQLite3 queries. This includes Chromium, because Chromium ships with WebSQL. The Google Home is probably vulnerable because it can be coerced to load a webpage. I doubt that this bug affects systems that merely use SQLite as a database without providing external query access.My best guess for the bug is that arbitrary SQLite queries, prior to 3.26.0, were permitted to write to the shadow tables used by various plugins to implement features. fts3/4, prior to 3.25.3, appear to contain an integer overflow bug which can be triggered by manually modifying the fts index data. A careful application of this integer overflow appears to make it possible to truncate a writable buffer, leading to a nice heap overflow c	nneonneo	13.584176	-5.5562	comment	3.0	14.0	1544835382	9.805994
18685757	SQLite can by principle not suffer f	SQLite can by principle not suffer from a RCE.	blattimwind	13.621578	-5.580116	comment	3.0	34.0	1544828947	9.840988
18717643	I’m not really sure they articulated	I’m not really sure they articulated why they had to switch very clearly. They didn’t like managing Mongo. They said they couldn’t use Mongo’s hosted solution BUT they switch to hosted Postgres. Why not just overcome the limitations preventing them from switching to hosted MongoDB?	tekmaven	13.698946	-5.3052053	comment	3.0	27.0	1545241945	9.877995
18718154	I never got around to using Mongo as	I never got around to using Mongo as my main doc db because it was incredibly hard to find a management tool.I now use json supported functions in SQL Server and do not have the need for a different type of database. SQL Server handles my small 'documents db' implementation with the infrastructure of a RDMS. Win win for me.To me Mongo just got popular by mistake way too early. It's like having a celebrity retweet your post because they liked what they saw at the time, exposing you to the world where everyone now thinks you have something important to say. Not surprisingly, you don't!	SonnyWortzik	13.65408	-5.3322573	comment	3.0	22.0	1545245294	9.897677
18718553	Those companies did not create PG, t	Those companies did not create PG, the company behind Mongo did and does not want Google / AWS / MS to make a service using Mongo for free.	Thaxll	13.7256565	-5.217985	comment	3.0	12.0	1545247522	9.932045
18719036	I don't have any links to prove my p	I don't have any links to prove my point but I suspect we need to thank Mongo for pushing the traditional SQL databases to support JSON.	mmsimanga	13.5797205	-5.4402285	comment	3.0	14.0	1545250027	9.814187
18717600	As a reminder, PostgreSQL is distrib	As a reminder, PostgreSQL is distributable under a license that's basically BSD/MIT: https://www.postgresql.org/about/licence/MongoDB, on the other hand, recently changed their license to an abomination that many people think is no longer Free: https://news.ycombinator.com/item?id=18301116	kstrauser	13.69442	-5.2348657	comment	3.0	17.0	1545241689	9.919969
18719650	I really don't get this as an indict	"I really don't get this as an indictment of MongoDB, or their OpsManager product really.They used the version of OpsManager that doesn't manage the deployment - is specifically not a deployment manager.  Mongo does offer a managed version of this software, which the author mentions - with a justification for why they couldn't use that offering.  However, I think this was the main mistake that The Guardian made.  As the author notes: ""Database management is important and hard – and we’d rather not be doing it ourselves.""  They underestimated the complexity of managing database infrastructure.  If they had been attempting to set up and manage a large scale redundant PostgreSQL system, they would have spent an enormous engineering effort to do so as well. Using a fully managed solution - like"	idbentley	13.689923	-5.2780814	comment	3.0	12.0	1545253753	9.919589
18720561	I have seen so many critical article	I have seen so many critical articles of Mongodb. Even if I did have a use-case particularly well-suited for it, I would never consider using Mongo.As an aside, I did consider using SQL Server until I looked at the licensing fees. Why would someone choose SQL Server when options like Postgres or MySQL/MariaDB exist? Is there a specific SQL feature (MSSQL or Oracle SQL) provides which is not available elsewhere and would be a core feature which the companies data storage is built upon? I.e. that feature is so important that the companies product architecture would be fundamentally different without using the proprietary database.	vonseel	13.632114	-5.308727	comment	3.0	11.0	1545259273	9.877577
18750200	> SQLite is likely used more than al	"> SQLite is likely used more than all other database engines combined. Billions and billions of copies of SQLite exist in the wild. SQLite is found in:> Every Firefox, Chrome, and Safari web browserWhere is SQLite in Firefox? It would be wonderful to use SQL in the browser, on the server, in mobile devices (everywhere!), but alas I suspect SQLite can be ""found"" in Firefox as the underlying storage engine on top of which IndexedDB is built.Dammit Mozilla, set SQLite free!"	virtualwhys	13.578389	-5.541714	comment	3.0	12.0	1545623530	9.779017
18755981	> The only way to read an SQLite fil	> The only way to read an SQLite file is using SQLiteThis part unfortunately isn't a position, it's absolute. It's hard to imagine a situation where as a developer we would not have access to a C runtime or for any reason whatsoever would not be able to use SQLite, but the hard dependency on its code is real, and represents a real hazard in the wrong environment. A super easy example would be parsing data on say, a tiny microcontroller on an IOT device. This can start to hurt quickly:> Compiling with GCC and -Os results in a binary that is slightly less than 500KB in sizeOpen formats at least give you the option of implementing whatever minimal hack is necessary to finish your job without say, introducing some intermediary to do an upfront conversion, and at least for this reason SQLite ca	_wmd	13.5972185	-5.5896544	comment	3.0	10.0	1545713629	9.835467
18771701	If you need lexicographically sortab	If you need lexicographically sortable uuids, you have a very different problem.	sharpercoder	13.97973	-5.2170963	comment	3.0	13.0	1545937889	-13.683697
18839630	Because C has no package system and 	"Because C has no package system and it sucks, and having a single file (ideally with no dependencies, which isn't the case here) makes it super easy to integrate it anywhere.A good example of that IMO is cJSON[1], it's a small self-contained single file implementation of a JSON reader and parser. It's easy to use, the code is pretty clean and easy to follow and I never ran into any obvious limitation. I very much recommend it.There are also projects that are developed as multiple files but amalgamated into a single huge file before release. SQLite does that: https://sqlite.org/amalgamation.html> Over 100 separate source files are concatenated into a single large files of C-code named ""sqlite3.c"" and called ""the amalgamation"". The amalgamation contains everything an application needs to emb"	simias	13.590711	-5.5752497	comment	3.0	15.0	1546798278	9.822065
18869971	seems an obvious response to https:/	seems an obvious response to https://www.mongodb.com/press/mongodb-issues-new-server-side...	notmyname	13.717214	-5.3051567	comment	3.0	16.0	1547075489	9.913055
18870051	Out of curiosity, what use cases did	Out of curiosity, what use cases did you have for CouchDB that weren't feasible with MongoDB?	anonytrary	13.619239	-5.2135944	comment	3.0	14.0	1547076112	9.703729
18870982	There's no secret formula to stop pe	There's no secret formula to stop people from competing with you. If MongoDB Inc is successful, it should be because they run a good document-database-as-a-service people want to use, not because they earn indefinite seigniorage from launching a popular open source project.	SpicyLemonZest	13.719445	-5.2234807	comment	3.0	13.0	1547086686	9.909238
18903641	I think it is too bad. Almost all br	I think it is too bad. Almost all browsers except for Firefox use Chromium (blink) as their browser engine. That means that a bug in Chromium is a bug in almost all browsers, and design decisions in Chromium impact the entire web ecosystem.I agree with your above comment, and we can argue that working on a single web-engine might lead to less duplicated work for Front-End devs, and less bugs in the web overall.Given that sqlite is the most widely deployed DB already, making it part of web browsers doesn't seem like a huge deal to me. https://www.sqlite.org/mostdeployed.html	vandorjw	13.542632	-5.5363693	comment	3.0	11.0	1547479655	9.804988
18920047	> The installation instructions I've	> The installation instructions I've always followed for MongoDB start with importing a key, and adding their official repo to my source list.Going with the maintainer's repo means that you trust the maintainer with providing security updates for the version you have installed or you trust them with providing a useable upgrade path.If you go with a distro package, you will get both the benefits of security updates for the lifetime of the OS itself and the benefits of the underlying software not changing.Of course it also means that you don't get new features for the lifetime of the OS.So depending on your target usage of MongoDB, you either would want to go with the OS packages (if MongoDB is just a dependency of a dependency and you don't really care about its functionality aside of it be	pilif	13.717276	-5.3077326	comment	3.0	25.0	1547639700	9.935026
18920220	>Going with the maintainer's repo me	>Going with the maintainer's repo means that you trust the maintainer with providing security updates for the version you have installed or you trust them with providing a useable upgrade path.Why should that be a problem if you use the official repo, handled by MongoDB themselves?	iqy	13.720587	-5.2404	comment	3.0	17.0	1547641801	9.932008
17218761	What exactly is the benefit of using	What exactly is the benefit of using sqlite over mysql in this case?Is the 10-15 minutes you might save looking up a quick setup tutorial for the system provided packages really worth the later problems? Postgres is slightly more complex (but pays for itself with additional capabilities), so I can see avoiding that unless your are already familiar with it.As for PHP, at this point it's not really any easier or harder to get up initially then Python, Ruby or Perl, so it really comes down to personal experience. Whichever one you know best, use it. Whichever framework you know best that has some solutions for what you want to do, use it. That will be quickest.	kbenson	13.555393	-5.502191	comment	3.0	11.0	1528018942	9.860604
17265712	I suspect the intent would be an ext	I suspect the intent would be an extension of the idea of using SQLite as the base for a custom binary file format.  One use case might be to embed non-code resources (graphics, audio, localization strings, etc.) such that they can be easily queried and loaded via SQLite instead of some other method.	yellowapple	13.586243	-5.5772476	comment	3.0	11.0	1528468068	9.839687
17266348	For a bit of context, in the Tcl eco	"For a bit of context, in the Tcl ecosystem there's the concept of ""Starkits"" which are executable scripts which contain a stub loader which mounts a virtual filesystem archive (which contains all the files the actual script needs to run).Typically this has been either a Metakit database or a Zip file, but they both have disadvantages when compared to SQLite and we've been wanting to move to SQLite for a while but it didn't support being appended to things, so we couldn't.  At the most recent Tcl Conference DRH agreed to fix this and with this change it looks like he has done it.  Expect an SQLite-backed Starkit soon !Also, and unrelated, Starkits can be converted to ""Starpacks"" which replace the script-based stub loader with a native executable, so you can distribute Tcl-based scripts as a"	rkeene2	13.599248	-5.578515	comment	3.0	24.0	1528471482	9.811025
17272617	Oh yeah. SQLite is incredibly versat	Oh yeah. SQLite is incredibly versatile and for most web applications it's more than enough. The only pain point I have with it is that all data is stored as a string no matter the table schema types specified, this can lead to some bugs, but if you have a good library in your language for SQLite then it's not a problem.	dom96	13.549052	-5.5945997	comment	3.0	19.0	1528545863	9.828458
17393198	MongoDB represents to me a very good	MongoDB represents to me a very good way to build a product. There has always been so much derisive criticism about MongoDB opting to prioritize convenience of customer workflows above all else, and to go back and add best practices, basic data safety, etc., on a piecemeal basis after the fact. Customers are surprisingly willing to put up with problems as long as usability and user experience is high, and they will wait for other features. Meanwhile, plenty of other database projects may start out with a more deliberate focus on classical database safety and guarantees, yet hardly build any customer base.Even though I may like e.g. Postgres features more, there is still something to be respected about how MongoDB has operated, and the constant vitriol about their chosen priorities has alwa	mlthoughts2018	13.670845	-5.320395	comment	3.0	16.0	1529940893	9.887275
17439041	Others are sharing out of the box so	"Others are sharing out of the box solutions.But I will say that many moons ago when I did actually write stuff for Mongo. The oplog was a god send. You can ""tail"" the oplog, and get every transaction in near real time. We used this for updating Elasticsearch indexes etc in what is basically realtime, without having to poll or modify existing code at all."	mindingdata	13.553037	-5.278444	comment	3.0	11.0	1530500117	9.853836
17439628	You are completely contradicting you	You are completely contradicting yourself.On one hand you complain about using technologies before you have done a prototype and evaluated the product. Then you blindly tell startups to just use MySQL/PostgreSQL without having any idea of their use case or whether it matches their query patterns.If you are a startup the right way to go is to document your use case, understand what queries those use cases demand and then find the right database that satisfies it e.g. don't pick MongoDB if you are doing lots of joins and don't pick PostgreSQL if you are doing wide-table feature engineering type analytics.Right tool for the right job.	threeseed	13.536148	-5.3409123	comment	3.0	20.0	1530511627	9.851774
17497372	These are fundamentally different da	These are fundamentally different database technologies. Postgres is a powerful SQL based store while Mongo was originally built around the idea of a write never failing.Postgres tends to keep a speed edge but the jsonb syntax is awkward and some operations can be trickier for a developer to navigate. Scaling uses traditional sql strategies.Mongo has a pretty nifty query language but more difficult queries start becoming quite slow. Scaling is a bit different then Postgres.Like any tech choice, it's not about what is vogue or trendy but what best fits your problem space.	vorpalhex	13.572518	-5.3578978	comment	3.0	11.0	1531225319	9.834346
17497641	Maybe not Mongo itself but schema-le	Maybe not Mongo itself but schema-less NoSQL databases are very useful for Data Hubs that integrate many different data sources. If you work as I do on a team that has 100+ members, trying to integrate 25 billion documents with 30+ datasources and 60+ APIs, then a schema-less database where you can more flexibly handle changes to the document model (which are happening every day) is ideal. Trying to build that in MySQL would be a disaster.	rjkennedy98	13.626301	-5.349393	comment	3.0	11.0	1531227678	9.86958
17497848	It's funny to see these things come 	It's funny to see these things come around and go around.~1998, there were quite a few megabytes burnt on discussing Postgres vs. MySql.  At the time, MySQL was not ACID compliant, and was (rightly) derided as a database shaped object, but not an actual database.  It was faster, provided you didn't need get back the same data you put into it.MongoDB seems to be in a similar situation.  Under the right conditions, it can be ACID compliant.  But it's a database shaped object.  As a developer, you have to actively manage aspects of your data that should be handled by the database itself.Every MongoDB project I've touched has run into a schema version issue.  Sure, you can put freeform data into Mongo.  But when you're querying your database, will a record made yesterday have the same shape as	tonious	13.600308	-5.374361	comment	3.0	11.0	1531229326	9.919415
17505208	Show HN: pgmongo - Drop-in replaceme	Show HN: pgmongo - Drop-in replacement for MongoDB using Postgres	thomas4019	13.57214	-5.3766503	story	3.0	24.0	1531296019	9.915798
17523132	> I think NoSql, especially things l	"> I think NoSql, especially things like Mongo, got popular because it is super easy to program with javascript.NoSQL caught on because of what it doesn't do: attempt to implement the relational model.A lot of people were using MySQL in infamous LAMP stacks to set up websites with virtually no business logic.So you had:1. An application that didn't need the relational model
2. A DBMS that had a very poor implementation of SQL, which itself is a poor implementation of the relational model
3. A large community who didn't know anything about database theory.When you're using MySQL as a glorified hashtable, you get none of the benefits of the relational model, and all the downsides.From their understanding of the technology, throwing all that out made a lot of sense. It's pretty reasonable to u"	ben509	13.522284	-5.418385	comment	3.0	14.0	1531491303	9.830512
17540631	Hm...Haskell was an important initia	Hm...Haskell was an important initial choice for us because of our team's comfort with the language and also because it's neat to implement parsers and compilers. The Hasura engine is essentially a GraphQL to SQL compiler :)I'm not sure I understand your point about AGPL? Do you have the same issue with the MongoDB license and would hesitate to use Mongo because of their AGPL? Why is this different? Just curious, would love to understand where you're coming from!	tango12	13.662536	-5.241408	comment	3.0	12.0	1531742955	-13.150942
17620034	MongoDB and Python	MongoDB and Python	bhishan	13.662132	-5.372505	story	3.0	14.0	1532631977	9.868645
17656797	I’d love to know if anyone here has 	I’d love to know if anyone here has done a deep eval of Citus vs CockroachDB. They seem to be the two most promising solutions for horizontal scale-out Postgres and both are under very active development.	hemancuso	13.5729885	-5.255882	comment	3.0	28.0	1533068956	9.82268
17704168	Just today, I finished writing my ow	Just today, I finished writing my own low level go sqlite driver. I haven't published it yet. I really thought there was a need for it.  I hate the database/sql integration that the other drivers have.  Now I'll have to see if my driver has any need to exist.This always seems to happen when I write something.	bvinc	13.624554	-5.6388187	comment	3.0	13.0	1533621568	-5.7660494
17764565	https://www.windowfunctions.com is a	"https://www.windowfunctions.com is a good introduction to window functions.Besides that, the comprehensive testing and evaluation of SQLite never ceases to amaze me. I'm usually hesitant to call software development ""engineering"", but SQLite is definitely well-engineered."	nanimo	13.60052	-5.5914817	comment	3.0	26.0	1534322825	9.848866
17764693	Ditto! For anyone who isn't familiar	Ditto! For anyone who isn't familiar with SQLite's testing procedures, read this[1] fascinating page.The SQLite project has a mind boggling 711 times more test code than SQLite itself has. Put another way, only 0.1% of the project's code is SQLite itself. The other 99.9% consists of tests for that 0.1%.[1] https://www.sqlite.org/testing.html	cosmie	13.653796	-5.6215444	comment	3.0	14.0	1534324979	9.863889
17764714	This is super cool.Does anyone know 	This is super cool.Does anyone know how to upgrade python3's sqlite module to the latest version?	est	13.610226	-5.596635	comment	3.0	10.0	1534325184	9.889122
17769781	I don't understand why you'd use SQL	I don't understand why you'd use SQLite for a deployment this heavy over PostgreSQL or MySQL.  Yes, SQLite is fantastic, but why would you choose to do it this way?	da_chicken	13.585084	-5.5268583	comment	3.0	22.0	1534367138	9.833887
17795961	I wonder if the world couls benefit 	I wonder if the world couls benefit from a SQLite-backed spreadsheet program. All the data type BS would be basically solved.	nerdponx	13.521892	-5.5851507	comment	3.0	15.0	1534709842	-12.218225
17867366	> LiteTree is more than TWICE AS FAS	> LiteTree is more than TWICE AS FAST than normal SQLite on Linux and MacOSX!!!In my experience, claims like these usually end up showing that the author didn't understand the `PRAGMA synchronous` setting at all, or they chose to ignore it to juice their stats.In this benchmarking test are the data durability guarantees the same for both LiteTree and vanilla SQLite?	beardicus	13.596028	-5.5082693	comment	3.0	17.0	1535541971	9.808402
16220284	"> SQLite backend
> Because comments "	"> SQLite backend
> Because comments are not Big Data.For small scale applications, I 100% agree. Sqlite3 is so easy to back up and configure."	NiceGuy_Ty	13.597545	-5.547361	comment	3.0	10.0	1516767534	9.831714
16329196	Adding Context to CockroachDB’s Arti	Adding Context to CockroachDB’s Article “Your Database Should Work Like a CDN”	dantiberian	13.683982	-5.2022004	story	3.0	84.0	1518049701	9.963557
16340646	Are there other macOS apps that can 	Are there other macOS apps that can read both MySQL and SQLite?	wingerlang	13.594687	-5.5573816	comment	3.0	12.0	1518188719	9.832847
16358866	> Sadly, in the browser SQLite has b	> Sadly, in the browser SQLite has been kicked to the curb, replaced by IndexedDBAre you thinking of WebSQL? I don't remember a SQLite interface client-side in any browser. I might be wrong, but I thought IndexedDB was originally implemented on top of SQLite in both Chrome and Firefox. I think Chrome moved to a different backing store, but that has no bearing on the API.	dahart	13.534103	-5.5042586	comment	3.0	14.0	1518446917	9.811683
16359465	I run a complex CRM that handles 1.2	I run a complex CRM that handles 1.2 million USD in transactions every year. It is running sqlite with a simple in-memory cache (just a dict) that gets purged when a mutating query (INSERT, UPDATE or DELETE) is executed. It is simple and fast enough.	michaelmcmillan	13.532136	-5.4798894	comment	3.0	10.0	1518451211	9.75836
16361590	One of my favorite points about SQLi	One of my favorite points about SQLite which hasn't been addressed yet in the comment thread is that its databases are just single flat files. Need to copy data from a server to a local dev machine? No need to log into the server, make a dump, copy the dump file to the local machine, and import the dump. Just copy the database file as you would any other file. That's it.Making a backup before trying something risky (and then restoring the backup when something screws up) is similarly trivial.Maybe to some of you it's not worth that much, but it's a legitimate timesaver in my opinion.	Cyberdog	13.600892	-5.521295	comment	3.0	10.0	1518466170	9.754854
16385018	or not, as the case may be https://w	or not, as the case may be https://www.mongodb.com/compare/mongodb-postgresql	mat_keep	13.634066	-5.3539705	comment	3.0	13.0	1518710431	9.8446
16385541	Its usually only after a while you r	Its usually only after a while you realize almost every piece of meaningful data is relational. It just didn't look that way when the project started. But now you're committed on the wrong database and its very costly to switch back to SQL.Literally every project I saw using MongoDB ended up going back to SQL within the first 2 years after realizing the data is indeed very much relational and theres no clean way to model it using documents.You always end up with either tons of duplication across documents, which is hell to maintain, or tons of multi-document queries with hacks to look ACID, which is also hell to maintain.Sure Mongo makes it easy to prototype applications, but it makes it very complex to build robust and maintainable software. Its especially bad if you think your data isn't	jeremiep	13.598978	-5.384196	comment	3.0	19.0	1518713825	9.858178
16385701	Most software developers have a nega	"Most software developers have a negative impression of MongoDB, based on the many flaws that it had back in 2010. Among the people who did the best job of documenting those flaws, was Kyle Kingsbury, in his Jespen series:https://aphyr.com/posts/284-jepsen-mongodbBut it is important to realize that the team at MongoDB has actually been working with Kingsbury, for several years now, and they have slowly and patiently fixed the problems he identified. Consider how the situation had evolved by 2017:MongoDB 3.4 Passes Jepsen – The Industry’s Toughest Database TestJepsen Evaluation Demonstrates MongoDB Data Safety, Correctness & ConsistencyOn February 7th 2017, Kyle Kingsbury, creator of Jepsen, published the results of his tests against MongoDB 3.41. His conclusions:""MongoDB has devoted signifi"	lkrubner	13.64365	-5.315447	comment	3.0	11.0	1518714989	9.892407
16386297	Mongodb can be quite a nightmare onc	Mongodb can be quite a nightmare once you start requiring anything more than a 1:1 relationship, which is pretty much any kind of app that is doing anything meaningful. Having to resort to doing things like map/reduce for a simple group by / order is not the way to go IMO. I think you later truly realize the beauty of SQL once you get far down that rabbit hole.Initially I rode on the Mongo's NoSQL bandwagon when I saw that you can just save a JSON hash and thought that's the coolest thing in the world. But ever since I tried out Postgres's JSONB, I just can't go back to Mongo anymore. With Postgres, I have the best of both worlds, performance, relational data, and reliability. I don't have to sacrifice any of it. Also, I don't know who codes using raw SQL, it's been years languages have ha	jaequery	13.581763	-5.396275	comment	3.0	14.0	1518719224	9.862514
36584128	So can you just run Django with SQLi	So can you just run Django with SQLite (the default) now, with no special setup? And no data loss? Years ago I tried that when I made a simple web app for a one-off data collection at work. I had maybe 10 users on it and started to encounter concurrency problems. This was about 5 years ago. What's changed since then?	globular-toast	13.599095	-5.5571	comment	3.0	12.0	1688462102	9.88453
36604335	I'm really glad to see this complete	I'm really glad to see this complete solution drop. I've cobbling together sqlite point-in-time restores, automatic snapshots, and S3 backups with litestream and scripts for too long.I've been bugging cloudflare to do this with D1+tunnels since D1 was announced and they constantly seemed confused what I was even talking about.	Spunkie	13.553226	-5.432134	comment	3.0	11.0	1688579933	9.802618
36699946	How does SQLite fare against Postgre	How does SQLite fare against PostgreSQL for this particular use case?	rane	13.570573	-5.534713	comment	3.0	26.0	1689188240	9.835057
36811357	The difference is that you can still	The difference is that you can still use sequential IDs internally, while exposing hashed IDs to the outside. This protects your database from collisions under all circumstances, while in the absolute worst case, a single user might experience bugs because two external IDs collide.	p-e-w	13.928032	-5.2235656	comment	3.0	17.0	1689927400	-13.6393385
36811570	You need it to make database indices	You need it to make database indices perform better.If you don't need that, but just need a random UUID, UUIDv4 is better.	madsbuch	13.980107	-5.213911	comment	3.0	37.0	1689929470	-13.662683
36815268	I’m feeling a bit like an accidental	I’m feeling a bit like an accidental time traveler, because I can recall a conversation at a tech meetup that had to have been at least ten years ago where someone was struggling with unique UUIDs because they were bursting above 1000 UUIDs per millisecond and not happy with the available options.How old is UUID7? I can’t get the internet to tell me.	hinkley	13.991045	-5.2112703	comment	3.0	12.0	1689954615	-13.669932
24494997	Should be fine for reads.  Sqlite.or	Should be fine for reads.  Sqlite.org is dynamic, pulling from sqlite data for ~20% of the pages, and it does fine with HN piling on.  The single threaded would be an issue for writes, but I don't see why they would be doing writes for a page view.  See https://www.sqlite.org/whentouse.html	tyingq	13.594196	-5.5256824	comment	3.0	14.0	1600277508	9.782742
24602160	I'm probably missing something here,	I'm probably missing something here, but is there a reason these toolkits don't require the dev to specify a stable, unique ID for each node? Feels like there's strong precedent with HTML's id attribute and CSS.	mattgreenrocks	13.88473	-5.1922736	comment	3.0	10.0	1601154716	5.487812
24645786	The concept of ULID is interesting, 	The concept of ULID is interesting, but the spec is a bit weird[1]. If you want the benefits of ULID, I'd highly suggest checking out KSUIDs:https://github.com/segmentio/ksuidhttps://segment.com/blog/a-brief-history-of-the-uuid/Same advantages of ULIDs, but I prefer the base62 to the base32 encoding (more compact; no need to bikeshed about upper versus lower case), it's been tested at scale, and the decisions made are sensible.[1]: Specifically, they try and guarantee absolute monotonicity. The way they do this is that if you ever try and generate more than on ULID per millisecond, you increment the least significant bit of the random component. In other words, we have a key that's basically <timestamp>-<random-int>, and if you generate more than one key per timestamp, you just increment t	Lazare	13.969715	-5.215544	comment	3.0	18.0	1601511654	-13.667639
24677422	Native support for complex types lik	Native support for complex types like URLs and UUIDs is a mistake. It just makes it more complicated and harder to interoperate with other formats like JSON. Look at all the archaic types ASN.1 supports.	IshKebab	13.94803	-5.218419	comment	3.0	14.0	1601802477	-13.65461
38601686	Something that wasn't clear to me fr	"Something that wasn't clear to me from the README: how does this handle duplicate IDs?If I have a table with a string primary key and I insert a row in one node with ID ""hello"" and do the same thing (but with different column data) on another node, what happens?"	simonw	13.878929	-5.2293983	comment	3.0	15.0	1702310214	-13.642761
38668492	Asked 11 years ago and still going s	"Asked 11 years ago and still going strong... ""To what extent are 'lost data' criticisms still valid of MongoDB?"" - https://stackoverflow.com/questions/10560834/to-what-extent-..."	belter	13.665714	-5.3066163	comment	3.0	15.0	1702766696	9.860298
38689015	Right: Is the idea here that you use	Right: Is the idea here that you use UUIDs for inserted rows, hence avoiding duplicate inserts?But what happens if multiple updates or deletes target the same existing row?	simonw	13.919018	-5.242691	comment	3.0	11.0	1702937160	-13.660554
38696315	We use it, we know it and can troubl	We use it, we know it and can troubleshoot it if needed, it satisfies our needs and it works. What more do you need?It also works for others, Github for example.The only thing I am missing at the moment is a native UUID type so I don't have to write functions that convert 16bit binary to textual representation and back when examining the data manually on the server.	gog	13.974581	-5.1983185	comment	3.0	20.0	1702997979	-13.637511
38749676	How does it work when indexing uuid 	How does it work when indexing uuid columns?	oggyboye	13.9866905	-5.2178264	comment	3.0	22.0	1703377137	8.635541
38824103	This is my experience as well. A ran	This is my experience as well. A random UUID is best IMO. Even a hash of the user's initial email isn't ideal since salting may not be enough, and others may assume they can safely hash any incoming email.	paulryanrogers	13.983753	-5.209757	comment	3.0	20.0	1704031585	-13.639955
38824447	Whenever WASM SQLite comes up there 	"Whenever WASM SQLite comes up there is discussion as to if it would have been better for WebSQL to have become a cross browser standard.I believe this route with WASM is the correct one. WebSQL would have been tied to one single version of SQLite, with no alternative implementation.With browsers adopting safe low level APIs like WASM and OPFS it enables a much broader range of databases to be available in the browser. We already have SQLite, DuckDB and various vector dbs.OPFS is still under active development, but with some of the changes coming to it in 2024 it's going to become significantly better to use.All of this is part of the enabling tech behind ""local-first"" apps. I'm somewhat biased as I work on ElectricSQL (we sync Postgres on a server to SQLite in the browser), but 2024 is goi"	samwillis	13.579658	-5.5596085	comment	3.0	12.0	1704034517	9.789458
38884003	Since you're willing to write since 	Since you're willing to write since code apparently: have you checked the internal databases? They're just sqlite, moderately understandable at a glance last time I looked.	Groxx	13.595524	-5.5707483	comment	3.0	14.0	1704484746	9.842423
38904007	"So it's the ""Supabase of SQLite""?Are"	"So it's the ""Supabase of SQLite""?Aren't there entire classes of problems that shouldn't exist for SQLite because it's intended to be an embedded database, as opposed to a client/server architecture like Postgres/Supabase?And as such, I'm confused why this exists."	tiffanyh	13.599123	-5.565738	comment	3.0	11.0	1704653666	9.847499
31824192	SQLite's virtual table API (https://	SQLite's virtual table API (https://www.sqlite.org/vtab.html) makes it possible to access other data structures through the query engine. You don't need to know much if anything about how the database engine executes queries, you only need to implement the callbacks it needs to do its job. A few years ago I wrote an extension to let me search through serialized Protobufs which were stored as blobs in a regular database.https://github.com/rgov/sqlite_protobuf	rgovostes	13.576543	-5.5575595	comment	3.0	18.0	1655820904	9.836624
31887035	I'm not religious but I've always li	I'm not religious but I've always liked this; it's fun to think of the SQLite developers as a small monastery. If monasteries can produce beer for the world (see: the Trappists), why not software?	ripley12	13.66789	-5.6005387	comment	3.0	33.0	1656271241	-8.5361595
31887886	The Contributor Covenant is the gold	The Contributor Covenant is the gold standard for a reason: it is a response to the bigotry and harassment problems that were endemic to the open source communities. Alone it doesn't achieve much, but combined with a good faith enforcement board it helps keep a community a pleasant, joyful place to contribute to, for everyone. And that will increase software quality and attract quality people, aside from being, you know, the right thing to do.The SQLite developers (developer?) are not interested in inviting more contributors to the table and that's fine, but for a functional public community the Contributor Covenant or something like it is pretty much table stakes.	bitwize	13.640427	-5.580179	comment	3.0	18.0	1656277097	-3.7349958
31888690	MongoDB is complex, that’s true. But	MongoDB is complex, that’s true. But DynamoDB or GCP Bigtable are pretty simple.	bluepizza	13.573247	-5.2370596	comment	3.0	13.0	1656282122	9.877136
31892479	"It also automatically enables ""globa"	"It also automatically enables ""global optimisation"" in most cases.This style is called ""amalgamation"" and SQLite is distributed (but not developed) in this way."	actionfromafar	13.610098	-5.582129	comment	3.0	11.0	1656323619	9.857098
31909360	There are enough SQL oopsies in this	There are enough SQL oopsies in this article to show that you should NEVER use sqlite for any production except as filter databases or other sort of throwaways. RDBMSs are there to enforce constraints on data.	Beltiras	13.609513	-5.5590024	comment	3.0	10.0	1656431819	9.826175
31909840	I had a look at SQLite around the ti	"I had a look at SQLite around the time sqlite3 appeared, and my notes say I decided I didn't like it because of the lax and sometimes inconsistent way it can treat its input.I thought I'd have another go at it today (sqlite 3.34) and I'm mildly surprised that the things I didn't like are still there:  sqlite> select '1 apple' + '2 oranges';
  3

  sqlite> select count(*) where 0.9;
  1
  sqlite> select count(*) where 1.1;
  1
  sqlite> select count(*) where not 0.9;
  1
  sqlite> select count(*) where not 1.1;
  0"	mjw1007	13.621961	-5.588302	comment	3.0	10.0	1656433877	9.863919
31910280	Can SQLite be used outside of single	Can SQLite be used outside of single threaded contexts? Last I checked having multiple concurrent readers and writers is very difficult. Multiple concurrent readers only is probably ok if that's all you need.	umvi	13.602499	-5.528207	comment	3.0	12.0	1656435922	9.779576
31997187	When someone says, hey forget postgr	When someone says, hey forget postgresql and just use SQLite, and someone else says good luck if you hit n rows, and someone says it can easily handle n+m rows with x memory …This is a good example of how devs get things wrong. The argument between which database to use because you might hit the row limit has zero benefit to the user. It's devs wanting to avoid future work to migrate from one database to another; a problem most apps will never actually see.There's even an aphorism about this exact thing in dev: YAGNI https://en.m.wikipedia.org/wiki/You_aren%27t_gonna_need_itSolve the problem you have, not thr problem you want.	onion2k	13.569491	-5.4924226	comment	3.0	22.0	1657086465	9.810579
32143942	> I led the team that designed Mongo	> I led the team that designed MongoDB’s pioneering user experienceAs someone who has used mongo, genuinely curious about which part of the user experience is being highlighted here.Thanks for all your work with the Go community and good luck with the new team!	Karupan	13.704197	-5.3106685	comment	3.0	17.0	1658179309	9.922435
32212607	But it's just a wrapper around SQLit	But it's just a wrapper around SQLite. Skip the middleman and just use SQLite.	apavlo	13.610078	-5.586017	comment	3.0	13.0	1658664197	9.860874
32212981	I expected to learn something from i	"I expected to learn something from it - especially when it's popped on the front page of HN. Am I expecting too much of HN?My train of thought when I saw the link ""a key-value store"": what data-structure are they using? A hashmap? How are they resolving conflicts? Is it in memory? How are they persisting data? Do they support multiple instances? What about concurrency? etc.Of course I might be a bit disappointed when the project is just 4 web APIs on top of sqlite table."	kklisura	13.527952	-5.5108	comment	3.0	19.0	1658667159	9.826505
32228562	Just because SQLite project hasn't s	"Just because SQLite project hasn't sued any Germans doesn't mean there's not legal risk involved.Build a billion dollar company on some ""public domain"" software in Germany, and you've given a stranger a gun to your head.  They might not exercise their copyright, but they also could."	kube-system	13.642206	-5.5823884	comment	3.0	12.0	1658772823	9.860503
32292254	> Therefore, the modifications from 	> Therefore, the modifications from a transaction will be applied in place in these pages.With mvsqlite it is applied to the transaction's own snapshot of the database. Changes are not visible globally until transaction commit. That's what we get from page-level MVCC.> More over, without WAL, SQLite to the best of my knowledge would require read-lock on every read as wellReads are also MVCC. Data is fetched from a consistent and clean snapshot of the database, without uncommitted data.	losfair	13.557358	-5.483616	comment	3.0	10.0	1659230944	9.770593
32303933	sqlite is not a serialization format	sqlite is not a serialization format though.	junon	13.622432	-5.5868454	comment	3.0	10.0	1659348526	9.855277
32320724	I wrote for the technical writing te	"I wrote for the technical writing team at MongoDB when this ""security issue"" made the news.  The precise problem was whether authentication was turned off/on by default for the default database, I believe, during installation.   Product management initially chose this configuration to make it quicker for evaluators to get something up and running as quick as possible.  The assumption was that no developer would actually use that in production.  Further, the documentation clearly stated that this default configuration option was not secure.Blaming that data loss on MongoDB rather than the noob dev who deployed that evaluation configuration is as erroneous as the logic used by the noob dev.  We  hear it from developers all the time, so let me repeat it: User error.  It's a thing."	docmechanic	13.714593	-5.257406	comment	3.0	14.0	1659457347	9.94885
32336490	Hey, author here, happy to answer qu	Hey, author here, happy to answer questions! A few other recent posts/tools that you may be interested in:- sqlite-lines discussion from a few days ago: https://news.ycombinator.com/item?id=32288165- htmlq, Rust CLI for (like jq but for html): https://github.com/mgdm/htmlq- The Go library that sqlite-html uses for making runtime-loadable SQLite extensions https://github.com/riyaz-ali/sqlite- sqlean, a ton of other helpful SQLite extensions (in C): https://github.com/nalgeon/sqlean	alexgarcia-xyz	13.600349	-5.624163	comment	3.0	11.0	1659559676	9.814827
32393395	No Worries! The Google Server in Mou	No Worries! The Google Server in Mountain View has had a disk failed in it's RAID and therefore the sqlite-DB has only half the iops to it's disposal. A new 500GB hard disk is already in dispatch with Amazon. These are the moments why Google is a proud Amazon Prime customer.	sydney6	13.587382	-5.4748707	comment	3.0	19.0	1660009999	9.850903
32408431	"So I am also ""really people, use Pos"	"So I am also ""really people, use PostgreSQL"", because you have way less tricks you have to play to get it working compared to SQLite, in serious envs. However, some challenges with Postgres, especially if you have less strict data integrity requirements (reddit-y stuff, for example):- Postgres backups are not trivial. They aren't hard, but well SQLite is just that one file- Postgres isn't really built for many-cardinal-DB setups (talking on order of 100s of DBs). What does this mean in practice? If you are setting up a multi-tenant system, you're going to quickly realize that you're paying a decent cost because your data is laid out by insertion order. Combine this with MVCC meaning that no amount of indices will give you a nice COUNT, and suddenly your 1% largest tenants will cause perf i"	rtpg	13.519994	-5.280779	comment	3.0	17.0	1660113251	9.800931
32429581	...but preferably using the SQLite e	...but preferably using the SQLite engine, and eschewing well-known proprietary formats.https://news.ycombinator.com/item?id=32275078	chasil	13.564204	-5.575014	comment	3.0	24.0	1660241142	9.792066
32437856	I've started using C++ for the REST 	I've started using C++ for the REST backend for a mobile app recently.I'm using restinio for the REST layer (sadly deprecated a couple of months ago, but it still seemed like the best option in terms of clean interface) and sqlite for the DB layer.I've architected it all so I have a purely insert-only and order-independent DB on the write-side, so litestream was seeming like a good fit for single-writer, multiple readers, but now that's been abandoned, I'll wait until litefs stabilises, or roll my own to do what I need.I originally started the REST side in dart so I could share code with the flutter client app, but I soon realised that performance wasn't where I wanted it to be and that the backend queries were all very different to client side anyway, so it seemed easier just to create th	ralferoo	13.567863	-5.4775195	comment	3.0	17.0	1660309156	9.762227
32479157	Came over this article as I was look	Came over this article as I was looking for interesting resources in the SQLite ecosystem. I'm building mvsqlite (https://github.com/losfair/mvsqlite), as an attempt to turn SQLite into a proper distributed (not just replicated) database. Check it out if you are looking for this kind of stuff!	losfair	13.557037	-5.4828916	comment	3.0	14.0	1660623638	9.806583
32479636	It feels bad to make a database choi	It feels bad to make a database choice which isn't capable of supporting lots of writes. Lots of things start small but get big unexpectedly, and if you choose sqlite then now you have to rearchitect things.	why_only_15	13.566491	-5.5062695	comment	3.0	11.0	1660629608	9.781831
22029088	There was a similar bug in unraid th	There was a similar bug in unraid that they ended up fixing in 6.8.0 where it turned out that SQLite wasn't handling some sort of error condition in read-ahead I/O? I wonder if this is related.https://forums.unraid.net/bug-reports/prereleases/sqlite-dat...From that report:====== 8< ======> In the Linux block layer each READ or WRITE can have various modifier bits set.  In the case of a read-ahead you get READ|REQ_RAHEAD which tells I/O driver this is a read-ahead.  In this case, if there are insufficient resources at the time this request is received, the driver is permitted to terminate the operation with BLK_STS_IOERR status.  Here is an example in Linux md/raid5 driver.> In case of Unraid it can definitely happen under heavy load that a read-ahead comes along and there are no 'stripe bu	mmastrac	13.568624	-5.5321627	comment	3.0	34.0	1578861066	9.747318
22044478	Sharing an SQLite database across co	Sharing an SQLite database across containers is surprisingly brilliant	vinnyglennon	13.581073	-5.522188	story	3.0	28.0	1579008153	9.771
22115946	next time try cockroachdb instead of	next time try cockroachdb instead of postgres.	_tkzm	13.537285	-5.3353696	comment	3.0	11.0	1579685054	9.823569
22151626	The main problem that I see for usin	The main problem that I see for using sqlite is exactly for it being 'Classic Serverless'. Because how does one keep an up te date backup? Deploying to Heroku, Dokku, AWS Lambda and such means the sqlite file will be lost on a crash or new deploy. Even a VM can crash. Export to S3 on every write? Maybe if changes do not happen often, so only for specific use cases (and actually I think you should just generate static html in that case).I use sqlite for local tests for cases where the live app has a 'neo-serverless' database. It is very, very fast so the tests run almost instantly.	Gys	13.569273	-5.5003614	comment	3.0	15.0	1580039246	9.790085
22152692	Does this mean that you can hack som	Does this mean that you can hack some database storage (w/ sqlite) together on frontend only hosting platforms like Github or Netlify?I think not, but I wonder if some hack is available by virtue of it simply being a file that you can read (and somehow) write to.The best I came up with: let's say you have a toy project, and you call the Github API and replace the file upon every write. Implementing a read is easier as you know where the file is located. This hack shows that you somehow need write access to get any form of performance out of it, because this hack is super slow.	mettamage	13.52854	-5.503452	comment	3.0	44.0	1580054674	9.798812
22152693	As you quoted, people in this discus	"As you quoted, people in this discussion are saying that writing a dummy program that has its own sqlite and does nothing but pass messages to it that it receives from all other processes on the system that need to talk to that sqlite file results in much better performance than accessing that file ""directly"" from the separate processes.so if everyone's saying this, is there such a standard dummy program?"	logicallee	13.6183	-5.590075	comment	3.0	12.0	1580054691	9.765185
22153173	I'm no SQLite expert but by this log	"I'm no SQLite expert but by this logic aren't all single-host databases that tick the ""Durability"" ACID checkbox ""just file formats"" in the sense that yeah, the bytes we care about exist somewhere in the filesystem?Moreover I'm having trouble coming up with things that I'd associate with a RDBMS and not ""just a file format"" that SQLite doesn't support. Transactions? SQLite has them. Relational constraints? SQLite has those too. Could you elaborate on some of the confusion that you've seen around this?"	zachthewf	13.577865	-5.5496187	comment	3.0	11.0	1580058583	9.801709
22153447	Using SQLite in my ETL processes is 	"Using SQLite in my ETL processes is something I have done for over a decade.  It's just so convenient and, at the end, I have this file that can be examined and queried to see where something might have gone wrong.  All of my ""temporary"" tables are right there for me to look at.  It is wonderful!"	at_a_remove	13.61907	-5.565762	comment	3.0	19.0	1580060941	9.83125
22153278	Consider: it’s totally possible to s	Consider: it’s totally possible to strip down Postgres until all you have left is an embedded RDBMS of the style of SQLite. (I’m not sure why nobody has done this yet, actually.) Would you call the result “just a file format”?Such an instance of “embedded Postgres” would still have a huge sprawling catalog (PG_DATA) directory attached to each use of it, so it wouldn’t be contained to a single file. But neither is SQLite contained to a single file—SQLite maintains a journal and/or WAL in a second file.And, yes, this “embedded Postgres” would require things like vacuuming. But... so does SQLite. Have you never maintained an application that maintains a long-lived “project” as a single SQLite file, where changes are written into this project file repeatedly over a long period? (Think: the “li	derefr	13.546075	-5.4675946	comment	3.0	23.0	1580059408	9.7610855
22172960	Yugabyte v. Cockroach analysis: http	Yugabyte v. Cockroach analysis: https://www.cockroachlabs.com/blog/unpacking-competitive-ben...disclaimer: I work at cockroach	dilloc	13.691866	-5.193559	comment	3.0	10.0	1580238620	10.230957
38965965	Partitioning Postgres tables by time	Partitioning Postgres tables by timestamp based UUIDs	amalinovic	13.661306	-5.286092	story	3.0	32.0	1705052033	9.7060375
38999470	>In wal2 mode, the system uses two w	">In wal2 mode, the system uses two wal files instead of one. The files are named ""<database>-wal"" and ""<database>-wal2"",Heh, I wonder how many people will delete the ""wal"" file thinking that, since they switched to wal2, the wal file must be a leftover."	vdaea	13.537091	-5.4111276	comment	3.0	22.0	1705316584	9.79161
38999475	I'm just speculating here, but in a 	I'm just speculating here, but in a normal database you would have different processes writing the wal files to the database or archives.You don't have that with sqlite, so I don't see an obvious advantage for this, except if they now spawn a process or thread to do this concurrently.Edit: so I read the doc (shame on me) and it has nothing to do with speed. Its purpose is to prevent a wal file from growing too large.	forinti	13.564672	-5.464952	comment	3.0	10.0	1705316607	9.819039
38999501	Now I can't help but wonder if there	Now I can't help but wonder if there should be a `waln` mode where the WAL files would round robin instead of alternate between just two potentially allowing for much more intense write cadence.	tomashubelbauer	13.555399	-5.4258814	comment	3.0	12.0	1705316862	9.801833
39000575	in the case of sqlite though, the te	"in the case of sqlite though, the technology is often used as a standalone file format. So it is very tempting to consider the "".sqlite"" file to be the one containing all the data, and all the rest to be temporary files that don't matter much.IMHO this (having a variable number of files containing the data, depending on your configuration) is the only real design quirks of this technology."	bsaul	13.541602	-5.5489593	comment	3.0	10.0	1705324546	9.773216
39039360	Yes, SQLite is row oriented. It's no	Yes, SQLite is row oriented. It's not a very space efficient format because it also doesn't support compression or compact representations of numbers in binary.But it doesn't rely on the JVM and a typical JVM ecosystem. It is a big benefit for some use-cases, like dealing with numerical data on the edge.	speedgoose	13.570452	-5.5687284	comment	3.0	13.0	1705566440	9.85091
32558036	"The ""lack of functions"" is what allo"	"The ""lack of functions"" is what allows SQLite to be what it is: a small, efficient SQL database that works on everything from mainframes to a watch. The fact it doesn't have every possible feature you want or need is not a deficiency of SQLite: if you need tons of features then, by definition, you're outside the niche of what SQLite was built to handle and you need a large, full-featured database server."	mikece	13.5836115	-5.5726805	comment	3.0	12.0	1661206918	9.840306
32567748	You should add RethinkDB! I moved to	You should add RethinkDB! I moved to it from MongoDB years ago.	NetOpWibby	13.6509	-5.314527	comment	3.0	16.0	1661273841	9.900847
32581375	Something I found non-obvious about 	"Something I found non-obvious about WAL mode in SQLite is that it's actually a property of the database file itself.When you run ""PRAGMA journal_mode=wal;"" against a database file the mode is permanently changed for that file - and the .db-wal and .db-shm files for that database will appear in the same directory as it.Any future connections to that database will use it in WAL mode - until you switch the mode on it back, at which point it will go back to journal mode.It makes sense when you think about it - of course a database can only be in one or the other modes, not both, so the setting must be at the database file level. But it took me a while to understand.I wrote some notes on this here: https://til.simonwillison.net/sqlite/enabling-wal-mode"	simonw	13.581208	-5.4895453	comment	3.0	10.0	1661357297	-10.28507
32581855	The name SQLite isn't Sequel-lite. I	The name SQLite isn't Sequel-lite. It's S.Q.L.-ite akin to graphite or Levite. It means a thing of SQLy stuff.The creator says it like Escue Ell-ite emphasis on the Es- and -ite. [0]https://youtu.be/Jib2AmRb_rk?t=99	srcreigh	13.614664	-5.5583696	comment	3.0	11.0	1661358778	-4.9516544
32584099	What's with so many SQLite posts on 	What's with so many SQLite posts on HN these days? Never saw so much love for sqlite before.	posharma	13.626983	-5.5798917	comment	3.0	15.0	1661367425	9.861601
39432404	I once tried both of these databases	I once tried both of these databases with an existing PostgreSQL database. I was never able to convert my pg database to YugabyteDB, YugabyteDB Voyager (a migration tool) would choke during the conversion/migration. I did manage to get a working CockroachDB version but had to drop quite a bit of features and consistency checks. I remember not being impressed with the added latency. Lessons learned: don't migrate existing projects to these distributed databases and only use them in new projects when you are in dire need of a distributed database and are comfortable with the added latency. Mind you, this was quite some time ago, I'm sure things have improved.	flagged24	13.575355	-5.2380643	comment	3.0	11.0	1708364100	9.793471
39464311	"In ""What you get with Atuin"" the fir"	"In ""What you get with Atuin"" the first(!) point is ""Sync your shell history to all of your machines, wherever they are"". That obviously cannot work with a local SQLite. Without syncing, this is a better ctrl+r, which I won't disagree is nice, but not the real point of this software. If the page says this is ""trusted"" by pretty much all major software companies, I would assume this includes syncing, which is the main feature.Also, even the possibility that the software would send this to the outside would make this impossible to use at my company, and I don't think we are overly strict in that sense here."	deng	13.534724	-5.5632367	comment	3.0	11.0	1708587630	9.830904
39501735	Definitely a tangent, but it's alway	"Definitely a tangent, but it's always interesting to see which of {a,an} people use for SQL and derivatives. It never occurred to me until today to pronounce ""sqlite"" as anything other than ""sequelite""."	lolinder	13.557613	-5.5983405	comment	3.0	19.0	1708876080	-4.804692
39567097	Link to how SQLite is tested, for an	Link to how SQLite is tested, for anyone who's curious: https://www.sqlite.org/testing.htmlThere's also an interesting thing where formal verification requires a formal specification, which afaik there isn't one for SQLite. One of the toughest problems that someone would run into trying to put together a formal specification for code as widely deployed as SQLite boils down to Hyrum's Law[1]: on a long enough time scale, all observable behaviours of your system become interfaces that someone, somewhere depends on.That massive suite of test cases isn't a formal specification but given that it achieves 100% branch coverage that implies to me that it:- pretty tightly bounds the interface without formally specifying it- also pretty tightly constrains the implementation to match the current impl	tonyarkles	13.646056	-5.6340137	comment	3.0	11.0	1709329111	9.921291
39604117	Interactive SQLite Documentation	Interactive SQLite Documentation	marcobambini	13.619645	-5.592682	story	3.0	32.0	1709650147	9.859958
39616476	Has anyone used sqlite for storing e	Has anyone used sqlite for storing embeddings? Are there any extensions or tips for making it easier?I have a small command line python app that uses sqlite for a db. Postgres would be a huge overkill for the appPS: is sqlite-vas good? https://github.com/asg017/sqlite-vss	nico	13.561539	-5.541514	comment	3.0	11.0	1709736335	9.84847
39628092	Even harder to understand is if you 	Even harder to understand is if you need high concurrency, multi-node replication, pub/sub capabilities, etc, what is the point of using SQLite in the first place?I love SQLite, but don't let love blind out technical decisions, folks.There are much better, battle-tested tools to solve these problems.	rmbyrro	13.586415	-5.533303	comment	3.0	21.0	1709813460	9.809003
39667053	I don’t disagree with the premise fo	I don’t disagree with the premise for very small applications, but> The quiz state machine is full in memory> The queue system for the matchmaking is in memoryMeans those will be nuked as soon as a new version gets uploaded. it really wouldn’t have been much extra work to put this into SQLite as well, and would lead to a much better user experience during updates	phyrex	13.597462	-5.5504646	comment	3.0	12.0	1710158563	9.812089
39667095	Title: You don't need a database.Hal	Title: You don't need a database.Half way down the article: The questions are stored in a sqlite database	vishnugupta	13.583025	-5.551014	comment	3.0	10.0	1710158793	9.862912
39671551	I love Go and SQLite and enjoy using	I love Go and SQLite and enjoy using them together. One bummer is that it requires CGO to use and that makes cross compiling a pain. It might be nice to use the modernc variant (via build tags) to make this more portable -- https://gitlab.com/cznic/sqlite	pstuart	13.618739	-5.6142626	comment	3.0	11.0	1710180835	-5.7301764
39671734	If ids are unique strings, then why 	If ids are unique strings, then why are `nodes` and `edges` arrays, as opposed to id-string-keyed maps?	Retr0id	13.910818	-5.2134895	comment	3.0	14.0	1710181749	-13.639673
32656423	If anyone is interested in the techn	If anyone is interested in the technical details, the database itself is a 4GB SQLite file which we are hosting with Datasette running on Fly.More details in our repo: https://github.com/simonw/laion-aesthetic-datasetteSearch is provided by SQLite FTS5.	simonw	13.58862	-5.5647016	comment	3.0	15.0	1661901451	9.821661
32676558	SQLite is always going to win in tha	SQLite is always going to win in that category just from the fact that there are less layers of code to be worked through to execute a query.	RedShift1	13.598212	-5.584751	comment	3.0	14.0	1662041918	9.854185
32677283	Here's sqlite doing 100 million inse	Here's sqlite doing 100 million inserts in 33 seconds which should fit into nearly every workload, though it is batched. https://avi.im/blag/2021/fast-sqlite-inserts/So write contention from multiple connections is what you're talking about, versus a single process using sqlite?	ledgerdev	13.542073	-5.5085254	comment	3.0	17.0	1662044461	9.756498
32683530	i strongly dislike planetscale  and 	i strongly dislike planetscale  and even i think this is not a useful or fair comparison .. sqlite works with local files, much simpler, no network latency, no HA	throwusawayus	13.589251	-5.561189	comment	3.0	12.0	1662067834	9.840055
32724337	SQLite 3.39.3	SQLite 3.39.3	marcobambini	13.627212	-5.591794	story	3.0	104.0	1662386269	9.859598
32809530	The cons that the author of the post	The cons that the author of the post lists make it a no-go. From SQLite not going to work well on sites with multiple authors (a killer from the start) to 'web hosts NEEDING TO ACT RESPONSIBLY' for this to work, literally make this the effort of a OSS project unknown to the WP ecosystem (50% of the web) to force its way into that ecosystem withouth having found any widespread use and people having accommodated it.If it was worth doing it, someone would have published a plugin for it and it would have been working already. WordPress provides filters for database functions as well. So whatever db you want to use, could be reliably integrated by injecting yourself in between the functions and the db.Of course, this means that you will immediately face compatibility problems with all the 60,00	unity1001	13.569161	-5.516168	comment	3.0	20.0	1662987878	9.781227
32825271	That's actually a good example, beca	That's actually a good example, because if the standard specified that POST must be idempotent, and that a POST without a uuid is invalid, we might have something here.Instead there's a workaround for a serious problem, and any client (browser being by no means the only client) which doesn't respect the convention can emit identical POSTs, with no way of knowing if that was intended.	samatman	13.956842	-5.200682	comment	3.0	13.0	1663081652	-13.670102
32852330	There is no point to use sqlite3 in 	There is no point to use sqlite3 in default journaling mode. I bet results may be even better than dbm if you use  PRAGMA journal_mode=WAL;	Snawoot	13.587821	-5.508265	comment	3.0	20.0	1663251168	-10.258148
32869672	Ask HN: Why do so many people dislik	Ask HN: Why do so many people dislike MongoDB?	kadomony	13.640183	-5.3447857	story	3.0	2.0	1663350844	9.896073
32910129	When you're accessing a SQLite datab	When you're accessing a SQLite database in code you have to generate a query string. Parameters ameliorate that somewhat, but in many cases you still have to regenerate a new string for each new query. It's inefficient to translate your query into a string only to have it parsed back into something structured by SQLite.	dkjaudyeqooe	13.581856	-5.613012	comment	3.0	15.0	1663671739	9.845752
32911922	> DRUIDS is not an open source desig	> DRUIDS is not an open source design system. These guidelines are specifically for internal Datadog users. [1]even npm package[2] asks for login[1] https://druids.datadoghq.com/foundations/contribute[2] https://www.npmjs.com/package/@druids/ui	rajveermalviya	13.866393	-5.2040486	comment	3.0	15.0	1663683278	-13.661614
32918332	SQLite Code of Ethics (2020)	SQLite Code of Ethics (2020)	modin	13.666063	-5.6022973	story	3.0	18.0	1663710969	-8.8883095
32926977	This is distributed SQLite 3, runnin	This is distributed SQLite 3, running (I assume at least partially managed?) LiteFS[5] for you. Which is pretty cool!What I'd like to have seen is how this compares to things like rqlite[1] or Cloudflare's D1[2] addressed directly in the articleThat said, I think this is pretty good for things like read replica's. I know the sales pitch here is as a full database, and I don't disagree with it, and if I was starting from scratch today and could use this, I totally would give it a try and benchmark / test accordingly, however I can't speak to that use case directly.What I find however and what I can speak to, is that most workloads already have database of some kind setup, typically not SQLite as their main database (MySQL or PostgreSQL seem most common). This is a great way to make very - i	no_wizard	13.522991	-5.4277277	comment	3.0	23.0	1663775690	9.750608
16441592	First things first, you'll want a DB	First things first, you'll want a DB that doesn't have cockroach in the name.I'm only slightly kidding.	scarmig	13.702919	-5.1978626	comment	3.0	13.0	1519335150	9.991214
16500267	I really wish I could get over my ir	I really wish I could get over my irrational fear that using an UUID will one day result in a collision and the associated data integrity issue when an update silently overwrites an unrelated record, where as the old sequential sequence never has this risk.	cube00	13.963355	-5.212498	comment	3.0	21.0	1519984357	-13.670264
16541414	I'm curious what you do for Postgres	I'm curious what you do for Postgres to get an HA, as the last time I worked with Postgres it was a nightmare to get even a bare bones HA working. I swore I'd never touch it again until they had a real HA solution. I ask ever year or so and keep being told it still doesn't have one.	eikenberry	13.521325	-5.23862	comment	3.0	12.0	1520471050	9.753103
16585302	Go and Rust is too heavy and require	Go and Rust is too heavy and require more dependencies for SQLite. SQLite runs even on the smallest exotic embedded systems.	ex3ndr	13.645075	-5.6839786	comment	3.0	23.0	1521040589	9.859536
16585336	Lets not create a false equivalency 	Lets not create a false equivalency between Go and C.Go is a good language, one of its core pieces is to increase memory safety through the use of a garbage collector.Much of what the SQLite post states may not be safe operations in Go.Rust would be a safer alternative that meets many of the SQLite requirements.The thing is, SQLite is bulletproof at this point, so do we need to replace it?	bluejekyll	13.628743	-5.660711	comment	3.0	30.0	1521040776	9.905818
16585379	You would have to start at languages	You would have to start at languages that are demonstrably better than C at being C for the reasons listed as to why C is still the best language for SQLite.In the present day context of vulnerabilities it's tempting to blame C. Yet it's still a good choice for many reasons. It's not wise to suggest that everything written in C must be re-written in some other language because of hand-waving reasons like buffer-overflows or off-by-one errors.Maybe you could prove Rust is a good choice by writing your own SQLite implementation feature for feature? Until then I don't think there's going to be a compelling reason to re-write SQLite because it's written in C.	agentultra	13.639558	-5.653549	comment	3.0	15.0	1521041086	9.855119
16617135	>Easy-to-use synchronous API (faster	>Easy-to-use synchronous API (faster than an asynchronous API... yes, you read that correctly)Who the hell decided that making sqlite asynchronous is a good idea in the first place? Node is so religious on async that creating everyday transactioned apps in it is PITA that never ends.	wruza	13.559195	-5.539436	comment	3.0	16.0	1521452275	9.761904
16679526	I find it hysterically funny that co	"I find it hysterically funny that companies think that operating their own mysql, postgresql, redis or mongodb is ""a difficult task"". It is like a home owner deciding that knowing how to operate their own toilet is a difficult task that must be outsourced.Oh and before someone says ""we outsource fixing our toilets to plumbers"" - in this case we are not event talking about replacing a flap, we are talking about being able to use a plunger."	notyourday	13.557611	-5.3678823	comment	3.0	12.0	1522077533	9.853645
16711340	The thing I really don't get is why 	The thing I really don't get is why CockroachDB is avoid benchmarking with it's rival tidb (https://github.com/cockroachdb/docs/issues/1412). tidb already pretty mature, used in many big companies (Let's say, Didi, which on the similar scale data with Uber, and banks).Even if I like CockroachDB's pg sql more, it would be helpful to have the comparison/benchmark to show something more.	wilbeibi	13.620167	-5.232951	comment	3.0	19.0	1522359874	9.901506
16711956	Show HN: Blog made with CouchDB/Pouc	Show HN: Blog made with CouchDB/PouchDB	oblib	13.616742	-5.1992884	story	3.0	6.0	1522364107	9.610201
16790889	I use a mix: UIDs (auto-incrementing	I use a mix: UIDs (auto-incrementing primary keys) for internal app use (e.g. joins), but use UUIDs for referencing records outside the app (anything sent out over the API).The UIDs just make for easier to read logs, and easier to inspect and hand-write db queries. The UUIDs just seem much more secure when communicating with client applications.I also agree that authing with a DB is preferable, if you can afford to do that at the scale your app needs (which is most apps out there).	jonny_eh	13.958375	-5.2156215	comment	3.0	18.0	1523255958	-13.666908
16792098	A UUID primary key has to live in ev	A UUID primary key has to live in every index in the table and every foreign key that references it.We have a table with a UUID as its primary and it alone consumes 22GB, then a index reference it, so now another 22GB... That one primary key uses over 100GB of storage, a developer recently went to add another table that reference it and we had to decide whether we were okay taking another hit. If we used your example of using a char type (we use blob) it would be double the size...It doesn't sound like much, but in a database with all primary keys being UUIDs you are going to inflate the size of your DB quickly, or have to forego using foreign keys. I imagine if we used only UUIDs we would have to double or triple our database infrastructure. Additionally, we would be forced to introduce p	bearjaws	13.9748955	-5.2227	comment	3.0	11.0	1523273900	-13.637485
19333941	> in the default configurationMongoD	> in the default configurationMongoDB shares some of the blame here. Software needs be secure by default.	ams6110	13.617801	-5.2461615	comment	3.0	13.0	1552003564	9.888959
19334933	here's my lazy PW script, written in	here's my lazy PW script, written in node. :)   require('uuid').v4().split('-').join('')	MrLeap	13.998724	-5.2103014	comment	3.0	14.0	1552017131	-13.663211
19498841	Since everyone is sharing their opin	Since everyone is sharing their opinion and experience with mongodb I think I’ll share mine.As an appeal to authority I would like to mention that I have relevant vocational qualifications on the subject (more geared towards scalability and operations). Although I don’t believe it really matters - it will to those who assume I don’t understand best practice.MongoDB itself is not /really/ a valid choice in many scenarios that it was painted as solving. Their only fault is overzealous marketing, it has (in my opinion) very clear pain points that should be avoided, but those painpoints are antithical to why many people used it in the first place.Most people pick up mongo because it’s painted as being “beginner developer friendly”, I don’t mean new developers, I mean picking it up and running 	dijit	13.682996	-5.336877	comment	3.0	32.0	1553673650	9.897994
19499766	The Jepsen tests [1] have been run a	The Jepsen tests [1] have been run against MongoDB - while older versions presented edge-case opportunities for data loss, that's no longer the case with recent versions. The Jepsen tests also specifically test sharded clusters. From Aphyr's report:> MongoDB 3.6.4’s sharded clusters offer comparable safety to non-sharded deployments.These tests are now integrated into MongoDB's regular test suite. Maybe MongoDB wasn't the right choice for you at the time you were evaluating it, but I just want to point out that MongoDB has matured and improved a great deal.(Disclaimer: I work for MongoDB)[1] https://jepsen.io/analyses/mongodb-3-6-4	TimFogarty	13.66662	-5.292049	comment	3.0	14.0	1553685832	9.88648
19501522	Postgres is not an alternative to Mo	Postgres is not an alternative to Mongo, though. Provide a noSQL alternative if you want an alternative. RDBs and non-RDBs seek to address different sets of problems, and sometimes you do not want or need a relational database.	ex_ex_nihilo	13.623375	-5.347541	comment	3.0	12.0	1553699101	9.867308
19518484	Why are so many MongoDB databases le	Why are so many MongoDB databases left unsecured? Are they extraordinarily hard to secure? I imagine the people who are working with these databases must be aware of the numerous leaks, and pay close attention to securing the data, no?	jjjjjjjjjjjjjjj	13.71029	-5.2559347	comment	3.0	20.0	1553824346	9.91905
19763178	> The SQLite developers believe that	> The SQLite developers believe that the lack of assert() disqualifies Go as a language for serious development work.Great comment.	shaklee3	13.624756	-5.6452293	comment	3.0	32.0	1556328614	-5.877272
19785893	Often UUIDs are used as keys to thin	Often UUIDs are used as keys to things...And these things are often stored in databases...And usually the database puts them into a btree internally, because that's how tables are stored.The moment you have any kind of load on such a table, your performance goes to hell.  This is because the inserts are going to happen all over the place, and the way tables are stored definitely prefers appends.So a common word of wisdom is to have an auto-increment primary key, and the uuid indexed!  Ugh what a work around.A better way is to discover ULIDs, which are like UUIDs but with the high-bits including a timestamp.  This turns inserts into, approximately, appends.  Much nicer!https://github.com/ulid/spec is fairly recent, but the 'trick' has been used for years.  I've build gazillion-row databases	willvarfar	13.971914	-5.21926	comment	3.0	25.0	1556610325	-13.672786
19817047	As a thought, since you're just gett	As a thought, since you're just getting into database stuff as time permits, it's probably better to start out with something like SQLite and/or DB Browser for SQLite, if you prefer the GUI way of doing things.https://sqlitebrowser.orghttps://a-gentle-introduction-to-sql.readthedocs.io/en/lates...SQLite is a bunch easier to get up and running than MySQL, and the data is all in one file you can copy around.  So, easy to backup. :DIf you do eventually hit it's limits, it's big brother is PostgreSQL, which is a really powerful database system. :)	justinclift	13.524806	-5.477922	comment	3.0	11.0	1556878863	9.810508
19877244	There was a story posted recently ab	There was a story posted recently about how the properties of UUIDs are not a good match for how databases index columns. It proposed the 'ulid' which helps in that regard.	yrro	13.982424	-5.2143636	comment	3.0	10.0	1557492900	8.623849
19877230	>As far as I know, no database has e	>As far as I know, no database has ever had any of the problems he mentions with IDs not round-tripping properly during backup/restore. (Please correct me if I'm wrong! But why do I think this is true? Because any database that doesn't roundtrip primary keys would break all foreign keys on backup/restore. Databases with broken backup/restore tend to either fix it real fast, or go away.)You might not use foreign keys, but still have autoincremented primary key.Database ids on the URL are also a security concern.	coldtea	13.888385	-5.2291436	comment	3.0	29.0	1557492713	-13.630737
19879719	So you rather your DB performance ta	So you rather your DB performance tank because of unsortable and unclusterable (sp?) PKs than expose a tiny bit information that shouldn't even be that important? You can use a UUID as a URI link, but you shouldn't use it as a PK on most databases. That means you would have to add another column for the link ID (which I think is a relatively good and clean solution)	fgonzag	13.972759	-5.2075286	comment	3.0	11.0	1557507480	-13.656911
19890189	I never had any uncertainty regardin	I never had any uncertainty regarding where I can use a given entity id in a well designed API. Fix the naming and organization of your API if that's a problem for your users.Conversely, I often need to log or store API-provided entity ids on my side, and having to parse it out of a URL or store irrelevant URL bytes in my own database would be really annoying.You're not going to avoid the need to compile entity URLs on the client side either, unless you only make requests to entities returned by the API, which would be a weird constraint to design client code around.I really don't see the point to any of this.	raquo	13.844227	-5.1955886	comment	3.0	19.0	1557636042	-13.677732
19913846	This benchmark is pretty ridiculous 	This benchmark is pretty ridiculous for the following reasons:1. Their database is run in asynchronous durability mode.2. They specifically do the one thing that TPC-C says you shouldn't do, which is get really high throughput on a small dataset. TPC-C enforces that you scale your data-stored with the query throughput. CockroachDB maxes out at ~12.8tpmC/warehouse because its waiting at the legal maximum throughput, as opposed to running up the numbers in a way that's against the rules (and spirit) of the benchmark.3. They make all the TPC-DS mistakes that georgewfraser points out elsewhere in this thread.4. They run in read committed mode (they don't support anything higher), CockroachDB runs in serializable mode.I ended up ranting about this on Twitter, so rather than reproducing everythi	arjunnarayan	13.535698	-5.240955	comment	3.0	15.0	1557867551	9.860624
33030720	Why Is MongoDB Still Unprofitable?	Why Is MongoDB Still Unprofitable?	osigurdson	13.713825	-5.2976384	story	3.0	3.0	1664510156	9.911354
24824212	SQLite Begin Concurrent	SQLite Begin Concurrent	creolabs	13.598179	-5.5385003	story	3.0	23.0	1603094895	9.803562
24947375	I bet we'd both seriously consider (	I bet we'd both seriously consider (if not prefer) sqlite over postgres in a bunch of scenarios?	pricechild	13.562844	-5.501736	comment	3.0	14.0	1604096105	9.827963
25047576	CockroachDB 20.2	CockroachDB 20.2	Alir3z4	13.683035	-5.2016606	story	3.0	51.0	1605024795	10.045937
25117216	still no wal_level = logical, so sad	still no wal_level = logical, so sadly.	merb	13.550667	-5.4567676	comment	3.0	14.0	1605562304	9.793761
25131869	Do you think that because your first	"Do you think that because your first thought of ""cockroach"" is ""doesn't die,"" or because you've researched about this DB in particular?"	pc86	13.706739	-5.1881304	comment	3.0	13.0	1605660513	10.168906
25168292	I’d really love SQLite to work on th	I’d really love SQLite to work on the nfs and cifs. Is there anything that can be done to make that safe at a kernel level?	foft	13.587235	-5.559041	comment	3.0	20.0	1605942412	9.854557
25202401	There's no such thing as Postgres or	There's no such thing as Postgres or Mongo developer. They are not programming languages.	itwy	13.600508	-5.353377	comment	3.0	15.0	1606247976	9.903441
25217029	Back in ~2012 I interviewed at a com	Back in ~2012 I interviewed at a company that chose Mongo as its database, and my white boarding question was to implement joins in nosql as that was a recent problem they were solving. After doing the problem I asked innocently, “but all your data is relational - why use mongo at all?” And the CTO went red in the face and exploded, actually yelling at me about mongo’s many benefits (just not, ya know, anything a normal database provides). Needless to say I didn’t get the job!	seibelj	13.677278	-5.3336363	comment	3.0	10.0	1606367226	9.868422
25235143	> particularly ones where you need t	"> particularly ones where you need to ensure that a user can't accidentally separate or delete a file. How do you keep a cache directory that backs a file with the file if the file system doesn't let you put folders ""inside"" of files?You are worried that if an application has a directory ""cache"" with files in it, a user will go into that directory and randomly delete the file ""cache/3F3819A1.dat"", and that might confuse the application.But, suppose instead you had a single file ""cache.sqlite"", containing a table ""cache"" with an ""id"" column. What's to stop a user from opening that file with the sqlite command line tool and running ""delete cache where id='3F3819A1'""If a user really wants to muck with your app's data by hand, you can't stop them. (Unless you go with some DRM-like solution in "	skissane	13.575879	-5.541092	comment	3.0	23.0	1606535913	9.763996
25235583	Understanding a file format means kn	Understanding a file format means knowing the significance of a given bit. Not just that X has value 13, but that 13 means something and might influence the significance of Y or Z.Having a table with columns A, B, and C doesn't say a ton about what the values in them mean. Or how they relate to one another. If it's a bunch of decimal numbers, it could be financial data, and the sums expected to sum depending on how another column that indicates a type is set. Or it could be temperature readings. Or distances, with the unit implied or tracked elsewhere.Generally this is the kind of data and rules for reasoning about data that isn't stored in a database. Certainly not a sqlite database. Column and table names are often vague or unclear, and in my experience it's an exceptionally rare develop	Kalium	13.553412	-5.578506	comment	3.0	13.0	1606542394	9.838693
25260846	I found myself in a similar situatio	I found myself in a similar situation with a budgeting app I wrote. Initially I was planning to make it public but the idea of dealing with people's financial data and paying for all the infrastructure caused me to change my mind.Instead I've been exploring a strange idea of using sqlite client side. People would save their data to a sqlite file that gets downloaded, then when they come back, drag the file back onto the browser to pick up where they left off. A little awkward, but 100% client side, side skirting most of the problems.(I realize hardly anyone would bother to use this app. But making it public with sqlite is really just an experiment. I host the app on a raspberry pi inside our home network and we use it that way.)	city41	13.5678215	-5.5272174	comment	3.0	14.0	1606782572	9.814713
25301883	So using random GUIDs is equally har	So using random GUIDs is equally harmful to indices? And how so?	pestaa	13.927988	-5.21735	comment	3.0	17.0	1607087717	-13.650742
25302611	> -- 8 bytes gives a collision p = .	> -- 8 bytes gives a collision p = .5 after 5.1 x 10^9 valuesSo yeah, a fifty-fifty chance of a collision after only five billion values. You’re at 10% chance before even two billion, and 1% after 609 million. I wouldn’t care to play this random game with even a million keys, the 64-bit key space is just not large enough to pick IDs at random. UUIDs are 128 bits; that’s large enough that you can reasonably assume in most fields that no collisions will occur.Storing a string is also inefficient, wasting more than three, and probably eight or more bytes (I’m not certain of the implementation details in PostgreSQL), growing index sizes and making comparisons slower. It’s more efficient to store it as a number and convert to and from the string form only when needed.	chrismorgan	13.955481	-5.21474	comment	3.0	16.0	1607092541	-4.216365
25303500	A couple resources with rigorous exa	A couple resources with rigorous examination of UUIDs and the tradeoffs involved with using them:- https://www.2ndquadrant.com/en/blog/sequential-uuid-generato...- https://github.com/uuidjs/uuid/issues/303 (also mentioned:  https://gist.github.com/1ma/c837e6f30c0869cfc1222f67ac8b1c52)I personally use v1 UUIDs as my main identifier and just take the performance hit. ksuids look interesting but don't think there's any need to use that when v1 uuids are good enough.	hardwaresofton	13.99256	-5.2161555	comment	3.0	13.0	1607096519	-13.661207
25350794	What is your distinction? Is mongodb	What is your distinction? Is mongodb a database? What about leveldb?Whether we want it to be so or not the term database is much more encompassing thank it used to be. You can try to fight that change if you want to but it means you'll be speaking a different language that most of the rest of us as a result.	zaphar	13.6310835	-5.3501325	comment	3.0	10.0	1607458804	9.879888
25368956	Not really as the WASM version of Sq	Not really as the WASM version of Sqlite is memory only and cannot write to disk. Please feel free to correct me if this has changed though	zubairq	13.59002	-5.5534053	comment	3.0	11.0	1607567905	9.727496
25411571	Also interesting: the latest version	"Also interesting: the latest version of my sqlite-utils CLI tool added a new ""sqlite-utils analyze-tables shanghai-ccp-member.db"" command which outputs interesting statistics about table columns - documentation here: https://sqlite-utils.readthedocs.io/en/stable/cli.html#analy...Here's a partial output from running it against that database file:    member.name: (2/11)
    
      Total rows: 1956731
      Null rows: 0
      Blank rows: 0
    
      Distinct values: 1072319
    
      Most common:
        650: 张伟
        621: 张敏
        620: 王伟
        579: 张磊
        507: 王磊
        488: 陈洁
        479: 张杰
        448: 王勇
        442: 李伟
        434: 张静
    
    member.sex: (3/11)
    
      Total rows: 1956731
      Null rows: 0
      Blank rows: 0
    
      Distinct values: 2
    
      "	simonw	13.598047	-5.575401	comment	3.0	13.0	1607902248	9.85799
25454726	Be very careful - even if things are	Be very careful - even if things are compatible, in my experience some things do not perform as well in CockroachDB which seems a bit counter intuitive but can be very true... We had problems making date range queries fast with tiny amounts of data, for example.I would seriously consider if you need CockroachDB - if you need that level of scaling you should also consider Cassandra (or Cassandra like) solutions as they will scale better but you will have to architect your app to think in this way (i.e. your app generates the views of the data it needs).If you don't need to scale yet use Postgres. Every piece of complexity has a cost and Cockroach while incredibly clever adds complexity that you might not understand or desire to manage over time. A nice interface won't help you when replicat	andy_ppp	13.561459	-5.2557335	comment	3.0	10.0	1608205864	9.8167305
25454871	I think it is bad. You just cannot g	I think it is bad. You just cannot go to your manager and PR and tell them we are using CockroachDB. If you have a manager who would understand this though, then your manager still cannot go to his manager with that name.	andi999	13.714556	-5.1902065	comment	3.0	10.0	1608207198	-4.5268974
25455093	We migrated a medium-to-large (in te	We migrated a medium-to-large (in terms of model complexity, not rows), from PG to CR about a year ago. It went pretty smoothly, but you'll definetly run into issues. (Very happy overall, btw)Every release has improved the compatibility story at an impressive rate.The 20.2 released added partial indexes and enums, which helped close the gap in our app(though, enums don't support binary encoding yet, so might not work with your pg driver (1))Things that are still an issue for us (all can be worked around):1 - Can't defer foreign key checks2 - No pg_trgm3 - Can't tell if an upsert was an insert or an update4 - No triggers (this is pretty huge)(1) https://github.com/cockroachdb/cockroach/issues/57348	latch	13.566554	-5.2518373	comment	3.0	14.0	1608209423	9.817364
25463110	What's the problem of linking agains	What's the problem of linking against SQLite? In my book it's much better because:- SQLite is coded in C, so performance and weight are going to be equal or better than any other reimplementation.- Having one code base means no compatibility issue between implementations- Also SQLite's codebase is so heavily tested and its track record is so good that I really don't see the point.	Ecco	13.636814	-5.6025887	comment	3.0	16.0	1608258380	9.875117
25463443	> Unless the app tracks all incremen	"> Unless the app tracks all incremental changes to apply when the user clicks ""Save"" instead of dumping it all back to disk, which seems difficult and error-prone to implement.That's the point of using SQLite instead of implementing it yourself. Because of how SQLite supports transactions, you can just update the database as you go; your changes will be physically written to disk, but they won't actually replace the old version from a reader's perspective until you explicitly commit, which is an atomic (and typically fast) operation.The downside of this approach is that if the application crashes while writing to disk, the database file itself might be in an inconsistent state, accompanied by a rollback journal (or write-ahead log) that contains the necessary information to recover it. But"	teraflop	13.580872	-5.5527043	comment	3.0	14.0	1608261798	9.722417
25464001	> [2] though paints a very different	> [2] though paints a very different picture.I don't agree.  That document states that the CVEs have historically required one of two preconditions:> The attacker can submit and run arbitrary SQL statements.> The attacker can submit a maliciously crafted database file to the application that the application will then open and query.If you look at the actual list of CVEs, all but one start with ‘Malicious SQL statement’.  The single one that doesn't is suffixed with ‘The bug never appeared in any official SQLite release’.In other words, there has never been an official release of SQLite which was vulnerable when presented with a crafted database file.	moonchild	13.622474	-5.596032	comment	3.0	19.0	1608267231	9.865085
25464140	I feel like there should be a way to	I feel like there should be a way to make a maliciously crafted database file execute arbitrary SQL... SQLite doesn't do stored procedures, but there's gotta be something in that surface area.	trevyn	13.575534	-5.576002	comment	3.0	10.0	1608268734	-4.321815
25465196	The SQLite website is a little more 	"The SQLite website is a little more positive than that, but as a ""quite a bit in the future"" option, rather than something that can happen today:> All that said, it is possible that SQLite might one day be recoded in Rust. Recoding SQLite in Go is unlikely since Go hates assert(). But Rust is a possibility.https://sqlite.org/whyc.html"	DougBTX	13.623026	-5.6596932	comment	3.0	11.0	1608281966	9.818377
25628474	Thanks.I think that you're spot on. 	"Thanks.I think that you're spot on. I've probably been more obsessed about ""the way it should be"" rather than ""what's the shortest path to get our first clients using it"". I suppose that it's a newbie mistake; out of fear.Part of me couldn't accept the idea of delivering something that would explode and that I wouldn't be able to support in production. It's still something I fear, especially when I look at our code coverage, even though I do care about the quality of what I create..As you say, switching from CouchDB to PGSQL wouldn't be easy at all.And yep, agreed about schools and restaurants, you're probably right."	dSebastien	13.583783	-5.2921276	comment	3.0	26.0	1609743095	-12.724771
35528095	As much as I detest MongoDB immaturi	As much as I detest MongoDB immaturity in many respects, I found a lot of features that are actually making life easier when you design pretty large scale applications (mine was typically doing 2GB/s of data out of the database, I like to think it is pretty large).One feature I like is change event stream which you can subscribe to. It is pretty fast and reliable and for good reason -- the same mechanism is used to replicate MongoDB nodes.I found you can use it as a handy notification / queueing mechanism (more like Kafka topics than RabbitMQ). I would not recommend it as any kind of interface between components but within an application, for its internal workings, I think it is pretty viable option.	twawaaay	13.643084	-5.331754	comment	3.0	18.0	1681233292	9.824092
35528255	The problem with a queue on SQLite i	The problem with a queue on SQLite is that every successful read implies a write. SQLite is fast enough that it may not matter, though.	zamalek	13.572218	-5.5233355	comment	3.0	12.0	1681233958	9.783162
35529136	Why use something as complicated as 	Why use something as complicated as SQLite? You can use a plain old set of directories and files as a queue, with sane, portable, exclusive, atomic locks, on any filesystem, with concurrent readers/writers. That's how we ran mail servers that handled millions (now billions) of messages a day, 20+ years ago.	0xbadcafebee	13.579109	-5.531002	comment	3.0	22.0	1681237515	9.763727
35544792	If there were JOINs it may be a sign	If there were JOINs it may be a sign MongoDB was not the best DB for you. It means the model was relational and a relational DB would be a better fit. MongoDB lookups are discouraged in general, and especially in analytical workloads, which cover a lot of data. MongoDB is better for the scenario, where all you need is already in the document.	skatanski	13.654222	-5.371136	comment	3.0	18.0	1681325353	9.879324
35544910	I would recommend against modeling t	I would recommend against modeling too many relations in a document DB. It can work, but it gets bogged down very quickly for the reasons you've stated.My off-the-cuff suggestion is that document databases are not built to model normalized relational data. If you try to do so, you bring a whole new level of pain upon yourself. It is do-able, but it is hard and annoying.I know this from extensive personal experience dealing with a large, highly relational Mongo database.I am very glad you found a solution within Postgres that works for you, and your mapping of document to row and collection to table is very apt!If possible, would you care to tell me what the size of said documents (rows) and collections (tables) are in your solution? I am curious if in another life, we might have built our 	softfalcon	13.601083	-5.3895497	comment	3.0	14.0	1681325860	9.865319
35547000	Yes, FerretDB is a layer which imple	"Yes, FerretDB is a layer which implements the MongoDB wire protocol on top of Postgres. Right now we are using JSONB, but this affects performance and we need to depart from this strategy in the long run.
We have an article which explains the concept [1].I wouldn't go into the document vs. relational argument, all arguments for and against would have merit. There are valid use cases for document databases (take e-commerce, for example), and we should not discount the fact that using a relational database is just more complicated. Using vanilla Postgres for a MongoDB use case will not be feasible for someone who's focus is, let's say, mobile application development. There is a reason behind MongoDB's popularity - it just provides a great developer experience. This is what we are aiming to r"	peterfarkas	13.596695	-5.3813963	comment	3.0	13.0	1681333901	9.861907
35547042	A use case I have for FerretDB is mi	A use case I have for FerretDB is migrating existing apps off MongoDB without needing to change the code. I find it funny that you could call these now „legacy“ apps.	mitjam	13.685598	-5.3156686	comment	3.0	13.0	1681334058	9.890115
35548224	80K is a good figure in my experienc	80K is a good figure in my experience.If you think about this in latency terms, you are able to insert a row and be done with the entire ceremony in about 12 microseconds. This is serialized throughput too.I think it is unlikely you would get this kind of performance with a hosted solution across the network. You could cheat with batching & caching, but for a cold, one-record non-query, nothing comes close to the latency of SQLite on a local NVMe device.	bob1029	13.550153	-5.512805	comment	3.0	20.0	1681340399	9.808691
35551235	Postgres over localhost is ~10x slow	Postgres over localhost is ~10x slower (as in RTT) than SQLite, I think mainly due to serialization and perhaps context switches?https://youtu.be/XcAYkriuQ1oIf you (more commonly) run on a different host, you’re looking more at 20x-50x and this is assuming you’re in the same region.To even get close to the SQLite level of throughput you’d have to stagger/pipeline your requests over a number of concurrent connections (proportional to the earlier x).You’ll eventually succeed at doing just that, with multiple machines. Congratulations, but now you have to also consider the N+1 problem, even for small Ns. In SQLite, you can afford much more back-and-forth with simple queries.	klabb3	13.562985	-5.502097	comment	3.0	14.0	1681362822	9.792402
35599506	Don't miss out on SQLite - https://n	Don't miss out on SQLite - https://news.ycombinator.com/item?id=31159281	draugadrotten	13.602396	-5.5794773	comment	3.0	15.0	1681733010	9.892716
35728115	Yeah, it's a complete bullshit move.	Yeah, it's a complete bullshit move. Mongoose OS (an embedded iot Plattform not the db) does something similar. It's extremely weasely and doesn't instill trust at all.	a2800276	13.632686	-5.300883	comment	3.0	11.0	1682603553	9.926881
35747748	Has SQLite ever attained multiuser f	Has SQLite ever attained multiuser functionality or is that still the main thing it lacks?	nickpeterson	13.575531	-5.516891	comment	3.0	10.0	1682719905	9.839331
35764945	This is brilliant, but please do Mon	This is brilliant, but please do MongoDB. It's less intuitive to query and could benefit greatly from GPT	hegem0n	13.607885	-5.328386	comment	3.0	11.0	1682877519	9.8497925
28710087	One thing that turned me away from M	One thing that turned me away from MongoDB was their utter lack of care for your data integrity that they displayed for years. Some of those instances were even documented. Then there were some bad defaults - some could _also_ cause data loss.For any component that's viewed as a database (as opposed to, say, cache), data integrity is one of the most important metrics (if not THE most).In contrast, PostgreSQL data loss bugs are rare - and are treated extremely seriously. Defaults are sane and won't lose data. It's one of the few databases I'm pretty confident that data will be there even if you yank a server power cord mid writes.Has MongoDB improved? Yes, leaps and bounds(seems to still fail Jepsen tests though). But I can't help but feel that it should have been released as a beta product	outworlder	13.664247	-5.313913	comment	3.0	12.0	1633029116	9.871748
28718459	WebSQL wasn't killed by opposition t	WebSQL wasn't killed by opposition to having a relational API, it was killed because the spec was tied to, and only implemented by embedding, a specific, identified version of SQLite.	dragonwriter	13.545127	-5.5379143	comment	3.0	11.0	1633096526	9.818194
28768680	I use Rails and Mongo at work. There	"I use Rails and Mongo at work. There is a schema, enforced declaratively at the application layer (mongoid). With Rails Console querying the database ad hoc is even easier than with SQL, thanks to mongoid api and Ruby’s expressiveness. 
There are no transactions, but single document writes are atomic. 
Performance is pretty good; the one hardship I run into is that the mongoid api is so high level that you don’t see when you’re firing way too many queries at the dB (but that’s an ODM issue, not mongo’s, other ODMs might not do that)."	felipeccastro	13.584853	-5.372084	comment	3.0	15.0	1633489357	9.849529
28768801	Single machine postgres is mostly fi	Single machine postgres is mostly fine when you're working with less than hundreds of million of rows, less than a few hundred gigs of data, don't need HA, and don't need more than a few thousand QPS. Outside of those constraints is why new things exist imo.	foota	13.5365505	-5.352996	comment	3.0	15.0	1633490559	-6.749253
28911164	> I still marvel that they've built 	> I still marvel that they've built such a big company around a SQLite fork.> Expensify is built on Bedrock - a private Blockchain-based data foundation atop a custom fork of SQLiteThis seems just that they use Bedrock, which itself is a blockchain data foundation (whatever that means I have not much idea), then that thing uses SQLite fork.For me this is more like someone uses ABSL or MYSQL. Not build around it, but just a small piece of tech.	justicezyx	13.622415	-5.571675	comment	3.0	14.0	1634588571	9.8574915
34163101	I was not aware that SQLite creates 	I was not aware that SQLite creates temporary indexes in places where other databases would perform merge joins.https://sqlite.org/tempfiles.html#transient_indicesSQLite also creates background indexes for ROWID, of which I was aware.https://sqlite.org/rowidtable.html	chasil	13.55061	-5.537607	comment	3.0	23.0	1672247248	9.790483
34177046	I wonder if there's an SQLite versio	I wonder if there's an SQLite version somewhere.	euroderf	13.622475	-5.586586	comment	3.0	10.0	1672343426	9.848158
34178898	> While all of these formats can be 	> While all of these formats can be generated by the client before inserting them into the database, for the purpose of simplicity and consistency, having them be generated within the database engine is preferred.This very much misses the point of UUID/ULID pkeys. The whole idea is that you can generate them client-side without needing a connection to the database and assume that they will not conflict. This speeds up everything considerably allowing you to just write to the database once when generating new records without holding onto a sequence, without needing to worry about synchronizing ids between client & server, and without needing to worry about synhronizing sequences between multiple shards.We've been using ULIDs with postgres in production for years without the database even be	ComputerGuru	13.959322	-5.2285376	comment	3.0	10.0	1672352697	-13.659552
34178605	I prefer UUIDv7 over ULID because of	I prefer UUIDv7 over ULID because of the standardization process.https://en.wikipedia.org/wiki/Universally_unique_identifier#...	onnnon	13.986494	-5.2152343	comment	3.0	12.0	1672351236	-13.67367
34208905	SQLite 2022 Recap	SQLite 2022 Recap	nalgeon	13.610702	-5.5848165	story	3.0	138.0	1672596675	9.839321
34250043	Even if you're not using LiteFS yet,	Even if you're not using LiteFS yet, the following bit of SQLite advice makes this article absolutely worth the 11 minutes it allegedly takes to read:> Use WAL mode(For bonus points, also bump cache_size up to 20000 or so and set synchronous=NORMAL)	PreInternet01	13.594404	-5.504296	comment	3.0	21.0	1672859782	9.818143
34250692	The SYNCHRONOUS pragma is great but 	"The SYNCHRONOUS pragma is great but I'll mention that there is a durability trade-off. In ""NORMAL"" mode, there is not an fsync() after every transaction so you could lose recent transactions if you unexpectedly shutdown. The WAL is append-only so you don't risk data corruption (which is great)."	benbjohnson	13.539973	-5.367589	comment	3.0	16.0	1672862821	9.786544
34260606	Whenever I read SQLite I think of mi	Whenever I read SQLite I think of missiles	turbobooster	13.612635	-5.580901	comment	3.0	10.0	1672931302	-4.281521
34260796	> A transaction committed in WAL mod	> A transaction committed in WAL mode with synchronous=NORMAL might roll back following a power loss or system crashThat's a pretty big failure to preserve durability.	gpderetta	13.544611	-5.3833385	comment	3.0	15.0	1672931934	9.785975
34268350	Good writeup on using LiteStream at 	Good writeup on using LiteStream at this early stage, though I wouldn't say it's production-ready based on a skim, though it might be a good fit for read-heavy apps which don't have a lot of data.One thing that's not clear to me is whether Litestream+SQLite works in-memory. If Litestream wrote to disk on the primary node, but kept the full DB in-memory for facilitating reads, I can definitely see how it would be a lot faster than Postgres (as the author claims).Though I'd also like to know if any RDBMSs have been designed for that use case, as I'd imagine traditional DB optimizations   have been made for high incidence of disk access that would no longer hold true if the entire DB was in-memory	pcthrowaway	13.556934	-5.4396963	comment	3.0	12.0	1672960403	9.723932
34329456	NoSQL fad was the most destructive I	NoSQL fad was the most destructive I can think of. Those had their place as niche tools, but they somehow became the default for a while. Once you pick the wrong DBMS, you're building on quicksand.	hot_gril	13.528579	-5.397266	comment	3.0	11.0	1673376176	9.83418
34355744	SQLite is the one project that deser	SQLite is the one project that deserves an exception. There is a near zero chance anyone else can do better with similar quality (and test coverage!)Sometimes you need to be pragmatic IMHO.	xenadu02	13.626223	-5.598541	comment	3.0	13.0	1673540037	9.866003
34360436	I do think it would be worth SQLite 	"I do think it would be worth SQLite having an ""official"" npm package - even though setting it up in the first place would require quite a bit of effort.The JavaScript world is culturally so dependent on npm now that adoption of SQLite in that world would massively increase given the availability of a good ""official"" package.And without an official one I imagine there will quickly emerge dozens of unofficial ones, many of which will end up poorly maintained in the future."	simonw	13.574035	-5.5713515	comment	3.0	10.0	1673558640	9.860046
34387675	Windows struggles horrendously with 	Windows struggles horrendously with lots of small files. If you tried the same task on Linux you’d see a large jump in performance. I don’t know if Linux small file access could match SQLite but it would be a lot closer.	chongli	13.546371	-5.543649	comment	3.0	13.0	1673770056	9.797388
34434222	Concurrent writes and replication!Se	Concurrent writes and replication!See also this thread on the SQLite forum: https://sqlite.org/forum/forumpost/d9b3605d7ff40cf4	simonw	13.570307	-5.5136256	comment	3.0	136.0	1674082061	9.788621
34435123	What does it mean for SQLite to use 	What does it mean for SQLite to use something as a backend?  How much of it is still SQLite at that point?	hinkley	13.577892	-5.5528264	comment	3.0	10.0	1674087944	9.846662
34435742	Litestream didn’t exist until late 2	Litestream didn’t exist until late 2020, meanwhile postgres has existed for decades.Moreover, SQLite requires the place you run your application to have durable storage, which is a huge departure from the status quo.It’s definitely neat, but the stack as a whole doesn’t strike me as mature enough to replace Postgres just yet.	hamandcheese	13.548926	-5.461178	comment	3.0	18.0	1674092876	9.739292
34436253	Just playing devil's advocate (I don	"Just playing devil's advocate (I don't have much of a dog in the fight):* SQLite's replication isn't built in, you have to use another library (LiteStream, LiteFS, etc) to achieve it. That in itself is an indication it's not inherently designed for such, and at a minimum will require a lot more testing to ensure your HA/DR failover scenarios work like you're envisioning. Perception matters.* Litestream, LiteFS today are in ""beta mode"", fairly DIY, mostly CLI and YAML configs, making it comparatively complex and error-prone to configure vs. most n-tier databases which offer OOTB replication via GUI, and it's usually just a checkbox with cloud PaaS databases.* ""No one ever got fired for choosing IBM"" there are tons of blogs and walkthroughs of setting up HA/DR for all the major RDBMSes, it's"	kthejoker2	13.560994	-5.4689007	comment	3.0	17.0	1674097659	9.755301
34440000	Developers can do a lot to fix this 	Developers can do a lot to fix this by simply choosing SQLite  to store all the local things.Performing backups of our production apps used to take hours (especially in cheap clouds) because of all the loose files. Today, it takes about 3-5 minutes since there are just a handful of consolidated files to worry about.	bob1029	13.579332	-5.5256443	comment	3.0	28.0	1674134759	9.799977
34451843	I've had good success with using aut	I've had good success with using auto-incrementing BIGINTs as internal IDs and creating an additional BYTEA field as external IDs. Foreign keys would be based on the internal IDs, anything user-facing would use external IDs. I think it's a good compromise as it keeps foreign key size small and still allows hiding internal structure from users.	ThePhysicist	13.943361	-5.223032	comment	3.0	19.0	1674215807	-13.647497
34453002	Why would you use an integer primary	Why would you use an integer primary key and a public facing UUID? That seems like it's the worst of both worlds: ugly externally visible identifiers, record bloat, a database that you can't easily merge in the event of backups or DR, and having to roundtrip to the DB before you know the ID of a record.I personally stick to UUIDs in pretty much all cases, with the exception of where there are justified and benchmarked performance reasons not to.	cameronh90	13.969373	-5.217464	comment	3.0	18.0	1674222267	-13.641434
34453305	Disclaimer: not a dba so my terms mi	Disclaimer: not a dba so my terms might not be appropriateI’ve seen uuid4 which replaces the first 4 bytes with a timestamp. It was mentioned to me that this strategy allows postgres to write at the end of the index instead of arbitrarily on disk. I also presume it means it has some decent sorting.[inspiration](https://github.com/tvondra/sequential-uuids/blob/master/sequ...)	nargella	13.961055	-5.2256346	comment	3.0	16.0	1674223684	-13.665721
34454092	The author misses one advantage of U	The author misses one advantage of UUIDs: if you’re working in high-throughput distributed systems, serial IDs create a bottleneck and single point of failure in the service handing out IDs.With UUIDs any service can generate an ID itself and tell downstream services about it in parallel—even if one of them is down, slow, or needs retrying.	glacials	13.9598	-5.200121	comment	3.0	11.0	1674227364	-13.647287
34455443	Are sequential id’s a security risk?	Are sequential id’s a security risk?In one of our systems we’ve seen customer guess at other accounts by just incrementing the sequence.The rule of thumb I used to use is if an Id is going to be used for lookups or being exposed externally use uuid otherwise us sequential.The hard thing about the above rule is that it’s hard to tell when you are designing the db if the id will be used externally/for lookups or not. Requirements change later.	victor106	13.947366	-5.205975	comment	3.0	15.0	1674232166	-13.637094
34504844	But is GPT a web scale like MongoDB?	But is GPT a web scale like MongoDB?	webscalist	13.644457	-5.3131585	comment	3.0	13.0	1674574488	9.8691435
34561384	Should I be using file extension .db	Should I be using file extension .db or .sqlite3 ?	jacob019	13.568246	-5.5657144	comment	3.0	11.0	1674937291	9.808871
23447462	This is really cool, thanks for your	This is really cool, thanks for your work! I really love couchdb. I have seen tickets for document based ACLs on their github recently, I think this is the last feature they need to open up usage across many more domains. The core app works great for replication between dbs and to the edge using pouchdb, but almost everyone is turned off by the database-per-user that is required to use it. If they solve that I think their adoption could skyrocket, if they can get over the hurdle of years of neglecting this core feature where everyone became disillusioned by it. It’s positioned as a “put your db up on the internet and interact/replicate over http” but it doesn’t work for most non trivial use cases because everyone can then see the data, so you end up layering adapters on to do ACL. This sho	lukevp	13.586263	-5.2098975	comment	3.0	32.0	1591539123	9.612501
23507210	After the latest Jepsen analysis of 	After the latest Jepsen analysis of Mongo I'm surprised anyone would use it for anything that serious.	pier25	13.708785	-5.3073726	comment	3.0	13.0	1592028198	9.921757
23508700	Shorting a banking company because t	Shorting a banking company because they chose to use MongoDB... you can tell that an engineer wrote this comment. You're missing the forest for one particular tree.	whack	13.716337	-5.3068633	comment	3.0	13.0	1592047684	9.921258
23508052	What's wild about this is that Mongo	What's wild about this is that Mongo isn't even in fashion anymore! NoSQL has been supplanted by NewSQL, and relational dbs are in season again. Even if they were trying to follow the trend, they'd be a half-decade behind.	sohamsankaran	13.617399	-5.34448	comment	3.0	20.0	1592039729	9.874756
23510405	I'm not sure how slqite as your appl	"I'm not sure how slqite as your application file format has anything to do with open source, honestly. It's certainly super easy for open source projects to use, but a closed source proprietary application using an encrypted sqlite file sounds perfectly sensible to me?We all win when folks decide to leave it accessible, but I'm not going to hold ""encrypting a file format so that people can't easily reverse engineer it"" against folks who are trying to sell software."	TheRealPomax	13.594388	-5.579077	comment	3.0	15.0	1592064469	9.830578
23510511	I have an application that uses sqli	I have an application that uses sqlite as their file format but they've cleared the header so you can't open it directly.I'd love to be able to make secondary applications like you've described but being enterprise software they don't want to make it too easy.They obviously want to keep people locked in with their $40k per seat application!I guess the first step is figuring out the page size and other bits the other meta data you set in the header [1].I know I just have to sit down and understand the format better and I will eventually figure it out...[1] https://www.sqlite.org/fileformat.html	lbutler	13.575601	-5.525391	comment	3.0	49.0	1592065338	9.839454
23510632	This is a security flaw of the syste	This is a security flaw of the system or application using SQLite, though. It is trusting data it should not trust and executing code provided with that data.	empthought	13.6301565	-5.590755	comment	3.0	15.0	1592066110	9.898643
23513009	I'm surprised that nobody's pointed 	"I'm surprised that nobody's pointed out that there are actually valid reasons other than greed to obscure your file format.  It's an implementation detail, not a contract.  If customers begin relying on the implementation details, you end up with angry customers when you change the implementation details.  A SQLite db without the header is basically a statement saying, ""we are using the obvious file format here for our convenience, not for general purpose access.  Screw around in here at your own risk.""If you modified their app's internal state db and screwed it up because they have designed their software with certain assumptions that aren't clear from just reading their db schema, that would be a nightmare for them to support.  The easiest thing for them to do is just to try to discourag"	hamburglar	13.584821	-5.5868535	comment	3.0	12.0	1592084463	9.759927
23519571	One of the more prominent uses of sq	One of the more prominent uses of sqlite in Firefox is the 'places' db where your history and bookmarks are stored.   If you go to History->Show All History, then select a few thousand entries and press delete, you can lock firefox up for several minutes, tens of minutes even.I don't think this is necessarily damning of sqlite though, I'm pretty sure Firefox is not quite doing things right in some cases.  I can delete thousands of rows in sqlite in mere milliseconds, so something else is going on.   A shitty schema maybe?  I'm not sure.	catalogia	13.570176	-5.5382714	comment	3.0	11.0	1592156170	9.843929
23541662	If you're interested in this, you mi	If you're interested in this, you might be interested in Datasette: https://datasette.readthedocs.io/en/stable/Which seems to me to be farther along in providing advanced querying/faceting/visualization/sharing capabilities on top of sqlite.(I love jupyter, and this kernel seems neat; not trying to throw stones at anybody, just to link a project in a similar domain)	llimllib	13.534895	-5.5711837	comment	3.0	15.0	1592328290	9.790241
23595522	I'm surprised to see that Boolean fe	I'm surprised to see that Boolean feature flags are common. We almost always ramp up percentages of UUID space or randomly chosen requests, to reduce the blast radius of a bad change.	erik_seaberg	13.978226	-5.19686	comment	3.0	23.0	1592774525	-13.5842905
23628407	MongoDB 4.4 seems to be a lot slower	MongoDB 4.4 seems to be a lot slower in data load and queries	PeterZaitsev	13.676117	-5.2840986	story	3.0	27.0	1593009929	9.867887
23678381	There is too much opinion in your st	"There is too much opinion in your statement.Mozilla opposed it, rightfully so, in that it would dictate that SQLite be the implementation used everywhere. Mandating the inclusion of SQLite is not a spec.As much as I like SQLite and looked forward to it being in 2/3 of browsers, Mozilla made the right call. The web should be implementable entirely by the specification.Google likes to define the spec as the identity function of the implementation. Popeye specs, ""I yam what I yam and dats all that I yam""."	sitkack	13.583111	-5.560032	comment	3.0	22.0	1593443898	9.834634
23725906	Author here. You can move the sqlite	Author here. You can move the sqlite database to a separate location by setting a variable, and that should resolve the syncing issues. I do this and have the files synced via Dropbox across my different machines.	jethroksy	13.573633	-5.492438	comment	3.0	10.0	1593798158	9.786574
20006276	You can generate uuids that play nic	You can generate uuids that play nicer with database storage / indexing. NEWSEQUENTIALID() in MSSQL, for example.The keys will be easier to guess again, but if all you have to do is guess a primary key to get access to the underlying data, something else isn't right anyways.	dvlsg	13.964743	-5.218987	comment	3.0	13.0	1558742364	-13.660583
20086307	I wonder how many poorly designed da	I wonder how many poorly designed database schemas this will break that used email as a primary key/id.	pmart123	13.860575	-5.2452354	comment	3.0	10.0	1559585721	-13.65484
20226903	I am a bit curious of the MongoDB re	I am a bit curious of the MongoDB removal.Truecrypt and Qt4 I sort of understand, but MongoDB is still actively developed, so there seem to be a story there...Update: I guess thats the reaction to the not OSI approved licence they switched to late 2018.	chme	13.718617	-5.2624693	comment	3.0	10.0	1560975358	9.864432
20265029	Query Plan Caching in CockroachDB	Query Plan Caching in CockroachDB	dilloc	13.615417	-5.2192016	story	3.0	68.0	1561392620	-10.796493
13611642	My use case: I run a couple of state	"My use case: I run a couple of stateful multiplayer games where I have a Node.js server writing to MongoDB on each player update (e.g. ""update player.x to 123""). I only read from the DB when a player logs in and is added to the game or when the server restarts (items etc). As long as a player is online the state is just kept in in memory (a big array of all the players) but is written to the DB every time it's updated.This means the game could theoretically work without a DB at all, the time it takes to write to the DB etc doesn't matter as long as it happens in the correct order. Read speed is also not really relevant since it happens so seldom.The MongoDB document is the same as the player object in Node.js.I've been thinking of migrating to RethinkDB but I've also been looking at Postgr"	Kiro	13.5840645	-5.4054193	comment	3.0	13.0	1486679457	9.852047
13611883	Even those use cases can sometimes b	Even those use cases can sometimes be met by an RDBMS. Postgres can outperform Mongo as a key value, or json doc store. But Mongo is what many people think of for something like that.	Bedon292	13.586569	-5.3932614	comment	3.0	24.0	1486681604	9.851745
13614247	You might have a point about Postgre	"You might have a point about Postgres being faster than whatever NoSQL database, but there's really no need for all the name calling. Especially the ""lazy"" is very uncalled for in my opinion - there's just too much to learn, and too little time. If you're a 20-something (or whatever age, for that matter) and have to maintain the entire system of a single company, you're simply not going to be able to be a master of every part of the stack, or even know where you're making the wrong choices."	Vinnl	13.538177	-5.330432	comment	3.0	14.0	1486718795	9.760482
13628328	If you are going to invoke the sacre	If you are going to invoke the sacred name of 'sqlite', then I expect to see rock-solid code and quality testing.Instead, there are two tiny tests, and I found a couple of issues in 30 seconds of looking at the code.EDIT: I should prove my point.1) Race condition on calculating uuid (obviously won't be too serious for a good uuid implementation)2) No check that file is written successfully.3) No check when json is invalid, just silently swallowed, or filesystem full.4) Makes one file a json file, will scale terribly past a few thousand json files.	CJefferson	13.582667	-5.58834	comment	3.0	18.0	1486908215	9.818751
13628371	Good point on 2 and 3. Should just i	Good point on 2 and 3. Should just involve checking the previous commands return code before echoing the uuid. I'll get that patched up and ship a new version in a bit.Not sure what you mean exactly  by 1 and 4 though.	nodesocket	13.994376	-5.2113347	comment	3.0	12.0	1486908776	-13.703801
13662133	Right now not really. Cockroach perf	Right now not really. Cockroach perf don't allow you do have a big dataset given the performances.	sametmax	13.658494	-5.209627	comment	3.0	14.0	1487268627	9.992336
13810654	Announcing Free Tier and Live Migrat	Announcing Free Tier and Live Migration Tool for MongoDB Atlas	nparsons08	13.570428	-5.2449074	story	3.0	12.0	1488897885	9.863344
13926988	WebSQL was basically SQLite accessib	WebSQL was basically SQLite accessible from JS - which also, unfortunately, was the reason for it being dropped... apparently the standards committees only want standards with multiple competing implementations.Which is total bananas, given the fact that there's only one (free, ultra portable, tiny) embeddable SQL database - SQLite. Which every browser except IE/Edge ships, anyways, for internal data storage.	mschuster91	13.542794	-5.5400963	comment	3.0	14.0	1490136323	9.795733
13987713	I am using MongoDB and it works like	I am using MongoDB and it works like I want it but I am roasted all the time on HN because of it and told to be using Redis instead. Still considering the switch but I don't want to run into problems like this.	Kiro	13.643891	-5.3080497	comment	3.0	13.0	1490804241	9.855107
30766404	MongoDB Zealots I hear you say? Wher	MongoDB Zealots I hear you say? Wherefore art these zealots? I watch social media for MongoDB on a regular basis and I can't say I have come across much zealotry in the last 8 years :-)Most of our customers are reasonable rational people who use MongoDB alongside a collection of other database technologies.Personally as someone who has worked in pre-sales and more recently developer relations, at MongoDB I find our customers and users are suspicious of zealots.	jd_mongodb	13.688415	-5.3085546	comment	3.0	10.0	1647958815	9.919166
30881478	For a small team, you could look at 	For a small team, you could look at fossil: https://fossil-scm.org. It’s what SQLite team uses.	anticrisis	13.570025	-5.554819	comment	3.0	15.0	1648836934	9.897055
30887559	> I watched with dread how the Mongo	> I watched with dread how the MongoDB fiasco played out a decade ago.Could you elaborate on this? MongoDB as a company is worth $30B, so it looks like they did at least some things right.	rsp1984	13.714175	-5.2690063	comment	3.0	12.0	1648900751	9.922637
30919774	A fork implies that the projects are	A fork implies that the projects are going diverge, which it seems they don't want to happen.From a quick reading of that page I think the LumoSQL authors are making the effort to maintain their set of modifications as some kind of patch which will continue to be compatible with future SQLite versions as they are released.	warp	13.641863	-5.583904	comment	3.0	10.0	1649170280	9.830706
30938068	I would love to see more stuff like 	I would love to see more stuff like that.An application I have written recently for personal use is a double entry accounting system after GNUcash hosed itself and gave me a headache.  This is based on Go and SQLite. The entire thing is one file (go embed rocks) and serves a simple http interface with a few JS functions like it is 2002 again. The back end is a proper relational model that is stored in one .db file. It is fully transactional with integrity checks. To run it you just start program and open a browser. To backup you just copy the .db file. You can run reports straight out of SQLite in a terminal if you want.This whole concept could scale to tens of users fine for LOB applications and consume little memory or resources.	uuyi	13.5415945	-5.4776955	comment	3.0	13.0	1649282878	9.782154
30972844	Signal's insistence on doing the wro	Signal's insistence on doing the wrong thing for 99% of users (storing media blobs in SQLite) drives me crazy. Protect our metadata over the wire, fine, but there is almost no additional protective benefit whatsoever by storing the files inside SQLCipher when the user's fingers can be broken one-by-one until they unlock their phone.Meanwhile it causes issues just like this, not to mention broken integration with every audio/gallery/video app on the device.	outsb	13.572486	-5.5407476	comment	3.0	14.0	1649543934	9.736053
30979765	This doesn't seem like a joke, it se	"This doesn't seem like a joke, it seems like a guy outright spreading misinformation. Not sure what was the point of the UUID preamble, his ""joke"" has nothing to say about UUIDs."	mdoms	13.99608	-5.2130837	comment	3.0	16.0	1649613633	-13.670318
31040659	I’d love to see a good open-source s	I’d love to see a good open-source sync solution between SQLite and PostgreSQL to get the best of both worlds, like what the Watcom/Sybase/SAP SQLanywhere offered.	fmajid	13.560224	-5.4962606	comment	3.0	10.0	1650032933	9.797283
31040897	One of the Bytebase authors here and	One of the Bytebase authors here and I am the one who chose SQLite in the first place.The project started in 2021 Jan and I did notice litestream. And actually, one of the main reasons I chose SQLite is because of litestream. Because I could see it could be our HA solution when needing it.SQLite is great, but the schema change constraint is really painful as you mentioned.As to the Tailwind, as a backend engineer working on database for most of my 10+ career and single-handedly built the site, I can only say it's godsend;)	tianzhou	13.585658	-5.5239863	comment	3.0	10.0	1650034276	9.790124
34650523	Setuid in Unix created to enable a g	Setuid in Unix created to enable a game	zdw	13.929654	-5.22103	story	3.0	93.0	1675475582	-8.975414
34727177	This is a great example of the kinds	This is a great example of the kinds of problems they're trying to tackle. This shouldn't be an issue. Just use sqlite or similar.	winrid	13.603487	-5.5728946	comment	3.0	20.0	1675962333	9.84134
34774358	For those of you interested in brows	"For those of you interested in browser-based search with SQLite WASM, I’ve written a small post on the Craft of Emacs search page.You can check out the actual search here:
https://craft-of-emacs.kebab-ca.se/search.htmlKudos to the SQLite team. It was a joy to implement."	zainab-ali	13.562718	-5.5300627	comment	3.0	10.0	1676301138	9.814511
34777420	WebSQL was a proposed web standard t	WebSQL was a proposed web standard that all standards-compliant browsers would have to implement. The standard was tightly coupled to the SQLite implementation, which was a problem for any browser that could not just bundle SQLite. Ultimately the standard was rejected because it was too coupled to a single implementation.	jt2190	13.553807	-5.5539503	comment	3.0	12.0	1676311246	9.815393
34813033	people have been providing acid tran	people have been providing acid transaction semantics on single machines for 50 yearsdo you think ims/db ran on a clusterthe d in acid stands for durabilityyou're talking about pitr, which is what mysql semi-sync provides (and afaik you are correct that sqlite doesn't offer pitr)	kragen	13.542074	-5.469967	comment	3.0	16.0	1676506606	9.804046
34813202	I would love to use SQLite for all m	"I would love to use SQLite for all my Django webapps that have only several simultaneous users, but this article suggests there are too many footguns for me to be able to do that.Is there a ""using SQLite for a multi-threaded webapp for dummies"" package that does all the config I need so I can just drop it in and go and not tune anything?Paging fly.io founders etc! If I have a persistent volume can my fly.io apps use SQLite? What are other good micro-hosting options?"	bravura	13.582674	-5.5251718	comment	3.0	26.0	1676507565	9.839451
34813600	> It's not a good option for what yo	"> It's not a good option for what you appear to want.Ok but the article you're replying in the comments to says ""SQLite is all you need for nearly everything"", and what the comment you're replying to is describing is, to use their very apt word choice, entirely ordinary.So how do we square this circle of somebody being told both ""SQLite is all you need for everything"" and ""it is not a good option for your totally ordinary use case""?I think the answer is that you are a different person than the author of the article and you don't agree with the article's claim. Which, great, that was irskep's entire point!I tend to agree with irskep that this SQLite architecture is really interesting, but I also don't quite get it. There seem to be a lot of missing details for totally bog standard applicati"	sanderjd	13.613569	-5.5728335	comment	3.0	31.0	1676510140	9.8130045
34814088	Everytime I try to use SQLite I run 	Everytime I try to use SQLite I run into db locking issues where I seemingly have to try to run my query in a retry loop. Am I doing something wrong or does SQLite just not play nice in multi threaded contexts?	umvi	13.594688	-5.543643	comment	3.0	11.0	1676513731	9.74074
34815441	Litestream isn't for those kinds of 	Litestream isn't for those kinds of use cases. It's for DR, not availability and/or scale.	im_down_w_otp	13.526916	-5.4976535	comment	3.0	10.0	1676525522	9.737789
34927076	I'm wondering why they don't give ev	I'm wondering why they don't give every mail a UUID. Probably because someone wanted to save a few bytes.	amelius	13.992478	-5.2102623	comment	3.0	12.0	1677259759	-13.652294
34956009	Little quick for the blame game, how	Little quick for the blame game, how about you try and find out why Couchbase withdrew their sponsorship in the first place	pluc	13.633541	-5.1918607	comment	3.0	14.0	1677503639	9.673445
34990037	If all of your agents are seeing the	If all of your agents are seeing the UUID for the first time, they cannot deduplicate amongst themselves without quorum or shared state which has race conditions itself. It’s non trivial.	birdyrooster	14.000488	-5.2166705	comment	3.0	13.0	1677714659	-13.667266
36901334	Even at a billion requests per secon	Even at a billion requests per second, 128 bit UUIDs shouldn't collide for something like a billion years.And that's if you're going completely random and not taking care to try to reduce collisions.	mabbo	14.015197	-5.236074	comment	3.0	17.0	1690499732	-13.663182
36946640	You'd also need to qualify it to exc	You'd also need to qualify it to exclude sqlite, which is on everything. No way there's more wordpress sites than phones.	giraffe_lady	13.572895	-5.518375	comment	3.0	10.0	1690827317	9.804171
37063599	How would mutually incompatible upst	How would mutually incompatible upstream changes from multiple SQLite edge instances be resolved? You'd need user input for that, right?	luckystarr	13.594914	-5.546772	comment	3.0	11.0	1691592690	9.840693
37067315	Postgres was cool. Now SQLite is coo	Postgres was cool. Now SQLite is cool. In a few years .INI files will be cool. Fads gonna fad.	0xbadcafebee	13.542467	-5.4359107	comment	3.0	10.0	1691609087	9.797979
37069343	Honest question: why is SQLLite need	Honest question: why is SQLLite needed for local? Why would you not have PG at edge that replicates data with central PG? That way the SQL dialect problem you mentioned wouldn't exist.	Omnipresent	13.627994	-5.5584826	comment	3.0	15.0	1691620750	9.865368
37197073	Datasette is a open project from sim	Datasette is a open project from simon willison (a fairly well known HNer), and this looks like his monetisation project - good luck to you, hope Softbank buys you out soon :-)(It's a sort of wrapper around sqlite files so it's fairly easy to publish a file, think maybe Tableau for sqlite?)Anyway all the best	lifeisstillgood	13.52051	-5.5523615	comment	3.0	22.0	1692518239	-11.5949545
37255619	[god damn is it annoying to navigate	[god damn is it annoying to navigate through fossil to actually find a file]It appears to be basically sha3sum against an included manifest file.https://sqlite.org/src/file?name=tool/src-verify.cI am kinda perplexed at the threat model resolved by including a manifest in the same tree as the adulterated sources, checked by a running a tool compiled from those same adulterated sources.	tedunangst	13.612468	-5.593907	comment	3.0	13.0	1692917789	9.638307
37255685	This version is still buggy for larg	This version is still buggy for large CTE or JOINs for edge cases. A bug has been introduced with the query planner optimizations in SQLite >3.39 (3.4X) that degrades query performance in some cases predictably by 3 orders of magnitude.So just to see if this was still a problem, I recompiled findsight.ai with this new amalgamation and yep, all queries that used to take about 300ms now take 3 to 10 seconds to complete. There's no difference in the query plans created, it's just a bug.I'll probably bisect by commit (or whatever Fossil calls it) at some point to nail down what changed, but then again 3.39 is rock solid enough I don't have a reason to upgrade. In the meantime, if you're running into one of these edge cases, try downgrading to 3.39. I also have no gripes, it clearly works well 	summarity	13.535614	-5.550935	comment	3.0	14.0	1692918276	9.779897
37258373	Not Postgres-based (but wire- and mo	"Not Postgres-based (but wire- and mostly syntax-compatible): cockroachDB using column families is much like a columnar MPP.
Yugabyte is PG-based and MPP but not columnar."	hazaskull	13.595599	-5.2829294	comment	3.0	20.0	1692940857	9.872573
37470475	Plus I could easily represent UUID i	Plus I could easily represent UUID in base64, such as JlEt5BSYe0enwB7nxl5V6g, which makes it shorter if I need that.	czechdeveloper	13.981265	-5.209678	comment	3.0	24.0	1694452972	-13.661329
37470513	It somewhat matters aesthetically, b	It somewhat matters aesthetically, but mostly people are going to ignore long random strings.UUIDs are at least visually kind of white noise, companies have no problem+with+links?that=look&like=this, so why do they care about UUIDs?	eternityforest	13.973616	-5.2097416	comment	3.0	20.0	1694453143	-13.663036
37470867	> Does it make the URL in the URL ba	> Does it make the URL in the URL bar longer? Yeah, but does that matter?I appreciate shorter URLs any time I copy and paste them, which always involves looking at them and sometimes involves scrolling to the end to remove tracking- and search-related fluff.128 bits is an absurd amount for a unique ID within a single system. Even 48 bits is very, very large -- enough to provide a unique ID (MAC address) to every Ethernet device made for something like 100 years.The purpose of a UUID is to provide a negligible probability of collisions between randomly-generated IDs in a global space forever. Almost no applications require that, so most of the time using a UUID is just needlessly taking up space.	AdamH12113	13.942609	-5.2064347	comment	3.0	11.0	1694454508	-13.651931
37471026	Author here. I posted this because I	Author here. I posted this because I've witnessed many systems in companies I've worked for where our end-users needed UUID to communicate with it (technical support, customer ID, etc.) in a way that makes communication harder. We could've used another shorter ID scheme, which would be fine.The good thing about UUID is that it's omnipresent. From what I've heard, it's this lengthy (2^32) because it was hard to guarantee uniqueness when it was conceived in the telecom industry. The length is overkill, and per se, that's fine, but the fact that it dampers communication is awful.That all said, since posting this, I've come to terms with accepting that it's part of life ¯\_(ツ)_/¯P.S. Using a second human-friendly ID to end-users is an alternative adopted by some projects. However, most project	henvic	13.965258	-5.195883	comment	3.0	12.0	1694455164	-13.645599
37495219	The big difference is that every Win	The big difference is that every Windows computer (in a professional environment) comes with a very nice GUI tool for easily editing Excel files. A tool that basically everybody know how to use. The same cannot be said for SQLite.SQLite is great for storing application state and config options set from within the app, but it is a pretty terrible format for end users to edit.	dagw	13.525103	-5.5744033	comment	3.0	10.0	1694603906	-12.221321
37553826	I was optimistic that Audacity adopt	I was optimistic that Audacity adopting SQLite would be a substantial improvement in its file saving capabilities. In practice I encountered many gotchas:- On Linux, saving into a new file onto a root-owned but world-writable NTFS mount created in /etc/fstab, fails due to permission errors or something. Saving into an existing file works as usual.- Files are modified on disk when you edit the project in the program, creating spurious Git diffs if you check Audacity projects into Git as binary blobs. And when you save the file, old and deleted data is left in the SQLite file until you close the project's window (unlike saving a file in a text editor), and you can accidentally commit that into a Git repo if you don't close the window before committing. (I recall at one point that you had to 	nyanpasu64	13.569337	-5.55101	comment	3.0	25.0	1695027329	-5.8772874
37553844	At this point, why are we still usin	At this point, why are we still using JSON/XML when there is SQLite for new projects? Stop the non sense of JSON/XML. SQLite is like json, but very queryable.  Just send SQLite files around.MongoDB also saves document db type of store space just FYI.	vmfunction	13.5460415	-5.506306	comment	3.0	16.0	1695027489	9.795808
37554196	- Why not? https://www.sqlite.org/ap	"- Why not? https://www.sqlite.org/appfileformat.html- Its size is less than a megabyte: https://sqlite.org/footprint.html- 750KB if all features are enabled: https://www.sqlite.org/about.html- Looks like fair amount of functionality can be left out when compiling sqlite and with options to influence/strip down query planner: https://www.sqlite.org/compile.html- And ""SQLite does not compete with client/server databases. SQLite competes with fopen()"": https://www.sqlite.org/whentouse.htmlIn the end, you don't need a database, but a library that gives you database API and behavior."	jve	13.566168	-5.562793	comment	3.0	25.0	1695031076	9.815525
37554321	> In the end, you don't need a datab	> In the end, you don't need a database, but a library that gives you database API and behavior.Why do you need a single library that gives you a database API and behaviour?Wouldn't it be better to decouple those: provide an open, standard format that enables compact, fast, structured storage that is built to allow transaction/atomic updates.If that exists then you can plug sqlite on top of that, or something else. Because you don't _need_ any of SQL, or really sqlite to improve the OpenDocument format. You need the storage format.OpenDocument is very different from the pretty scientific/niche/highly-vendor-locked examples given in replies by others here. Locking this into a format developed by essentially a single person with a single implementation is absolutely mad.But... it's less mad 	orf	13.541846	-5.546122	comment	3.0	16.0	1695032371	9.810556
37554346	Duplicate keys in a SQLite file soun	Duplicate keys in a SQLite file sounds like an audacity bug. :(	justinclift	13.627264	-5.575692	comment	3.0	13.0	1695032660	9.889347
37554933	Sqlite format is smaller than the or	Sqlite format is smaller than the original format only because xml is super verbose, so any uncompressed binary format ends up being less than lightly zipped xml.But sqlite files aren't small. One thing I don't understand is why they don't do string deduplication in sqlite (as in you only store a string once and every other occurence is just a pointer to that string). It seems such an obvious and easy way to reduce file size, memory consumption and therefore increase performance (less I/O). Is there a technical reason why this would not be desirable?	cm2187	13.570741	-5.546373	comment	3.0	11.0	1695037684	9.790156
37556073	But other databases cannot access sq	But other databases cannot access sqlite databases, because the file format is internal...	orra	13.560047	-5.555209	comment	3.0	12.0	1695044882	9.820006
28996077	I had a really great experience buil	I had a really great experience building an EAV store with Datalog as the query interface on top of SQLite for embedding in native mobile apps.Pros: querying complex data hierarchies was easy, and was able to skip the pain typically associated with managing a SQL schema.	heyzk	13.569979	-5.5443883	comment	3.0	14.0	1635218769	9.814118
28996223	I tried to use couchdb with pouchdb.	I tried to use couchdb with pouchdb. It was a mess to add the proper authentication layer over it and the fact that even the couchdb team has changed their opinions on the right way to do it was not impressive.I love RxDB with Hasura behind it. It's incredible and you get a great postgres front end to boot.	xrd	13.582227	-5.195854	comment	3.0	18.0	1635220434	9.692192
29037252	Ask HN: Has anyone use YugabyteDB or	Ask HN: Has anyone use YugabyteDB or CockroachDB in production?	bennyp101	13.637447	-5.221337	story	3.0	10.0	1635506456	9.884928
29074087	Nobody remembers the MangoDB spoof w	Nobody remembers the MangoDB spoof where they made fun of mongodb reliability by writing to /dev/null ?  https://github.com/dcramer/mangodbIf this project is real they chose the worst name possible.	joshhart	13.667486	-5.3085065	comment	3.0	16.0	1635805743	9.941427
29075817	I have seen multiple benchmarks that	I have seen multiple benchmarks that show PostgreSQL has better performance than Mongo in almost all use cases.A simple wrapper in a language like Go or Rust is sufficient to surpass Mongo performance.Personally, I have shifted database operations behind a GRPC service that uses Go language and PostgreSQL back-end. Allows me to customize the data store to suit the requirement.PostgreSQL does not get enough love in this world.	kumarvvr	13.6375265	-5.348606	comment	3.0	24.0	1635817329	9.886408
29154704	As for SQLite GUIs, there is also th	As for SQLite GUIs, there is also the free open-source cross-platform SQLiteStudio.https://sqlitestudio.pl	tempodox	13.556335	-5.565485	comment	3.0	11.0	1636408164	9.864242
29164662	Uuidv4 have worse performance when i	Uuidv4 have worse performance when inserting into the btree for the primary key.	mjgp2	13.973824	-5.2200847	comment	3.0	12.0	1636479457	-13.666661
29167768	Show HN: I Built UUIDs-as-a-Service	Show HN: I Built UUIDs-as-a-Service	kagitac	13.990091	-5.193577	story	3.0	3.0	1636493543	-13.6519
29187689	Cue nmcli (CLI for Gnome's NetworkMa	"Cue nmcli (CLI for Gnome's NetworkManager) which uses UUIDs for everything and (at least a while ago) did not accept partial-but-unique UUIDs. Basically goes ""nmcli connection up 5095665a-d82c-4ae6-8964-283623387941""."	formerly_proven	13.991697	-5.2098646	comment	3.0	12.0	1636638004	-13.661827
29203846	Scaling SQLite to 4M QPS on a Single	Scaling SQLite to 4M QPS on a Single Server	exec	13.5521145	-5.4709916	story	3.0	38.0	1636747011	9.801379
29295871	Sure. Here are a few examples. They'	Sure. Here are a few examples. They're all based on my experience with the MongoDB API for CosmosDb. Your mileage with other APIs may vary.1. CosmosDB has a hardcoded 60-second timeout for queries. That means that queries that take longer than that are literally impossible to run without breaking the query into smaller chunks. This is worse than it sounds because CosmosDB doesn't have some of the basic optimizations that exist in other databases. For example, finding all distinct values of an indexed field required a full scan which wasn't doable in 60 seconds. Another example is deleting all documents with a specific value in an indexed field - again, not doable in 60 seconds. When deleting or updating multiple documents, we'd write short snippets of code that queried for the ids of all d	maltalex	13.584109	-5.3224053	comment	3.0	12.0	1637497677	9.880555
29348065	> How often do you need to select un	> How often do you need to select unique elements by ID? Don't use IDs in the first place.wait a minute, does everyone NOT use IDs for unique elements on page (not each element)? I mean I am genuinely interested in knowing why not to use IDs. There are unique elements which need to be selected on a page like #logout or something.	iKevinShah	13.922548	-5.1948705	comment	3.0	18.0	1637910357	-13.601938
29364038	Well I definitely prefer the new str	Well I definitely prefer the new strict mode, I'll enable that right away. I've long fantasized about a mode that would make SQLite behave like a normal SQL database, but this is not that. You still can't store a float in the database and get it back out unmodified. SQLite will expand it to a double, and it can't store NaNs. And probably more overhead to be able to support storing strings in my REAL column. Oh well.I tried out DuckDB which is more my style but the .NET libs are poor and I can't shave that yak right now.	mastax	13.618902	-5.5858703	comment	3.0	16.0	1638050688	9.837905
29459753	Verneuil: S3-backed asynchronous rep	Verneuil: S3-backed asynchronous replication for SQLite	pkhuong	13.591955	-5.4761257	story	3.0	14.0	1638798988	9.787235
29462109	Hundreds of SQLite files? In active 	Hundreds of SQLite files? In active use? Unless iOS itself spawns a few hundred instances and actively uses them all the time I have a hard time thinking of what would use so many databases, much less that they’re actually in active use.	Aeolun	13.568495	-5.5248957	comment	3.0	11.0	1638809367	9.823031
29484689	MongoDB is an even more terrible nam	MongoDB is an even more terrible name in my country. I know they named it that because it’s humongous but in my country, “mongo” is a derogatory term that is equally offensive as calling someone a retard and is derived from the word “mongolid”.I remember when I grew up we used to call each other mongo as a joke and not meaning anything bad about it, but then on one occasion a teacher overheard us and told us that she was sad to hear people use the word that way because she had a grandchild with Down’s syndrome. I think this was one of the first times I learned that words said to one person can be hurtful to someone else even if they were not the person you said it to. And after that I’ve tried to be more conscious about which words I use in public.	codetrotter	13.714796	-5.299794	comment	3.0	22.0	1638971702	-4.378655
29484894	We indeed had a hard time finding a 	We indeed had a hard time finding a good name, especially with the situation around domain names nowadays. An infinite amount of time can be spent on these things. However, we decided that we would rather focus on things which are more likely to determine the overall success of FerretDB - the vision and the execution. We quite like ferrets, though!	peterfarkas	13.603266	-5.2883644	comment	3.0	17.0	1638972886	9.805616
29485278	"The idiom ""ferret away"" means to sto"	"The idiom ""ferret away"" means to store something in a secret place, and the idiom ""ferret out"" means to find something by careful searching.  Seems like a pretty good name for a database."	patpending	13.543752	-5.3160853	comment	3.0	13.0	1638974746	2.9668212
29485812	Is there a suite of conformance test	Is there a suite of conformance tests and/or benchmarks for MongoDB?A blackbox test suite that tests common query types and could be run against mongo itself (similar to pgbench, TPC-C, etc) and can optionally test for correctness/speed would go a long way towards making it easier to trust this project with workloads.	hardwaresofton	13.625476	-5.3424783	comment	3.0	12.0	1638976955	9.871466
29536188	too bad the unifi controller require	"too bad the unifi controller requires the use of a ridiculously outdated version of mongodb, to the extent that installing it to self host unifi on a debian system becomes more of a pain in the ass every year.ubnt patched this because it's a huge highly publicized hole.but the software stack that runs under the rest of unifi is a real mess.people have said to me: ""oh, okay, so they're trying to force people to buy their unifi security appliance or cloudkey thing, right?""but the same very old stuff runs on those as well, if you poke around under the hood"	walrus01	13.681743	-5.2958655	comment	3.0	21.0	1639365307	9.886639
35887182	It probably isn't good enough. But i	"It probably isn't good enough. But it's hard for the audience to tell.""Any questions?""""How are we going to scale the data storage?""""Oh, we're confident that the data will all fit in a single SQLite instance.""""Great.""It's only six months later, when it turns out it won't, and there's a lot of stress and panicked re-working, that the lack of preparation will be obvious. And by then, everyone will have forgotten the presentation."	twic	13.567022	-5.547807	comment	3.0	12.0	1683725912	9.729055
35906841	By choosing SQLite.No server process	By choosing SQLite.No server process and a single file per DB which I can put wherever I like.	MrThoughtful	13.553594	-5.5366454	comment	3.0	20.0	1683831946	9.874134
35994960	While in general I agree, database l	While in general I agree, database libs are probably the worst example of this - in practice you can't just swap sqlite for postgres or mysql. I usually avoid the generic driver wherever possible and use one specific to my database.	andrewchambers	13.570378	-5.5338454	comment	3.0	18.0	1684448334	9.8480015
35995974	I would highly recommend against thi	I would highly recommend against this.  For example, postgres and sqlite differ in what they accept as meaning 'true' or 'false'.  Try this with both databases, 'create table foo (whatever bool not null)', then insert 't', 'true', 1, true, 'f', 'false', 0, false.  Postgres will reject 0 and 1.  Now query for true and false values, like 'select count(1) from foo where whatever=true'.  Sqlite returns 2!  Postgres returns 3.  Do the same for false, same results.  Now ask Sqlite the count of 'select count(1) from foo where whatever != true and whatever != false'.  It returns 4.You are in for a world of hurt if you think your SQL statement parsing means that your application is going to work.  Changing database backends, in my mind, amounts to a full rewrite of the data layer.  Whatever quirks 	jrockway	13.568997	-5.520502	comment	3.0	10.0	1684453765	9.824047
36102077	"> There are no ""natural keys"". They "	"> There are no ""natural keys"". They don't exist in nature. They don't exist as a thing in our physical reality. And when it comes to human-assigned identifiers, it should be emphasized much more strongly that whatever external thing you think is a good unique ID, it isn't.It seems to me that nature has plenty of natural keys, it’s human created constructs that don’t.For example, the periodic table has natural keys."	genuine_smiles	13.896332	-5.235082	comment	3.0	29.0	1685260921	-13.6645975
36102802	Yes, but what would be the alternati	"Yes, but what would be the alternative?Of course you can use artificial keys like a random UUID for each of your db objects. Which will work quite well if you only interact with your own system.But as soon as one of your db objects needs to be linked to some other system, you will need some common ground for a correlation, and something like a personnummer will help immensely and solve 99.9% of your problems. The 0.1% of problematic cases is far less than the headaches that the absence of some common ID scheme will cause you.Imagine e.g. having to correlate on the usual ""Name, First Name, Birth Name, Place of Birth, Date of Birth"" dance: My place of birth used to be called Lower Unxton at the time of my birth, now it has been reformed  with Upper Unxton and Exampleville into Greater Unxton"	c00lio	13.949796	-5.21641	comment	3.0	12.0	1685269606	-13.643324
36121450	At the risk of shoehorning SQLite in	At the risk of shoehorning SQLite into this as a solution, would it?  Does SQLite handle this type of data (big multidimensional time series sensor data) well?	xarope	13.5333	-5.491814	comment	3.0	13.0	1685424831	9.867567
36155488	I wonder if there's been any observa	I wonder if there's been any observable correlation between JSON support in the major SQL databases and the decreased (or increased?) adoption of NoSQL document databases like MongoDB. It would be interesting to do some bulk analysis on GitHub commits to compare their use over time.	czx4f4bd	13.525882	-5.4636545	comment	3.0	29.0	1685644936	9.79789
36156859	One thing that has always agitated m	One thing that has always agitated me about SQL is that although it's standardized, and the standard seems to encompass a shit-ton, in practice a lot of SQL engines don't really seem to have any meaningful interoperability for practical uses among the world's most popular database engines.For example, OK, I realize auto-incrementing IDs are not the most important thing in the world, and arguably not even a good approach in many cases. But sometimes you want them, and helpfully almost every database engine I know of has some kind of support for this, even if the semantics may differ. It's a super basic thing to want a unique ID that roughly counts upward on a table. You might have specific needs about re-using numbers and whatnot, but the general idea is very simple.However: in practice, th	jchw	13.9266	-5.2322464	comment	3.0	12.0	1685651048	-13.647327
36167405	How is SQL hard for a computer to pa	How is SQL hard for a computer to parse? SQLite can parse its flavour of SQL using a plain old LALR grammar and that covers a lot of SQL.And even if it was, how does having an ORM generate the SQL behind your back change anything for the computer that still has to parse SQL?	hobo_mark	13.536808	-5.644525	comment	3.0	10.0	1685723995	9.872984
36210832	> Onboard code logs ~4000 messages a	> Onboard code logs ~4000 messages a second into three SQLite databases. After a drive session a script merges the three databases into a single SQLite session log.A bit unrelated, but curious as to why you wrote to three separate databases only later to merge them.	hiatus	13.596825	-5.5664744	comment	3.0	24.0	1686048957	9.796383
36224749	Why not distributed databases like C	Why not distributed databases like CockroachDB?	tmikaeld	13.52884	-5.185811	comment	3.0	14.0	1686130500	9.83151
36303238	This isn't remotely comparable. Thos	This isn't remotely comparable. Those .DS_Store files are created in arbitrary directories by the Apple file manager or something. The SQLite temp files are created in the OS-specific temporary directory (e.g. C:/Users/username/AppData/Local/Temp or whatever on Windows) which is specifically intended for that purpose. SQLite isn't doing anything wrong; that's where it's supposed to store temporary data that doesn't fit into memory.The problem is that virus scanners sometimes misclassify those temp files as belonging to malware apps, or sometimes they might be written by real malware apps, but even in the latter case, that only happens because the malware uses sqlite as a library. The malware isn't written by the SQLite authors, so complaining to them is pointless.	sltkr	13.570138	-5.551938	comment	3.0	26.0	1686614820	-8.191718
36328290	What's the self-hosted Postgres HA s	What's the self-hosted Postgres HA story these days?	whitepoplar	13.522043	-5.33925	comment	3.0	14.0	1686759812	9.777374
36430666	Yes, UUID v7 can be generated indepe	Yes, UUID v7 can be generated independently. The UUID has three parts, which maintains strict chronological ordering for UUIDs generated in one process, and to within clock skew when UUIDs are generated on different systems.The three parts are:- time-based leading bits.- sequential counter, so that multiple UUID 7s generated very rapidly within the same process will be monotonic even if the time counter does not increment.- enough random bits to ensure no collisions and UUIDs cannot be guessed.	stevesimmons	13.987276	-5.2165327	comment	3.0	12.0	1687434453	-13.676753
36433268	Out of my scope, but why are UUIDs e	Out of my scope, but why are UUIDs even discussed? ULIDs ~~(and i think Nanoids?)~~ don't suffer these same problems. Locality and ordering alone make me[1] think ordered ULIDs (and friends) are the only thing worth discussing.Is there some value to UUIDs over ULIDs that make these discussions largely revolve around Autoincrement vs UUIDs rather than Autoincrement vs ULIDs(and friends)?[1]: Again, totally out of my wheel house.edit: Apparently UUIDv7 exists, which is similar to ULID, so my question pertains to UUIDv5 and below, i think.edit2: I think Nanoids do suffer the same problem. They're just small... i think.	unshavedyak	13.979551	-5.2169104	comment	3.0	19.0	1687446394	-13.66703
36509584	UUIDv7 has been taking HN by storm f	UUIDv7 has been taking HN by storm for years now!  When is it going to become a proper standard, and when are libraries and databases and all the rest going to natively support it?	wood_spirit	13.989522	-5.2098594	comment	3.0	12.0	1687972948	-13.633188
36509807	Assuming you don't need to use UUIDv	Assuming you don't need to use UUIDv7 (or any UUID's) then https://github.com/segmentio/ksuid provides a much bigger keyspace. You could just append a string prefix if you wanted to namespace, but the chance of collisions of a ksuid is many times smaller than a UUID of any version.ksuid is the best general purpose id generator with sort-able timestamps I've found and has libraries in most languages. UUID v1-7 are wasteful.	Xeoncross	13.972749	-5.216854	comment	3.0	13.0	1687973779	-13.672279
36510396	No identifier can guarantee that. We	No identifier can guarantee that. We just get close enough to be acceptable.Per Wikipedia, the probability to find a duplicate within 103 trillion version-4 UUIDs is one in a billion.so-youre-saying-theres-a-chance.gif	ceejayoz	13.977301	-5.195389	comment	3.0	14.0	1687976267	-13.662611
36510420	Not every bit of UUID is required to	Not every bit of UUID is required to be random.The goals are smallness, uniqueness, monotonicity, resistance to enumeration attacks, etc. Not randomness for randomness sake.My UUIDv7+ can be consumed as a standard UUIDv7. It is not intended to be v8. A program can treat the last 16 bits as random noise if it wants.	pphysch	13.992394	-5.21335	comment	3.0	16.0	1687976413	-13.635019
36517421	Python 3.12 will include a SQLite CL	Python 3.12 will include a SQLite CLI/REPL in the standard library too[0][1]. This is useful because most operating systems have sqlite3 and python3, but are missing the SQLite CLI.[0]: https://github.com/python/cpython/blob/3fb7c608e5764559a718c...[1]: https://docs.python.org/3.12/library/sqlite3.html#command-li...	polyrand	13.621235	-5.5984874	comment	3.0	17.0	1688023198	9.858003
36521456	I have a genuine appreciation for ho	I have a genuine appreciation for how Linear has built this. We have had to build something similar for our note taking application (Reflect). It is very tricky to do and I wish there was more research on this.In my opinion, what we need is:1) A client-side performant SQLite database that supports live queries. I.e. you can automatically re-render the page when the queries change. That way your database can drive the UI and be the source of truth in regards to what's displayed on the screen.2) A separate realtime syncing protocol that syncs database state to client state.And ideally this is all open source, and that these two endeavors are not coupled tightly.[1] Wa-sqlite is the best (imo) client-side db - better than than the official Sqlite WASM build (for now) because it had a indexedd	maccaw	13.530856	-5.5090256	comment	3.0	11.0	1688051436	9.783656
36526951	I like these kinds of blog posts. No	"I like these kinds of blog posts. Not because he's ditching mongo, I like the detail around his thought process because there's an over-abundance of articles about ""large company does X"" but less of the hobbyist version of the same."	jamiepenney	13.701713	-5.301531	comment	3.0	20.0	1688073920	9.940309
36529910	In the article, he mentioned that wo	In the article, he mentioned that working in JSON seemed natural and comfortable. So after checking to be sure mongo was fairly mature and commonly used, went with it.Sounds reasonable and not hype train driven	pachouli-please	13.656292	-5.352675	comment	3.0	10.0	1688093087	9.84607
25799077	Each has its place.Three years ago I	"Each has its place.Three years ago I started a new project and elected MariaDB. I was coming from a project that was using MongoDB. Because the new project seemed to have very structured data, mostly coming from third party systems, I opted for a structured solution.Three years later and my structured database has tons of tables and requires lots of brain twisting joins. It slowly evolved this way, while our UI basically evolved to use a single React ""state"" to represent an ""order"".It's tempting to consider what it might be like to store an order as a single Mongo document and forget all this structure."	codazoda	13.612824	-5.3729978	comment	3.0	14.0	1610761247	9.845753
25844320	"So we start adding sqlite.
Then come"	"So we start adding sqlite.
Then comes some sort of small framework for templating.
Then we add session storage.
Then we add an api endpoint so we can serve a SPA.
I think after that it's really time to create a VM in sqlite so we can emulate linux and run somethings else in the 'serverless' endpoint"	jbverschoor	13.549435	-5.513888	comment	3.0	14.0	1611134509	9.83048
25845933	Thanks for making Datasette! I've be	Thanks for making Datasette! I've been using it to build a project to make US ranked choice election results more accessible. It's very intuitive and easy to use. The main difficulty for me is how to get around the limitation that the sqlite files have to be colocated on the same server. These datasets can get pretty large, and I can't host them on Github, and since I can't put the datasette db on an S3 bucket, I've been exploring mounting AWS Elastic File System to the Docker container. Is there a better way?	picardo	13.568909	-5.4500833	comment	3.0	13.0	1611147967	9.691124
25870714	Query : For people who recommend UUI	Query : For people who recommend UUIDs as a unique identifier in a distributed sytem, does the above satisfy the need?In the SO answer[0] uuid v4 is being recommended but that is the most random version of uuid. Isn't that going to hurt the b-tree performance by having a very high fanout? How does it help the primary index?[0] : https://stackoverflow.com/questions/33274291/postgresql-uuid...EDIT : Apologies. I meant low fanout. What I meant was that you need something ordered to have a better organised b-tree node. If all values are random, each node will have a lot of children, increasing the search space. It might turn into Linked list in the worst case scenario.	abhishekjha	13.982383	-5.21754	comment	3.0	44.0	1611315115	-13.689983
25870769	We moved away from UUIDs for differe	We moved away from UUIDs for different reasons. It is hard to work with UUIDs when multiple entities have them. You do not know if you are looking at a user or a group if both is just a UUID. We created our own IDs with prefixes and using base58 encoding for the random part, for example: user-AhnPpn7CbbwPykmux11LJ39Jk. It has the same amount of randomness in it and we can understand what we are looking at.	StreamBright	13.987521	-5.207944	comment	3.0	36.0	1611315569	-13.667328
25870875	Why would you ever be in a situation	Why would you ever be in a situation where you have a UUID but don't know what it refers to?	globular-toast	13.9944725	-5.2127523	comment	3.0	28.0	1611316716	-13.670794
25876617	Hmmmm, that's a different issue. :-)	Hmmmm, that's a different issue. :-)Today the rqlite code deletes the SQLite database (if present) and then rebuilds it from the Raft log. It makes things so simple, and ensures the node can always recover, regardless of the prior state of the SQLite database -- basically the Raft log is the only thing that matters and that is guaranteed to be the same under each node.The fundamental issue here is that Raft can only guarantee that the Raft log is in consensus, so rqlite can rely on that. It's always possible the one of the copies of SQLite under a single node gets a different state that all other nodes. This is because the change to the Raft log, and corresponding change to SQLite, are not atomic. Blowing away the SQLite database means a restart would fix this.If this is important -- and w	otoolep	13.539142	-5.4656863	comment	3.0	11.0	1611351385	9.762172
25888139	The problem with NoSQL is that your 	The problem with NoSQL is that your simple model inevitably becomes more complex over time and then it doesn't work anymore.Over the past decade I've realised using a RDBMS is the right call basically 100% of the time. Now pgsql has jsonb column types that work great, I cannot see why you would ever use a NoSQL DB, unless you are working at such crazy scale postgres wouldn't work. In 99.999% of cases people are not.	martinald	13.526657	-5.4234915	comment	3.0	14.0	1611452736	9.812609
25915788	To me it looks like there are not ma	To me it looks like there are not many affordable options right now.CockroachDB understandably wants you to use their Cloud or Enterprise products: the OSS version is quite limited. For example it doesn't support row-level partitioning (https://www.cockroachlabs.com/docs/stable/configure-replicat...). Which means, if I understand correctly, it is not of much help for scaling writes to a single big table.	cuu508	13.549179	-5.2389984	comment	3.0	10.0	1611669559	9.799629
25975303	Great writeup! I think it's useful t	"Great writeup! I think it's useful to talk more about complete stacks instead of focusing on individual parts without mentioning the ""glue"" between them so I really like these kinds of posts. Just two questions:1. If you're not going for scalability why Postgres and not SQLite?2. What does your monitoring look like? I've read something about Grafana and Hetzner dashboards in the comments but what exactly do you use and where do you run that? Also, do you have anything for intrusion detection specifically? (I'd be extremely paranoid about that.)"	t0astbread	13.528302	-5.446186	comment	3.0	14.0	1612061377	9.776446
25975774	I love SQLite, but it really doesn't	I love SQLite, but it really doesn't have a great answer to HA/failover. If you enable WAL mode, even NFS is off the table.	spiffytech	13.568547	-5.461337	comment	3.0	11.0	1612065648	9.812638
25984912	Never use MongoDB.  Ever.  It's a ru	Never use MongoDB.  Ever.  It's a rule of thumb that hasn't led me astray yet.http://www.sarahmei.com/blog/2013/11/11/why-you-should-never...	rubyist5eva	13.689204	-5.323693	comment	3.0	11.0	1612146494	9.900749
25992765	Well I guess we are discussing diffe	"Well I guess we are discussing different angles of this matter, I actually didn't thought that my comment would go to the top since it was supposed to be a random naive statement.I'm not about making things that simple by default, but I don't like those absolutist titles like ""Never use MongoDB"", also because the years since 2013 actually proved the article to be kind of wrong.""Never do X"" is what I tell to children about matters that they wouldn't be able to understand, and making a point like ""we used an immature tool that wasn't the best choice for what we were building, and on top of that we used it wrong, so you random guy should never use it for anything, ever"" sounds like fearmongering to me and it's not something suitable to my taste.But I get your downvote :+1:"	01acheru	13.699781	-5.3146105	comment	3.0	14.0	1612208636	-4.434085
26080817	Exposing sequential IDs is bad Here 	Exposing sequential IDs is bad Here is how to avoid it	pazvanti	13.953568	-5.2102146	story	3.0	6.0	1612894877	-13.641251
26107086	This is my first time hearing about 	This is my first time hearing about H2, what's the benefit of H2 over sqlite?	xrendan	13.621825	-5.577316	comment	3.0	10.0	1613077218	9.850368
26108042	Regarding SQLite's performance, some	"Regarding SQLite's performance, some things I've found very useful:Use WAL mode (writers don't block readers):  PRAGMA journal_mode = 'WAL'

Use memory as temporary storage:  PRAGMA temp_store = 2

Faster synchronization that still keeps the data safe:  PRAGMA synchronous = 1

Increase cache size (in this case to 64MB), the default is 2MB  PRAGMA cache_size = -64000

Lastly, use a modern version of SQLite. Many default installations come with versions from a few years ago. In Python for example, you can use pysqlite3[0] to get the latest SQLite without worrying about compiling it (and it also comes with excellent compilation defaults).[0] https://github.com/coleifer/pysqlite3"	polyrand	13.576832	-5.523429	comment	3.0	11.0	1613081289	9.799207
26151553	"SQlite ""merely"" assumes that the pro"	"SQlite ""merely"" assumes that the problems that come with distributed systems are handled at the application layer. You'll have to solve those problems for yourself, sure, but in practice I have rarely (I think never actually) had dataloss through a fault of sqlite.Also, did you know you can use in-memory instances (and share them across threads!) with the right incantation? And that you can backup your on-disk instance to an in-memory one, do your expensive transactions without hitting the disk then backup the modified instance right back to disk, even in-place if you want!Sqlite is amazing when you don't expect the DB to do replication or failover on its own."	zdkl	13.59413	-5.514682	comment	3.0	12.0	1613457797	9.800408
26151777	What I've never got to grips with is	"What I've never got to grips with is the ""use a single writer with SQLite"" advice. That seems doable with a long-running application server, but if your application boots up on every request (like PHP, Python & Ruby applications generally do) how do you do this, when you have multiple simultaneous users?It feels like SQLite is missing a separate gatekeeper-binary to act as the single writer: the database server as it were."	pbowyer	13.577743	-5.515256	comment	3.0	10.0	1613461363	9.793417
26151806	Good reply, thank you.Yes 200k SLOC 	"Good reply, thank you.Yes 200k SLOC is huge (modern development practices notwithstanding). SQLite creates temporary files at whim - nine different kinds! https://sqlite.org/tempfiles.htmlI know how to atomically write a JSON file. But when I read, for example:""The temporary files associated with transaction control, namely the rollback journal, super-journal, write-ahead log (WAL) files, and shared-memory files, are always written to disk. But the other kinds of temporary files might be stored in memory only and never written to disk. Whether or not temporary files other than the rollback, super, and statement journals are written to disk or stored only in memory depends on the SQLITE_TEMP_STORE compile-time parameter, the temp_store pragma, and on the size of the temporary file...""My eye"	millstone	13.584606	-5.53832	comment	3.0	16.0	1613461695	9.754539
26152472	This is exactly how I accomplished h	This is exactly how I accomplished high performance in sqlite too.I'm surprised more people don't use transactions in sqlite given transactions are a staple of using any enterprise RDBMS.	hnlmorg	13.581824	-5.521955	comment	3.0	30.0	1613469043	9.80406
26191116	My main gripe with UUIDs at the mome	My main gripe with UUIDs at the moment is that they look ugly in urls :/	Cthulhu_	13.984219	-5.2056837	comment	3.0	13.0	1613726135	-13.664302
26193050	"The reason (other than ""don't expose"	"The reason (other than ""don't expose integer PK externally"") people say you should use integer as PK and UUID as a secondary/external facing id is that conventional B-tree indexing of UUID is not as efficient as B-tree indexing of autoinc integers in most databases.However if you want any sort of efficient lookup on the external key (UUID), your database still needs an index on the UUID, and you are back at square one.I choose to forego the integer PK and just use UUID since I have to create index over it anyway."	chromatin	13.980501	-5.215973	comment	3.0	11.0	1613742344	-13.622769
26193867	No you should not.UUIDs are not alwa	No you should not.UUIDs are not always a good solution.If you order things by id (often useful for pagination, since incrementing ids are usually ordered by creation date) uuid are of no help.You would need to sort by created_at and this would require an additional index.No to speak of pagination by id ranges or whatever is used sometimes.UUIDs are mpossible to remember and thus somewhat cumbersome to use too.The weird id mixed up with index problem from the article is something which never happened to me ever in over 10 years of web development.I stay away from PHP as much as possible so that may be the reason ;)	LordHeini	13.970803	-5.218546	comment	3.0	12.0	1613746899	-13.6706705
26216540	Yeah Mongo is 10 years old or so at 	"Yeah Mongo is 10 years old or so at this point. This article was written in 2015 about decisions made years earlier. It's now reached maturity and stability. It's now ""boring tech""."	chrisco255	13.700975	-5.2969675	comment	3.0	10.0	1613937367	9.90572
26219178	I regularly use SQLite as the databa	I regularly use SQLite as the database for production apps.User registrations, content posts, in-app purchase receipts etc. Up to hundreds of thousands of concurrent users it works just fine.It saves me a tone of time and complexity from setup I don’t have to do for a dedicated database engine.There is a good overview with general use cases here: https://sqlite.org/whentouse.html	isodev	13.52186	-5.4957333	comment	3.0	13.0	1613955265	9.783754
26291994	I have found that for many personal 	I have found that for many personal projects, sqlite is more than good enough and the simplification of infrastructure makes it worth it over pg.	PurpleFoxy	13.558935	-5.4903665	comment	3.0	11.0	1614504875	9.806876
26292764	I thought sqlite was very resilient 	I thought sqlite was very resilient and have a hard time understanding how an sqlite file can be corrupted. Are they manipulating the sqlite file outside of sqlite APIs? Are they mixing up file descriptors and writing garbage into an sqlite handle?	0x0	13.584652	-5.5639653	comment	3.0	12.0	1614513557	9.820718
26336750	Hacker rewrote complex backend with 	Hacker rewrote complex backend with Postgres and cron, CEO fired 40% of devs	samokhvalov	13.541974	-5.3125734	story	3.0	20.0	1614816415	1.8068653
26346830	Reminds me of SQLite and the Rule of	"Reminds me of SQLite and the Rule of St. Benedict.
https://sqlite.org/codeofethics.html"	lainga	13.646536	-5.5935225	comment	3.0	12.0	1614885402	-8.820517
26421162	MongoDB is like snapchat for databas	MongoDB is like snapchat for database	soulchild37	13.676029	-5.3295007	comment	3.0	11.0	1615446459	9.885674
26440756	> To delete a column, SQLite have to	> To delete a column, SQLite have to completely overwrite the table - so the operation is not fast. But it’s still nice.Can someone with more knowledge/experience ELI5, please? Is this essentially how it's done in other db engines? TIA	dmarlow	13.592636	-5.58188	comment	3.0	12.0	1615582336	9.859794
26441254	`RETURNING` will substantially clean	"`RETURNING` will substantially clean up my code, and I already have one migration which could have just been a `DROP COLUMN`, so this is great news.On the subject of ""it's called 'lite' for a reason"", my wishlist does include library functions for working with RFC3339 timestamps. SQLite already ships with a fairly large suite of JSON tools, which are optional to compile into the library, so there's precedent.Datetimes are of those things which is incredibly annoying to get right, and really belongs inside the database. RFC3339 timestamps are already well designed, since if you stick to UTC (and if you don't store timezone data separately you deserve those problems), lexical order is temporal order, but queries which would be rendered in English as ""return all accounts where last payment is"	samatman	13.523599	-5.5592356	comment	3.0	22.0	1615584876	-0.38044935
31083132	I couldn't find anything about the w	I couldn't find anything about the wire protocol being compatible with MySQL or PostgreSQL and it seems to need a specific SDK. This will limit adoption considerably.	gtirloni	13.5296135	-5.4092464	comment	3.0	10.0	1650376518	9.828632
31090337	EDIT: Title has been slightly change	"EDIT: Title has been slightly changed, now. It was originally ""Jepsen testing of rqlite, the distributed DB built on Raft and SQLite""Hmm, perhaps a bit of confusion from the title. It sounds like they ran the Jepsen suite of tests against rqlite, which is great, but not done _by_ Jepsen / Kyle (https://jepsen.io). Others have done this themselves too and that's fine, but half the of the problem is correctly implementing the tests which has been done incorrectly by others in the past."	Operyl	13.610627	-5.5607347	comment	3.0	16.0	1650408131	9.840306
31153569	Litestream is indeed a missing piece	Litestream is indeed a missing piece of the puzzle. But it also defeats some of the purpose of using an embedded database library in the first place. Now you're back to juggling separate processes once again.	fauigerzigerk	13.568656	-5.476646	comment	3.0	10.0	1650890222	9.740983
31153705	I’ve worked on several projects with	I’ve worked on several projects with sqlite, both read and write heavy, all with high concurrency, with databases in the few hundred MB with 400k server clients, and 100 bare-metal servers running at capacity. The sqlite part of our system is never the problem. In our case sqlite has been an alternative to custom files on disk or replacing a spaghetti of hashmaps in memory. we also replaced a single postgresql instance with all customers into many sqlites per customer. Performance and reliability is why I always reach for it first. At this point I’m a zealot and would argue your first ‘data structure’ of choice should be an sqlite database :)	matthewaveryusa	13.548185	-5.4988847	comment	3.0	10.0	1650891005	9.772699
31153727	It blew up big time. I would have sa	It blew up big time. I would have saved myself lots of trouble if I had just gone with postgres from the getgo.The workload was simple (single node work tracking) and I didn't expect it to become a bottleneck. Unfortunately, there were some default settings in the storage backend (tiny page size or WAL or something) that caused severe thrashing and a dearth of tooling to track down the issue. After making a custom build with custom instrumentation and figuring out the problem, I found an email thread where the sqlite community was arguing about this exact issue and the default settings in question. A couple of people had forseen the exact problem I had run into and suggested a fix. Their concerns were dismissed on the grounds that the problem could be configured away, and their concerns ab	jjoonathan	13.563983	-5.501392	comment	3.0	15.0	1650891104	-8.528984
31157878	Take this with a huge grain of salt 	Take this with a huge grain of salt because I am by no means an expert, but I currently am working on some scripts that import a few million rows into SQLite. I am using bash and the sqlite command line. I was getting a lot of concurrent write errors from sqlite (bear in mind i am only doing inserts of separate rows so in theory there is never an actual conflict), so I tried using WAL mode. It actually resulted in more contention. I ended up just going back to non-WAL mode and implementing an exponential backoff in bash to retry writes.	woah	13.558339	-5.487171	comment	3.0	10.0	1650906956	9.78487
31201731	Awesome SQLite	Awesome SQLite	sqlsite	13.613162	-5.5793786	story	3.0	37.0	1651209756	9.845941
31254517	SQLite is one of the few file format	SQLite is one of the few file formats that's recommended by the US Library of Congress for archival storage: https://www.loc.gov/preservation/digital/formats/fdd/fdd0004...See also this page on the SQLite website (they're understandably very proud of this): https://www.sqlite.org/locrsf.htmlI think it's a fantastic format for archiving and distributing data.	simonw	13.524647	-5.5463824	comment	3.0	13.0	1651617748	9.781897
31271513	Wait , are you running this site on 	Wait , are you running this site on a raspberry pi?The biggest issue with SQLite is what happens if your server serving stuff goes down mid write? Power surge maybe. You lose data from that day till previous cronjob?	ramraj07	13.599024	-5.572452	comment	3.0	10.0	1651745500	4.938991
31319296	Looks v cool, but I feel like I'm mi	Looks v cool, but I feel like I'm missing a big part of the story, how do 2 app 'servers/process' connect to same sqlite/litestream db?Do you 'init' (restore) the db from each app process? When one app makes a write, is it instantly reflected on the other app's local sqlite?	swaraj	13.583798	-5.5023365	comment	3.0	18.0	1652128169	9.777076
31319809	It was too much work to migrate from	It was too much work to migrate from SQLite to PostgreSQL, so you migrated to... a NoSQL DB?	luhn	13.588397	-5.521131	comment	3.0	10.0	1652130677	9.858039
31320166	This constraint is common to most n-	This constraint is common to most n-tier architectures (with Postgres or MySQL) as well. Obviously, part of what's interesting about Litestream is that it simplifies fail-over with SQLite.	tptacek	13.545407	-5.4586782	comment	3.0	46.0	1652132557	9.764176
31320277	There's no magic here (that there is	There's no magic here (that there is no magic is part of the point). You have the same phenomenon in n-tier Postgres deployments: to be highly available, you need multiple instances; you're going to have a write leader, because you're not realistically want to run a Raft consensus for every write; etc.The point of the post is just that if you can get rid of most of the big operational problems with using server-side SQLite in a distributed application --- most notably, failing over and snapshotting --- then SQLite can occupy a much more interesting role in your stack than it's conventionally been assigned. SQLite has some very attractive properties that have been largely ignored because people assume they won't be able to scale it out and manage it. Well, you can scale it out and manage it	tptacek	13.56791	-5.47814	comment	3.0	16.0	1652133158	9.766768
31322162	No; there's no such thing as a sqlit	"No; there's no such thing as a sqlite3 server. The database is the file(s). Litestream runs alongside everything else using sqlite3 and ensures that it's replicating. If Litestream crashes, reads from the database keep working fine (though, of course, they'll start to stale if it doesn't come back up).This is why we called out in the post that Litestream is ""just sqlite3"". It's not sitting between apps and the database."	tptacek	13.583383	-5.496328	comment	3.0	12.0	1652145261	9.73204
31323483	I do understand the point of running	I do understand the point of running SQLite in-process to speed up reads.I do not understand why SQLite must also handle intense write load with HA, failover, etc.I would rather have the best of both worlds: a proper DB server (say, Postgres) replicated to super-fast and simple read replicas in SQLite on every node.(My ideal case would be some kind of natural sharding where each node keeps its own updates, or just a highly available data browsing app, with data in SQLite files updated as entire files, like a deploymen.)	nine_k	13.570798	-5.5119333	comment	3.0	13.0	1652157339	9.775654
31322619	I mean, there are managed SQL servic	I mean, there are managed SQL services too. Comparing managed SQLite to DIY Postgres seems disingenuous.EDIT: I didn’t expect this to be controversial, but I’d like to know where I’ve erred. If you need lightstream to make SQLite operationally simple (beyond single servers, anyway), that seems pretty analogous to RDS to make Postgres operationally simple, right?	throwaway894345	13.536044	-5.4326186	comment	3.0	16.0	1652148936	9.814983
31322736	Mongodb is also taking quite a beati	Mongodb is also taking quite a beating. Probably doesn't help that sqlite has been all over the front page lately (e.g. right now).	bob1029	13.615962	-5.5079412	comment	3.0	12.0	1652149976	9.870031
31387124	Don't forget to stop writing to the 	Don't forget to stop writing to the database while doing the backup, otherwise you can run into an infinite loop if you write faster than sqlite3 .backup is doing the backup :DLearned that the hard way when implementing sqlite3 backups on Gladys Assistant ( open-source home automation platform https://github.com/GladysAssistant/Gladys )	pierregillesl	13.585861	-5.4896345	comment	3.0	17.0	1652617270	9.785954
31387159	Litestream author here. The motivati	Litestream author here. The motivation for this docs page was two-fold. First, laying out the different options with their trade-offs helps people understand what Litestream is trying to be so it helps keep my focus narrow. For example, if someone is looking for very high durability guarantees then they can see that rqlite might be a better fit and they don't try to fit Litestream into that mold.Second, Litestream doesn't interfere with other backup methods so you can run it alongside a cron-based backup. I typically run both because I'm overly paranoid and because it's cheap.	benbjohnson	13.526537	-5.4929214	comment	3.0	15.0	1652617696	9.721276
31387179	>Do not use `cp` to back up SQLite d	>Do not use `cp` to back up SQLite databases. It is not transactionally safe.I've read that this is true, but it has always confused me because I would expect that using cp would be equivalent to if the application had crashed / you lost power.	charcircuit	13.593258	-5.522578	comment	3.0	11.0	1652617997	9.788081
31400819	It isn't safe to copy a SQLite datab	"It isn't safe to copy a SQLite database because the file might be in the middle of a transaction. You need to use the "".backup"" command instead."	andai	13.59495	-5.5456114	comment	3.0	10.0	1652722659	9.784653
31413617	Time might be up (saying as a long t	Time might be up (saying as a long term PG user) with Litestream adding distributed features to SQLite, local inprocess databases might be the next thing.	KingOfCoders	13.556148	-5.4618344	comment	3.0	17.0	1652807423	9.753022
31468870	Is sqlite a flat file disqualifier?	Is sqlite a flat file disqualifier?	g5095	13.567167	-5.573616	comment	3.0	10.0	1653231376	9.876227
31469132	uncle roger voice just use SQLite ha	uncle roger voice just use SQLite haiyaaaaa	RedShift1	13.622623	-5.5835795	comment	3.0	15.0	1653232954	-5.0529275
31473368	The answer is much simpler.When peop	The answer is much simpler.When people created desktop apps - they needed a datastore that was simple and reliable to use. SQLite was perfect for this.Now, no-one is creating desktop apps anymore (everything is a web app), but people still need a simple & reliable datastore. Even though SQLite has historically advertised to not be used for client/server, people are finding that SQLite works great for most web apps as well.	tiffanyh	13.533168	-5.508566	comment	3.0	10.0	1653257902	9.814786
31473512	That's a fair point. AFAIK SQLite us	That's a fair point. AFAIK SQLite uses a queue (in WAL mode) in order to handle concurrent writes. I imagine it basically couldn't handle 10K concurrent writes to begin with in a practical application since newly read data would be out of date pretty quickly.	endisneigh	13.576396	-5.4984665	comment	3.0	12.0	1653259101	9.78813
31473551	"> The point of much of the ""SQLite h"	"> The point of much of the ""SQLite hype"" is that there are many applications where read load is high and queries complicated, but the write load is low to non-existent. In situations like these, you can make do with a smaller DB than Postgres.Sure, but my point is that unless you know for sure your app will stay the same forever, why not just use Postgres or something more flexible to begin with? With things like Supabase, Hasura, and Managed Postgres why even bother with SQLite? Just seems like you're causing your tech team inevitable pain when you have more writes than expected and have to migrate off of it.Both Fly.io and Cloudflare's solutions are a good example of this. If you're going to use another service, why even bother with SQLite? I totally get the SQLite use case when you're u"	endisneigh	13.558101	-5.476483	comment	3.0	11.0	1653259545	9.7726345
31473829	In my experience most SQLite writes 	In my experience most SQLite writes take less than 1ms. So if your app is handling less than a thousand writes per second you will probably be OK!A common pattern (which I've implemented myself in Datasette) is to put your writes in an in-memory queue and apply them using a single dedicated connection.	simonw	13.559713	-5.5142527	comment	3.0	22.0	1653261965	9.777527
31474503	I'm still bitter that we could've ha	I'm still bitter that we could've had SQLite in the browser as WebSQL but it got killed off in favor of IndexedDB which is terrible.The code is in the public domain. The spec could just say to include SQLite.IndexedDB implementations all use SQLite under the hood anyway, AFAIK.	TheAceOfHearts	13.5678625	-5.5437474	comment	3.0	10.0	1653269547	9.825242
31531718	Datasette is pretty cool.But AFAICT,	"Datasette is pretty cool.But AFAICT, it just doesn’t scale whatsoever. That SQLite db is both the dataset index and the dataset content combined, right? So you're limited by how big that SQLite db can realistically be. The docs say ""share data of any shape or any size"", but AFAICT it can't handle large datasets containing large unstructured data like images and video and multi-billion data point datasets are hard to store in a single machine/file.Not really a criticism, but more wondering if there are scale optimizations in Datasette I'm not aware of since the docs do say any shape or size."	redredrobot	13.549941	-5.519127	comment	3.0	13.0	1653670027	9.832827
31551029	What is your actual objection to dat	What is your actual objection to databases?SQL is a skill, and not a hard one.  Develop it once, and its availability becomes a benefit.Relations are trivial once you have the skill of SQL.Foreign keys are entirely optional sanity checks.  Ignore them.SQLite comes built in to all your favorite languages, and no need for docker-compose.And all the other things, like letting the database protect you from race conditions, recovering from crashes and the like, are good.	btilly	13.576969	-5.534026	comment	3.0	30.0	1653846019	9.846441
31654908	This looks really cool. Albeit feels	This looks really cool. Albeit feels that it is actually a feature implemented in the driver (client side) so my initial impression is that is not a meanignfull innovation on the server side. This can be implemented with any Database, even with current MongoDBs	rafaelturk	13.673349	-5.329451	comment	3.0	10.0	1654612332	9.883002
31707155	I love the webamp website. But, in t	I love the webamp website. But, in the world of multigig RAM and multigbps I/O speeds, 1.2GB isn't that much. Not sure if that's something novel for SQLite3 though.	sedatk	13.581642	-5.528544	comment	3.0	26.0	1654973995	9.817636
31707658	I remember reading about a company t	"I remember reading about a company that upgraded their production database from a JSON file to SQLite.We really need this counter culture in software development that emphasis simplicity over the ""Start with Kafka-on-k8s"" madness."	keewee7	13.53642	-5.297066	comment	3.0	43.0	1654976989	9.819209
31716799	I’ve been working on a robust scheme	I’ve been working on a robust scheme for encrypted sequential IDs, which is done, including library implementations in Rust, JavaScript and Python, pending just a smidgeon more writing about it and reviewing a decision on naming. You store an integer in the database, then encrypt it with a real block cipher, and stringify with Base58. I have three modes: one for 32-bit IDs, using Speck32/64 and producing 4–6 character IDs; one for 64-bit IDs, using Speck64/128 and producing 8–11 character IDs; and one hybrid, using the 32-bit mode for IDs below 2³² and the 64-bit mode above that, providing both a forwards-compatibility measure and a way of producing short IDs as long as possible. Contact me (see my profile) if you’re interested, or I’ll probably publish it in another day or two. Trouble is	chrismorgan	13.968326	-5.2108345	comment	3.0	11.0	1655057575	-13.657977
31716848	"""Unique IDs"" _can_ be super really e"	"""Unique IDs"" _can_ be super really easy to work with if they're not so baffling complicated.A random string generated using quality randomness can be adjusted to length to suit the quantity of data (negligible probability of a collision) which in most cases is very short.It's easy to increase the length as you get more data.They are visually very different for each item of data.They're evenly spread which means they hash/index well.You can tune a subset of characters if you want to decrease ambiguity eg. when exchanged by voice (no zero vs. letter O, upper/lower case etc.)And a final bonus, when working with user input only a a short prefix is needed to uniquely identify an item (in contrast, it seems like UUIDs deliberately share a common prefix)I'm very happy to concede I must be missing"	zbuf	13.951339	-5.2034426	comment	3.0	17.0	1655057900	-13.647893
31741432	If you mix fork with threads, you're	"If you mix fork with threads, you're going to have a [undefined behavior] time. It seems like if you link with the sqlite that comes with macOS, you're using threads whether you like it or not. I think ending up at ""you shouldn't use fork() at all"" is a bit of an extreme conclusion, though.BTW, article title needs a (2016). It appears that the relevant Python bug has long since been closed, by avoiding linking with the system sqlite on macOS."	jordemort	13.607626	-5.565467	comment	3.0	20.0	1655222762	9.795709
13999461	Other than Couch/Pouch, are there an	"Other than Couch/Pouch, are there any other projects providing solutions to this problem?  The one thing I dislike about couchdb is the default ""user-per-db"" model.I'm interested in solutions that allow a traditional relational db instead of a key-value store.   Seems like with indexeddb on the client, and postgres on the server, you could probably keep a segment synced."	tarr11	13.546292	-5.19592	comment	3.0	11.0	1490912903	9.669632
14067445	I am considering more and more a mov	I am considering more and more a move back from MongoDB to PostgreSQL. I will be missing being schema less so much though. Migrations - particularly Rails migrations - left a bad taste in my mouth. Anyone did the move recently and what are their feelings?	hartator	13.585661	-5.3737903	comment	3.0	13.0	1491666192	9.976293
14070317	I've literally been waffling back an	I've literally been waffling back and forth between UUID and BigInt for the last week. The reason for this is I need to handle eventually distributed systems. Do I need UUIDs? Maybe not, but after much debt, I've decided that the storage requirements of such an index in memory is worth the ability to move from Postgres to Postgresql-xl.	virmundi	13.97608	-5.2209888	comment	3.0	14.0	1491709622	-13.66786
14240513	Any newer Jepsen test since this one	Any newer Jepsen test since this one: https://jepsen.io/analyses/cockroachdb-beta-20160829Also, how's the performance nowadays?	didip	13.623383	-5.2280855	comment	3.0	12.0	1493665822	9.902366
14274386	Genuine question, why does SQLite ge	Genuine question, why does SQLite get so much hate? Is it because it's SQL, or it's embedded, or what? I've used it for a lot of projects where I have to move the server around a lot and it's super convenient	jedimastert	13.60564	-5.567785	comment	3.0	13.0	1493999836	9.88135
14291161	I've asked many devs why they chose 	I've asked many devs why they chose Mongo over a RDBMS.  They can never give me a technical answer.  It's always 'it's cool' or because they just read something about it on some non-technical blog.It usually only takes me a minute or two to ask them a future function question that's not reasonably attainable (and performant) with a NoSQL solution... so they wind up going back to whatever RDBMS is their standard.	mkosmo	13.662374	-5.313669	comment	3.0	17.0	1494249208	9.866958
14304121	I use SQL Server daily and I love th	"I use SQL Server daily and I love the relational model.  The core SQL language I dislike because it's verbose, backwards, and restricts sane forms of reuse.  The procedural components of MS SQL are just plain miserable.I'm constantly frustrated that the two options in the database world appear to be ""use SQL and all its anachronistic warts"" or ""give up on the relational model"".  NoSQL throws the baby out with the bath-water.But this is a tangent.  The original post came about calling T-SQL a ""procedural language"".  Which is inaccurate... but the author was talking about adding extensions to Sqlite - SQlite is already a SQL dialect.  So if you're bolting on T-SQL to Sqlite, what's the main thing it will bring to the table?It's procedural components.  So, in the context of comparing Sqlite t"	Pxtl	13.566898	-5.599179	comment	3.0	16.0	1494366798	9.895158
14308387	I really like the fact that the Cock	I really like the fact that the CockroachDB team recently did a detailed Jepsen test with Aphyr. The follow up articles from both CockroachDB and Aphyr explaining the findings are very interesting to read. For those who might be interested -https://www.cockroachlabs.com/blog/cockroachdb-beta-passes-j...https://jepsen.io/analyses/cockroachdb-beta-20160829	dis-sys	13.681341	-5.1923532	comment	3.0	36.0	1494426166	9.985736
14308431	What advantages do I have using Cock	What advantages do I have using Cockroach compared to Postgres, Cassandra, Rethink or MongoDB? (I know that all of them are completely different, that's part of the question)	nik736	13.6011505	-5.251538	comment	3.0	19.0	1494426462	9.900426
14310262	"""Deragatory"" isn't the problem; the "	"""Deragatory"" isn't the problem; the issue is whether it invokes visceral feelings of disgust. Many terms can be used as an insult, but are still tolerable as a name because a) they have non-insulting usages, and b) the emotional response does not rise to the level of ""visceral disgust"".The Spanish Wikipedia suggests many usages of the term ""mongo"", which probably wouldn't persist if the term was so repulsive: https://es.wikipedia.org/wiki/Mongo"	SilasX	13.7087755	-5.29732	comment	3.0	15.0	1494439733	-4.4907494
14367411	Congratulations to the team. The rep	Congratulations to the team. The replication/partition improvements are significant and much appreciated.My favorite improvements are full text search of JSON & JSONB; this makes pg a full replacement for Mongo for my use cases.	jph	13.553616	-5.378893	comment	3.0	45.0	1495117266	9.861964
14368655	I know it's pretty popular to hate o	"I know it's pretty popular to hate on Mongodb now (even more so than it was to love on Mongodb 4 years ago), but there are still areas where it's better than a relational db. In game development, it's extremely helpful (especially as an ""indie"") to change the structure on a whim so easily. Also based on the design of the game I'm working on, I believe the document structure captures the structure of the data so much better than if I was forced to make a bunch of tables. This aides in understanding the representation of our game's data, and I believe (but haven't tested) it will be faster than a relational db for my use case, but that's an ancillary benefit anyway."	fnayr	13.601278	-5.3789954	comment	3.0	16.0	1495125251	9.853507
14509827	I can actually fill in some of the d	I can actually fill in some of the details about the history of UUID's.  Paul Leach was an architect who worked at Apollo, OSF, and later Microsoft.  I met Paul in the mid-90's when he was an architect at OSF, and I was the tech load for Kerberos v5 development at MIT.  OSF DCE was going to use Kerberos for authentication, and was going to use Apollo RFC as its RPC layer.It was from talking to Paul that I learned about UUID's, and I added libuuid into e2fsprogs 1.05, released September 7, 1996.  UUID's were used in Linux in the ext2 superblock, and later on, GNOME picked it up and used it extensively, which meant among other things that if you wanted to run GNOME on FreeBSD or NetBSD or Solaris, you had to compile e2fsprogs to get libuuid.  :-)Later on Paul went on to Microsoft, and I'm fa	tytso	13.994346	-5.2132354	comment	3.0	12.0	1496869199	-13.669513
14511302	If you're not specifically requestin	If you're not specifically requesting a time based ID, any proper uuid lib should just return 16 bytes of randomness from the system rng.	MichaelGG	13.983123	-5.2141333	comment	3.0	11.0	1496886808	-13.663659
14523797	> secondary primary keyThis is calle	"> secondary primary keyThis is called a ""candidate key"" in existing literature. much has been written about such things.Both UUID's and auto ID's are ""surrogate keys"" because they are arbitrary with respect to the data.lastly, ""natural keys"" are combinations of columns that consist of the business data."	platz	13.944293	-5.234838	comment	3.0	54.0	1497036714	-13.652164
14523851	Why would you format it as a UUIDv4 	Why would you format it as a UUIDv4 instead of just leaving all bits intact?	MichaelGG	13.994209	-5.20943	comment	3.0	19.0	1497037151	-13.696639
14525043	Item name was never suitable as a ke	Item name was never suitable as a key... It's not stable. There are natural keys, they are just very rare. And the thing is even when you think you've got one it is often better to err conservatively. A good anti-example is SSN, often used in text books. They do change. Other than DNA sequences I can't think of a good person key. Just use an internal surrogate and be done with it.	kpxxx3	13.91347	-5.2062206	comment	3.0	11.0	1497046888	-13.627049
14525264	>Presumably records are locked in su	">Presumably records are locked in such a way that simply knowing a URL doesn't allow you to bypass security.
In case this doesn't happen. If there is a leak, with sequential ID, you run the risk of leaking the whole table. With UUID, the leak can be more limited.Also, sequential ID may reveal some information you may not wan to share. If someone's user ID is 1234, that may be an indication the service has at least 1234 users."	peterjlee	13.934755	-5.191651	comment	3.0	12.0	1497049794	-13.614724
14550622	FYI, in sqlite is still on disk.	FYI, in sqlite is still on disk.	notacoward	13.612815	-5.5824842	comment	3.0	13.0	1497414008	9.8586445
14550693	Interesting and very relevant to the	Interesting and very relevant to the discussion!Hmm... Does SQLite have some geo data or 2d coordinate lookup capabilities as well?	asmosoinio	13.610883	-5.568151	comment	3.0	10.0	1497415271	9.85704
14551331	SQLite is good when you’re mostly re	SQLite is good when you’re mostly reading.For writing, the major drawback of SQLite is it doesn’t support concurrent writes.All filesystems do (at least when writing different files), all full-fledged RDBMS-es do, even some embedded databases do (like ESENT). Yet, in SQLite only a single thread can write.Even embedded chips are multicore these days…	Const-me	13.568235	-5.5173535	comment	3.0	10.0	1497427882	9.792938
14551381	The reason I still use files rather 	The reason I still use files rather then SQLite is that I don't know how SQLite handles concurrency.For example I have a PHP app that is used by 10k users a day and it happily handles 100k tmp files in a single directory. On each request, it checks the file age via filemtime() and if new enough, includes the tmp file with a simple include(). (I write PHP arrays into the tmp files). If too old, it recalculates the data and writes it via fopen(), fputs() and fclose().This migh be archaic but it has been working fine for years and never gave me any problems.Somehow I would expect that if I simply replaced it with SQLite, I would run into concurrency problems.	TekMol	13.586043	-5.554691	comment	3.0	11.0	1497428797	9.779544
14626252	MongoDB has purpose, but inventory m	MongoDB has purpose, but inventory management is not one of those purposes.	russdpale	13.670807	-5.33119	comment	3.0	30.0	1498322911	9.870537
14626335	> MongoDB has purpose, but inventory	> MongoDB has purpose, but inventory management is not one of those purposes.What purpose does it have frankly? The only one I see might be GridFS for what it is worth, though I don't believe one second the performances are that great, but when it comes to document oriented DB, Postgres can store both JSON and XML and query them and also do partial atomic changes. Scaling? easier maybe... Now competition is good and I'm sure NoSQL db success kind of forced traditional players to innovate. But I see no reason to use MongoDB in 2017.	camus2	13.6447735	-5.351952	comment	3.0	18.0	1498323814	9.872441
14626559	"""No reason to use MongoDB in 2017""I "	"""No reason to use MongoDB in 2017""I would reply: replica sets and sharding and multi-threaded architecture and the absence of impedance mismatch, all in a single product that was designed for these features."	weddpros	13.693808	-5.2835617	comment	3.0	15.0	1498326173	9.892786
14676438	The Lonely Story of MongoDB versus t	The Lonely Story of MongoDB versus the World	WolfOliver	13.701916	-5.311793	story	3.0	12.0	1498905291	9.899941
20400671	SQLite supports multiple simultaneou	"SQLite supports multiple simultaneous connections to the
database from separate processes.  It just does not let
more than one connection write at a time.  SQLite takes care
of serializing access for you - you don't have to put
any synchronization code in your application.  Your app
just needs to be prepared to retry an insert if it gets
back an SQLITE_BUSY result code."	SQLite	13.581848	-5.5158677	comment	3.0	11.0	1562754741	9.779419
20454053	How does YugaByte compare to Cockroa	How does YugaByte compare to CockroachDB?	noncoml	13.65543	-5.2120533	comment	3.0	17.0	1563312415	9.962742
20472414	"> You might instead ask, ""What are t"	"> You might instead ask, ""What are the key differences between MySQL and SQLite"" which can then provide the insight to answer your original question as well as help other users.I'm pretty sure if you ask that exact question, an even if nobody has asked it before so it isn't a duplicate, someone will find some reason to shoot it down."	eitland	13.607986	-5.5751333	comment	3.0	11.0	1563473151	9.8308
20494906	Anyone wanna tell us what's happened	Anyone wanna tell us what's happened to RethinkDB since then, and what's happened to SageMath since then?	jrochkind1	13.684874	-5.2850676	comment	3.0	12.0	1563761049	-12.828658
20546959	> What part of VPC networking is cha	> What part of VPC networking is challenging to you?It can be a source of friction for someone that is just trying to accomplish a specific goal, in this case it might just be to use AWS to go live.If building a database-backed prototype is your goal, designing a schema is only tangentially related to that goal. Schema design ability can slow you down if you have limited familiarity with SQL and/or the entity relationship model used by RDBMS.NoSQL allows you to reach that specific goal faster than with an RDBMS by lowering the friction of creating database records and it does it by flipping the schema model from schema-on-write to schema-on-read which is a huge time saver. This made NoSQL great for building prototypes, especially for devs with little or no familiarity with SQL, because it 	sah2ed	13.559357	-5.41756	comment	3.0	10.0	1564313092	9.874057
20756496	ArangoDB 3.5 Released	ArangoDB 3.5 Released	ShadowFaxSam	13.636821	-5.2700033	story	3.0	18.0	1566388952	9.9156275
20776850	About the well-tested bit: Per it's 	About the well-tested bit: Per it's own documentation, SQLite has a massive test suite. [*Not all of] the test suite is actually open source though, so the overlap between commenters selling you on how well tested SQLite is and those that have seen how the sausage is made is probably [close to] zero.However, pointing this or any of the other practical shortcomings of SQLite out on hacker news is blasphemy and will invariably get you downvoted into oblivion by people who (apparently) never ran into them.	firebacon	13.645573	-5.614867	comment	3.0	12.0	1566563780	9.856719
20776931	That completely depends on the chose	That completely depends on the chosen metric/definition though. For example, you could consider the most used database the one that handles the most queries per day. Not so clear who is the winner now. The claim that SQLite is one of the 5 most widely deployed pieces of software worldwide is completely unsubstantiated and most likely untrue once you count in things like ICU, the linux kernel, etc.	firebacon	13.57799	-5.517818	comment	3.0	11.0	1566564505	9.82702
20777223	Any features in this library you'd l	Any features in this library you'd like to see standard library's sqlite3 [1]? Maybe a PEP [2, python enhancement proposal] could do it.[1] https://docs.python.org/3/library/sqlite3.html[2] https://www.python.org/dev/peps/pep-0001/	tony	13.596167	-5.573595	comment	3.0	14.0	1566566383	9.847517
20777686	When you have a write-heavy workload	When you have a write-heavy workload with multiple servers that need to write concurrently to a shared database (backend to a website), you would probably want to choose something that has a client-server model instead like PostgreSQLIt's easy to get really stellar concurrent performance out of SQLite using a many reader, single writer model (ie many threads, single process). In testing we did it easily surpassed Postgres.	marktangotango	13.524465	-5.459376	comment	3.0	16.0	1566568871	9.766101
20837989	The one annoying thing about SQLite 	The one annoying thing about SQLite is that there is no easy way to change the table structure. Adding/Removing/Renaming columns is super complicated and afaik there is no good command line tool that does it for you.That is the primary reason why I do not consider it for new projects. It's just to slow to iterate on.	FreeHugs	13.588742	-5.587518	comment	3.0	17.0	1567169162	9.847139
20862421	It's interesting that people would p	It's interesting that people would pay amazon, but not mongodb...	chii	13.705481	-5.2728906	comment	3.0	19.0	1567466173	9.970852
20862475	I used to build drivers for MongoDB 	I used to build drivers for MongoDB because it was so easy.MongoDB had a good run, I enjoyed it before migrating away. This license definitely hurts companies.What to? I built my own Open Source solution (MIT/Zlib/Apache2).Around same time Firebase was getting popular, and Graph databases were the way forward.Combined them all together, now have Internet Archive and HackerNoon running it (https://github.com/amark/gun) in production!	marknadal	13.708682	-5.257276	comment	3.0	10.0	1567466860	9.903322
20862658	Because we had data that fit better 	"Because we had data that fit better in a non relational store.  We stored data that created from user generated forms and we loaded data back into those forms.Why use a relational store? If you’re working with a system that will only be read and written by an object based language? Why keep converting back and forth between a relational model and an object oriented model?In C#  var seniorMales = from c in context.Customers 
  where c.Age > 65 && c.Sex == “M”

Would be translated at runtime to either MongoQuery, Sql, a foreach loop, etc depending on what “context” represented.You get autocomplete and compile time checks.When you want to add an record to your Mongo collection, you work with strongly typed  IMongoCollection<Customer> 

And the compiler will ensure that your collection stays c"	scarface74	13.642191	-5.377136	comment	3.0	23.0	1567469073	9.868727
20862270	"What you do mean by the ""mongoDB tra"	"What you do mean by the ""mongoDB trap""?Are you saying companies are hurt by the license, or are you saying companies are hurt by software's behavior (e.g. consistency model)?"	Thorrez	13.751949	-5.200314	comment	3.0	60.0	1567464494	9.94618
20875027	> progres native json and array fiel	> progres native json and array fields - good luck running your tests on sqliteyou're not testing what you actually run in production, then what are you testing? If you just need to test in-mem behaviour, mock the DB completely; instead of expecting compatibility for vendor specific features across vendors.	satyanash	13.602682	-5.591558	comment	3.0	16.0	1567584750	9.819628
23895728	Why would you want this?The entire p	Why would you want this?The entire point of UUIDs is I can quickly generate them knowing that they will be universally unique, I don’t need to check for their existence anywhere.This dramatically increases the likelihood of collision to the point I can almost certainly guarantee that they won’t be unique in any non-trivial context.	PaulRobinson	13.979665	-5.2122283	comment	3.0	14.0	1595232462	-13.668263
23896185	What is the use case for having to r	What is the use case for having to remember UUIDs?I can see how it might speed up writing say, SQL queries if you don't have to look up the UUID but not sure that this warrants the effort of committing this to memory.	reallydontask	13.975917	-5.2016478	comment	3.0	18.0	1595237188	-13.661286
23896194	> Great man! Why don't you port uuid	"> Great man! Why don't you port uuid-readable to python? It creates a meaningful grammatically correct sentence and is a UUID, 128 bits of informationI personally don't think the gramatically correct sentence helps here. To me,""may-hold-come-foreign-low-white-cold-team-point-study-others-home-service-body-child""and""Cathleen d Dieball the Monolith of Alderson reflects Arly Arnie Keenan and 18 large ants""Are equally poor representations of a UUID. Typically ""human IDs"" are useful for quick recognition or transferring over ""voice"" which neither of these approaches work well with (I'm biased, but IMO the first one is better for transferring over voice due to simpler words).Human IDs shine when you have a comparitively tiny set of ""things"", like nodes in a cluster or Docker containers, and huma"	orf	13.955944	-5.184774	comment	3.0	18.0	1595237259	-13.643552
23896636	Added this to my UUID as a Service A	"Added this to my UUID as a Service API! [0]
Just add ?readable to any endpoint!
Eg. https://uuid.rocks/json?readable[0] https://uuid.rocks/"	geostyx	13.966189	-5.2072206	comment	3.0	20.0	1595243264	-13.673642
23940156	Are you living on another planet? Ar	Are you living on another planet? Are you seriously suggesting people replace SqlServer or MySQL with SQLite?If you can come to my company and replace our 96-core SqlServer boxes with SQLite I'll pay you any salary you ask for.	saberience	13.586192	-5.541902	comment	3.0	20.0	1595602150	9.896405
23940651	In some respects, I think the constr	In some respects, I think the constraints of something like SQLite can focus people's attention on making things work properly rather than throwing hardware at the problem.I can think of a couple of places I've worked where they had simple problems that could have been solved by some thinking and coding but instead were solved* by more expensive hardware.	zimpenfish	13.611645	-5.578226	comment	3.0	10.0	1595604607	9.839291
23941318	Is SQLite likely to be faster than p	"Is SQLite likely to be faster than postgres? In terms of ease of use / admin overhead I consider them mostly equivalent. I thought the main problem with SQLite was it was slow tih concurrent writers. Whereas the ""bigger"" SQL databases have code that allows concurrent writes."	nicoburns	13.560559	-5.4857283	comment	3.0	10.0	1595607690	9.781335
24048444	">But more something like ""It is mark"	">But more something like ""It is marketed as open source but it is not"".
Developers should be aware that VSCode is not as open source as it claims it is.Honest question...Is SQLite also deceiving people about its ""open source credentials""  because the Encryption Extension is proprietary and costs $2000?[1]... because as far as I can tell, most conversations do refer to SQLite as ""open source"" without always bringing up the encryption extension as a disclaimer in every online discussion.  SQLite's creator, Richard Hipp, has a company selling a commercial license for the encryption add-on but it doesn't seem to tarnish the ""open source"" perception of SQLite.[1] https://www.hwaci.com/cgi-bin/see-step1"	jasode	13.604017	-5.5843616	comment	3.0	21.0	1596536103	9.869958
24159579	Wait, MongoDB is still hot?  I thoug	Wait, MongoDB is still hot?  I thought it was debunked years ago and was essentially a laughingstock.	joncrane	13.703923	-5.3155813	comment	3.0	10.0	1597420593	9.900181
24178129	It is very good to hear there are ot	It is very good to hear there are others leveraging the full capabilities of this software.We haven't broken the 100GB barrier for a single SQLite database file yet, but we have strong confidence that everything will simply continue working as expected once we do.	bob1029	13.568932	-5.5421004	comment	3.0	20.0	1597588345	9.777833
24178931	Out of curiosity I wondered what was	Out of curiosity I wondered what was the biggest Sqlite databse in my filesystem:find / -name *.sqlite -printf '%s %p\n' 2>/dev/null | sort -nr | head -n 1The winner is `favicons.sqlite` from Firefox profile directory, which is 40 MB.	NewEntryHN	13.58002	-5.537583	comment	3.0	12.0	1597594296	9.801679
24259842	As long as SQLite doesn't catastroph	As long as SQLite doesn't catastrophically break under load it's fine for production, but only as long as it has a single client; traditional database engines can deal with multiple applications connecting to them.I'm using sqlite for a production application as well, but its load will be in the range of - at best - thousands per day. The only complexity will be that there has to be a secondary 'fallback' server; the current application just copies the whole .db file over to the secondary server after certain events.	Cthulhu_	13.573162	-5.5011334	comment	3.0	11.0	1598271212	9.820198
24339444	> What I miss from it that SQLite do	> What I miss from it that SQLite doesn’t provide is the ability to run it on the browser.Cries in abandoned Web SQL[0][0] https://en.m.wikipedia.org/wiki/Web_SQL_Database	virtualwhys	13.610406	-5.56164	comment	3.0	14.0	1598946184	9.834488
24379364	Lots of interesting info, and I real	"Lots of interesting info, and I really like working with MongoDB. But I am baffled by the claim that ""MongoDB is the king."" In all the circles I work in, I only hear Mongo dismissed as a joke. Unfortunately the company's dismissiveness of RDBMSes, their hubris in pushing NoSQL, and their blunders over what are extremely poor default settings all combine to make MongoDB something I don't see anyone taking seriously. I use it in a project where it's basically just serving as a big cache, so the reliability and durability of the data is not critical. It's certainly way easier to query than any other document-oriented database, but getting a foothold to use for anything requiring long-term storage would be a major challenge."	skywhopper	13.668467	-5.334267	comment	3.0	32.0	1599257190	9.8772955
33074629	I would have liked to have learned m	"I would have liked to have learned more about how the query planner and evaluator work!   There was almost nothing about that?  Just the tests magically moving from 0% to 95%.e.g. What table and value representation was used?FWIW I suspect using a LALR(1) parser in Zig on the sqlite grammar would have saved some time and gotten past the parsing headache.The sqllogictest comes directly from sqlite, so it seems like the parsing problem is mostly ""port from C to Zig"" (which are very similar metalanguages, or I guess meta- meta- languages in this case :) )Lemon is apparently a mini-yacc, just for sqlite's grammar, and is about 7K lines of C code, with no deps: https://sqlite.org/src/doc/trunk/doc/lemon.html"	chubot	13.584254	-5.622523	comment	4.0	15.0	1664836668	9.881056
33083025	There is something distasteful about	There is something distasteful about this announcement but I can’t quite pinpoint it. Maybe it feels like a bait and switch announcing their own fork after the whole qemu commentary, or the wording about the code of conduct. I don’t know.One of the greatest things about SQLite is how easy it is to embed in random targets/build systems/languages: a .c and .h and you are all set. Moving away from that model will turn off many people away so I hope they retain that model.	elteto	13.638423	-5.6034613	comment	4.0	22.0	1664901981	9.87404
33099661	That is a lot of effort to complain 	That is a lot of effort to complain about SQlite's Code of Conduct.	pexabit	13.650328	-5.601229	comment	4.0	34.0	1664995590	9.870941
33099928	This was posted yesterday, complete 	"This was posted yesterday, complete with an inflammatory blog post.This fork has exactly zero new code, but they already managed to change the license and the code of conduct. Their plans include io_uring, Rust and WASM functions - the first two negate the ""single-.c-and-.h multi-platform"" paradigm that made SQLite what it is, the third thing seems like a feature very few people would care about. They also want to make SQLite distributed for some reason (uh, just use Postgres?)"	Kwpolska	13.627561	-5.587369	comment	4.0	29.0	1664996811	9.847039
33100519	"I am guessing that ""SQLite does not "	"I am guessing that ""SQLite does not accept contributions"" and ""the industry is going in a new direction"" are what most find objectionable.SQLite cannot accept random contributions. It's on A350 flight systems, where failure is not an option. The maintainers are able to uphold this quality, but random contributors are not.It appears that the true desire is log shipping (archived logs, transaction logs, etc.) - the ability to move transaction data between databases, perhaps in multimaster.The only way such functionality is getting into SQLite is if the project agrees to write it, likely for major funding.A fork implementing these features will be regarded with interest, but will not be accepted without substantial rework."	chasil	13.61141	-5.5649323	comment	4.0	16.0	1664999765	9.901164
33136315	A lot of people moved from MongoDB b	A lot of people moved from MongoDB back to traditional RDBMSs like MySQL because most data is in fact... relational.There's probably a good use-case for MongoDB, but what I saw in practice was that it was an excuse for poor developers to avoid learning some dialect of SQL.It's the same story with ORMs. You will eventually need to learn to write SQL. For some reason developers try to avoid this almost as much as possible. Maybe more than other technologies.At some point, you are going to want to query data. And eventually you will reinvent what RDBMSs do out of the box, because they're purpose built for this work.Further, if you need to just dump JSON, an RDBMS is still a better choice for all the reasons above.	andrewmcwatters	13.578251	-5.4198213	comment	4.0	16.0	1665265599	9.840263
33274788	Anyone can share their experience wi	Anyone can share their experience with the somewhat new STRICT mode? Does it help? I tend to use Postgres when available, primarily for the added strictness, but I'd surely prefer SQLite in more scenarios as it's easier to operate.	drej	13.592695	-5.5564485	comment	4.0	14.0	1666274359	9.823229
33302466	It isn't, because as long as the pri	"It isn't, because as long as the price for a direct license is reasonable, companies will pay it just to have the paperwork.SQLite is public domain, and makes money by selling ""licenses"" to such companies (they're called something else, but it allows the company buying it to file it in their ""licenses"" folder and tick a checkbox; https://www.sqlite.org/copyright.html)."	tgsovlerkhgsel	13.673516	-5.5848346	comment	4.0	15.0	1666474774	9.864587
33321000	I still wish for something like Ever	I still wish for something like Everything on Windows (https://www.voidtools.com/)I wrote my own solution using fd + sqlite + fzf but it's nowhere as fast as Everything, and it also requires me to focus the Terminal to use it.	alin23	13.595202	-5.5791316	comment	4.0	18.0	1666638544	9.825396
33331273	> It is absolutely not easy to achie	"> It is absolutely not easy to achieve the kind of coverage that sqlite has.It is though. Give me one project and I'll send you a test suite that ""tests"" 100% of executable lines. It won't have any actual assertions, but that's not what code coverage is about anyways, so hopefully you won't mind.Number of assertions per line of code is about as good metric for how well tested something is as code coverage, which means just about nil."	capableweb	13.647413	-5.6249623	comment	4.0	15.0	1666709559	9.911022
33377940	This is good but it can never be as 	This is good but it can never be as good as Web SQL could have been, because it can't be a truly shared library. Like all WASM modules, It has to be downloaded and JIT compiled separately for every site that uses it. Not for technical reasons, but privacy reasons, so it's basically unfixable:  https://developer.chrome.com/en/blog/http-cache-partitioning...Maybe if half the sites on the web start using it, browsers can finally be convinced that it would be OK to add SQLite to the base platform.	modeless	13.560659	-5.5455456	comment	4.0	42.0	1666991276	9.790496
33378057	I disagree, this is much better than	I disagree, this is much better than WebSQL. WebSQL would have been tied to one specific version of SQLite, and developers would have to work to the lowest supported version. There would have been no extension mechanism.WASM SQLite is the correct solution. It’s extendable by the developer using it, they can uses SQLite extension modules, and build their own.But almost more so it proves the idea of a WASM db engine backed by a low level block FS api. We will see other db engines uses this architecture. DuckDB have already done it. I’m sure MongoDBs Realm and CouchBase Mobile will do the same soon too.We are in for an exciting time in the next few years.	samwillis	13.542492	-5.5260463	comment	4.0	22.0	1666991932	9.788912
33378149	sqlite3.wasm should be included in C	sqlite3.wasm should be included in Chrome, Firefox, Safary, Brave, etc. And updated automatically.Sqlite updates are solid and as far as I know, do not break your code.	hochmartinez	13.622715	-5.5893626	comment	4.0	18.0	1666992549	9.83565
33379240	I assume due to Hyrum's Law. Any qui	I assume due to Hyrum's Law. Any quirks/oddities in sqlite would become the de facto standard.	googlryas	13.627336	-5.6015363	comment	4.0	13.0	1666999282	9.87179
33490378	Pleroma still requires PostgreSQL wh	Pleroma still requires PostgreSQL which is an overkill for individuals/families. Instead try GoToSocial which is just a golang binary + sqlite db file: https://gotosocial.org/	nileshtrivedi	13.6132765	-5.5970035	comment	4.0	15.0	1667722768	9.79951
33528755	I know very little about the embedde	I know very little about the embedded world. Does anyone familiar with that space know how this compares to SQLite?	koshergweilo	13.63489	-5.5688806	comment	4.0	16.0	1667982376	9.853086
33692546	Semantic Search with SQLite	Semantic Search with SQLite	txtai	13.5518055	-5.546074	story	4.0	107.0	1669039415	9.766003
33700274	Just curious to learn: when do you n	Just curious to learn: when do you need sortable primary keys?	dvnguyen	13.8361435	-5.2743983	comment	4.0	22.0	1669077380	-13.668212
33700970	"Pretty much, my first reaction was """	"Pretty much, my first reaction was ""people use UUIDs for session tokens ? why? ?Seems like author made some bad choices in previous systems and now just figured out why tbh."	ilyt	13.992907	-5.2067404	comment	4.0	28.0	1669083676	-13.641905
33701564	Tell that to Django (well 5 years ag	Tell that to Django (well 5 years ago anyways iirc, don't know what it does now).  Pretty sure it used to store uuids as strings columns in your sql.	throwawaymaths	13.989675	-5.212194	comment	4.0	15.0	1669088838	-13.660811
33732238	Looks interesting.Why does it need a	Looks interesting.Why does it need a Postgresql server? For just a handful of users, isn't sqlite the leaner, yet sufficient choice?How does it compare to GoToSocial, which requires 50-100MB of RAM? They are also in alpha stage and i like their approach of keeping the web UI separate.	Tepix	13.521431	-5.4380198	comment	4.0	24.0	1669303091	9.837534
33862539	Disagree. UUIDs are a waste of space	Disagree. UUIDs are a waste of space, and they aren’t sorted.Use 64-bit ints. Prefer not exposing them to users, but it’s not a problem for most software.If you ever get so big you need to shard, use Snowflake or a 64bit scheme that encodes the shard.Don’t overcomplicate things. You’re already using either SQLite or PostgreSQL and it already gives you auto-incrementing integer keys by default, without the need to encode/decode UUIDs in whatever software you’re writing to interface with it.	alxmng	13.970811	-5.2178464	comment	4.0	14.0	1670224840	-13.65902
33934851	For me it's maintenance.  Sysadmin l	For me it's maintenance.  Sysadmin level of effort on a SQLite file is near 0	freedomben	13.599654	-5.564596	comment	4.0	16.0	1670694994	9.843589
33976142	> The idea that SQLite shouldn't be 	> The idea that SQLite shouldn't be use for web applications is about a decade out-of-date at this pointI think it's still very relevant. I mean you have service XYZ replicated two times behind a load balancer, how do you use SQLite out of the box? You can't, you have to use one of those service that will proxy / queue queries, so then why even trying to use SQLite.The fact that it's just a file on disk make it a bad solution for a lot of simple use cases.	Thaxll	13.59283	-5.5367823	comment	4.0	12.0	1670967049	9.849202
33977738	ids being sortable has a lot of adva	ids being sortable has a lot of advantages over random guids.	knodi123	13.916755	-5.2187076	comment	4.0	18.0	1670973777	-13.653677
34069121	You still have to keep the database 	You still have to keep the database nature of the SQLite file in mind when doing backups, as far as I understand it is not safe to just copy the file while the DB is running unless you use snapshots or ensure that nothing is written to the DB during that time.SQLite is still easier to manage than a standalone database server, so it is interesting in any case. But I'm not sure it makes backups easier.	fabian2k	13.598246	-5.529535	comment	4.0	12.0	1671557336	9.781459
26547201	SQLite: Code of Ethics	SQLite: Code of Ethics	zrkrlc	13.655773	-5.596341	story	4.0	37.0	1616447692	9.798244
26581019	Don't forget about User-Defined Func	Don't forget about User-Defined Functions.https://www.sqlite.org/appfunc.htmlWe just started enhancing our SQL dialect with new functions which are implemented in C# code. One of them is an aggregate and it is really incredible to see how it simplifies projections involving multiple rows.One huge benefit of SQLite's idea of UDFs is that you can actually set breakpoints and debug them as SQL is executing.	bob1029	13.565833	-5.575555	comment	4.0	13.0	1616684058	9.848085
26581149	SQLite is so robust, that I bet most	SQLite is so robust, that I bet most websites could use it without really needing to move onto a client/server RDBMS.[1] I use MySQL, and I know PostgreSQL has a large marketshare now, but I wonder how much of either is really necessary when you think about traffic usage alone. I know at least in my use cases, neither seem necessary.[1]: https://sqlite.org/whentouse.html	andrewmcwatters	13.5860195	-5.5118155	comment	4.0	58.0	1616684715	9.833986
26704084	The ID prefixing is cool from an ide	The ID prefixing is cool from an identification point of view, but we've been using UUIDs for tokens and if we implemented this we wouldn't be able to use the UUID optimized datatype field in Postgres.	revicon	13.961266	-5.2194605	comment	4.0	13.0	1617653793	-13.644948
26765118	Ask HN: Deploying SQLite on a Produc	Ask HN: Deploying SQLite on a Production Website	iio7	13.578885	-5.5063963	story	4.0	5.0	1618088868	9.794537
26817127	Cool article. I definitely agree tha	Cool article. I definitely agree that SQLite is the way to go in 99% of the cases you're making some kind of app.I have often seen Postgres, MySQL and MongoDB in places where they were really overkill and added unnecessary network and deployment complexity. And upon asking the designers it turns out they simply didn't know about SQLite...Small gripe in case the poster reads this: There's a malopropism in the opening bit:> SQLite is properly the only database you will ever need in most cases.Should be:> SQLite is probably	not_knuth	13.56878	-5.5267076	comment	4.0	25.0	1618471285	9.83413
26817323	I use Gitea(Github clone) locally wi	I use Gitea(Github clone) locally with SQLite running on ZFS where I can take atomic snapshots of both the SQLite database and git repositories.This would not be possible if I used a remote database, as there is no way to do a atomic snapshot of both the remote database on another filesystem(even if its ZFS) and the git repository.Developers of multiple services, please support SQLite and don't lock yourself to a single database like PostgreSQL and MySQL. Even if the service is embedded in a Docker Container it is still painful to manage.	olavgg	13.556366	-5.4902782	comment	4.0	25.0	1618472579	9.773642
26821115	> In the end, I always come back to 	> In the end, I always come back to Postgres. It's unbelievably powerful, lightweight and there's not much it can't do.How lightweight?SQLite itself is around 600 KB. That's with all features enabled. I believe you can get it it down to about half that if you disable features you don't need. RAM usage is typically under a dozen or so KB.It doesn't even require that you have an operating system. All you need for a minimal build is a C runtime that includes memcmp, memcpy, memmove, memset, strcmp, strlen, and strncmp, and by default also malloc, realloc, and free although it has provisions for providing different memory allocators, and you have to provide some code to access storage if you are running on a system that doesn't have something close to open, read, write, and the like.This means	tzs	13.560983	-5.4963117	comment	4.0	14.0	1618497861	9.799959
26883858	The project isn't about performance,	The project isn't about performance, it's about providing an embedded version of MongoDB - it clearly states that if you grow too large, then you can easily migrate to the full MongoDB. It also clearly states not to use it if you want a relational database.	abrookewood	13.659859	-5.3273726	comment	4.0	26.0	1618964842	9.855611
26883378	> Mongita is to MongoDB as SQLite is	> Mongita is to MongoDB as SQLite is to SQLit really isn't if it's written in python	latenightcoding	13.605023	-5.5539474	comment	4.0	27.0	1618961399	9.858545
26923594	Also, from the point of query optimi	"Also, from the point of query optimisation this is a really bad idea. Usually you DO actually care about size of fields in SQL databases, because something like BOOLEAN is usually stored as single byte (or bit in a bitfield) vs 4 bytes or even 8 in case of timestamp. This not only multiplies on disk usage by at least 4 times, but also makes ALL indexes using this field way bigger. Also boolean indexes can be compressed (or stored as bitmaps), while timestamp indexes  contain lots of unique values, so they can't be.
This is also the reason why  serial IDs are way better than UUIDs for internal IDs."	antender	13.954642	-5.223977	comment	4.0	22.0	1619257158	-13.610535
26997434	You could also go entirely into the 	"You could also go entirely into the matrix and write custom functions + wrappers for SQLite that are able to parse & pass-through shell commands. For instance:  ./customsqlite ""SELECT 1, 3, 5 FROM MyLogParser(Shell('tail -n 50 mylog.txt'))"" | grep 'something really important'

This stuff is dangerously powerful. User/Application-defined functions in SQLite do not have to be free of side-effects. You could also do something like:  tail -n 50 mylog.txt | customsqlite ""SELECT Shell('ping ' || ip.IpAddress) FROM ParseAsMyIpData(STDIN()) ip""

  Where the following are custom UDFs:
  - MyLogParser
  - Shell
  - ParseAsMyIpData
  - STDIN

See: https://www.sqlite.org/appfunc.html"	bob1029	13.55788	-5.5882263	comment	4.0	13.0	1619807531	9.812996
27030607	I think the issue with a lib like th	I think the issue with a lib like this is that people might use it, thinking they don't need the IDs to be secure... until they need to be. But by then plenty would have been generated, and a lot of code would rely on this sortable property.In fact, I don't see the point of a library like this, it's trying to encode two pieces of information into one string. Why is that? Why not encode geolocation or IP while they're at it. If some data is important, like the order, then a separate database column can easily be used and that would make for a much more durable and reliable solution.	laurent123456	13.859119	-5.2294374	comment	4.0	17.0	1620075797	-13.628084
27238683	True, until it isn’t? It’s quite a b	True, until it isn’t? It’s quite a big gamble and a large lock-in.What would the benefit be for choosing Sqlite over MySql?	dstick	13.592799	-5.5266304	comment	4.0	17.0	1621624834	9.846079
27238896	What is not so obvious to me: When s	What is not so obvious to me: When should WAL be used and when not? Does it even make a difference? It says that WAL might be 1-2% slower on read heavy applications, but how much faster is it for write heavy applications? I'm trying to think of a use case because most (web) applications are ready heavy.And another question: Are both, WAL and rollback journal multithreading and multiprocess safe while being accessed by multiple applications on a single server? I always asked myself this but somehow never found a clear yes/no answer.	zubspace	13.559676	-5.4355936	comment	4.0	12.0	1621625916	9.838425
27347397	I don't think a lot of the argument 	"I don't think a lot of the argument that integer IDs reveal too much.Yes, they are guessable but your application should not rely solely on the ""secrecy"" of the ID to authorize access to a record. If you are worried about someone crawling your public API with wget or curl and an incrementing counter you should re-think whether your data are really public or not, or maybe rate-limit anonymous users, etc.They also reveal something about the total number of records in your database, I guess that could matter in some contexts but it's never really been an issue in practice for me.I have definitely used the technique of defining non-overlapping sequences in different shards (with Oracle, not Postgres, but they are very similar in this regard). It worked very well and was easy to reason about.As"	throwawayboise	13.955277	-5.2154217	comment	4.0	19.0	1622489582	-13.6498785
27346901	About UUID as Primary Key and perfor	About UUID as Primary Key and performance, the following article has some insights and benchmarks as well: https://www.2ndquadrant.com/en/blog/sequential-uuid-generato...Essentially, they observed sizeable performance improvements by using UUID generators that are tweaked to get more sequentia resultsl. It results in better indexes. The articles compares sequences, random UUIDs and 2 kinds of sequentialish UUID generators.	magicpointer	13.9857645	-5.221998	comment	4.0	42.0	1622485925	-13.660098
27435258	I do respect the technical chops aro	"I do respect the technical chops around sqlite. However, I think a ""fork for every single http request"" server isn't really useful in many situations.That the sqlite website is able to run this way is more a testament to Linux's work on a lightweight/fast fork() than anything else.  This would perform terribly on a more traditional Unix."	tyingq	13.610386	-5.5589933	comment	4.0	17.0	1623160543	9.8251505
37585535	I want to be able to have a Postgres	I want to be able to have a Postgres database as the central source of truth for all data and user accounts, but then have each users private content to be siloed and synced to their own SQLite database which they alone have access to (maybe even they’re have one SQLite file on server and one SQLite file on phone or etc.). Is this possible with electricSQL? I remember looking at it a year ago or so and was excited but not sure if worked for my use case. Great work tho looks really good and very much in line with what I’d like to be able to do.Also is there a way to transition an existing Postgres data base into using electicsql?	canadiantim	13.541638	-5.471982	comment	4.0	22.0	1695224157	9.81322
37599272	This article seems to have inspired 	This article seems to have inspired others to look at MongoDB again, so I'll give my thoughts after using it recently.MongoDB Atlas is a surprisingly good managed database product. I'm not a huge fan of someone else running my databases, but I think it might be the best one you can run across any cloud. If you like MongoDB (and, ignore the memes, there is a lot to like nowadays), and are OK paying a bit more to have someone run your database, I'd strongly consider Atlas.	bit_flipper	13.626837	-5.327893	comment	4.0	22.0	1695310651	9.839537
12544437	As an low-profile developer who's be	As an low-profile developer who's been using CouchDB for a long time, some weeks ago I've written some quick personal opinions on what CouchDB has become: http://fiatjaf.on.flowi.es/about-couchdb/	fiatjaf	13.602224	-5.2125688	comment	4.0	25.0	1474416550	9.671176
12544892	My thoughts exactly. I'm not sure wh	My thoughts exactly. I'm not sure who CouchDB is supposed to be for anymore. The original developers who fell in love with it are moving on. Who is the audience for 2.0? Who does IBM hope to reach with Cloudant?BTW, you are spot on about continuous replication. Try using continuous replication on Cloudant and you will end up with a fat bill.	pokstad	13.610182	-5.207542	comment	4.0	17.0	1474423217	9.654294
12565538	I have been running Firefox for a lo	I have been running Firefox for a long time with an LD_PRELOAD wrapper which turns fsync() and sync() into a no-op.I feel it's little antisocial for regular desktop apps to assume it's for them to do this.Chrome is also a culprit, a similar sync'ing caused us problems at my employer's, inflated pressure on an NFS server where /home directories are network mounts. Even where we already put the cache to a local disk.At the bottom of these sorts of cases I have on more than one occasion found an SQLite database. I can see its benefit as a file format, but I don't think we need full database-like synchronisation on things like cookie updates; I would prefer to lose a few seconds (or minutes) of cookie updates on power loss than over-inflate the I/O requirements.	zbuf	13.544454	-5.4907475	comment	4.0	18.0	1474646178	9.683494
12578486	This used to be how I felt, since th	This used to be how I felt, since the performance criticism of SQLite is vastly overblown. However, the safety criticism of a dynamically typed database is vastly underblown.Since it completes with fopen(), you get about as much structure and validity.	nilved	13.589663	-5.5372624	comment	4.0	23.0	1474852221	9.84676
12578615	I teach SQL to non-techie students. 	I teach SQL to non-techie students. I used to give the the option of doing either MySQL or SQLite, but not only did I underestimate how different the syntaxes were, I also underestimated how not-trivial it is for students to successfully install and run both the MySQL server and client. These are students who can't even use a spreadsheet well, not that that makes a huge difference in understanding databases.I've moved everything to SQLite and couldn't be happier. Not only is it easier to distribute assignments (e.g. a single SQLite file, instead of CSVs that need to be manually imported), it does everything I need it to do to teach the concepts of relational databases and join operations. This typically just needs read-only access, so our assignments can involve gigabytes of data without i	danso	13.524034	-5.568889	comment	4.0	30.0	1474853722	-12.110339
12578710	SQLite is quite possibly one of the 	SQLite is quite possibly one of the most useful pieces of software ever created. It's small, relatively fast, and unbelivably solid. It's up there with bash, curl, grep, emacs, and nano: tools that are just so good at their job that we don't even notice how amazing they are.I mean, really. SQLite is remarkable, impressive, and used everywhere, and we never talk about it. Emacs is a remarkably impressive piece of engineering, bash is the world's default shell for a reason, Nano is the newbie's text edior, and, well, just imagine for a second what would happen if grep or curl stopped working.	qwertyuiop924	13.558734	-5.5642147	comment	4.0	44.0	1474855131	9.8583145
12579089	I'm looking at a project right now w	"I'm looking at a project right now where I'm planning to use SQLite as a high-level solution to file locking (i.e. create a record in the DB to ""lock"" a file, delete it when you're done, and don't create a record if a record for that file is already in the DB).  Sound like an appropriate use of SQLite?  Is there a better, more direct solution?  (I understand there are platform-specific utilities but I would want something portable.)"	theseoafs	13.586642	-5.5477204	comment	4.0	14.0	1474861691	9.774181
12618912	One more war story about the bad des	One more war story about the bad design decision in MongoDB resulting in unresponsive nodes and data loss.Hopefully, people will have figured out by now that MongoDB is not ready for production.	user5994461	13.709581	-5.3061914	comment	4.0	13.0	1475343228	9.889013
12649494	Okay...but if Rethink couldn't make 	Okay...but if Rethink couldn't make their business self-sustaining, why would Mongo when there are a plethora of other open source databases/datastores that can do Mongo's job better than Mongo?EDIT: We'll just wait for Mongo to burn through all their cash then.	toomuchtodo	13.689534	-5.288293	comment	4.0	24.0	1475717888	9.844765
12649731	At my last workplace, I finally aske	"At my last workplace, I finally asked: ""Since you guys bitch about mongo so much, why do we use it? Why not something else?"". Response: ""It's not actually that bad, it does the job"".Half the crap people speak about Mongo seems to be from either the early days, or from people who just like to complain. It certainly has it's issues, but there doesn't seem to be much community will to replace it with $superdupernosqldb."	vacri	13.700784	-5.3069205	comment	4.0	13.0	1475720558	9.907568
12649751	Wow. I was seriously rooting for the	Wow. I was seriously rooting for them. I'm looking forward to Slava's posts about their challenges on the business side. There's a part of me that's angry that MongoDB - which some would say has made an objectively worse product - has succeeded.My initial thought is that MongoDB has done a way, way better job at SEO. The number of blog posts about RethinkDB pales in comparison to Mongo. I wonder if they got beat on sales as well? Not sure.	misterbowfinger	13.695656	-5.2943954	comment	4.0	25.0	1475720753	9.912323
12649792	"Mongo also got there ""first"". I mean"	"Mongo also got there ""first"". I mean, Mongo isn't much compared to Rethink, but they're both in the ""not a traditional SQL database"" camp and Mongo came before and had all the hype first.I wouldn't be surprised if people a) didn't use Rethink because they're happy with Mongo and its popularity b) hated Mongo and saw Rethink as too similar/didn't research it enough."	sotojuan	13.670331	-5.3023105	comment	4.0	19.0	1475721363	9.946503
12651172	A while ago, I heard how good Rethin	A while ago, I heard how good RethinkDB is and tried to check it out and found this page.https://rethinkdb.com/docs/sql-to-reql/javascript/The more complex the query becomes I just felt everything was getting less intuitive compared to the SQL version and ended up not actually using it.For anyone who switched from SQL, I'd like to know how it felt to write RethinkDB queries. Did they start to feel fluent later on?	h1d	13.655188	-5.304253	comment	4.0	16.0	1475745944	-12.812078
12651810	It seems that unfortunately RethinkD	"It seems that unfortunately RethinkDB the company was architected in such a way that the success of their product, in terms of performance and developer experience, led to a decrease in revenue.This shutdown therefore goes a long way to say how talented and ethically correct the team was, something extremely evident in how they put correctness and reliability in front of performance.In short, RethinkDB is a very solid piece of software that does well where (many) other NoSQLs fall short, that is:  * easy HA and automatic failover
  * easy auto sharding
  * rational query language
  * ease of administration and awareness (webUI)
  * realtime capabilities
  * perform well on the Jepsen test!

Now, what could have they done differently to stay afloat? 
What avenues do we have to fund fund suc"	simon_acca	13.655896	-5.277163	comment	4.0	31.0	1475756666	-12.837803
12660588	OP here. I'm an open source contribu	"OP here. I'm an open source contributor, not affiliated with RethinkDB Co. I've been using RethinkDB in production for years, and it has been one of the greatest blessings of my engineering career.I am a big believer in RethinkDB and I want to see the project continue forward just like many fellow HN members have expressed in the past few days. I plan to share this with open source foundations to help spark an opportunity to help find RethinkDB a new home.I would encourage constructive communication here. This is about the RethinkDB community working together to help the project end up in a good spot. What foundation or company is not the goal here. Saying this foundation is ""good"" and another is ""bad"" is not the goal here. The goal is to work together and make it clear we the community su"	chrisabrams	13.664977	-5.2684364	comment	4.0	15.0	1475847780	-12.807709
12702498	This worked for me on OS X:  sqlite3	"This worked for me on OS X:  sqlite3 ~/Library/Keychains/*/ocspcache.sqlite3 'DELETE FROM ocsp WHERE hex(serialNum) IN (""040000000001444EF03E20"", ""040000000001444EF04247"");'

What a pain in the behind :/"	SysArchitect	13.651869	-5.534026	comment	4.0	16.0	1476379881	9.891724
12795542	It wasn't so much of an implementati	"It wasn't so much of an implementation issue as it was politics around the spec that killed it: As WebSQL basically happened by just exposing a SQLite runtime to JS, there was never a clear spec of what WebSQL should support (no - ""it just supports all that SQLite supports"" is not good enough).And even if somebody went in and specified all of SQLite's features, then there would still be the issue that any accepted web standard needs two independent implementations, meaning that one of the browsers would have had to clean-room reimplement SQLite.And finally, there would be the question of what to do as SQLite involved. What would browsers do as SQLite gains features or changes behaviour? Keep the old version of SQLite around for JS? Freeze the whole browser on the old version of SQLite?I ag"	pilif	13.6175585	-5.5549593	comment	4.0	19.0	1477480618	9.806904
12983331	Open-RethinkDB meeting notes	Open-RethinkDB meeting notes	deepanchor	13.679176	-5.290131	story	4.0	158.0	1479430125	-12.788405
13171131	I also have done 3 years of MongoDB 	I also have done 3 years of MongoDB before I (unwillingly) wrote an app with it... worst development experience I've ever had. I wouldn't have used it were it not for my corporate overlords at the time.My new rule of thumb: Use plain databases for most things and only use DynamoDB if there's a precise feature in your system that it is well suited for.DynamoDB is a horrible general use database.	jonthepirate	13.638445	-5.193883	comment	4.0	13.0	1481663930	9.742832
13185134	Every time I read these MongoDB arti	Every time I read these MongoDB articles, I question why RethinkDB didn't rise up.	overcast	13.675164	-5.292039	comment	4.0	21.0	1481815397	-12.771126
13203268	"In the FAQ it just says ""Come on"" fo"	"In the FAQ it just says ""Come on"" for SQLite included in the list.  Can you provide a bit more detail?  This feels like a pretty great option to include here."	quinthar	13.618835	-5.5798006	comment	4.0	22.0	1482015970	9.884674
13213968	So this is a good place to list real	So this is a good place to list really nice codebases. sqlite is a fantastic piece of source code, totally worth reading.	weeksie	13.609545	-5.589528	comment	4.0	13.0	1482174022	9.855859
13249552	Honestly, I cringe everytime I read 	Honestly, I cringe everytime I read about gundb.Db made in nodejs? Check.No mention of multiprocess? Check.No mention of persistence? Check.(lol @ s3 persistence)All tests failing ? Check.Optimizing if/else? Check.Faster than redis? Check.Store non-optimized json in disk(not sure but looks liek it)? Check.I cringe at every page on their docs(like sharding). It just feels like the templeos situation. Upvoted for discussion though.	ddorian43	13.587239	-5.2877336	comment	4.0	14.0	1482582773	9.834482
13260231	I don't see any articles on motivati	"I don't see any articles on motivation / benefits of RavenDB. For example:- How many benefits does it have over something like Mongo?- I'm not sure how .net is a benefit since others have C#/linq drivers- Isn't this concerning? https://jeremydmiller.com/2013/05/13/would-i-use-ravendb-aga...- $6000 is not cheap
- Is Marten free? Seems hard to compete with a foundation as powerful as Postgres."	WhitneyLand	13.58854	-5.3741884	comment	4.0	14.0	1482793136	9.868722
13262959	In this day and age with breaches ha	In this day and age with breaches happening daily and publicly why hasn't mongo taken security seriously and enabled authentication by default?	agotterer	13.726058	-5.2578926	comment	4.0	15.0	1482844970	9.950745
13375027	I think the problem is developers ru	I think the problem is developers running apt-get install mongodb and assuming all other considerations, like a firewall, are somehow magically taken care of, then patting themselves on the back for not needing a sysadmin.	00deadbeef	13.719004	-5.260833	comment	4.0	18.0	1484151882	9.949366
13424184	I really can't read all this negativ	I really can't read all this negativity. Seriously you guys need to snap out of it. You created something fantastic, a database that perfectly answers need of developers. Clearly you need to give it time and align your expectations with market.RethinkDB is fresh view on how databases can work and look, it provides level on goodness not seen before. Just continue building on it. Horizon is also awesome. Things don't happen overnight.	desireco42	13.642159	-5.3101907	comment	4.0	12.0	1484716715	-12.796829
13459011	Embedded Python/NumPy in MonetDB	Embedded Python/NumPy in MonetDB	espeed	13.598183	-5.4219666	story	4.0	61.0	1485135629	9.79133
13493748	"News: ""Our initial plan was to acqui"	"News: ""Our initial plan was to acquire the intellectual property left over from the RethinkDB company, enabling us to relicense the code and use the name RethinkDB.  After aggressively pursuing this plan since the company shut down in September, little progress has been made.""   Dang."	williamstein	13.692507	-5.2713995	comment	4.0	31.0	1485454550	-12.808642
13579635	Am I reading this right? Rethinkdb i	Am I reading this right? Rethinkdb is now under apache 2? That's awesome news - such great software.	divbit	13.670825	-5.2931447	comment	4.0	16.0	1486391202	-12.805816
13581872	Sorry if this should be obvious but 	Sorry if this should be obvious but what is/are the killer  feature/s of RethinkDB, what differentiates it from something like Redis or even CockroachDB?	hd4	13.7168665	-5.2431936	comment	4.0	31.0	1486402769	-12.816204
13591326	I think if you look back objectively	"I think if you look back objectively, there are very few database platforms that were absolutely ""fit for public consumption"" right out of the box.  Look at all the SQL Server shops out there (mine included) that won't even roll out a new version of SQL Server until it hits SP 1 at a minimum...  For MongoDB, If you look forward based on what they are doing now rather than at how early adopters may have had a sub-optimal experience way back when, you'll see a mature product that is consistently improving and is demonstrably reliable.  Can you give an example of another option you are referring to?"	BillFinchDba	13.637352	-5.319187	comment	4.0	61.0	1486491430	9.87183
13591231	Given their start point (a product u	Given their start point (a product unfit for public consumption) that is the absolute minimum they need to do.I at least will never trust Mongo for anything but a toy project. There are so many better options out there, options whose technical capabilities are as good as Mongo's marketing.	radicalbyte	13.707051	-5.2775726	comment	4.0	82.0	1486490830	9.923404
13591433	Why would anyone use MongoDB when Re	Why would anyone use MongoDB when RethinkDB is available?	rocky1138	13.674549	-5.319102	comment	4.0	19.0	1486492447	9.891942
27552058	Can you think of any good use case f	Can you think of any good use case for a non-arbitrary primary key? You are right that first name + last name + dob is not a good way to design the system. For example someone could differentiate their twin children only by their middle name. So, what's an example of a non-integer non-arbitrary primary key?	whatshisface	13.879918	-5.257648	comment	4.0	12.0	1624033725	-13.6453085
27552154	I don't have an answer for you but y	I don't have an answer for you but you do have my curiosity. Why did you choose UUIDs as primary keys?	steelbrain	13.969178	-5.223451	comment	4.0	25.0	1624034203	-13.664701
27552176	Student IDs are certainly not ‘natur	Student IDs are certainly not ‘natural’ keys.I am almost entirely convinced that there is actually no such thing as a natural key.	jameshart	13.8941965	-5.228309	comment	4.0	25.0	1624034317	-13.666501
27669402	Will my mongodb instance be even fas	Will my mongodb instance be even faster piping to this instead of /dev/null?	distantsounds	13.706556	-5.312364	comment	4.0	15.0	1624921147	9.904457
27671223	That might be true, but regardless o	That might be true, but regardless of docker (or other, similar solutions), shouldn't MongoDB have had auth protection?	thatwasunusual	13.703892	-5.2488756	comment	4.0	39.0	1624935751	9.967314
27673385	I'd be fascinated to hear more about	I'd be fascinated to hear more about this.Where do the SQLite files live? Are you using some kind of NFS or EFS or similar for them? Sharding them across many machines?How are you handling backups and high availability? Are you using Litestream?How many SQLite files do your application servers have open at any one time?	simonw	13.5961685	-5.529486	comment	4.0	17.0	1624956273	9.816442
27719660	fun fact: the `ite` ending in SQLite	fun fact: the `ite` ending in SQLite is a reference to the `ite` ending in minerals (granite, magnetite, pyrite, bauxite...) so it is not a lightweight SQL but rather a rock-stable SQL	afiori	13.603214	-5.6208243	comment	4.0	15.0	1625291330	9.882338
27732127	> Wouldn’t this be more worthwhile t	> Wouldn’t this be more worthwhile to write in [insert favorite modern language]?sqlite isn’t your average C development, it’s got more lines of code written for tests than it does for actual code. Given the extensive tests written against sqlite, rewriting it from scratch in any language, even a more modern/safer one, would ultimately end up with a buggier program.The only practical reason for rewriting sqlite is as a learning exercise. Which is what I believe the point behind this submitted project.	laumars	13.622962	-5.612441	comment	4.0	43.0	1625428291	9.850214
27856147	This is why you should never expose 	This is why you should never expose your database IDs to the customer. They just complain about it, and it invites them wanting to assign meaning and have control over the values.	agent327	13.786698	-5.2062902	comment	4.0	18.0	1626443026	-13.600432
27874169	Hey, sorry for the misleading title.	Hey, sorry for the misleading title. I started with ‘Fast SQLite Inserts’ and it had many iterations. In the title, I wanted to intend that I want to insert 1 billion rows under a minute on my machine. I thought the current title is fine, since I got LGTM for earlier drafts. The detail about on my machine is also important since mine is a two year old laptop and all the measurements are done on it.Also I got another feedback that title should indicate that it is a test database and emphasise that it is not durable.I am wondering the right way to convey all of this in the title yet also keep it short.	avinassh	13.536162	-5.543172	comment	4.0	14.0	1626625401	9.76541
27875786	Sqlite has been battletested for yea	"Sqlite has been battletested for years.I utterly fail to see the point in reimplementing it in some other language.Innovate in databases - yes please - but ""rewrite"" - why?Not being able to use battletested libraries written in plain C (e.g. sqlite) sounds like a hugh mark against rust as a systems programming language.Is using C libraries an actual issue or just an aesthetic grumble?"	fsloth	13.638157	-5.6600266	comment	4.0	18.0	1626636225	9.8240385
27908746	This feels restrictive, especially i	This feels restrictive, especially in comparison to Postgresql. Where you have projects like CockroachDB which utilize the Postgresql wire protocol because of how well documented it is.	skunkworker	13.523516	-5.3806996	comment	4.0	15.0	1626886350	9.84995
27909197	A company I worked at was hounded by	A company I worked at was hounded by MongoDB to the point where the sales rep turned up unannounced and talked his way to the dev department.  He was quickly escorted off site.	comprev	13.717193	-5.2776337	comment	4.0	13.0	1626888090	9.937364
12011911	What are some counterindicated use c	What are some counterindicated use cases for rethinkdb?	colordrops	13.667219	-5.293806	comment	4.0	22.0	1467322167	-12.8052225
12290867	I think it's ironic that the page sa	"I think it's ironic that the page says ""Error establishing a database connection"".As someone who used MongoDB extensively in the past (8TB+ of data) and also managed the devops side of things, I can tell you straight out that MongoDB has a place in a lot of startup stacks.I would likely not use it as a main source of truth for any application. However for a lot of things, it's a good database.Since I can't read the post I can't really address the points made in it, so at this point enough said."	avitzurel	13.682213	-5.31869	comment	4.0	32.0	1471273237	9.8739805
12291205	Actually, when you have a toy projec	Actually, when you have a toy project that needs a RDBMS, go ahead and use SQLite.The consensus is that relatively few applications are a good fit for MongoDB, irrespective of scale.	rch	13.5903015	-5.4761357	comment	4.0	17.0	1471276137	9.874
12291459	> Like the author, I really cannot w	"> Like the author, I really cannot wrap my head around this. While I understand that duplicating documents across collections may make querying faster, what about when you want to change the document? You need to propagate the change across every duplicate of the document in every collection where it exists. This means that any ""de-duplication"" logic needs to happen at the application level, rather than the database level.You're assuming that you need to change things. Almost all big-data approaches work better when you abandon that and go for a log-structured model where you only ever append.> I think the real issue is that ""if you have a hammer, everything looks like a nail."" Mongo and other NoSQL stores have some real use cases, but people who are more familiar with Mongo than RDBMS are"	lmm	13.620175	-5.344343	comment	4.0	23.0	1471278249	9.884126
12297676	Because Mongo is wrongly marketed as	"Because Mongo is wrongly marketed as ""all-in-one"" database.Instead it should be marketed as ""good database for dynamic data that requires complex filtering, also we have very good drivers for many languages"" because that's the only thing it's good at."	romanovcode	13.685082	-5.3249745	comment	4.0	16.0	1471357792	9.847088
12298395	"You have to separate between ""Mongo "	"You have to separate between ""Mongo the database"" and ""Mongo as it's used by companies""; the latter causes far more problems than the former.I last used MongoDB seriously in 2012-2015. We had myriad operations problems including inconsistent indexing across shards (where some shards had an index created and others didn't, it was baffling), issues with the balancer not moving chunks properly, and more. Also it's just different than other DBs with its lack of transactional consistency (I think they've made progress on building this), but that's part of why it's fast.However, the bigger problem is that document databases -- in general -- enable a kind of software development where the model sort of emerges over time, rather than being carefully designed from the beginning. Yes, it's flexible,"	eldavido	13.623099	-5.3388267	comment	4.0	14.0	1471363891	9.863
12325319	I don't say this lightly, but wasn't	I don't say this lightly, but wasn't the open source license of MySQL the main source of its success?  As I recall, it didn't really get huge until they loosened up the licensing terms. And wasn't that one of the main reasons it made $1 billion?  Not criticizing – his business is his business. Just curious.	tomcam	13.523475	-5.3448467	comment	4.0	21.0	1471669779	9.932618
12386689	Really liking CockroachDB so far.Als	Really liking CockroachDB so far.Also reading through their site, I didn't know Google's Spanner required AtomicClocks! Holy deep pockets Batman!	filereaper	13.69105	-5.19409	comment	4.0	12.0	1472519501	10.010728
12523880	Are there any legal implications for	Are there any legal implications for doing this? Was going to do something similar with Redis and MongoDB.	heydonovan	13.661498	-5.271196	comment	4.0	18.0	1474171472	9.87102
12534982	I'm wondering chow CockroachDB will 	I'm wondering chow CockroachDB will work in a distributed mesh network. I've never seen someone talk about it but how would this work out?	gravypod	13.607867	-5.219502	comment	4.0	15.0	1474321166	9.8968315
35318527	I think SQLite + WAL could be a comp	I think SQLite + WAL could be a compelling solution for game patching scenario.There are already SQLite clustering technologies that utilize WAL frame shipping in order to replicate data. I don't see why a steam patch couldn't just be a range of WAL frames to be applied to a client's database.	bob1029	13.543594	-5.4640155	comment	4.0	16.0	1679858858	9.821112
35481426	How does cockroach compares in terms	How does cockroach compares in terms of performance to manual sharded databases ?My intuition is that a properly sharded database will perform faster-or-same as a non-sharded one in all scenarios. Whereas automatically-sharded database will actually perform worst until you start reaching critical traffic that a single instance won't handle no matter what.Am i wrong ?	bsaul	13.607583	-5.219735	comment	4.0	14.0	1680874615	9.854262
35489192	It's a really neat project. I did so	It's a really neat project. I did some simple benchmarks of it and it was between 10% slower to twice as slow. Which depending on your use case isn't that bad!https://datastation.multiprocess.io/blog/2022-05-12-sqlite-i...	eatonphil	13.564576	-5.534978	comment	4.0	35.0	1680915138	9.776895
35490559	Why would you want to do this? SQLLI	Why would you want to do this? SQLLITE is so stable. Why would you switch to some port that will be dead in a year?	tetete	13.626174	-5.55889	comment	4.0	14.0	1680928364	9.857503
28017640	Yeah but a key value system lacks al	Yeah but a key value system lacks all the really good things about SQL. And locally with sqlite you don't really have to worry about latency, so you should be able to just get atomicity and consistency on the thread. This shouldn't be a lot to ask from an embedded web DB. I think as with other standards bickering, ten years from now something (Canvas API) will come out that more or less replicates the technology that was already standard ten years ago (Flash graphics), with lots of people cheering for it as if someone just invented sliced bread.	noduerme	13.588252	-5.5436935	comment	4.0	14.0	1627735678	9.84554
28044562	I thought the fact that mongodb data	I thought the fact that mongodb data files were essentially mmapped was used as a critique against its durability as a primary database. Is that not true?Or was that not a relevant critique?	atonse	13.692855	-5.311868	comment	4.0	13.0	1627951900	9.905854
28068897	Basically, if it doesn't look like a	"Basically, if it doesn't look like an INT, it won't be coerced into it.The edge case I hit was when it did look like an integer, but had leading zeroes that were important:    sqlite> create table example(a int, b text);
    sqlite> insert into example values ('00123', '00123');
    sqlite> select * from example;
    123|00123

My fault for a bunch of reasons, but still, surprised me."	banana_giraffe	13.62643	-5.6152687	comment	4.0	15.0	1628128869	9.846983
28072134	> I mean, you can still use it, but 	> I mean, you can still use it, but you have to do your own type checking/coercion in codeCan you explain why you wouldn't have to check what you're putting into the database? If you're just stuffing values of unknown type into a statically typed DB you're going to get errors up front and if you stuff values of unknown type into SQLite you might get errors down the road. Either way you probably should know what you're putting into the DB in the first place.	clnhlzmn	13.592022	-5.615203	comment	4.0	14.0	1628161864	9.855116
28076036	SQLite is an exceptional piece of so	SQLite is an exceptional piece of software as well…It’s lightweight, reliable, knows what it’s tasked for, does exactly wat it does, and easy to extend. I personally reach SQLite first in so many cases, including web backends. That the DB is a file that’s literally a cp away to backup is super-useful in development and debugging.Really the only complaint is that type enforcement is lacking… which I wish I could have said not a big deal, but it turns out it is. I wish I had a embedded DB that’s as reliable and trustful, lightful as SQLite, but with types enforced. :-(	pcr910303	13.572372	-5.5353193	comment	4.0	17.0	1628181307	9.81714
28086022	I'm curious, why postgres.app and no	I'm curious, why postgres.app and not SQLite? I'd usually reach for SQLite as my next step up from Excel, but maybe that's wrong (it's very possible that you're talking about an order of magnitude more data than I am).	easton	13.532982	-5.5219774	comment	4.0	13.0	1628251827	-12.181237
28090597	> implementations MAY dedicate a por	"> implementations MAY dedicate a portion
   of the node's most significant random bits to a pseudo-random
   machineID which helps identify UUIDs created by a given node.  This
   works to add an extra layer of collision avoidance.> This machine ID MUST be placed in the UUID proceeding [sic] the timestamp
   and sequence counter bits.  This position is selected to ensure that
   the sorting by timestamp and clock sequence is still possible.This guarantees uniqueness at a global level, as long as each machine doesn't run out of sequence counters within a given timestamp.But why must that machine ID must preceding the timestamp & sequence counter? Why not have it after? (or does ""proceeding"" has a meaning I'm not aware of? I read it as a typo for ""preceding"", but I'd assume it should be succ"	fhrow4484	13.9747	-5.2285395	comment	4.0	13.0	1628272149	-13.684313
28091332	Uuids are bulky if you store them in	Uuids are bulky if you store them in text form, but in binary form they are only 128 bits.The main feature of a uuid is it allows distributed generation.  32-bit or 64-bit integers are almost always sequential numbers.  The sequential nature allows efficient page filling and index creation, but the contention involved in creating a sequence grows rapidly with scale.So while a 128-bit uuid is larger than a 64 bit integer, this version allows for the bulk of the benefits of sequential integers while reducing the biggest drawback of contention at the point of creation.	NyxWulf	13.985444	-5.2116833	comment	4.0	13.0	1628275657	11.400676
28259975	This is nice. Very nice. But to be h	This is nice. Very nice. But to be honest, having used SQLite in many hobby/toy projects for ~15 years, I have never ever encountered a type error with it. Stricter handling of types is a good idea, IMHO, but if the alternative had been, say, a reasonable type to represent date/time values, I would have chosen the latter.	krylon	13.604914	-5.6014547	comment	4.0	16.0	1629575348	9.864328
28260479	Honestly in that case you should jus	Honestly in that case you should just use Postgres locally. SQLite was never meant to be a stand-in for a true RDBMS. As they say, it's intended to be a replacement for fopen(). The fact that it works for local development is a fluke.	zarzavat	13.580898	-5.532791	comment	4.0	25.0	1629579185	9.844725
28279392	How is Rust in regards to the SQLite	How is Rust in regards to the SQLite's requirements now?	juice_bus	13.615623	-5.6674004	comment	4.0	31.0	1629740558	9.87806
28279520	I suppose that a version of SQLite w	I suppose that a version of SQLite written in a safe(r) language will eventually appear, and hopefully become popular.But it will take a long time to mature. SQLite the project cannot switch languages, sadly. The only way to migrate is that another project would grow beside in the meantime, mature, and become a viable and compatible alternative.	nine_k	13.637575	-5.6191583	comment	4.0	43.0	1629741164	-6.6222277
28282638	Personally, I dislike UUIDs that enc	Personally, I dislike UUIDs that encode timestamps. They embed information in identifiers that look opaque, and can therefore accidentally communicate information about the history of an object that is intended to be kept secret. Much better to just use a randomly generated ID and then provide a separate timestamp, so that you can provide one without revealing the other.	jasonhansel	13.976503	-5.216186	comment	4.0	15.0	1629756675	-13.667023
28331950	"""Sharding"" ""Backups"" and ""Failovers"""	"""Sharding"" ""Backups"" and ""Failovers"" are NOT ""practical"" aspects of any database. They're theoretical. Most databases are not big enough to need sharding. Most backups go unused. Most failover happens automatically, totally managed by your hosting provider.You know what is practical? Schema design. Query language. That's what made MongoDB super popular; no schemas to worry about. A query is just '{ firstName: ""John"" }'.I cannot emphasize this enough: I cannot summon even a milliliter of desire to care about whether Mongo's way of doing these things is actually ""better"" or ""worse"". But it is what made it popular."	015a	13.563178	-5.2880187	comment	4.0	12.0	1630092226	9.818996
28404561	This is the way.My previous company 	"This is the way.My previous company had a HUGE problem with Devs cowboying off and doing whatever and dumping it on the Ops team at the last minute.One of the biggest (but for damn sure not the last) issues was a dev who designed and built an entire new product around a MongoDB database, which wasn't something we had in production, and something he didn't mention during the months of development and demos to stakeholders. Week before the launch date he hits up our Ops folks to get production set up.Ops was calm and collected about the whole thing. ""We don't have MongoDB in production. Are you volunteering to learn how to correctly install it, write monitors for alerting, be paged with issues, figure out backups and how to ensure our data stays safe, secure, and available? You're not? Then "	generalk	13.671608	-5.314357	comment	4.0	21.0	1630678798	9.890276
22315682	The mongoDB comment rings true at le	The mongoDB comment rings true at least from the pastNever heard of the OS mentioned	anon102010	13.689356	-5.330944	comment	4.0	16.0	1581574523	9.895056
22325039	I still remember interbase, now call	I still remember interbase, now called firebird. Of course, sqlite is much more prominent today for an embeded database, but for the times without sqlite...	altmind	13.552568	-5.5048795	comment	4.0	20.0	1581670718	9.830267
22369285	SQL is a standard, but SQLite doesn'	"SQL is a standard, but SQLite doesn't implement ""standard SQL"", it implements ""SQLite SQL"".For better or worse, the web has always been driven by specifications, rather than implementations. Properly standardizing all of SQLite in a spec is not trivial, and as much I think SQLite is great software, I don't think that relying on SQLite the library specifically would be a good idea. What if the latest version of SQLite does something that's not in the spec or prohibited by the spec?Either way, there's IndexedDB now, which is supported by almost everything, including IE."	Carpetsmoker	13.599137	-5.567117	comment	4.0	14.0	1582141614	9.846194
22369190	One thing that I wish more people re	One thing that I wish more people realized, especially ones developing native apps, is this: unless you really need an specific file format for your application, don't design your own. Just use SQLite. You get so much out of it (including features like undo), as well as a huge toolkit.	outworlder	13.567229	-5.5582857	comment	4.0	19.0	1582141128	9.77355
22426582	MongoDB has _suspiciously_ amazing S	MongoDB has _suspiciously_ amazing SEO and marketing. CouchDB's by contrast is awful.As silly as that sounds as a reason to choose CouchDB it demonstrates where the respective company's priorities lie.	Quarrelsome	13.639838	-5.2494435	comment	4.0	18.0	1582746573	9.718201
22734973	> Dolt is the only database with bra	"> Dolt is the only database with branchesThere's also litetree, whose slogan is simply ""SQLite with branches"":https://github.com/aergoio/litetree"	samatman	13.601035	-5.5707445	comment	4.0	16.0	1585629568	-11.823568
22757507	The moral of the story is once again	The moral of the story is once again that focusing on user acquisition at all costs is an effective strategy. MongoDB disregarded reliability, Youtube disregarded copyright, Reddit faked comments, Facebook disregarded privacy. Yet they were all ultimately successful. Could it have happened differently ? Not so sure.	fvdessen	13.695777	-5.3003826	comment	4.0	25.0	1585821239	9.906291
18992607	CockroachDB's Consistency Model	CockroachDB's Consistency Model	dilloc	13.572577	-5.2157683	story	4.0	119.0	1548361864	9.886858
19072989	I don't understand the desire to sto	I don't understand the desire to store timestamp information into a UUID. Why not just add an extra timestamp field to your data? That seems like such a simpler solution then embedding it into your UUID. I would go further and argue that embedding anything but randomness into your UUID is a bad idea that you will pay for in the future.	ch33zer	13.982698	-5.2127147	comment	4.0	12.0	1549238072	-13.659485
19159060	Wow was MongoDB really that bad?	Wow was MongoDB really that bad?	Bucephalus355	13.706271	-5.3043203	comment	4.0	23.0	1550109804	9.901658
19159080	MongoDB by default is (was? It’s bee	MongoDB by default is (was? It’s been a while since I’ve used it) schemaless, which means all of your data validation must take place in your app instead of the database. Your data integrity is then only as good as your weakest validation.Edit: scheme/schema autocorrect typos corrected. Thanks!	toomuchtodo	13.594698	-5.376022	comment	4.0	76.0	1550110072	9.871051
19499821	I’m a big fan of Mongo for the use c	I’m a big fan of Mongo for the use case you described - searching by ID and all information in one document.But people don’t seem to understand that there are plenty of scenarios where you really either don’t know the schemes in advance and/or the “schema” is defined by an external source.I worked for a company that sold software that allowed users to create forms that could be filled out either on the web or via a mobile app.The user created the form and the schema and the indexes were created on the fly - one collection per type of form. What would an RDMS have bought us?	scarface74	13.619468	-5.346555	comment	4.0	31.0	1553686382	9.867369
19738196	At some point I'll write up my notes	At some point I'll write up my notes about how I've been using MongoDB. I've basically given up on SQL databases. Every architecture, for every scale, from small to Enterprise, is really better handled by MongoDB, sometimes in conjunction with Kafka (since any sufficiently large operation is automatically heterogeneous and polyglot, with different database technologies).When you're a small startup and you're just starting up, you can create a single MongoDB instance (ignore everything about you've heard about Web Scale) and stuff data into it as needed, without thinking much about the structure. You can add in contracts on your database functions, which slowly specify the contract, as you learn more about what your project is really about. To get a sense of that style of development, pleas	lkrubner	13.627464	-5.349209	comment	4.0	20.0	1556113338	9.873584
19746038	MongoDB to acquire open-source mobil	MongoDB to acquire open-source mobile database Realm for $39M	febeling	13.595238	-5.2648053	story	4.0	38.0	1556179771	9.842769
19879777	Pick a primary key (i.e., set of col	"Pick a primary key (i.e., set of columns) for a table.  If you expose this outside the database in stable ways (e.g., in URIs), then do not permit changes to that table's rows' primary keys.There's NO NEED for a primary key to be an INTEGER or any sort of ROWID.I agree with TFA -if this is what it says- that one should not put INTEGER PRIMARY KEY values in URIs -- it's useless to users.  Just make the ""slug"" a column, make a NOT NULL and UNIQUE, disallow changes, and use that.  You don't have to make the slug a PRIMARY KEY -- NOT NULL and UNIQUE has the same semantics as PRIMARY KEY.Surely TFA wouldn't argue to have no DB key at all in URIs, so I won't bother with that possibility.  And yes, I should read TFA..."	cryptonector	13.829795	-5.2514915	comment	4.0	22.0	1557507766	-13.661863
15857225	Can anyone elaborate as to how Cockr	Can anyone elaborate as to how CockroachDB compares to Scylla? It seems to me like they're very similar on a surface level.	sempron64	13.661282	-5.218312	comment	4.0	12.0	1512516982	10.000097
15862300	This seems as good of place as any t	"This seems as good of place as any to ask novice-level questions about PostgreSQL. I teach students SQLite and one of the most massive pain points in transitioning to PgSQL is how the latter, in the `WHERE` clause, fails to recognize aliases in the `SELECT` clause, e.g.   SELECT UPPER(name) AS bigname
   FROM people
   WHERE bigname = 'JOE';

https://stackoverflow.com/questions/38040631/postgresql-does...Apparently this is the SQL standard, which PgSQL seems to do a better job of following than SQLite, but I'm at a loss to understand why this computation is particularly problematic for PgSQL (or any variant) to adopt? Unlike other SQL standard rules that PgSQL follows that SQLite/MySQL doesn't (such as forbidding the selection of column names that aren't being GROUPed by in a GROUP BY clau"	danso	13.551415	-5.551218	comment	4.0	17.0	1512577331	9.8489685
15862637	It's because the WHERE clause is eva	It's because the WHERE clause is evaluated before the SELECT. The reason that SQLite allows you to do that is because SQLite is much, much simpler than PgSQL, MySQL and SQL Server (all of which don't allow you to do this).http://tinman.cs.gsu.edu/~raj/sql/node22.html	hungerstrike	13.609967	-5.596407	comment	4.0	13.0	1512579467	9.853
16118689	Ok, I'm sceptical about the results.	Ok, I'm sceptical about the results. The reason is that there doesn't seem to be a massive difference between the tests. Since this fix is about speculative exec, why would it affect crypto code which is very register based and branchless as much as sqlite which is full of branches and memory/storage based? Why would it affect AES which is hardware accelerated as much as integer processing which is not?I'm not saying this is impossible - maybe there's something that I'm missing. But it just doesn't add up at the moment. I'd love a more detailed / repeatable test.	viraptor	13.633592	-5.612723	comment	4.0	15.0	1515615839	7.781851
17872690	Another MongoDB misconfiguration, wo	Another MongoDB misconfiguration, wow. How is it still so easy to configure mongo with no creds and an open port? Feels like these alone cause a large % of data leaks.If I was running a cloud platform of such a massive scale I'd probably scan my own ports to identify glaring problems like this one. Kind of surprising that isn't happening considering how bad it is to have the brand associated with a report like this.	uses	13.707525	-5.302484	comment	4.0	24.0	1535582286	9.932688
17951181	Why not use SQLite directly instead 	Why not use SQLite directly instead of this extra layer?	bufferoverflow	13.616249	-5.5789785	comment	4.0	21.0	1536581617	9.855949
17966070	Surprisingly SQLite does actually em	Surprisingly SQLite does actually embrace formal methods in various places.Such as, in their draft goals [0], under S30200, they outline a memory allocator goal by referring to a proof.Though, if the parents goal was to imply that the whole of SQLite should be verified... I'm not convinced its entirely possible. Quite a lot of SQLite revolves around things around where the halting problem may come into play.[0] http://www.sqlite.org/draft/sysreq.html	shakna	13.631243	-5.6067634	comment	4.0	14.0	1536734493	9.854758
18180367	> why no run your own DB?Running you	> why no run your own DB?Running your own DB introduces tons of risk that just isn't worth saving a couple bucks (until you're at the scale that it is).> That said, Mongo is a poor choice for any app ever written.Sorry, that just isn't true. It works great for us, and is the 4th most popular database by usage (and growing). https://insights.stackoverflow.com/survey/2018#technology-da...	a13n	13.629349	-5.3363466	comment	4.0	14.0	1539124110	9.849878
18229682	I had the feeling that AWS and Azure	I had the feeling that AWS and Azure are pushing their own NoSQL solutions and don't care much about MongoDB.	k__	13.603066	-5.229099	comment	4.0	28.0	1539700493	9.889691
18273696	"First, 
I never knew SQLLite was qui"	"First, 
I never knew SQLLite was quite so religious,Second
69. Love your juniors.
Really? Won't HR get involved?"	LawnDart1	13.661629	-5.5985856	comment	4.0	12.0	1540207172	-8.604459
18274457	The SQLite folks are saying that cod	The SQLite folks are saying that code of conducts are irrelevant. Hence, they are saying that the problems solved by CoCs do not exists, or are not problems.This is a disgusting move and we need to make sure to react appropriately by not using sqlite and fossil and other software these people created.	julian-klode	13.641316	-5.5942903	comment	4.0	17.0	1540215056	9.862585
18294772	If you have a relatively small set o	"If you have a relatively small set of users, setting up your own database is usually as simple as setting it up locally and you won't need shards or anything. And setting up backups is as simple as adding a cron job that calls your backup shell script, which you can test separately. And by ""small set of users"", consider what SQLite's own website[1] says:    Generally speaking, any site that gets fewer than 100K
    hits/day should work fine with SQLite. The 100K hits/day
    figure is a conservative estimate, not a hard upper bound.
    SQLite has been demonstrated to work with 10 times that
    amount of traffic.

If SQLite is able to comfortably handle 100k hits/day, I imagine that more ""legitimate"" databases can handle more traffic comfortably without needing to jump to scale horizontal"	sdegutis	13.591074	-5.5245085	comment	4.0	15.0	1540403842	9.791452
18419216	The problem with noSQL is that there	The problem with noSQL is that there are too many players out there making duplicated efforts. You have MySQL & MariaDB and PostgreSQL as the two main SQL platforms, but you have too may to list in the noSQL field- most of them providing the same amount of functionality.	lykr0n	13.538814	-5.4599266	comment	4.0	23.0	1541810521	9.811692
18503236	Identifying Unused Indexes in MongoD	Identifying Unused Indexes in MongoDB	LoriP	13.612601	-5.3670473	story	4.0	35.0	1542813170	9.837526
18504773	Hah, no we didn't use Mongo at all. 	Hah, no we didn't use Mongo at all. It was just the lie.	isoskeles	13.704909	-5.312546	comment	4.0	15.0	1542824426	-10.042449
18568502	MondriPong	MondriPong	caiobegotti	13.747097	-5.2728043	story	4.0	24.0	1543579813	9.836732
18582588	Does anyone know a comparison betwee	Does anyone know a comparison between this and CockroachDB? Or have experience running either in production?They seem to compare against other databases, but not against Cockroach which seems to be the biggest competitor. I'm looking at implementing a global-scale database cluster with very specific requirements, and YugaByte seems to meet those but a comparison against CockroachDB seems warranted.Edit: just noticed they do compare features against CockroachDB: https://docs.yugabyte.com/latest/comparisons/#distributed-sq..., but they don't have an in-depth comparison.	lukeqsee	13.592923	-5.215447	comment	4.0	16.0	1543763314	9.879383
18611891	One thing Postgres definitely doesn'	One thing Postgres definitely doesn't do, and I wish it did, is embedded. This is usually the place that people use SQLite, for example, apps that are clients, but still need to do substantial work on the client side.The problem is, SQLite does have a few limitations that it doesn't make obvious: some of the more complex SQL syntax that Postgres supports are missing, but more importantly, it can only ever do one write or read to the database predictably. (Don't believe me? Try this: https://gist.github.com/mrnugget/0eda3b2b53a70fa4a894)I know that SQLite supports concurrent writes and reads technically, but it predictably leads to 'database is locked' issues. In practice you have to use it in a fashion that it only ever does one thing, read, or write. No multiple writes. No single write an	rolleiflex	13.569293	-5.4870734	comment	4.0	17.0	1544040206	9.801042
18618984	ArangoDB 3.4 GA Release: Full-Text S	ArangoDB 3.4 GA Release: Full-Text Search, GeoJSON, Streaming and More	rubbercasing	13.633012	-5.2796	story	4.0	30.0	1544111262	9.934998
18685566	Python ships with a sqlite3 module i	Python ships with a sqlite3 module in the standard library.Does this mean Python needs to ship a security path? What should Python users be doing about this?	simonw	13.601702	-5.612421	comment	4.0	15.0	1544827342	9.843094
18718953	While we are here. I know HN hates m	While we are here. I know HN hates mongo.But lemme ask this question, what are the things in which mongo is better than postgres?	InGodsName	13.638508	-5.365109	comment	4.0	24.0	1545249564	9.890703
18755444	> Single-File Documents. An SQLite d	"> Single-File Documents. An SQLite database is contained in a single file, which is easily copied or moved or attached. The ""document"" metaphor is preserved.Is this still true by default? With write-ahead (wal) and shared memory (shm) enabled, it is no longer safe to consider only the database file. Pragmas exist to disable those, but people should be familiar of these features and use with care. The document should be updated to introduce these concepts."	LeoNatan25	13.558917	-5.5542645	comment	4.0	14.0	1545703950	9.77652
18771765	What problem does this solve? Why is	What problem does this solve? Why is it necessary to sort a unique id?	Kip9000	13.887478	-5.2542195	comment	4.0	14.0	1545938323	-13.661195
18873082	> They are not advertising their rep	> They are not advertising their replacement as MongoDB, either.I don't really agree there. The service is called documentDB and this is how they describe it [1]:> Amazon DocumentDB (with MongoDB compatibility)> Fast, scalable, highly available MongoDB-compatible databaseAnd the first 2 sentences:> Amazon DocumentDB (with MongoDB compatibility) is a fast, scalable, highly available, and fully managed document database service that supports MongoDB workloads.> Customers use MongoDB as a document database to store, retrieve ...You have to read all of that pretty carefully to understand that it's NOT MongoDB (a term they mention 5 times in the first 4 sentences). And if you read it carefully it seems to say it's compatible with MongoDB, whereas the Techcrunch article states it's only compatib	askmike	13.655211	-5.2239017	comment	4.0	18.0	1547119276	9.8814535
18871612	It's mongodb though... It's well doc	It's mongodb though... It's well documented at this point you shouldn't be using mongo on anything that matters	exabrial	13.692419	-5.327912	comment	4.0	21.0	1547095752	9.87856
18926494	Making mistakes means the author del	Making mistakes means the author delivered a lot of features to users that they wouldn’t have otherwise.RethinkDB sounds terrifying though, I’d hate for my DB errors in production to literally have no idea what to do, it makes me feel sick thinking about :-)I think we should aim for kludgy but boring working solutions first - for example I’m tempted to write a redux middleware that sends dispatched actions to the server and manually sync, order and manage conflicts in these events to build a “perfect” system where front end state management and backend CQRS perfectly marry up. It’s a terrible idea because I know how to build the Podcast app I’m making perfectly well without any of this nonsense.	andy_ppp	13.64243	-5.2872705	comment	4.0	29.0	1547680160	-12.803806
29728586	I don't know what backup tools you h	I don't know what backup tools you have in mind... But since a SQLite database is a single file (modulo write ahead journal and whatnot), making whatever you need is trivial.	lrem	13.598242	-5.511591	comment	4.0	17.0	1640804684	-1.9025141
29737382	ELI5, why do people still choose to 	ELI5, why do people still choose to use mongo?	dblooman	13.691491	-5.313424	comment	4.0	12.0	1640877542	9.927611
29759308	So.. are database IDs numbers? Becau	So.. are database IDs numbers? Because they sure are autoincrement integers in almost every DBMS. I always thought that was a mistake but it's practical.	NelsonMinar	13.86638	-5.2240286	comment	4.0	15.0	1641051485	-13.6273775
29809807	The whole section on serial number I	The whole section on serial number IDs is a bit FUDy in my opinion, especially this:> If you suddenly have a million people who want to buy things on your store, you can't ask them to wait because your sequence generator can't number their order line items fast enough. And because a sequence must store each number to disk before giving it out, your entire system is bottle-necked by the speed of rewriting a number on one SSD or hard disk — no matter how many servers you have.There’s maybe a handful of apps in the world that see so much traffic that this would be a problem. Unless you expect to reach Amazon-scale anytime soon, or need distributed ID generation (like generating them in mobile apps or SPAs), just starting with a simple BIGSERIAL (or rather, BIGINT GENERATED BY DEFAULT AS IDENT	mikl	13.966254	-5.2057953	comment	4.0	14.0	1641395037	-13.62637
29850179	Interestingly, for other systems you	Interestingly, for other systems you sometimes want the exact opposite: for your key space to be distributed across indexes to balance the load (vs wanting them all to hit the same “hot” index for MySQL).For example, Google’s Cloud Firestore is bottlenecked to 500 writes/second if your key is monotonically increasing (like a timestamp or these timestamp-based UUIDs) causing you to “hotspot” the index: https://cloud.google.com/datastore/docs/best-practices#high_...	yeldarb	13.531964	-5.2405367	comment	4.0	24.0	1641636134	-13.654353
29851297	"""Bad for performance as primary keys"	"""Bad for performance as primary keys"" -> ""Bad for performance as primary keys in MySQL"".  This isn't an issue in PostgreSQL and perhaps the lesson here is that as you scale, you need to understand more about the internals of the DB system you've chosen.  This isn't limited to RDBMS as it's pretty easy to show trade-offs in choosing a NoSQL as well."	smoyer	13.556282	-5.360513	comment	4.0	15.0	1641647286	9.807198
29850110	As far as I can gather from this pos	"As far as I can gather from this post and looking at the data type documentation, MySQL does not have a specific UUID type, but Postgres does.[0]  I'll assume that Postgres has some internal optimisations to UUID that MySQL thus lacks.Addendum: I also realise this is anecdotal, but someone on Stackoverflow mentions a significant speed up from changing `text` to `uuid` in Postgres.[1]  But this also fits with what I've been told on #postgresql on libera.chat.  That being said, integers would still outperform uuid.[0] https://www.postgresql.org/docs/14/datatype-uuid.html
[1] https://stackoverflow.com/questions/29880083/postgresql-uuid..."	Svip	13.974288	-5.2182474	comment	4.0	21.0	1641634995	-13.664857
29898713	"Yes, when I said  ""production databa"	"Yes, when I said  ""production database"" I meant a database for a web application.  My iPhone running SQLite doesn't relate to Web 3.0."	luhn	13.662661	-5.5849705	comment	4.0	21.0	1641938503	9.843388
29989438	"> ""The author's obvious preference f"	"> ""The author's obvious preference for subjective ethics""I doubt this interpretation, given SQLite's Code of Ethics (https://sqlite.org/codeofethics.html). Abrahamic faiths and subjective ethics don't go well together; ""I am the way, the  truth, and the life"" doesn't leave much room for alternatives."	Georgelemental	13.673904	-5.595792	comment	4.0	36.0	1642561595	-0.9095818
30073410	A long these lines if you're looking	"A long these lines if you're looking for a way to sync your SQLite DB to an S3 like object store there is https://litestream.io/. 
It creates a snapshot of your DB on s3 and then handles checkpointing of the WAL."	quadrature	13.544634	-5.4316363	comment	4.0	14.0	1643126771	9.755216
30080219	Ask HN: What do you use SQLite for?	Ask HN: What do you use SQLite for?	spacesarebetter	13.605346	-5.567493	story	4.0	8.0	1643157857	9.859779
30161115	You could potentially keep a website	"You could potentially keep a website ""on a bookshelf at home"" as well, provided the database is small enough.  It doesn't even need to be SQLite.  No matter the data format, you could get a fully running website on a raspberry pi, maybe with a subset of the data.I'm picturing a bookshelf of raspberry pis in custom ""boxes"" like a collection of 8-tracks.  Pull one out, plug it it, turn it on, and connect to it.Considering the majority of my 20 year web-building career is long gone, this idea kind of intrigues me."	enobrev	13.58749	-5.555356	comment	4.0	19.0	1643714412	9.81968
30172241	EIDs (Encoded IDs)	EIDs (Encoded IDs)	brandur	13.946468	-5.185327	story	4.0	14.0	1643764644	-13.581788
30369095	We way over complicate things.SQLite	We way over complicate things.SQLite can be used for 95% of real world use cases.And whenever WAL2 + BEGIN CONCURRENT get merged into main, it will be able to handle 99% use cases.And don’t fool yourself into believing you’re not in that 1%.	alberth	13.620403	-5.4902487	comment	4.0	39.0	1645067284	9.819686
30400648	Squeezing Performance from SQLite: E	Squeezing Performance from SQLite: EXPLAINing the Virtual Machine	thunderbong	13.539735	-5.5351114	story	4.0	109.0	1645305686	9.822633
30438975	I don't get this, as far as I unders	I don't get this, as far as I understand there is no reason at all to use a string column for a UUID. Your primary keys are important for performance and extremely important for integrity. Making them slower and less robust by using a string column just doesn't make any sense, why would you ever do that?UUIDs are binary data, they should be stored as such.	fabian2k	13.983725	-5.2179437	comment	4.0	13.0	1645605047	-13.660726
30637326	This is just sql in json, I prefer m	This is just sql in json, I prefer mapping SQL semantics onto HTTP semantics like postgrest does. Not aware of any project that does that for sqlite.	SahAssar	13.564786	-5.5773764	comment	4.0	15.0	1646984370	9.802104
30644918	For Anyone with experience with Foun	"For Anyone with experience with FoundationDB!
How does it compare to CockroachDB ?"	skyde	13.559834	-5.2437434	comment	4.0	47.0	1647027202	9.925609
16194894	No primary/unique keys on the partit	No primary/unique keys on the partition table and only on the partitions still seems like a common dealbreaker.	da_chicken	13.785825	-5.2549887	comment	4.0	27.0	1516475849	-13.666953
16231971	Simpler than a log file? What's the 	Simpler than a log file? What's the significant advantage of SQLite vs just appending to a file?	creeble	13.5617	-5.5516624	comment	4.0	16.0	1516897518	9.667801
16233023	I looked into SQLite a while ago, an	I looked into SQLite a while ago, and it wasn't so much its robustness that was the deal-breaker, but more the fact that it couldn't handle writes from parallel processes from multiple users (i.e. concurrency) like a normal SQL database could.I see SQLite as a file-format with a SQL interface.	wenc	13.55194	-5.5348	comment	4.0	17.0	1516903916	9.789059
16309891	When I learned one thing about colla	"When I learned one thing about collaborative apps, it's that there is no automerge that works for all use-cases.Couchdb does it the right way, it simply keeps all versions and lets the application logic decide which is the ""one true state""."	k__	13.587231	-5.2027774	comment	4.0	19.0	1517848589	9.653586
16330215	My problem with CockroachDB comes do	My problem with CockroachDB comes down to two major issues:1. I need a read slave. With MariaDB Galera, I can slave a database of a local master, but Cockroach AFAIK can only do master master. Adding another node to a cluster that will just be read from seems like a lot of unneeded overhead, and can cause massive issues if there are sync issues.2. WAN sucks. Where I work, I've seen mysql slaves get hours out of sync due to packet loss. With a centralized system, I don't have to worry about reconciling data. If every site can accept data, then I have to assume that every site will remain in sync. If Site 1 gets out of sync and/or stops transmitting data, another site could make further changes to the record in question causing issues. Some places this is perfectly fine, but dealing with tra	lykr0n	13.557043	-5.2026634	comment	4.0	15.0	1518064687	9.817852
16358303	Well, actually it is very simple whe	Well, actually it is very simple when you understand the why SQLite performs differently than other database systems. The major difference is that 'normal' database systems have a process which receives and processes SQL queries and has the exclusive access to the database file.SQlite on the other hand doesn't have such a process so, every client has to open the database file itself, process the SQL and close/write the file again.So the biggest difference is, that if you want to use SQLite, you will have to limit your database operation to one or fewer ;-) processes to not get into a situation where one process has to wait until the other finished writing the database file to the filesystem just to read it again in the next moment. Otherwise your filesystem and the continuing reading and w	JepZ	13.587628	-5.5345974	comment	4.0	18.0	1518440441	9.766186
16359075	What would be a bottleneck / limit f	What would be a bottleneck / limit for SQLite? If you have to many SELECT query because your site is too busy, what would happen?	neals	13.57934	-5.532199	comment	4.0	13.0	1518448519	9.843222
16384884	I beg to differ. (Disclosure: I work	I beg to differ. (Disclosure: I work for MongoDB.) Using JSON as your data model, rather than relational tables, lets you build different applications that don't need multi-document transactions as often, because the data is already together in a single document. But when you do need multi-document transactions (a small percentage of applications do, and only few use cases inside those applications), they are now available. There is no speed impact on cases when you don't use them. And most of the time, you shouldn't use them, otherwise you wouldn't be capitalizing on the advantages of JSON. I think that's a game changer, but then again: I do work for MongoDB.	drmirror	13.56757	-5.420373	comment	4.0	32.0	1518709399	9.850623
16385683	If you're playing the long game and 	If you're playing the long game and not looking to make a profit that's fine, but PostgreSQL as a company would have been doomed a long time ago. You have to keep in mind the timelines of the business and what they need to do to keep the lights on.MongoDB has identified a real pain point: many developers don't like to use SQL to interface with a transactional database. I'm not going into the merits of SQL vs. NoSQL, I'm just stating that it's clear there's a need or they wouldn't have gotten any traction.Now they are maturing the product to the point it might be a safe bet for some use cases, it remains to be seen if their approach to product development will pay dividends or the reputation they have created for themselves has created a time bomb that will eventually kill them.	luckydata	13.615483	-5.3356695	comment	4.0	21.0	1518714880	9.870141
16386934	It's probably better to go with Cock	It's probably better to go with Cockroach or TiDB. RethinkDB has problems of its own.	SamReidHughes	13.64143	-5.224228	comment	4.0	14.0	1518724093	9.929316
16441367	CockroachDB fares well on the distri	CockroachDB fares well on the distributed side of the spectrum, and thus shows all the best properties of this kind of systems: replication, resiliency, horizontal scalability, modern ops experience.This is no small feat, and - personally - I am sold on it. Yet, looking at its benchmarks (pre 2.0), and knowing how carelessly some enterprise software is written, how would I convince a pointy haired boss to leave the practically monolithic mega-pumped Oracle RAC server he is accustomed to, and go down the distributed route?	muxator	13.557661	-5.2100353	comment	4.0	20.0	1519333410	9.859707
16579986	How to Corrupt an SQLite Database Fi	How to Corrupt an SQLite Database File	jeffreyrogers	13.582546	-5.5927825	story	4.0	104.0	1520976473	9.813553
16619080	Just because SQLite's API is synchro	"Just because SQLite's API is synchronous does not mean that it must block the node process. libuv manages a thread pool, which node uses to offload sync APIs and let the main event loop run. This is described here under ""What code runs on the Worker Pool"": https://nodejs.org/en/docs/guides/dont-block-the-event-loop/"	zbjornson	13.567296	-5.566809	comment	4.0	20.0	1521473146	9.696197
16709516	Using it in production currently wit	Using it in production currently with dual-write and dual-read to compare perf. I'll do a write-up showing how Cockroach performs to Citus and Cassandra for my use case.	welder	13.608043	-5.2351146	comment	4.0	26.0	1522347363	9.867733
16709630	We use Citus and Memsql (big data an	We use Citus and Memsql (big data analytics use cases). How does Cockroach handle joins and other OLAP style queries?	qeternity	13.608173	-5.24331	comment	4.0	22.0	1522347859	-10.798738
16711350	Project idea: globally hosted / mana	Project idea: globally hosted / managed CockroachDB that lets developers quickly start building small apps cheaply or free using this database.This database has the potential to dethrone Spanner in a major way.	etaioinshrdlu	13.648694	-5.210056	comment	4.0	18.0	1522359935	9.889808
16713995	There are two versions, one with SQL	There are two versions, one with SQLite built in. The choice of TCL is super interesting given its pedigree and could easily bring TCL back from its quiescent state.	tomcam	13.60075	-5.576156	comment	4.0	17.0	1522389148	9.862333
16781447	But it is SQLite under the covers? A	But it is SQLite under the covers? A better title then would be an SQLite wrapper for use in shell pipelines.	gaius	13.611679	-5.60693	comment	4.0	18.0	1523118939	-0.46104023
16806264	It's funny that they don't list the 	It's funny that they don't list the real reason, which is that Fossil is built on top of SQLite and they want to dogfood it.	monocasa	13.597411	-5.5782785	comment	4.0	109.0	1523400119	9.734189
16853445	"Add ""help avoid sending teenagers to"	"Add ""help avoid sending teenagers to prison"" to the list of reasons why you should prefer UUIDs over integers in your Internet-facing REST API.This API was supposed to be private and yet supported trivial enumeration?"	politician	13.985178	-5.208711	comment	4.0	32.0	1523917811	-13.66233
16873611	  This is how my intuition went: it'	"  This is how my intuition went: it's probably less than 128 
  bits because UUIDs are 128 bits, and they're universally 
  unique.

But what's in a name? There's no natural law constraining the UUID standard, such that they must be actually universally unique. And 128 bits isn't such an incredible bit space.MD5 hashes are 128 bits, and prone to manipulating in favor of collisions.Don't get me wrong, 3.402823669209385*10^38 is a huge number, and we haven't used enough passwords to occupy every value in that key space, but I still don't imagine 128 bits provides truly universally unique coverage, but really just pretty okay uniqueness coverage."	replicatfied	13.984586	-5.209673	comment	4.0	17.0	1524117099	11.509312
16996055	Could somebody clarify the license? 	"Could somebody clarify the license? I was excited this was Open Source, but then some people say you are only allowed to run it on MacOS? How can that be?Also, how does FoundationDB compare (in general, and in performance) to:- CockroachDB (competitor) https://www.cockroachlabs.com/blog/2-dot-0-perf-strides/- Redis (competitor) https://redis.io/topics/benchmarks- GUN (ours) https://github.com/amark/gun/wiki/100000-ops-sec-in-IE6-on-2...- Fauna (competitor) https://fauna.com/enterprise#Scalability- VoltDB (competitor) <a href=""https://www.voltdb.com/blog/2017/10/02/comparing-fast-data-performance-a-comparison-of-voltdb-and-cassandra-benchm"	marknadal	13.527213	-5.214499	comment	4.0	16.0	1525452801	-9.692992
16996519	We use SQLite in an app with about 1	"We use SQLite in an app with about 1,000 active users. It took us:- 0h to manage backups (""cp""),- 0h to manage seeds and tests fixtures (""cp""),- 0h to configure and secure (void),- 0h to write the deployment scripts (void),- 0h monitoring/watchdog jobs (void),- 1h to rsync for failover (""rsync"")My last projects always spent at least a good 100h to do all of this the right way. Then, if it is not good enough, we'll move to RDS or equivalent."	batmansmk	13.5726385	-5.496742	comment	4.0	29.0	1525455702	9.764501
16996831	FYI: SQLite doesn't have ALTER TABLE	FYI: SQLite doesn't have ALTER TABLE.	captain_perl	13.604009	-5.590496	comment	4.0	12.0	1525457617	9.883715
17027466	Ask HN: GUID, int, or both for prima	Ask HN: GUID, int, or both for primary key?	Fsp2WFuH	13.944447	-5.224205	story	4.0	5.0	1525841317	-13.644813
17042573	This is great!  Given that SQLite is	This is great!  Given that SQLite is generally used for small projects and not in any sort of cluster or HA environment, pushing this kind of work (the if/then/else block that you don't have to write in your code anymore) makes a ton of sense.I actually like this feature more in SQLite than in Postgres.  In Postgres I worry about pushing that kind of work into the database in clustered situations, as there are places where it can go wrong and it would be more likely that the code wouldn't be able to handle that failure properly (as opposed to having to write the if/then/else yourself, which if you're a good coder would also involve some try/catch and proper fallback behavior in case of an error).	jedberg	13.562465	-5.512701	comment	4.0	48.0	1525983455	9.784278
17115649	CouchDB. It's rare that a piece of s	CouchDB. It's rare that a piece of software is bad enough to give its language and runtime a bad name, but it's actually that bad.	facetube	13.606763	-5.206249	comment	4.0	46.0	1526866025	-4.673982
17135520	uuid's aren't guaranteed to be uniqu	uuid's aren't guaranteed to be unique at generation, there is still a non-zero chance of it having a collision.  using it as a primary key to be generated by the database helps mitigate that, as there will normally be a uniqueness clause on the index.creating that uuid on the client likely will not accomplish what you're hoping.	jerrysievert	13.985288	-5.214599	comment	4.0	23.0	1527093378	-13.659808
17272574	I am seeing SQLite pop up more and m	I am seeing SQLite pop up more and more in articles that tout its effectiveness and simplicity for many use cases over popular alternatives like PostgreSQL. It has definitely persuaded me to consider it on future projects.	hellofunk	13.589401	-5.5625606	comment	4.0	25.0	1528545166	9.847257
22835986	I can’t address MongoDB, but nosql v	I can’t address MongoDB, but nosql vs relational generally, there are two reasons:(1) what’s faster than a fast join? No join. With nosql you have more flexibility to store the data organized in the same way it is accessed. You don’t need to join to another table if the data your app needs is already directly part of the main data the app requests. You do need to understand your access patterns well, and develop migration plans when they change.(2) scalability. nosql databases generally let you scale horizontally more easily/gracefully than relational databases, though there are trade offs.Put it together and you get performance at scale, though you generally need to understand your data access patterns and usually need to be more resilient to inconsistencies.	jmull	13.568722	-5.377097	comment	4.0	17.0	1586543573	9.798857
22840355	AES-based Synthetic IDs: determinist	AES-based Synthetic IDs: deterministic AE for 64-bit integers	beefhash	13.979438	-5.1894855	story	4.0	64.0	1586592524	-13.655781
22869143	I stumbled across Druid (with supers	I stumbled across Druid (with superset) and it looks great but has a really low profile, even though it is in a hot area. Does anyone actually use it?	rb808	13.884776	-5.188367	comment	4.0	13.0	1586886874	-13.665693
23153315	CockroachDB 20.1	CockroachDB 20.1	dilloc	13.697211	-5.213192	story	4.0	127.0	1589287431	10.049644
23270767	MongoDB is a pretty good database IM	MongoDB is a pretty good database IMO. I've used it at several companies in the past and wouldn't mind using it again.My favorite DB is RethinkDB. It's a shame that the company behind it fizzled out and was absorbed by Stripe. I still cannot wrap my mind around why it's not more popular. It's similar to MongoDB but much better. It's the perfect database. It adds constraints which improve the quality of your code. Also RethinkDB scales very well and the control panel that comes with it is mind-bendingly powerful, I'm not kidding; you can click a button to shard or replicate a table over multiple hosts! WTF! I can't say the same about Postgres unfortunately. There is nothing truly remarkable about it.I use Postgres for one of my projects today but purely because of compatibility reasons with	jondubois	13.548739	-5.331278	comment	4.0	29.0	1590145580	9.823207
23271085	Yes. We have applications running on	Yes. We have applications running on both PostgreSQL and MongoDB and I find that working with MongoDB is just more pleasant. I think it mostly boils down to my preference of document databases as opposed to relational ones. It feels much more natural to me to embed / nest certain properties within a document instead of spreading it across several tables and then joining everything together to get the complete data. MongoDB makes working with these sometimes nested documents easy (I mean, it better) and there's always Aggregation Pipeline when you need it (something that I again find much more pleasant and readable over SQL).What always irks me is when somebody suggests PostgreSQL's json (or jsonb) types as an alternative to using MongoDB. All it's saying is that the person hasn't really in	jiripospisil	13.600766	-5.406442	comment	4.0	14.0	1590148169	9.851748
23272148	Yes.If we were going to start from s	"Yes.If we were going to start from scratch today, we'd probably use Postgres. But, realistically, the primary motivation behind that decision would be because Postgres is available on AWS, and that would centralize more of our operations. (DocumentDB is, of course available. Its not Mongo. I'd be curious to hear from people who actually had Mongo deployments and were able to move to DocumentDB; its missing so many of MongoDB's APIs that we physically can't, our applications would not run).Mongo isn't that bad. It has limitations. You work within the limitations... or you don't. But I really don't think a valid option is ""mongodb fuckin sucks m8, shit tier db"". We're not going to be migrating terabytes of data and tens of thousands of lines of code when the benefit is tenuous for our busine"	013a	13.653366	-5.2975254	comment	4.0	22.0	1590156213	9.872437
23286019	"The joke I learned early on: ""Migrat"	"The joke I learned early on: ""Migrating away from Mongo is trivial: wait long enough, and all your data will be gone anyway.""I imagine things are better now."	macintux	13.670405	-5.316308	comment	4.0	20.0	1590265134	9.90693
23288102	Firstly let me point out that this r	Firstly let me point out that this response is neither intended as a defence of MongoDB defaults which are atrocious, or of the company, who are arguably duplicitous.However I can _quite easily_ see how a non-native English speaker could use the phrase “if you know what you are doing” to mean “if you are careful”.	jen20	13.694622	-5.316514	comment	4.0	31.0	1590281571	1.9033352
23289874	Just imagine that SQLite is written 	"Just imagine that SQLite is written in C and the major of bugs are logical/optimization ones, not related to memory management.And when talking about C++, since 2011 there are smart pointers to help developers managing memory kind of automatically.I believe most of the problems are due the people typing on those keyboards such bad code, especially when it comes to ""smart"" code.In 2020 we have plenty of tools supporting the developer job (memory sanitizers, static analysis tools, linting, profilers, etc.): The big problem is failing to / ignoring to use such tools."	mister_hn	13.614654	-5.623474	comment	4.0	19.0	1590306149	9.793096
23291232	I am tech lead for a project that re	I am tech lead for a project that revolves around multiple terabytes of trading data for one of top ten largest banks in the world. My team has three, 3-node, 3TB per node MongoDB clusters where we keep huge amount of documents (mostly immutable 1kB to 10kB in size).Majority write/read concern is exactly so that you don't loose data and don't observe stuff that is going to be rolled back. It is important to understand this fact when you evaluate MongoDB for your solution. That it comes with additional downsides is hardly a surprise, otherwise there would be no reason to specify anything else than majority.You just can't test lower levels of guarantees and then complain you did not get what higher levels of guarantees were designed to provide.It is also obvious, when you use majority concer	lmilcin	13.632853	-5.2817616	comment	4.0	38.0	1590325733	9.893847
23292368	At this point I think we might be go	"At this point I think we might be going a bit overboard with title changes.Now that it's just ""MongoDB 4.2.6"", the title makes me think that this is a release announcement, not an analysis of the software.The first title (that specifically referenced a finding of the analysis) was best, imo. Mildly opinionated or whatever, but at least it quickly communicated the gist of the post. On the other hand:""Jepsen: MongoDB 4.2.6"" – not super helpful if you're not already familiar with the Jepsen body of work.""MongoDB 4.2.6"" – as stated above, sounds like a release announcement.If you want a suggestion, maybe something like ""Jepsen evaluation of MongoDB 4.2.6""? Not overly specific (/ negative) like the first title, but at least provides some slight amount of context.@dang"	fastball	13.706441	-5.318247	comment	4.0	27.0	1590335651	9.9526825
23326349	Absolutely amazed that MongoDB is th	Absolutely amazed that MongoDB is the most wanted database at 19.4%, and is less dreaded than MySQL. What is their marketing team doing that's so effective?	shay_ker	13.728475	-5.28114	comment	4.0	35.0	1590599135	9.921447
23358803	SQLite is a much younger project tha	SQLite is a much younger project than I thought it was. Given the ubiquity, and capabilities that it provides, it's impressive. On the other hand, Linux and Python are 29 years old.Postgres, in its current form is ~23 years old. It started in the 1980s.	sargun	13.565292	-5.5018363	comment	4.0	12.0	1590817620	9.861366
23358863	Where can you use SQLite?Embedded Sy	Where can you use SQLite?Embedded Systems: YesRaspberry Pi    : YesMobile Apps.    : YesDesktop Apps    : YesBrowsers         : NoServers         : YesSupercomputers  : Yes	me551ah	13.600674	-5.5706797	comment	4.0	19.0	1590818324	9.846451
23358930	One of the notable aspects of SQLite	One of the notable aspects of SQLite as a open source project is being open source but not open-contribution. drh put it in public domain, and doesn’t accept outside contributions to prevent it from being contaminated in any way. In an open source landscape where bazaar seems to have mostly won, SQLite remains one of the (last?) cathedral strongholds, and serves as a good reminder to aggressive contributors that open source maintainers don’t have to accept or even consider  their PRs.https://sqlite.org/copyright.html	oefrha	13.631962	-5.574438	comment	4.0	15.0	1590819188	9.8556185
37734500	I'm a fan of Cuid2[1] for this reaso	I'm a fan of Cuid2[1] for this reason.They are compact, don't leak information, and make a good case why k-sortable IDs are unnecessary, or even harmful for performance.I'm using sequential integers and created_at/updated_at timestamps for internal use, and Cuid2 IDs externally.[1]: https://github.com/paralleldrive/cuid2	imiric	13.928632	-5.239337	comment	4.0	20.0	1696226703	-13.672734
37734624	You can make bad technology choices 	You can make bad technology choices today.For example, if you were using Typescript to build a mobile app, you might be tempted to use TypeORM (32k stars on GitHub, been around since 2016, widely used). If you wanted to also use transactions and concurrency then this would be a mistake, because you would quickly find that TypeORM's SQLite adapter doesn't have a connection pool or locking for transactions, and will happily execute statements inside a transaction then roll them back without your knowledge.	strken	13.629185	-5.586534	comment	4.0	13.0	1696228053	9.829502
37736257	Having sequential ID's is more than 	Having sequential ID's is more than just a security risk, it's an information risk. Competitors can use them to estimate the size of your business, the number of customers you have, and all sorts of stuff.This was used in the war to estimate the number of German tanks based on the sequential IDshttps://en.wikipedia.org/wiki/German_tank_problemSo just for business intelligence you don't want to leak your IDs.	dalore	13.939305	-5.2032285	comment	4.0	25.0	1696242083	-13.6095705
37737498	Is there some reason new versions of	Is there some reason new versions of UUID keep appearing? It seems like the desired properties are never quite achieved so new ones appear later. Is there a table with UUID version across the top and characteristics down the side, so I can see the differences and pick one that fits my needs? That might also help to explain why there are so many variants.	phkahler	13.990773	-5.2132373	comment	4.0	26.0	1696251559	-13.668877
37770660	What’s the case against cgo for SQLi	What’s the case against cgo for SQLite? Just the usual cgo performance overhead?It seems like a pretty good cgo use case: a decent amount of work, which is typically slow enough that cgo overhead isn’t perf critical (because DB usually means disk reads), a super robust and well tested C library with a super well maintained cgo wrapper (mattn).	scosman	13.599238	-5.570202	comment	4.0	42.0	1696448985	9.914323
37862532	Stark-DB: SQLite-backed, change-trac	Stark-DB: SQLite-backed, change-tracking database available over HTTP	thunderbong	13.541701	-5.485437	story	4.0	53.0	1697141387	9.792198
38037966	SQLite is an awesome tool, but I wis	SQLite is an awesome tool, but I wish we’d stop trying to force it into situations it wasn’t made for. It doesn’t belong anywhere near a web app deployment that currently or will span two or more machines. Once you have a “distributed system” and the complexities of a DR scenario, reach for a tool that was built for such. You can’t go wrong with PG/MySQL. You can go very wrong with a VC-hyped replicated file system from a company known for outages.	beoberha	13.549093	-5.499351	comment	4.0	22.0	1698412289	9.800671
25463393	Can you elaborate about this? What a	Can you elaborate about this? What are the gotchas when opening an untrusted SQLite3 database?(I am developing a web application that will allow users to upload application files, which are SQLite3 databases)	remram	13.602404	-5.5699987	comment	4.0	12.0	1608261232	9.851555
25463591	You’d think so from reading [1]. [2]	"You’d think so from reading [1]. [2] though paints a very different picture.> The attacker can submit a maliciously crafted database file to the application that the application will then open and query.I think it’s not impossible to secure SQLite better but it takes some work (like how Chrome sandboxes it in a separate process).[1] https://www.sqlite.org/security.html
[2] https://www.sqlite.org/cves.html"	vlovich123	13.610943	-5.5913877	comment	4.0	34.0	1608263266	9.850753
25464346	Lack of multiple independent impleme	Lack of multiple independent implementations means we can't ever switch to a different programing language or radically different system architecture.Nobody is feasibly going to rewrite Sqlite in Rust.So yeah, it is important.	otabdeveloper4	13.624597	-5.665183	comment	4.0	22.0	1608271554	9.846632
25463352	> The atomic update capabilities of 	"> The atomic update capabilities of SQLite allow small incremental changes to be safely written into the document. This reduces total disk I/O and improves File/Save performance, enhancing the user experience.How would this work without breaking the conventional ""Save"" paradigm? Unless the app tracks all incremental changes to apply when the user clicks ""Save"" instead of dumping it all back to disk, which seems difficult and error-prone to implement."	rlpb	13.564031	-5.52108	comment	4.0	23.0	1608260857	9.744882
25464846	Nobody is feasibly going to rewrite 	Nobody is feasibly going to rewrite Sqlite in Rust.Per (Genuine) curiosity why ? I know (good) database systems are hard to make but do sqlite have particulary 'hard' part which are near impossible to replicate ? Especially since we now have a (I assume) well documented base implementation and an extensive test suite/history of error to avoid ?Is making à file based database that hard,compared to creating new programming language for exemple ?	GaelFG	13.6255	-5.679692	comment	4.0	12.0	1608277991	9.854865
25551674	Let me first say, I think all of the	Let me first say, I think all of the criticisms I am reading here are valid. That said, partitioning in PG still isn't great, and though it's better now than in say, v9.x, I'm not sure it's ever going to get where multinode NoSQL is without sacrificing core ACID that makes PG so great. I know it's not in keeping with the general HN dislike of Mongo, but if you have large scale data that has a stable partition key, data that you write and store authoritatively elsewhere like a relational DB, that you don't have to update with real time writes, but you need to do a lot of heavy reads of most of the fields, I think Mongo makes a lot of sense. To be clear, ALL of those things have to apply. And when you factor in ease of setup, adding new nodes, and training new devs that, doubt you will find 	lr4444lr	13.547419	-5.3195667	comment	4.0	14.0	1609083252	9.807312
25698217	iRacing is a bunch of kludges all th	iRacing is a bunch of kludges all the way down. For the longest time the only way to race was as a solo driver. However, some of the biggest races in the world of real racing is endurance events where 3-4 people share a car over 24 hours. So iRacing added team races at some point. I've done a few things with data endpoints from iRacing, and it reveals a bit about how they did it.Every driver has an ID. It's just an integer sequentially increasing every time a new person joins the service. Teams, however, are the opposite. Every time a new team is created they are assigned a negative ID, perpetually decreasing as new teams are created. Because of this, an entry into a racing session can be handled by way of a single database column for both drivers and teams. Keep in mind that a racing sess	herbstein	13.870172	-5.1873546	comment	4.0	17.0	1610176114	-13.667113
25800478	> But in 2010's, internet datasets w	"> But in 2010's, internet datasets were growing much faster - and computing power wasn't. So Relational DBs weren't ""fast enough"" for these cases... hence ""NoSQL"".I joke that the only thing a NoSQL database can do faster than an RDBMS is give you the wrong answer to a query.There are two different features that people typically think of when they think of NoSQL as compared to a traditional RDBMS:1. Document database (i.e. unstructured, or at least weakly structured data)2. Eventual consistencyYou could have an ACID document database, or an eventually consistent relational database, so the two are actually orthogonal.  It's definitely easier to get something up and running quickly if you aren't going to implement all of SQL though.If you make money serving up ads on lists of documents, then"	aidenn0	13.538524	-5.451625	comment	4.0	12.0	1610777447	9.826632
25870865	I'd worry a bit about the chance of 	"I'd worry a bit about the chance of collisions.They correctly state you can generate 50 million of them per millisecond with only a one in a billion chance of a collision (per millisecond).Unfortunately this means the chance of a collision in a year is 99.999999999998% which isn't great!(I think they've given too many bits to the timestamp.)Also, the uuid format it creates isn't a valid uuid which is a pity.If you want to have ""only"" a one in a billion chance of a collision a year, you can only generate about 300 a millisecond."	Ellipsis753	13.982185	-5.210414	comment	4.0	19.0	1611316672	-13.663391
25870772	There’s a spec called ULID that’s pr	There’s a spec called ULID that’s pretty much this with default base32 encodinghttps://github.com/ulid/specI’ve also worked on a UUID-ULID bridge for Gohttps://github.com/sudhirj/uulid.goAnd seeing as this is just 128 bits it’s quite easy to move seamlessly between formats and representations.I’ve found this concept especially useful in nosql stores like DynamoDB, where using a ULID primary key makes objects time sortable automatically. It’s also quite easy to query for items by zeroing out the random component and setting only the time stamp bytes.	sudhirj	13.950356	-5.210275	comment	4.0	21.0	1611315604	-13.675879
25870964	Can someone expand on this please.> 	Can someone expand on this please.> They should be random, but roughly-ordered over time so that your MySQL/Postgres indices stay fast and efficient as the dataset grows.I'm currently facing an issue where the chosen uuid format was v4. From my understanding this is the least preferable because it's true random, which causes hell for mysql indices.What I don't quite udnerstand however, is why is sorted random better if I'm using an index in both cases? I'd like to know what I should be doing and if there is a way to move/migrate if possible	chrisacky	13.969312	-5.221673	comment	4.0	13.0	1611317382	-13.668837
25873029	I've been following this, and am anx	"I've been following this, and am anxious for the direct-to-sqlite replication.One of rqlite's big limitations is that it resyncs the entire DB at startup time. Being able to start with a ""snapshot"" and then incrementally replicate changes would be a big help."	mrkurt	13.539758	-5.4621387	comment	4.0	22.0	1611332769	9.7988405
26105354	I've been building a web service on 	I've been building a web service on a cheapo DigitalOcean box lately, so I'm excited to see explorations in this space, especially with an eye towards staying cheap! I'd probably only use this particular tool if it could hook up to Backblaze B2 instead of S3, since life's too short to ever have to engage with the hell that is AWS for a hobby project, but since B2's API-compatible it seems like a feature that could be added in the future.That said, I've always been a little worried about trying SQLite since I'm so used to Postgres. I've currently got Postgres running alongside my app in a Docker container, which isn't too hard to manage. I'm curious whether anyone has switched from Postgres to SQLite in a web app context (whether in the same project, or when making a new project) and if the	avolcano	13.583318	-5.527314	comment	4.0	15.0	1613068475	9.83837
26151577	> The Appropriate Uses For SQLite pa	"> The Appropriate Uses For SQLite page says that dynamic pages on the SQLite website typically do about 200 SQL statements each. This has provoked criticism from readers. Examples:> ""200 SQL statements is a ridiculously high number for a single page""> ""For most sites, 200 queries is way, way, way too much.""> ""[This is] bad design""Funnily enough, at a recent workplace the guideline was ""if it only does 200 queries, you've optimized it enough""."	ThePadawan	13.569954	-5.546525	comment	4.0	25.0	1613458248	9.709079
26151594	The limited type system and loose da	The limited type system and loose data validation always prevented me of using SQLite.It's a nice data store but a poor database in my opinion.	LunaSea	13.5931	-5.568504	comment	4.0	23.0	1613458749	9.834013
26151935	When I started a project with SQLite	When I started a project with SQLite, the available data types struck me as odd (coming from MySQL), but as I learned I started asking the question: are there any more fundamental data types other than null, int, real, text and blob? For example dates are just a facade for an integer of some kind, JSON is really just text adhering to certain formatting rules, booleans are usually stored as some kind of byte anyway so why not drop that abstraction?With this limited set of datatypes it really makes you think harder about the data you are processing, because in the end all your data is one of these types anyway.	RedShift1	13.5833435	-5.6126924	comment	4.0	45.0	1613463340	9.849773
26152084	My understanding is that SQLite does	My understanding is that SQLite doesn't impose any format either?	millstone	13.58559	-5.584251	comment	4.0	20.0	1613464824	9.824972
26192700	The main issue in my experience are 	"The main issue in my experience are so called ""user enumeration attacks"", especially with sequential ids that are normally used.This is where an attacker is able to leak information from your system just by guessing ids. If you used a sequential id then you can cycle from 1 to X and probably easily find which are valid users. You can then likely see how many valid users/ids there are and potentially pull their data if the authentication has been implemented incorrectly.By using a UUID, the key space is so large that you cannot reasonably guess user ids. So you can't use those same brute force techniques and it makes extricating data much harder."	dkarp	13.963585	-5.190183	comment	4.0	19.0	1613740008	-13.643231
26222251	Has anyone here used SQLite on a web	Has anyone here used SQLite on a web app with database file per tenant or even lower granularity? How fast does the attach work? Can you do transactions over multiple databases as well?	yread	13.573912	-5.5033135	comment	4.0	21.0	1613983878	9.799951
26290984	I kinda disagree with separate branc	"I kinda disagree with separate branch for ""document database"" for Mongo. Mongo is a key-value storage, with a thin wrapper that converts BSON<->JSON, and indices on subfields.You can achieve exactly the same thing with PostgreSQL tables with two  columns (key JSONB PRIMARY KEY, value JSONB), including indices on subfields. With way more other functionality and support options."	deepsun	13.560931	-5.4394836	comment	4.0	13.0	1614491051	9.748739
26440973	> SQLite is called ‘lite’ for a reas	> SQLite is called ‘lite’ for a reason. If you need functions, add them yourself.Most people I know, myself included, pronounce it that way. But Richard Hipp, the creator of SQLite, actually pronounces it SQL-ite, like a mineral.	Felk	13.584799	-5.589518	comment	4.0	14.0	1615583470	-4.902024
26444163	I firmly believe that RethinkDB coul	"I firmly believe that RethinkDB could have been a huge player along with the likes of MongoDB and Elasticsearch if they could have gotten additional funding or focused more on business development. Note: both MongoDB and Elasticsearch are now hugely successful public companies.  - Changefeeds were so useful and still to this day not really matched in quality.  
  - Official client libraries were very high quality. I mainly used Node.js.
  - Performance (reads and writes) was impressive.  
  - Setting up a highly available cluster with sharding was incredibly easy with a few clicks and types in the aforementioned web U/I.
  - Their web U/I was the best to ship with a database at the time.  

I still wear my RethinkDB shirt around, and it was a pleasure meeting one of the founders Michael Gl"	nodesocket	13.635415	-5.290946	comment	4.0	21.0	1615612352	-12.795526
26447243	As someone using RethinkDB in produc	As someone using RethinkDB in production for the last 6 years or so: I am really disappointed by how software development world is dominated by fashions and fads.RethinkDB was done really, really well. It is one of the very few distributed databases that went through Jepsen relatively unscathed and delivered on promises made. Development was done in the public, questions were asked through StackOverflow. You interacted with competent, skillful and experienced developers.And yet MongoDB was the latest fashion fad, end even though it did NOT deliver on the promises, it was the hot-database-du-jour that kids used.The article is mostly about the business model, and I also always thought they would have a hard time making money on the database. But I think they would have had a much better shot	jwr	13.697147	-5.300398	comment	4.0	13.0	1615649914	-12.798195
26466850	I am worried.We will start having tr	I am worried.We will start having trouble with random UUID collisions when we have made 2^64 of them,  which is a huge number.  It's about as many iron atoms as are in an iron filing.It is also about 200,000 times 100 trillion,  so AWS is just 18 doubling times away from the UUID system breaking down.	PaulHoule	13.97145	-5.18567	comment	4.0	13.0	1615820726	-13.647112
35530961	> Postgres is probably the best solu	> Postgres is probably the best solution for every type of data store for 95-99% of projects.I'd say it's more like:- 95.0%: SQLite-  4.9%: Postgres-  0.1%: Other	alberth	13.594164	-5.536426	comment	4.0	14.0	1681244426	9.826681
35546668	Ok, old man yelling at clouds moment	"Ok, old man yelling at clouds moment finally coming for me. Now that we've been through the document-database heyday and are out the other end, what have we learned about where document databases are a good fit?At the time I looked at them like a fad. ""These script kiddies want to write javascript and ignore schemas. Let's see how well that works out for them."" As expected, most of what I ever hear is regret.Today, MongoDB has grown out of the reliability issues it had in the past, and Postgres has json features for the occasional times it's useful to store some loosely structured data along with otherwise relational data. Question is, what applications is a document-first database good for, outside of prototyping?Edit: and to make sure I understand, FerretDB is a layer reimplementing Mong"	kbd	13.607472	-5.368432	comment	4.0	26.0	1681332644	-2.6878033
35553518	Google didnt, thus Chrome started re	Google didnt, thus Chrome started replacing sqlite with https://github.com/google/leveldb	rasz	13.577314	-5.546721	comment	4.0	17.0	1681382854	9.814702
36594759	Honest question: why doesn't Couchdb	Honest question: why doesn't Couchdb receive any love on HN?It's such a perfect tool for my side projects and most projects that will never reach Twitter scale	yawnxyz	13.62376	-5.209945	comment	4.0	19.0	1688522682	9.676216
36603977	my sqlite pain point is not being ab	my sqlite pain point is not being able to access sqlite over NFS or remotely on a separate server. i want the best of both worlds: behave like a file locally + act like a server	Kalanos	13.584884	-5.524418	comment	4.0	12.0	1688578843	9.816533
36620562	Vector DB with no network latency – 	Vector DB with no network latency – SQLite	elamje	13.570877	-5.526552	story	4.0	16.0	1688667961	9.802143
36779878	One of three core principles: fastTe	One of three core principles: fastTechnology choices: JavaScript and MongoDBSeems off.	RhodesianHunter	13.680608	-5.314596	comment	4.0	19.0	1689719198	9.879983
36798393	To do 2-25 million transactions per 	To do 2-25 million transactions per day you might as well use SQLite. Sounds like this was a career development push more than anything.	hsjqllzlfkf	13.596887	-5.5094256	comment	4.0	17.0	1689845048	9.857704
36811020	If you need unique nanosecond, keep 	If you need unique nanosecond, keep track of the previously generated one and increase it if necessary. Would require global lock or atomic stuff, but should be good enough for practical uses.	vbezhenar	13.971897	-5.206678	comment	4.0	16.0	1689924571	-13.661369
36812226	More importantly if you have an inde	More importantly if you have an index on purely random IDs, then each insert will go to some random position into the tree whereas having IDs that increase with time will make all new IDs end up at the end of the tree which reduces index fragmentation.	danbruc	13.8596115	-5.245544	comment	4.0	48.0	1689936118	-13.65196
36821736	Fixed Bits of Version 4 UUID (2015)	Fixed Bits of Version 4 UUID (2015)	susam	13.988913	-5.2101626	story	4.0	34.0	1689984405	-13.668892
36897056	Not to start a flamewar, or discount	Not to start a flamewar, or discount SQLite, I love SQLite... but if you really need this kind of feature, wouldn't something like Firebird DB be a better option at that point?  I know the licensing and embedding is different, just curious what others think.	tracker1	13.556359	-5.528867	comment	4.0	16.0	1690478774	9.838036
37093099	> Split up the monolith into multipl	"> Split up the monolith into multiple interconnected services, each with its own data store that could be scaled on its own terms.Just to note: you don't have to split out all the possible microservices at this junction. You can ask, ""what split would have the most impact?""In my case, we split out some timeseries data from Mongo into Cassandra. Cass's table structure was a much better fit — that dataset had a well defined schema, so Cass could pack the data much more efficiently; for that subset, we didn't need the flexibility of JSON docs. And it was the bulk of our data, and so Mongo was quite happy after that. Only a single split was required. (And technically, we were a monolith before and after: the same service just ended up writing to two databases.)Ironically, later, an airchair ar"	deathanatos	13.594179	-5.3097515	comment	4.0	15.0	1691783107	9.87165
37165908	Worthless clickbait.SQLite is belove	Worthless clickbait.SQLite is beloved here (for good reason) but this adds nothing to our understanding and utilization of it.The gold standard for correlation confusion: https://pastafarians.org.au/pastafarianism/pirates-and-globa...	pstuart	13.612131	-5.580135	comment	4.0	12.0	1692296508	9.823374
37326148	You may not like Mongo, but it's had	"You may not like Mongo, but it's had this feature for a long time. https://www.mongodb.com/docs/manual/core/gridfs/ Title maybe needs to say ""Xata now can store..."" ?"	maerF0x0	13.674776	-5.322953	comment	4.0	12.0	1693418205	9.86717
37471721	IMO, a good middleground is using sc	"IMO, a good middleground is using schemes like TypeID[0], ulid[1], or KSUID[2] that provides a more compact and readable (base32) representation and provides better database locality (K-sortable).[0] https://github.com/jetpack-io/typeid
[1] https://github.com/ulid/spec
[2] https://github.com/segmentio/ksuid"	ekojs	13.980851	-5.229901	comment	4.0	15.0	1694457705	-13.668421
37472744	Also as a developer I really dislike	Also as a developer I really dislike UUIDs because the hyphens make it impossible to double-click copy.It’s a small gripe, but I need to copy IDs multiple times per day and it adds up. Other ID formats like cuid or KSUID don’t have hyphens in their canonical representation, and it makes them far more pleasant to work with	sophiabits	13.969234	-5.2037983	comment	4.0	12.0	1694462071	-13.663686
37503099	I think you are thinking that Fly is	I think you are thinking that Fly is like a serverless platform. They aren't. They are the opposite. They are a server platform. They provide server for you and you have to manage your server yourself.Nothing they provide is managed by them. You have to do that.LiteFS is just a replication service for your sqlite database so you can keep your database synced across multiple nodes.https://github.com/superfly/litefsLiteFS Cloud which is the a service they provide just helps you backup and recover sqlite databases. You can do this yourself.https://fly.io/docs/litefs/backup/	impulser_	13.573408	-5.463196	comment	4.0	25.0	1694648468	9.738724
37503534	> User can open the application, get	"> User can open the application, get the database, the frontend does all the offline updates the user want to perform.""get the database""How small do you think these databases are?!You're going to download the entire hotel booking platform's database?For how many hotels?  One at a time, and then get another databse?  Or are you getting a Sqlite booking database for every hotel in the world?  And you're going to send them to each user?  For what date range?And even if that were possible, you then have to commit your offline updates.  What if someone else booked the date range prior to you?  Now your Sqlite copy is stale.  Download the entire thing again?  There could have been countless changes from other users in the time since you last got your copy.This explanation just leaves me even mor"	EMM_386	13.576307	-5.5237956	comment	4.0	13.0	1694652442	9.733438
37553887	Hmm, me too, and Wikipedia says:> Op	Hmm, me too, and Wikipedia says:> OpenDocument - Initial release: 1 May 2005; 18 years ago> SQLite - Initial release: 17 August 2000; 23 years agoWonder what gives.	capableweb	13.588039	-5.5722404	comment	4.0	15.0	1695027915	9.83127
37554956	Why do you use a secondary, volatile	"Why do you use a secondary, volatile database ? Performance-wise you won't gain a lot more (we're talking about a user editing a file, so not even 1 write per second).A proposal: write directly, and automatically in the database. No more Save button. There are multiple advantages:- the system is crash-resistant. I like taking the approach of CouchDB where the only correct way to close the system is to crash it. That way a crash is an expected situation that you actually account for, not a special case that you might forget- there is only one database. Less code, fewer bugs.- it is safe. A write to SQLite works or doesn't work, there is no in-between. As said in the VACUUM doc you point to: ""However, if the VACUUM INTO command is interrupted by an unplanned shutdown or power lose, then the "	rakoo	13.5758915	-5.5176854	comment	4.0	30.0	1695037850	9.74364
37554969	Exactly. Some formats are designed, 	"Exactly. Some formats are designed, first and foremost, for interchange. SQLite is pitching that you, as an ""app"" owner, force the SQLite format upon your users to make it a de-facto standard, without putting the work in to make it a de-jure standard.Show me a formalised ISO / IEC / ANSI / ETSI SQLite standard that the Richard Hipp and his company never deviates from, and the full legal search to ensure there are no patents that might affect it, and show me the multiple compatible implementations of SQLite that _all_ have these touted advantages, and _then_ we can talk about prosletizing it as a file format. If they don't, they're saying ""take a hard dependency on a single-source implementation, and make all your users take it too"".XML is a formal standard. ASN.1 is a formal standard. JFIF"	amiga386	13.534879	-5.555964	comment	4.0	12.0	1695037905	9.83493
37555595	> Such a query either returns an und	"> Such a query either returns an undefined answer or generates an error in many other SQL database engines, but in SQLite it does what you would expect:It may be a useful functionality, but it is NOT what I would expect such a query to return, to be frank.Also you don't need a nested query in this specific, you can order by checkinTime and limit the result to one.> select manifest, versionId, checkinTime from version order by checkinTime desc limit 1or something like that. This should work in SQlite and Postgresql at the minimum. I think to remember that in Oracle you have to use ""where rownum=1"" so indeed you have to use a nested query. I don't know about other databases."	mrighele	13.611214	-5.603032	comment	4.0	19.0	1695042526	9.874418
37575792	Ask HN: Is there is an sqlite3_expan	Ask HN: Is there is an sqlite3_expanded_SQL()'s equivalent for other DBMS?	lfconsult	13.536077	-5.6443033	story	4.0	6.0	1695154118	9.846692
24429481	For every 1 of those crazy high secu	For every 1 of those crazy high security companies, there’s probably 1000’s that couldn’t secure MongoDB instances.	postpawl	13.701947	-5.2519383	comment	4.0	12.0	1599719271	9.917464
24729008	Geez, what's with those weird projec	Geez, what's with those weird project names? For a second I expected/hoped this would be some cool hack storing data in actual seaweed. (You know like pingfs..) No it's not! It's some S3 k8s ... thing. Nothing wrong with that but come on, choose a better name!And no I'm not particularly fond of the namr CockroachDB either.	ganafagol	13.701842	-5.193899	comment	4.0	15.0	1602244846	-4.622396
25216962	> But this is not the case! Some of 	"> But this is not the case! Some of these parts have never been the case - MongoDB has never been ""eventually consistent"" - updates are streamed and applied sequentially to secondary nodes, so although they might be behind, they're never inconsistent.This is what eventually consistent means! If i wrote (key=X, value=Y) to a primary, then read X and see a value thats not Y (because the secondary node hasn't caught up yet), that is inconsistency. Strong consistency (e.g in a single node SQL database) would mean its impossible to read stale values."	zaptheimpaler	13.610426	-5.270437	comment	4.0	32.0	1606366668	9.737872
25306252	Coinbase: Seamless MongoDB to Postgr	Coinbase: Seamless MongoDB to PostgreSQL Migration	openmosix	13.557102	-5.3631496	story	4.0	41.0	1607108463	9.903714
38627527	What a curious state, there is just 	What a curious state, there is just one jdbc (=java) driver for SQLite. Why are there 6 (or more!) for Go?	Traubenfuchs	13.63619	-5.628318	comment	4.0	16.0	1702476436	-5.7391353
38628077	Sqlite developers go to very great l	Sqlite developers go to very great lengths making sure their software works reliably. You can't just introduce some transpiler in-between and expect that it'll work. It's a different software and it should not even be called sqlite IMO.The only proper way to use sqlite is to use FFI.	vbezhenar	13.614373	-5.596654	comment	4.0	13.0	1702478773	9.861926
38668752	Almost decided to use MongoDB in a p	Almost decided to use MongoDB in a project for the first time.Kind of makes me unsure if it’s going to be the right choice.	toasted-subs	13.654313	-5.332173	comment	4.0	21.0	1702768874	9.854824
38669405	Legitimate question, please don't do	Legitimate question, please don't downvote.Are you basing this opinion on:- popular HN opinion- issues that Mongo experienced in its infancy- mis-modelling highly relational data on a non-relational DB, and blaming the DB for ensuing problemsOr are you basing it on extensive experience with wide range of use cases?	merek	13.672204	-5.3268867	comment	4.0	14.0	1702775014	9.848546
38786012	Show HN: sqlite-memory-vfs - Open a 	Show HN: sqlite-memory-vfs - Open a SQLite db in Python without hitting disk	michalc	13.615733	-5.5773335	story	4.0	17.0	1703707534	9.840907
38924832	Also recall that a 50% speed improve	Also recall that a 50% speed improvement in SQLite was caused by 50-100 different optimisations that each eeked out 0.5-1% speedups. On phone now don’t have the ref but it all adds up.	bomewish	13.584985	-5.544981	comment	4.0	19.0	1704799275	9.868885
38938694	Completely agree. I remember when Mo	"Completely agree. I remember when Mongo / NoSQL was peak hype cycle, and every new  project ""needed"" to use it despite being a big step down in terms of features, ability and maturity. A few years later I ended up on a system with Mongo as the database, started when Mongo was at peak hype. It was every bit as bad as I expected.I have never seen a Mongo Based system that didn't work off of a single server, the one place where it did actually have an advantage."	collyw	13.64163	-5.3317823	comment	4.0	15.0	1704883128	9.888639
38938881	I would hold SQLite up against anyth	I would hold SQLite up against anything.Likely the second most widely deployed software ever. https://www.sqlite.org/mostdeployed.htmlThe best tested piece of software that I know of. https://www.sqlite.org/testing.htmlPeople call it a toy database. Some toy.	btilly	13.589849	-5.560656	comment	4.0	12.0	1704884426	9.833436
38999908	when doing backups, managing file pe	when doing backups, managing file permissions, etc, it's really convenient to only have a fixed number of known files to worry about.Switching to WAL already makes handling Sqlite databases much less convenient, since you now have three files instead of one, and need a filesystem snapshotting mechanism to reliably back them up (so you don't have one state in the database and another in the wal). Making the filenames and number of files less predictable would make that mode not worth it for many use cases	wongarsu	13.55068	-5.413353	comment	4.0	17.0	1705320572	9.76116
39003874	Talks about lack of professional ser	Talks about lack of professional seriousness. Goes with MongoDB. Sometimes reality writes the best jokes.	sgift	13.700923	-5.308309	comment	4.0	29.0	1705341491	9.901707
39005708	If anyone wants to try this out on m	"If anyone wants to try this out on macOS here's the fastest way I've found to try a new SQLite version there: https://til.simonwillison.net/sqlite/sqlite-version-macos-py...Short version:    cd /tmp
    wget 'https://www.sqlite.org/2024/sqlite-amalgamation-3450000.zip'
    unzip sqlite-amalgamation-3450000.zip
    cd sqlite-amalgamation-3450000
    gcc -dynamiclib sqlite3.c -o libsqlite3.0.dylib -lm -lpthread
    DYLD_LIBRARY_PATH=$PWD python3 -c ""import sqlite3; print(sqlite3.sqlite_version)""

That prints ""3.45.0"" for me.If you have https://datasette.io/ installed you can then get a web UI for trying it out by running:    DYLD_LIBRARY_PATH=$PWD datasette"	simonw	13.646708	-5.6255074	comment	4.0	13.0	1705350778	9.839886
39007295	Who is doing this and where can I re	Who is doing this and where can I read more? What are the tradeoffs?I imagine that you get a a dataset that is significantly smaller but it is much trickier to keep a dataset in memory the way you could with MySQL.It's like having a free implicit index on the customer (because you had to lookup the sqlite db file before you could start querying).I spend a lot of time thinking about tenancy and how to handle it. Tenancy is such a common problem.Performance is the number one reason tickets are hard to estimate. The second in my experience is security.Time and tenancy are the number one opportunities for SQL to just be better (I always need tenancy and my Order By or at least one constraint can typically be satisfied with time).	safetytrick	13.563804	-5.538157	comment	4.0	14.0	1705360232	9.813548
32540435	I've seen a lot of Sqlite hype here 	I've seen a lot of Sqlite hype here in the past weeks and months.Please excuse my ignorance, but what do all these Sqlite-but-make-it-X solutions offer over a simple, more established solution like (nobody ever got fired for choosing) Postgres?	solarkraft	13.58563	-5.511988	comment	4.0	15.0	1661091494	9.868069
32582150	SQLite needs some 'put your money wh	SQLite needs some 'put your money where your mouth is' benchmarks.EDIT:Lots of devs have (unfounded) doubts about performance regarding SQLite for web apps, a single machine benchmark against postgres (with postgres and the app in the same server) would clear many doubts and create awareness that SQLite is going to be more than enough for many apps.. The app doesn't have to be a web app (we are not testing web servers) but maybe some code with some semi-complex domain models.	ithrow	13.597852	-5.5047827	comment	4.0	18.0	1661359751	9.827892
32583565	It's become popular to talk about ho	It's become popular to talk about how scalable SQLite is lately, but let's not forget the elephant in the room, it only allows a single writer at a time.It's obviously easier to manage and maintain due to it being an embedded database, but that seems to be a very separate issue from the data structure involved, which definitely has disadvantages compared to a typical SQL system.	etaioinshrdlu	13.578402	-5.505116	comment	4.0	14.0	1661365022	9.777168
32680248	> SQLite is pretty bad when it comes	"> SQLite is pretty bad when it comes to transactions per second. SQLite even owns up to it in the FAQ: ""it will only do a few dozen transactions per second.""That is an extremely poor quote taken way out of context.The full quote is:FAQ: ""[Question] INSERT is really slow - I can only do few dozen INSERTs per second. [Answer] Actually, SQLite will easily do 50,000 or more INSERT statements per second on an average desktop computer. But it will only do a few dozen transactions per second. Transaction speed is limited by the rotational speed of your disk drive. A transaction normally requires two complete rotations of the disk platter, which on a 7200RPM disk drive limits you to about 60 transactions per second.""https://www.sqlite.org/faq.html#q19"	tiffanyh	13.53362	-5.5162044	comment	4.0	12.0	1662054583	9.778153
32724874	For discussion on SQLite 3.39.0, see	For discussion on SQLite 3.39.0, see https://news.ycombinator.com/item?id=31876604I'm not sure why a minor SQLite bugfix release needs to be posted here.	pdw	13.621722	-5.594622	comment	4.0	38.0	1662389120	9.872234
32724773	Ask HN: UUIDs vs. Human-Readable IDs	Ask HN: UUIDs vs. Human-Readable IDs in APIs?	emschwartz	13.929243	-5.2075057	story	4.0	1.0	1662388606	-13.631255
32752674	I don't think it has much to do with	I don't think it has much to do with the name. I think the biggest perceptual impact on SQLite came from Rails, and its default for using SQLite as a test database while strongly discouraging people from using it in production.	tptacek	13.619249	-5.5862055	comment	4.0	19.0	1662567786	9.852536
32797809	> Require the domain name to be a UU	> Require the domain name to be a UUID or include the date or something else that makes it unsquattable.What's the benefit of a UUID over a raw IP address?	arinlen	13.981685	-5.2114997	comment	4.0	15.0	1662884588	-13.653519
38181590	When will Postgres be supported?	When will Postgres be supported?	aantix	13.538928	-5.420483	comment	4.0	41.0	1699385357	9.81371
38284862	The Design of SQLite4 (2014)	The Design of SQLite4 (2014)	iamwil	13.605601	-5.5751452	story	4.0	41.0	1700098267	9.820897
38416424	I haven’t been able to find a case f	I haven’t been able to find a case for this because ids either need to be unique or they’re not going to be large. If they’re unique, I’m using uuid or ulid (uuidv7 of tomorrow) as the sortable primary key type to avoid conflicts without using the db to generate and maintain sequences.Where do you have unique ids that aren’t the primary key? I would be more interested in a retrospectively unique truncated encoding for extant ulid/uuid; ie given that we’ve passed timestamp foo, we know that (where no external data is merged) we only need a bucketed time granularity of x for the random component of the id to remain unique (for when sortability is no longer needed).Or just more generally a way to convert a ulid/uuidv7 to a shorter sequence if we are using it for external hash table lookups on	ComputerGuru	13.950485	-5.227007	comment	4.0	16.0	1700944165	-13.676023
38421052	Because MongoDB's license change dis	Because MongoDB's license change disallowed cloud service provider to host MongoDB. This reduces the competition and *probably* making MongoDB more expensive than says PostgreSQL. Which I can find a hosted solution anywhere I host my VPS.	thangngoc89	13.6956005	-5.265749	comment	4.0	15.0	1701000923	9.934232
38501088	Have you considered using SQLite vta	Have you considered using SQLite vtables for this?	zffr	13.599238	-5.572101	comment	4.0	12.0	1701544230	9.821687
38542396	Unrelated question: what languages i	Unrelated question: what languages integrates best with sqlite? I am using it with go and cgo, but it is    often advised to avoid cgo. Perhaps it doesn't matter so much, I can use it anyways, but would be interesting to hear about other experiences.	mongol	13.580114	-5.5917635	comment	4.0	14.0	1701860245	9.920374
14712382	MongoDB is like the PHP of databases	MongoDB is like the PHP of databases. I started programming PHP and currently I bash it every time I can, because it is a terrible language. But it is easy to start and do cool stuff, just like mongodb. Initial traction is more important than initial architecture, I guess.	owebmaster	13.6495905	-5.3322625	comment	4.0	37.0	1499363972	9.865107
14712558	If you actually need certain feature	If you actually need certain features like a document store, then Postgres is less mature than MongoDB in that regard.	squeaky-clean	13.631561	-5.3591456	comment	4.0	15.0	1499365012	9.873266
14728489	SQL in CockroachDB: Mapping Table Da	SQL in CockroachDB: Mapping Table Data to Key-Value Storage (2015)	yinso	13.62998	-5.214672	story	4.0	55.0	1499578208	9.9033575
14795993	Just about to decide between Mongo a	Just about to decide between Mongo and Rethink. I know HN is not on good terms with Mongo but I'd like to have insights on...- Setup of a replica set: is it easier/faster than with Mongo (which I find complicated)?- Sharding: Easier than with Mongo?- Rethink's query language: Is it really better than Mongo's after you used it for some time?Happy to hear more insights if you know more noteworthy stuff and please no bashing of any of them. Just try to make an educated decision.	cupcakestand	13.67132	-5.3190246	comment	4.0	22.0	1500381185	-12.819411
14805546	I'm a long-time MongoDB user and lar	I'm a long-time MongoDB user and largely a fan of it because I believe the interface is superior to some text-based SQL statements.But whatever DB you like, if you move the state of your application to another application (i.e, a database) you better make sure you really understand how it works.For SQL databases, many people think they know how they work, but misconceptions seem widespread. Essentially, many beginners believe that SQL databases guarantee serializability everywhere and all the time, relying on the database (and OR-mappers) a lot / too much in my opinion.Choosing a system that only offers very few guarantees forces you to think about them more explicitly. On the other hand, if you never bothered to understand SQL, you probably won't bother understanding anyDB's restrictions 	cmenge	13.626763	-5.3658686	comment	4.0	33.0	1500482080	9.881736
14805558	Today in 2017, there is no real reas	Today in 2017, there is no real reason to use MongoDB other than in prototyping. I am happily waiting until the final nail is put on the coffin of this overhyped, flawed document store.	flavio81	13.666555	-5.334953	comment	4.0	28.0	1500482152	9.902344
14805805	It terrifies me to see this quote fr	"It terrifies me to see this quote from their CTO:""MongoDB's CTO disagrees with this statement arguing that nearly 90% of database installations today would benefit from being replaced with MongoDB.""I used to attend ""office hours"" at MongoDB's office where guests ask MongoDB employees for help. Most of my questions involved very complex aggregation queries (that would have been trivial in SQL) that even MongoDB employees could not solve.While I waited to be helped I would listen to other people ask the same questions over and over and over: ""How do I join these two collections? How can I <perform a transaction> and ensure both writes succeed/fail?""Rather than say ""MongoDB doesn't offer this functionality"" and maybe advise them that this database isn't what they needed for the specific proje"	slap_shot	13.709493	-5.296873	comment	4.0	16.0	1500483788	9.888044
15024945	Reliability and implementation ideas	Reliability and implementation ideas aside, MongoDB popularized document stores and document stores can sometimes be a good thing (even if there's usually little to no reason to prefer them to plain SQL databases for most applications). So they deserve credit there.	meowface	13.652687	-5.3258586	comment	4.0	16.0	1502857900	9.896
15124323	(Author here) You can read parts 1 a	(Author here) You can read parts 1 and 2 of the three part series:- Part 1, Why Did So Many Startups Choose MongoDB: https://www.nemil.com/mongo/1.html- Part 2, Startup Engineers and Our Mistakes with MongoDB: https://www.nemil.com/mongo/2.htmlYou can see most of the notes from my interview with MongoDB's CTO, Eliot here:https://news.ycombinator.com/item?id=14804765And the interview notes related to MongoDB's marketing are somewhere in this HN post:https://news.ycombinator.com/item?id=15124316	nemild	13.723282	-5.285921	comment	4.0	23.0	1504015430	9.908041
15169067	On a related note (and this seems a 	On a related note (and this seems a good forum to ask), are there any typed databases available similar to sqlite?	14113	13.600908	-5.5885177	comment	4.0	17.0	1504540932	9.795218
15226459	For years already I've been using UU	For years already I've been using UUID v4 (generated from a good random source) then base64url encoded, resulting in a 22 characters/bytes long identifier.The nanoid implementation does not really bring anything new to the table except having fewer SLOC (which I personally don't find important). It is also incompatible with https://tools.ietf.org/html/rfc4648#section-5 for no good reason. It is noticable again and again that devs publishing to npm are not up to snuff, I wish I knew why, as this does not happen with other dynamic languages/their code repos.	bmn__	13.986571	-5.210724	comment	4.0	22.0	1505216331	-13.706322
15235864	Ask HN: How do you handle mongodb mi	Ask HN: How do you handle mongodb migrations?	uptownhr	13.690471	-5.32434	story	4.0	5.0	1505281641	9.890374
15303969	I really wish the android team would	I really wish the android team would create an officially supported ORM package to wrap sqlite like CoreData on iOS. Global data access is even more important on android since Activities are stateless, and data access always seems to be to failure point in so many of our projects.	seanalltogether	13.571968	-5.5343127	comment	4.0	16.0	1506005396	9.871576
15303873	I really don't understand why majori	I really don't understand why majority of websites use mysql or even postgres for that matter. The vast majority of websites would run perfectly fine on sqlite.Not only would you get rid of network latency, you would also vastly reduce your dependencies.I have a side project to try to see if I can build a minimal micro-blogging type server application on sqlite and try to test how many requests it can handle per second (reads and writes).I have a hunch it will be able to handle quite a lot. Specially if the server code is written in a fast language that compiles to native code (e.g. D) with some caching of the most commonly requested items in memory.	hasenj	13.572497	-5.5260053	comment	4.0	25.0	1506004881	9.8171625
15308275	There seems to be some high level ex	There seems to be some high level execs that just left. I wonder why they left before the IPO - maybe their options were forced to expire?  Matt Kroll was their head of sales and he just went to google - how is Mongo going to grow without a good sales team?	opendomain	13.744412	-5.2608514	comment	4.0	28.0	1506038045	9.920262
15308879	I don't get it. I don't get it. I do	"I don't get it. I don't get it. I don't get it.1) Mongo is not better than Postgresql JSONB and other Postgresql features, especially in 10.
2) There was NEVER a Mongo cluster management tool named Sheriff Bart! It litterally sells itself: Mongo Loves Sheriff Bart.
3) ArangoDB is able to provide many of the Mongo features with some ACID compliance and a better graph solution. It even has joins. I get that people use documents to avoid joins, but really. You still want them."	virmundi	13.64688	-5.343641	comment	4.0	46.0	1506045623	9.856199
15335861	The thing is ORMs have made writing 	"The thing is ORMs have made writing easy queries easy and hard queries possible since at the very least 2005 with Rails, and they are easily extensible and composable. It's mostly a solved issue. If you want to do complex data manipulation, surprise, it takes a powerful tool. Seems a lot of the hype is the result of VC $ + naiveity/overselling about what MongoDB and co would be capable of. The marketing is natural - MongoDB made databases ""easy"" and easy is the only way to sell lowest common denominator tech to become a unicorn. Bad incentives for all involved.Sql is a kind of rite of passage? If you can't learn it or can't be bothered to learn it, you don't need to go anywhere near a database because you can't be bothered to understand the right tool.Granted, nosql has some uses, but thos"	aaron-lebo	13.540212	-5.455896	comment	4.0	16.0	1506395852	9.846015
15396470	I am no so keen on the government is	I am no so keen on the government issuing us other numbers either, but there has got to be a better way.As for UUID, so now I need to remember a 64 character UUID?	BatFastard	13.990263	-5.2110963	comment	4.0	23.0	1507067045	-13.661933
15459606	What are the people of the HN commun	What are the people of the HN community using CockroachDB for? In what kind of scenarios is this a good tool to choose?	stingraycharles	13.669416	-5.1894994	comment	4.0	15.0	1507829282	9.935593
15509968	"->""MongoDB was the database that mos"	"->""MongoDB was the database that most software developers said they wanted to work with, according to StackOverflow's survey of 64,000 developers.""Does this just seem like it can't be true? Does anyone know where or why this would be the case?"	jc_811	13.691405	-5.3063297	comment	4.0	14.0	1508435332	9.937544
15607584	Please don’t.When people are sending	Please don’t.When people are sending or sharing a document, they don’t expect to leak edit history of that document. And SQLite inherently leaks that edit history, in database freed pages and unallocated space. You can VACUUM the database after each save, but that’ll negate the performance benefits. Also VACUUM was designed to save space, not sure it reliably cleans up unwanted data.OTOH, these zipped XMLs are free from unwanted data, they (hopefully) only contain the data user wants to save, i.e. the content of the last version of the document.	Const-me	13.559723	-5.529056	comment	4.0	28.0	1509592913	9.763382
15608635	For me, the biggest reason not to do	For me, the biggest reason not to do this sort of thing is that SQLite still often refuses to work over network filesystems.I appreciate that this is because the authors are being careful about possible corruption when locking isn't working properly, but if they really mean the « SQLite competes with fopen() » line they need to find a way to get round this, because fopen() doesn't do that.	mjw1007	13.580072	-5.5378175	comment	4.0	19.0	1509610025	9.798061
15610327	I'd like to take a moment and look a	"I'd like to take a moment and look at this ""what if"" from the point of view of data archiving.Zip files use a well documented, easily-reproducable and widely implemented deflate algorithm. It's reasonable to assume that someone could, 100 years from now, unzip an OpenDocument file. The contents are XML files - basically text - which can be read with any simple text editor and parsed. The XML is also at least somewhat self-documenting regarding the contained document.SQLite databases have a binary format which is known to change periodically. An attempt to read a SQLite file in 100 years would have to know the exact version of the file, and be able to reach back through history to find that version of SQLite (or a compatible version), and find a way to compile it for whatever CPU architectu"	falcolas	13.543545	-5.540233	comment	4.0	19.0	1509630315	9.808837
15648691	Richard Hipp has said that they have	Richard Hipp has said that they have signed contracts to support SQLite3 for 35 years. SQLite4 is never going to happen.	assface	13.631362	-5.590384	comment	4.0	39.0	1510097168	9.841967
15648745	The biggest thorn I found working wi	The biggest thorn I found working with sqlite was the lack of ability to modify columns with ALTER TABLE which was a real pain.Doesn't look like this is fixed in sqlite4 though...	hoodoof	13.617391	-5.596715	comment	4.0	21.0	1510097625	9.856084
15648780	Anyone know how sqlite makes money?	Anyone know how sqlite makes money?	the_common_man	13.622495	-5.573522	comment	4.0	23.0	1510097852	9.873383
15648942	Everything I hear about SQLite3 alwa	"Everything I hear about SQLite3 always suggests that, essentially, it is considered ""done"". It does what it is supposed to do with great performance. There is nothing major left to do. If it doesn't meet your needs, pick a different SQL database.Which, while a totally alien concept in the modern software world, is actually a pretty cool thought.(I'm sure under the hood bugs are getting fixed and all)"	sliverstorm	13.579919	-5.553712	comment	4.0	20.0	1510099526	9.844197
15649288	>SQLite License. Warranty of title a	">SQLite License. Warranty of title and perpetual right-to-use for the SQLite source code.<from more info>Obtaining A License To Use SQLiteEven though SQLite is in the public domain and does not require a license, some users want to obtain a license anyway. Some reasons for obtaining a license include:    Your company desires warranty of title and/or indemnity against claims of copyright infringement.
    You are using SQLite in a jurisdiction that does not recognize the public domain.
    You are using SQLite in a jurisdiction that does not recognize the right of an author to dedicate their work to the public domain.
    You want to hold a tangible legal document as evidence that you have the legal right to use and distribute SQLite.
    Your legal department tells you that you have to pur"	ktta	13.65667	-5.596529	comment	4.0	16.0	1510104309	9.879419
15648590	Doubt still exists... Does this mean	"Doubt still exists... Does this mean 'concluded' as in ""We've finished polishing the pre production code and are close to releasing it"" or 'concluded' as in ""We have thrown our hands up in the air and won't be working on this thing any more to bring it to production"" ??!!??EDIT Seeing as I am getting slammed by downvotes, my comment here was simply pointing out that the headline I saw on HN could be read in multiple ways.  As a long time user of SQLite3, I was initially excited when I read the title as I had thought it meant something good coming from the SQLite team.  Turns out not to be.  That, to me, still entails doubt."	cyberferret	13.626522	-5.584868	comment	4.0	19.0	1510096355	9.87744
15712968	Don't use SQLite for production, for	Don't use SQLite for production, for all the love I have for it, the client libraries are usually locking accesses and don't work properly with concurrent reads/writes.	StavrosK	13.622925	-5.570138	comment	4.0	23.0	1510843634	9.821351
17393235	Following through the blog to the ac	Following through the blog to the actual docs: https://docs.mongodb.com/master/release-notes/4.0/> By default, multi-document transactions wait 5 milliseconds to acquire locks required by the operations in the transaction. If the transaction cannot acquire its required locks with the 5 milliseconds, the transaction aborts.Automatic cancellation rather than actual deadlock detection is going to be one hell of a footgun.I'd argue this is a double barreled footgun as most usage of MongoDB is from garbage collected languages. One wrongly time GC and your transaction is dead.	koolba	13.680536	-5.3114567	comment	4.0	19.0	1529941178	9.903466
17406400	I once undertook a contract at a pla	"I once undertook a contract at a place that opted for MongoDB based purely on 'speed' and then effectivity used it to build a relational database once they realised the need to apply different permissions to different parts of a document.Some hilarious bugs included a ""relationships"" collection that stored a record's identifier and an array of all the other documents it was related to. It was intended to be used for ""joins"" (yeah, I know). As the system grew and some customers created tens of thousands of records, all of which belonged to them so were represented in this collection. Eventually, the max array size in MongoDB was hit, which failed silently, rendering all of the data worthless.I spent much of my time creating a roadmap for them to migrate to PostgreSQL.I'm not blaming MongoDB"	petepete	13.628912	-5.361722	comment	4.0	14.0	1530085014	9.871404
17439705	For those seeking tl;dr: The answer 	For those seeking tl;dr: The answer is not to use MongoDB.	drej	13.683015	-5.321298	comment	4.0	12.0	1530513288	9.882147
17498090	Partly it is.  I had issues with bot	Partly it is.  I had issues with both sequelize and any-db.  However, since not using them resulted in a lot of bespoke SQL and object mapping, I found MongoDB preferable to  SQL without these libraries as well.	kevinoid	13.624523	-5.3693	comment	4.0	18.0	1531230931	9.859018
17506000	SQLite with a Fine-Toothed Comb (201	SQLite with a Fine-Toothed Comb (2016)	jxub	13.614886	-5.58357	story	4.0	109.0	1531307584	9.869487
17520927	> NoSQL came into existence because 	"> NoSQL came into existence because the databases at the time couldn’t handle the scale required.Arguably the first ""NoSQL"" database was a DIT, generally accessed via the LDAP protocol. OpenLDAP is one of the better known open source instances, but Novell eDirectory was there in the early part of this century, as was MS AD.In the case of Directory Services, it's a completely different approach to both SQL and the common ""Document Store"" approach of modern ""NoSQL"" options. Unless you go cowboy-mode, you're still adhering to schemas (albeit with the option to combine schemas), you still use indexed attributes to conduct searches, but you have a literal tree of objects with a more flexible layout (e.g. multi-value attributes without needing to use a JSON column) than with a regular SQL RDBMS."	stephenr	13.523553	-5.4203725	comment	4.0	50.0	1531463691	9.830349
17605110	They added a solution for this three	"They added a solution for this three or four years ago, by adding ""Open File Description Locks"" which don't have the misbehaviour that that SQLite comment is complaining about.See https://www.gnu.org/software/libc/manual/html_mono/libc.html..."	mjw1007	13.588977	-5.5597944	comment	4.0	35.0	1532467773	9.80747
17702320	This is a good article, but I feel l	This is a good article, but I feel like using Postgres instead of SQLite on the server side would achieve his goals even better:- No need to link with C code. There's a pure go driver for Postgres.- You get the 'psql' command to inspect and change the database, even while the web app is running.- You get a lot more database features.- You can keep the deployment simple by running Postgres on the web app server until you need to scale up.- Conversion to a full blown cloud database and horizontal scaling is just a matter of configuration.I understand the desire to keep the stack as simple as possible, but it looks to me like Postgres would actually be simpler than SQLite for the server side.	hathawsh	13.552294	-5.4633703	comment	4.0	19.0	1533594399	9.79892
17765135	I am interested in this topic as wel	"I am interested in this topic as well, although sqlite explicitly says that it is not meant for client-server configuration.
I still want to see if it is feasible and someone is using it in production."	newusertoday	13.586491	-5.544596	comment	4.0	14.0	1534330961	9.902854
17811332	We're loading all public-facing reso	"We're loading all public-facing resources - so posts, tags, authors and importantly the relations between them - in as few queries as possible, using fairly typical where...in queries in order to build the relations. SQLite uses variables for in queries, and so sites with a lot of content triggered the ""more than 999 variables"" error.Solvable, of course, but quite an interesting limitation to discover!"	erisds	13.591411	-5.553799	comment	4.0	14.0	1534870471	9.823585
21163788	We have started a project with SQLit	We have started a project with SQLite as the data store, but ended up replacing it with Firebird embedded due to two main reasons:- Lost decimal places on a simple database round-trip.- Issues with accessing the DB from multiple threads.	insulanian	13.561664	-5.515413	comment	4.0	19.0	1570249327	9.861093
21164038	I remember reading once upon a time 	I remember reading once upon a time about the sqlite file format being a good candidate for data transfer between systems/machines, as it's standardized, stable, and infinitely queryable. Has anyone here had any experience actually using it as such? What are your takeaways?	ISO-morphism	13.561309	-5.559648	comment	4.0	14.0	1570254762	9.847844
21404987	I wonder if sqlite could become this	I wonder if sqlite could become this in the future.	WrtCdEvrydy	13.614717	-5.573857	comment	4.0	30.0	1572487137	9.855704
21437345	Power outage corrupts Mongodb in the	Power outage corrupts Mongodb in the UniFi Cloud key. They won't fix that.There is no option to remove the dead/unplugged devices from the device list. The only way to remove is to reset and reconfigure everything from scratch.	newhotelowner	13.733693	-5.2235537	comment	4.0	13.0	1572821886	-0.5333311
21499176	The only drawback I have with FF now	The only drawback I have with FF nowadays is history management.I have enabled 'infinite history' (do not delete old history, ever) so I can keep a journal of what I've visited when. The history, as large as it might turn out, is just a few MB of an sqlite3 database (places.sql) -- problematic is the management of it using the Firefox UI. Searching is laggy and deletion of swaths of entries is impossible as it makes the  history manager UI hang for many minutes or even hours (=essentially I always kill Firefox when I do this by mistake). I suspect the GUI constructs a view of the sqlite db using single GUI objects tied to single DB entries and therefore has maximum overhead.Editing the places.sql file directly via the sqlite3 CLI (with Firefox shut down) is a matter of (milli)seconds at be	2ion	13.564195	-5.5241184	comment	4.0	27.0	1573408641	9.829133
21675536	I strongly recommend using Sqlite fo	I strongly recommend using Sqlite for your own document format. Sqlite is one of the most well-tested pieces of software on earth and ACID-compliant. You can even make it safer than the default if you don't need maximum performance only need it for storing documents. It is very crash and corruption proof, especially with the full sync option and if you use it from one thread only.	JohnStrangeII	13.533599	-5.51465	comment	4.0	28.0	1575209308	9.769812
21721034	Ask HN: Some questions on transition	Ask HN: Some questions on transitioning to UUID in a large ecosystem	rottyguy	13.987143	-5.216032	story	4.0	22.0	1575633517	-13.652968
39165626	SpatiaLite: Library extending SQLite	SpatiaLite: Library extending SQLite to support Spatial SQL capabilities	thunderbong	13.594385	-5.558415	story	4.0	44.0	1706449255	9.834229
39205098	RavenDB is expensive pay-to-use data	RavenDB is expensive pay-to-use database. I do not understand why would one choose this over Postgres.	romanovcode	13.576448	-5.4281945	comment	4.0	20.0	1706715658	9.853464
39219897	This is an awesome project, I love S	This is an awesome project, I love SQLite extensions and I think they have a ton of use. Giants props to Dan here, I haven't seen many SQLite extensions written in Zig, and I'm learning a ton reading through the source code.The column-oriented data is stored in large BLOBs inside of regular SQLite tables. It uses the SQLite incremental BLOB I/O API [0] to incrementally read/write data in a column oriented way.However, this project (and other SQLite extensions) will eventually hit a limit with SQLite's virtual table API. When you create a virtual table, you can perform a number of optimizations on queries. For examples, SQLite will tell your virtual table implementation the WHERE clauses that appear on the virtual table, any ORDER BYs, which columns are SELECT'ed, and other limited informat	alexgarcia-xyz	13.56346	-5.548022	comment	4.0	16.0	1706814798	9.846753
39260533	Is performance of UUIDs that importa	Is performance of UUIDs that important? In what practical scenario are you inserting thousands of records continuously all the time?	RedShift1	13.973379	-5.216391	comment	4.0	13.0	1707136142	-13.67403
39261226	Nice, but somewhat pointless, since 	Nice, but somewhat pointless, since the UUID (or any other type of ID representing an external entity) better be generated by the actor creating that entity, i.e. the FE client, or in the worst case, the BE/application server. If it is a database server generated ID, it could as well be a serial autoincrement bigint ;)EDIT:For those who misunderstood: I'm very much pro-UUID, and against serial autoincrement server-generated IDs. With the exception when you need to heavily optimize for speed and/or index storage space. And even then there are hybrid solutions like using UUID externally, and serial IDs internally.https://news.ycombinator.com/item?id=39261435	nivertech	13.9689665	-5.2181892	comment	4.0	24.0	1707141379	-13.655932
39261730	Not OP, but I can answer this:Intege	Not OP, but I can answer this:Integers don't scale because you need a central server to keep track of the next integer in the sequence. UUIDs and other random IDs can be generated distributed. Many examples, but the first one that comes to mind is Twitter writing their own custom UUID implementation to scale tweets [0][0]: https://blog.twitter.com/engineering/en_us/a/2010/announcing...	welder	13.903532	-5.190952	comment	4.0	32.0	1707144327	-13.664579
39261919	"I'm amazed at how ""we"" have managed "	"I'm amazed at how ""we"" have managed to turn such a simple idea as ""128 bits is a large enough address space for uncoordinated generation to be essentially collision free"" into such a ""heavy"" concept with 7 different versionsIf you want to do something smart like encoding your node ID within the value, or prefixing a timestamp for sortability, then sure, do that in your application. No one else really needs to care how you produced your 16 bytes. Just do some napkin math to make sure you're keeping sufficient entropyI'm not sure ""UUID"" even needed to be a column type, versus a ""INT16"" and some string formatting/parsing functions for the conventional representation (should you choose to use that in your application). You could also put IPv6 addresses in the same type. Though I guess this dep"	didntcheck	13.956742	-5.2021813	comment	4.0	30.0	1707145469	-13.694396
39268156	I've said this before on HN, but we'	I've said this before on HN, but we're talking about UUID v7 again, so it bears repeating: prefer UUID v4 for unique keying, of the sort that's transferable between databases. For timestamps, use timestamps, to sort by insertion, use an autoincrementing primary key. Disk space is not so expensive that we can't afford all three of these things.Conflating timestamps and uniqueness is a conflation. These concerns are best separate.  If you put a timestamp in your UUID, your UUID now has a timestamp. You can't remove it if you don't want the timestamp to be a part of the uniqueness any more.	samatman	13.9785795	-5.217649	comment	4.0	18.0	1707172329	-13.670974
32808282	WP could make a test suite mandatory	WP could make a test suite mandatory and run tests on their hardware under their supported configurations; if it doesn't work on sqlite, it is not accepted in the plugin index.Likewise, security checks.	Cthulhu_	13.658509	-5.6134715	comment	4.0	29.0	1662979977	9.850428
32808805	SQLite also doesn't use CVS, SVN, or	"SQLite also doesn't use CVS, SVN, or Perforce.If this title were ""SQLite uses Fossil"", it'd be more apparently just another ad for Fossil."	sshine	13.617055	-5.587353	comment	4.0	17.0	1662983752	-11.949528
32909167	SQLite: Past, Present, and Future	SQLite: Past, Present, and Future	ingve	13.608549	-5.579771	story	4.0	96.0	1663663130	9.843667
32963219	What's the use case for something li	What's the use case for something like this? I'd think that instead of building a distributed version of SQLite on top of another database engine, you'd just choose a distributed database in the first place. Are there benefits to the way SQLite works that outweigh the choice to just use some other flavor of SQL?	bastawhiz	13.569908	-5.5130625	comment	4.0	17.0	1664031538	9.829715
33048469	Magma, a new storage engine for Couc	Magma, a new storage engine for Couchbase	hodgesrm	13.522706	-5.212308	story	4.0	51.0	1664646790	9.624356
33070968	just wondering, what did you use SQL	just wondering, what did you use SQLite for on a wedding website?	peanut_worm	13.607309	-5.577307	comment	4.0	20.0	1664818878	9.92133
31770618	CockroachDB's Consistency Model	CockroachDB's Consistency Model	Twixes	13.566947	-5.207049	story	4.0	102.0	1655411414	9.851455
31785613	>SQLite4 was an experimental rewrite	>SQLite4 was an experimental rewrite of SQLite that was active from 2012 through 2014. All development work on SQLite4 has ended. Lessons learned from SQLite4 have been folded into the main SQLite3 product. SQLite4 was never released. There are no plans to revive it. You should be using SQLite3.https://sqlite.org/src4/doc/trunk/www/index.wiki	tesrx	13.623963	-5.588825	comment	4.0	15.0	1655507252	9.866039
31821060	"Is MongoDB really ""in"" now? From wha"	"Is MongoDB really ""in"" now? From what I've seen it was popular for a while a few years ago with the MEAN stack and all that but it didn't stay popular, every job I've looked at was still SQL. I did work somewhere that went NoSQL but it wasn't MongoDB, it was DynamoDB."	s-lambert	13.642702	-5.330873	comment	4.0	13.0	1655795477	9.871663
31873529	They're hard if you can't tolerate d	They're hard if you can't tolerate downtime, which most production users can't.While that's true for a lot of database systems, some more recently designed are much better. [1][1]: https://www.cockroachlabs.com/docs/stable/upgrade-cockroach-...	sascha_sl	13.701383	-5.2516294	comment	4.0	29.0	1656146224	9.902016
31886804	Hmm, is this some sort of Meta I’m m	Hmm, is this some sort of Meta I’m missing? It feels strange to mix so many cultural ‘suggestions’ with a database product.> Listen willingly to holy reading.> Devote yourself frequently to prayer.> Daily in your prayers, with tears and sighs, confess your past sins to God, and amend them for the future.Anyway, sqlite is a good product and I don’t even mind all that much to have a code of Ethics associated to it, just not a thing you see often.	ThalesX	13.625481	-5.5580673	comment	4.0	19.0	1656269830	9.839152
31887562	> The founder of SQLite and all curr	> The founder of SQLite and all current developers have pledged to follow the spirit of The Rule to the best of their ability.Sure, as far as I'm aware code of conducts/ethics only ever apply to contributors, no-one has beliefs being forced upon them. But that seems to be about the highest bar of entry for an interested developer I have seen in any project.Not waving pitchforks here, I'm fine with them having this code of ethics, even tough I disagree with about half the points and find being asked to do such a pledge way to intrusive into personal life.	smoe	13.666338	-5.601232	comment	4.0	20.0	1656274788	-8.946318
31909866	I mean SQLite is living on a single 	I mean SQLite is living on a single node, what exactly do you do when you have failure, when more than one process need to acces the DB, when you need RBAC etc ...	Thaxll	13.568848	-5.4984293	comment	4.0	15.0	1656433968	-4.3278527
31909133	> Once again, SQLite happily stored 	> Once again, SQLite happily stored my UUIDs on this column and even indexed them, but to get these across to PostgreSQL I needed to fix the schema and properly declare these keys as strings.In PostgreSQL you're leaving performance on the table if you store UUIDs as strings instead of as the built in UUID type (128-bit value under the hood)	msbarnett	13.983197	-5.219968	comment	4.0	45.0	1656430778	-13.6568575
31991598	The SQLite Index Suggester	The SQLite Index Suggester	polyrand	13.542593	-5.5469985	story	4.0	199.0	1657044172	9.780585
32014957	Litestream is awesome, but I don't s	Litestream is awesome, but I don't see that it enables multi-way merges yet. Am I wrong?	uniqueuid	13.519751	-5.530612	comment	4.0	15.0	1657206032	9.736539
39383725	Optimizing SQLite for Servers	Optimizing SQLite for Servers	unsolved73	13.584431	-5.516233	story	4.0	65.0	1708010506	9.813467
39414646	> As I discussed in an earlier post[	> As I discussed in an earlier post[3] when you use Postgres native UUID v4 type instead of bigserial table size grows by 25% and insert rate drops to 25% of bigserial. This is a big difference.Does anyone know why UUIDv4 is so much worse than bigserial? UUIDs are just 128 bit numbers. Are they super expensive to generate or something? Whats going on here?	josephg	13.984934	-5.2188063	comment	4.0	13.0	1708213721	-13.6623535
39527441	I was surprised to see SQLite listed	I was surprised to see SQLite listed as a source but not as a destination. Any big reasons for that or is it just something you haven't got around to implementing yet?I've been getting a huge amount of useful work done over the past few years sucking data from other systems into SQLite files on my own computer - I even have my own small db-to-sqlite tool for this (built on top of SQLAlchemy) - https://github.com/simonw/db-to-sqlite	simonw	13.654152	-5.571646	comment	4.0	13.0	1709057787	9.888242
39549463	How (and why) we brought SQLite to t	How (and why) we brought SQLite to the Cloud	marcobambini	13.628143	-5.5629807	story	4.0	8.0	1709215796	9.877425
39559972	I once worked at a place that had ma	"I once worked at a place that had many different specialised  applications serving different needs and serving different data.The incoming CEO who wanted to make his mark (let's call him Derek) had an impressive background in marketing decided that the right thing to do was to rationalise everything into one huge database.They employed a small army of consultants who covered the entire office (it was a big office) in huge database schema diagrams.  This took several months. 
 Eventually they ""discovered"" that the only data that the schemas had in common was a reference, a description, and a created date field.So they immediately cancelled the project and we all breathed a sigh of relief.  Haha, only kidding.  Of course they didn't.  The right solution was to go schemaless.  Enter mongodb. "	MattPalmer1086	13.57627	-5.3755803	comment	4.0	12.0	1709283426	9.875035
39657397	SQLite on macOS: Not ACID compliant 	SQLite on macOS: Not ACID compliant with the bundled version (2022)	tempodox	13.636784	-5.5986695	story	4.0	72.0	1710056118	9.861608
32158251	Back from the Future: Global Tables 	Back from the Future: Global Tables in CockroachDB	andreimatei1	13.611665	-5.216225	story	4.0	94.0	1658266283	-10.693654
32159791	>Fits well in a lot of use cases.Can	>Fits well in a lot of use cases.Can you share the use cases? Why Mongo works better than Postgres?	asadawadia	13.630251	-5.379203	comment	4.0	26.0	1658277037	9.873012
32256971	I sometimes wonder how much of this 	"I sometimes wonder how much of this objection to SQLite is purely technical, and how much is due to the fact that Dr. Richard Hipp would not exactly be a great ""cultural fit"" at places like the New York Times or Mozilla."	LAC-Tech	13.642911	-5.599507	comment	4.0	15.0	1658956017	9.853349
32279383	I have been using Apache Superset on	I have been using Apache Superset on top of sqlite for my personal use, and am fairly happy with it. Any advantages/disadvantages of Tabler compared to Superset?	asdvasewe	13.590613	-5.5638733	comment	4.0	15.0	1659114208	-11.467642
32320009	Mongo FUD has more to do with the fa	Mongo FUD has more to do with the fact that RDS...es work better with almost any line of business application. The ONLY application I have ever seen Mongo, or any other key:document store work well is integrating with form.io for custom forms. And even then, RDS might have been a better choice.	throw1234651234	13.6596985	-5.3292913	comment	4.0	25.0	1659454703	9.962851
32335295	SQLite-HTML: A SQLite extension for 	SQLite-HTML: A SQLite extension for querying, manipulating, and creating HTML	thunderbong	13.601141	-5.575763	story	4.0	130.0	1659551802	9.841753
32356633	I really like ULID for this problem 	I really like ULID for this problem (e.g: https://github.com/ahawker/ulid)- similar characteristics to UUID: same number of bytes, equivalent collision resistance, hard to guess, etc.- start with a date, is monotonic, and is lexicographically sortable: not only it has great locality but sorting is super easy and most code get it right by default.- can be created from an existing date or uuid, and exported to a uuid, so there is a migration path.- you get the creation date for free, which is always nice. As a bonus, you can now use the uuid as a base for dispatching, bracketing, sharding, etc.	BiteCode_dev	13.985872	-5.2156253	comment	4.0	23.0	1659709940	-13.672775
32359039	UUIDs have always seemed to be an ov	UUIDs have always seemed to be an over-engineered solution to a minor problem. In the cases I've seen them used folks are trying to get away from auto-incremented identifying serial numbers. Ostensibly, this is because it makes guessing other IDs in the database (or whatever) fairly simple and that could be a source for leaking information.To me this is just security though obscurity. Just because I know an identifier doesn't mean I should be able to do _anything_ with it. If there are contexts where you really can't share the ID you should salt and hash it and use that value.	codereviewed	13.974909	-5.2064247	comment	4.0	12.0	1659719790	-13.641236
32407919	They were using it like a NoSQL data	They were using it like a NoSQL database back in 2010, just one year after MongoDB started. So there were no options.In 2022, there are so many more mature, reliable, battle-tested NoSQL options that could have solved their problem more elegantly.But even today, if I were to build Reddit as a startup, I'd start with a Postgres database and go as far as I can. Postgres allows me to use relations when I want to enforce data integrity and JSONB when I just want a key/value store.	senttoschool	13.544615	-5.3849525	comment	4.0	27.0	1660106585	9.82532
32408378	On a side note, I find it a bit iron	On a side note, I find it a bit ironic how NoSQL was all the rage back in the last decade or so but in 2022, NoSQL DBs are racing to add SQL querying back to key value stores.It turns out that SQL is crucial to non-app-developers such as business analysts, data scientists. Trying to setup an ETL to pull data from your MongoDB datastore to a Postgres DB so the analysts could generate reports is such a waste of time and resources. Or worse, the analysts have to request devs to write Javascript code to query the data they need. For this reason alone, I will always start with a DB that supports SQL out of the box.	senttoschool	13.543318	-5.424214	comment	4.0	16.0	1660112682	9.814658
32408603	Indeed, I do wonder why industry sti	Indeed, I do wonder why industry still defaults to sql/relational instead of mature nosqls (there aint just mongo)	hardware2win	13.5583	-5.40985	comment	4.0	19.0	1660114979	9.857106
32415293	A company I work for runs MySQL on a	"A company I work for runs MySQL on an IoT base station product (Beaglebone-like hardware).  Tables seems to corrupt every so often, which typically are repairable with a ""mysqlcheck --auto-repair"" which they have as part of the boot sequence, but not always.  These corruptions seem to be due to bad batteries or the field team holding down the power button too long.Would sqlite be less prone to table corruption?"	agildehaus	13.641702	-5.6268067	comment	4.0	12.0	1660151208	9.784617
32438489	I am curious what the situation is w	I am curious what the situation is where the recovery log grows to large size and what the actual consequence of this would be.We have been using SQLite in WAL mode for over half a decade and never witnessed this. Several of our databases can see concurrent access from hundreds of users with transactions in the 1-10 megabyte range, so I find it a bit odd this never came up.	bob1029	13.589374	-5.508541	comment	4.0	12.0	1660311695	9.819034
32477284	I have been thinking about using som	I have been thinking about using some sort of UUID-generator ([UUID]@mydomain.xz) whenever I sign up for a new site, but I just can not think of a _good_ way to keep track of them.	xdrosenheim	13.98522	-5.211416	comment	4.0	14.0	1660607448	-13.655689
32479558	> The SQLite documentation literally	"> The SQLite documentation literally says use Postgres and not it for networked use cases> https://www.sqlite.org/useovernet.htmlIt's not what this page says. This page suggests PostgreSQL if accessing the SQLite file from the application would induce a network connection (because of a network filesystem). Not if the application is accessed over the network.Using SQLite for a network service when the app runs on the same machine as the SQLite file is perfectly fine.> (unless you use WAL or rollback, in which case why not just use Postgres?)Again. WAL / rollback is how SQLite works by default. The page does not suggest using WAL, it suggests using WAL, ""but do all reads and writes from processes on the same machine that stores the database file"", is you use a networked FS. And yes, in this "	jraph	13.5895815	-5.5087833	comment	4.0	14.0	1660628612	9.847649
32479113	Does SQLite still not support remote	Does SQLite still not support remote connections? Without that, it's hard for me to take it seriously for most RDBMS use cases.	beebmam	13.589085	-5.556758	comment	4.0	20.0	1660623068	9.857126
22099387	In WAL mode you can write from multi	In WAL mode you can write from multiple threads without any problem, but you need to keep serializability in mind. Specifically, no concurrent write transactions are allowed. In other words, you can't have a transaction start at X, have another transaction start at X+1, issue DML and commit, and expect your original transaction from X being able to commit - it will never be able to.Some SQLite wrappers (notably, Python's) mess with the start and rollbacks of transactions and make this appear buggy.	blattimwind	13.56318	-5.4669003	comment	4.0	14.0	1579533760	9.806873
22152538	«just write your own server on top o	«just write your own server on top of serverless embedded SQLite to get to acceptable performance without needing a client/server database»(Honestly, once you are at the point where concurrency causes performance issues with SQLite, you are better off moving to databases designed to handle concurrency rather than trying to cobble together your own workaround - you have reached the point where the drawback of SQLite‘s architecture outweigh its advantages and the advantages of other databases architectures outweigh their drawbacks)	pilif	13.599097	-5.5330505	comment	4.0	18.0	1580053091	9.813014
22153537	You can read/write CSV files, JSON, 	You can read/write CSV files, JSON, JPEG, WAV, MP3, MP4, etc. into memory as well. That doesn't make any of them an RDBMS.SQLite is a file format. It has a nice API and uses SQL as the domain language for read/write logic. If it didn't use SQL for the logic, would you still be confused?	bane	13.542769	-5.5735397	comment	4.0	17.0	1580061831	9.769745
22239366	In fairness, the guidelines they ref	"In fairness, the guidelines they reference suggest you do exactly what the comment says they're doing (assuming they're keying the hash). The guidelines seem explicitly written with the idea that unique identifiers _derived from_ this value are not similarly quarantined, provided that you cannot take the derived value and ""reverse"" it back to the original identifier.Quoting from https://www.freedesktop.org/software/systemd/man/machine-id....:This ID uniquely identifies the host. It should be considered ""confidential"", and must not be exposed in untrusted environments, in particular on the network. If a stable unique identifier that is tied to the machine is needed for some application, the machine ID or any part of it must not be used directly. Instead the machine ID should be hashed with "	chias	13.968276	-5.19787	comment	4.0	14.0	1580841884	-13.587976
35612379	Ask HN: Anyone Using RethinkDB in Pr	Ask HN: Anyone Using RethinkDB in Production?	m33k44	13.683927	-5.2718296	story	4.0	8.0	1681815994	-12.812456
35648076	I’ve said it before, but I’d love to	I’ve said it before, but I’d love to see a best-practices CRUD app done in tcl, tk, and SQLite along the lines of the north winds thing from Microsoft.  The SQLite interface in tcl is a thing of beauty to rival tk.	buescher	13.561657	-5.5518575	comment	4.0	13.0	1682034248	9.793714
35743408	> compiling SQLite to WASMIs there s	"> compiling SQLite to WASMIs there support for ""compiling"" WASM to java so we can use Sqlite from java without using any JNI library?"	silvestrov	13.60125	-5.6077585	comment	4.0	14.0	1682698722	9.777522
35906947	Can you give a specific example of w	Can you give a specific example of what you are missing when using SQLite?	MrThoughtful	13.608036	-5.5883603	comment	4.0	15.0	1683832355	9.883619
35963602	How are people using sqlite within a	"How are people using sqlite within a multi-threaded, asynchronous runtime: are you using a synchronization lock?  SQLite seems to ""kinda, sorta"" support multi-threading, requiring special configuration and caveats.  Is there a good reference?"	say_it_as_it_is	13.59426	-5.537456	comment	4.0	17.0	1684252535	9.779954
35983996	- DuckDB is written in C++  - SQLite	"- DuckDB is written in C++  - SQLite is written in C

I wouldn't consider any of those written in a memory safe language. Although SQLite has been battle hardened over many years, while DuckDB is a relatively new project.That being said, has been efforts of reimplementing SQLite in a more memory safe language like Rust.e.g. https://github.com/epilys/rsqlite3"	de6u99er	13.5977335	-5.6679673	comment	4.0	17.0	1684382393	9.407631
36022678	Why plain text over something like s	Why plain text over something like sqlite (or another similar open database).	crop_rotation	13.582478	-5.565256	comment	4.0	12.0	1684687735	9.785561
36113774	No outgoing http requests, no abilit	No outgoing http requests, no ability to connect to an external database such as mysql- only SQLite is used.No explanation for what vulnerabilities standard Drupal is actually being hardened against.	zdragnar	13.579494	-5.563257	comment	4.0	22.0	1685367124	9.862594
36156806	MongoDB remains the 5th most popular	MongoDB remains the 5th most popular database: https://db-engines.com/en/rankingAnd there are four major reasons still to choose MongoDB over something like PostgreSQL.a) PostgreSQL has terrible support for horizontal scalability. Nothing is built-in, proven or supported.b) MongoDB has superior ability to manipulate and query the JSON.c) MongoDB is significantly faster for document-attribute updates.d) MongoDB has better tooling for those of us that prefer to manage our schema in the application layer.	threeseed	13.618102	-5.3506646	comment	4.0	20.0	1685650818	9.880991
36186368	I was curious how this works and the	I was curious how this works and then I saw the sqlite requests in the network tab. It's amazing to see what we have access to these days -- SQLite over HTTP over IPFS to provide a giant, censorship-resistant database!	mmastrac	13.5825815	-5.5410542	comment	4.0	33.0	1685892517	9.853562
36216490	I built myself something similar on 	I built myself something similar on top of SQLite and Combine.Now I’m confused, should I abandon it and go with the first hand solution? I would actually prefer that but this requires the new versions of the Apple platforms. Why wouldn’t Apple make these available downstream?	mrtksn	13.597977	-5.560938	comment	4.0	29.0	1686073576	9.813262
36303263	I wonder why users were angry about 	I wonder why users were angry about some files in their temp folder. Did McAfee fail to cleanup those files, or were they too big?Edit: more information here: https://www2.sqlite.org/cvstrac/wiki?p=McafeeProblem Apparently, McAfee kept those files locked when it was using them, so the files couldn't be deleted and people got angry that they couldn't clean them up. Sounds like a loud minority to me.	sedatk	13.578294	-5.571243	comment	4.0	23.0	1686615011	-7.8752704
36337983	SQLite seems to be gaining popularit	"SQLite seems to be gaining popularity with even larger projects which is surprising to me. As I see it, the big value prop of SQLite is that it runs in-process which, for a webapp, is almost nil?Other than that, it's not like queries are any simpler and the ""simple"" type system is, in my opinion, not a feature. I get that some might disagree with that.Is there some other reason why you would prefer it?"	kristiandupont	13.58909	-5.572451	comment	4.0	18.0	1686819746	9.844828
36431082	> sacrifice the beauty and elegance 	> sacrifice the beauty and elegance of UUIDsOut of curiosity, what makes UUIDs more elegant or beautiful than just plain old integers?	dewey	13.999625	-5.2078447	comment	4.0	28.0	1687436811	11.309847
36431576	For me, the visual noise is a downsi	For me, the visual noise is a downside for UUIDs.  A lot of time investigating data issues means glancing at query results and deciding if something looks unexpected.  I just can't parse a UUID with my eyes that quick.  I've come up against this at my current job a little too often and I'm cursing the decision to switch to UUIDs.  I know, it's a balancing act of competing concerns.  But for us moving to UUIDs was future proofing for a problem that never arose, and the senior dev who made us switch left the company a few years ago.  I just don't like the dev experience of UUIDs in a world where you do have to get hands (and eyes) on the data all the time.	Timpy	13.961065	-5.208021	comment	4.0	17.0	1687439276	-13.660589
36479117	A few sites of mine are backed by SQ	A few sites of mine are backed by SQLite databases replicated daily from another source. Right now I’m rsyncing them, but sending an even increasing number of gigabytes a day isn’t great for the long term. Anyone aware of some sort of checkpointing and incremental sync solution for SQLite? Doesn’t need to be real time, and shouldn’t be real time, really. This one isn’t what I’m looking for unfortunately, the “sign up for a free account” part is also pretty crazy.	oefrha	13.5621	-5.4785905	comment	4.0	14.0	1687784138	9.790744
28706151	Any suggestions to learn and go deep	Any suggestions to learn and go deep in PostgreSQL for someone who worked mostly on NoSQL (MongoDB)?From the few days I have explored it, it is absolutely incredible, so congratulations for the work done and good luck on keeping the quality so high!	hackandtrip	13.553227	-5.3945394	comment	4.0	16.0	1633009070	9.869086
28708734	As someone that mostly shared that o	"As someone that mostly shared that opinion for the last decade or more, I recently set up a cluster for work, and everything seems much more production level quality than I remember or what I assumed it was going to be like.  I'm not the one using it for queries every day, but I did do a bunch of testing for replication and failed nodes to confirm that I understood (and could rely) on the claims of robustness, and it seemed to be stable and with good documentation of what to expect in different scenarios and how to configure it (which is not what I experienced doing the same testing back in 2010-2011).All in all, my impression of MongoDB now is that they're one of those ""fake it till you make it"" success stories, where they leveraged their popularity into enough momentum to fix most their "	kbenson	13.656657	-5.3071566	comment	4.0	24.0	1633022372	9.885112
23414585	What strikes me as odd is why SQLite	What strikes me as odd is why SQLite is committing changes just to make an unreleased compiler happy...	jfkebwjsbx	13.661325	-5.6048846	comment	4.0	21.0	1591264152	9.869229
23417345	What happened:1.  OSSFuzz reports a 	What happened:1.  OSSFuzz reports a bug against SQLite.2.  SQLite dev tries to fix the reported problem but is unable to repro the bug on his desktop3.  SQLite dev replicates the OSSFuzz build environment which uses clang-11.0.0 and is then able to repro the reported bug4.  SQLite dev finds that the bug isn't in SQLite at all, but rather in clang-11.0.05.  SQLite dev patches SQLite to work around the clang bug, posts a brief note about this on the SQLite forum, and goes to bed.6.  The post on the SQLite forum is picked up by HN while the SQLite dev is asleep.  LLVM devs read HN, isolate and fix the clang problem, all before the SQLite dev wakes up.	SQLite	13.642767	-5.606532	comment	4.0	19.0	1591282308	9.803729
23447525	Thanks for reading. We have some pla	Thanks for reading. We have some plans around this, see the RFC - https://github.com/apache/couchdb-documentation/pull/424In general, we are trying to move away from running your whole application in CouchDB. We would prefer that you have an application layer in front of your CouchDB instance. We recommend that you put up a proxy if you want to expose your replication to PouchDB. That way you can add security around that endpoint.	garrensmith	13.598643	-5.2060823	comment	4.0	27.0	1591539720	9.679246
23508225	I was there in Aug 2019 and I did he	"I was there in Aug 2019 and I did hear them talking about mongo, There was a programme at the time to ""refactor"" their estate, a part of that they wanted to replace bunch of ad-hoc databases with clunky- or no data governance with one (or fewer) central places, which will be under Data IT control. The rationale was to reduce risk of data loss, leak or general business continuity issue in what was 6-12 month project.The cost of architecting relational model that would be cover for 65 mini databases in a bank will be astronomical. It is far easier to setup no-SQL entry point that would auto-conform for whatever requirements upstream applications might have.It is a technical win for Mongo, but I don't believe this is an attempt by HSBC to get up to speed with database trends. HSBC are removin"	bluestreak	13.672517	-5.3187184	comment	4.0	16.0	1592041448	9.883542
23508799	This title is misleading, and the ar	This title is misleading, and the article is missing a key piece of information.This is ONE system at HSBC - out of literally HUNDREDS (maybe thousands) of applications.  It's not as if HSBC is moving ALL of its applications to MongoDB.  HSBC doesn't have a single tech stack.  They have thousands of IT employees all using different tech, in different parts of the world, for different departments.  This might be as inconsequential as the system that catalogues security camera feed URLs - or maybe the one that monitors remote employee company mobile data usage - who the F knows, because the article gives us zero information.Account Management, Credit Cards, Mortgages, Security, Asset Management, HR, Legal, Compliance, Regulatory, Risk Management, Trading, Operations, Building management, Pay	koheripbal	13.691533	-5.298035	comment	4.0	21.0	1592049425	9.907472
23510420	Amongst all the praise we're seeing 	Amongst all the praise we're seeing for this approach here, may we please just have a minute's silence for the various exploits sqlite has seen when loading arbitrary database files over the years?My recent favourite being https://media.ccc.de/v/36c3-10701-select_code_execution_from...	ris	13.59527	-5.5721965	comment	4.0	22.0	1592064623	9.868668
23511478	I don't see the practical attack vec	I don't see the practical attack vector. For every use case I have for SQLite, none of them involve allowing someone to execute arbitrary SQL against one of my databases. We also don't do any loading of databases from untrusted parties. Seems like a hypothetical scenario was invented here that could just as well be applied to any database engine with similar outcomes.	bob1029	13.55272	-5.5352955	comment	4.0	15.0	1592072741	9.8737135
23511706	To my very limited knowledge it is v	To my very limited knowledge it is very common for iOS and android apps to store data in SQLite.Is it possible to extract or change these databases?I have a few (offline) apps on my phone that I’d love to append data to	wodenokoto	13.564004	-5.5190496	comment	4.0	14.0	1592074419	9.810951
23856069	I always use    UUID PRIMARY KEY DEF	"I always use    UUID PRIMARY KEY DEFAULT uuid_generate_v1mc()

In Postgres. It will give you UUIDs and the larger keyspace, without being excessively random (they're basically almost sequential). I do this always, even if the table has other int columns that look like friendly values that could be used as PKs. Some time in the future they will ruin your day."	minxomat	13.970411	-5.223542	comment	4.0	19.0	1594877195	-13.663576
23898187	Really, I would have thought to succ	"Really, I would have thought to successfully pull off a scam like this, you would need to wait at least another decade for the practitioners burned by MongoDB and the rest to retire or forget. Yet here we are in 2020, and it's suddenly 2009 all over again.Hats off to the founders for netting $15MM in VC money for a ""disruptive, innovative, game-changing"" rehash of IBM's IMS from 1966."	longtermmemory	13.7052	-5.2897615	comment	4.0	14.0	1595255320	9.920067
23996435	You can't possibly be serious.There 	You can't possibly be serious.There is no hype for NoSQL or MongoDB on HN. In fact it is the complete opposite with every one trying to push SQL and PostgreSQL for every use case under the sun.	threeseed	13.623389	-5.3455424	comment	4.0	12.0	1596104081	9.877473
24120536	A very simple, basic SQL query would	"A very simple, basic SQL query would be something like ""select * from users where foo=bar;""Already, we're introducing a weird inversion of syntax that, in my experience, trips up people learning it: data in SQL is stored as ""rows"" with ""columns"" inside ""tables"". More formally, we've got a hierarchical relationship where Tables > Rows > Columns, yet we write the query as Columns > Table > Rows.There are far more consistent and beautiful querying languages than SQL: I would point to MongoDB's query language, which is less of a query language and more of a static javascript-interpretable library, but is still far easier to learn and more consistent than SQL. The same query in MongoDB: ""db.users.find({ foo: ""bar"" });"". How is this better? It embeds the operation in the statement (""find""); read"	013a	13.533815	-5.4816904	comment	4.0	32.0	1597155822	9.8697195
24120916	>  I would point to MongoDB's query 	">  I would point to MongoDB's query languageseriuosly?    db.orders.aggregate([
       {
          $lookup:
             {
               from: ""warehouses"",
               let: { order_item: ""$item"", order_qty: ""$ordered"" },
               pipeline: [
                  { $match:
                     { $expr:
                        { $and:
                           [
                             { $eq: [ ""$stock_item"",  ""$$order_item"" ] },
                             { $gte: [ ""$instock"", ""$$order_qty"" ] }
                           ]
                        }
                     }
                  },
                  { $project: { stock_item: 0, _id: 0 } }
               ],
               as: ""stockdata""
             }
        }
    ])

VS    SELECT *, stockdata
    FROM orders
    "	lostjohnny	13.585792	-5.402169	comment	4.0	19.0	1597157747	9.838843
24146488	My initial thought is I'd rather jus	"My initial thought is I'd rather just have a module that would find project-related .sql files and parse into named blocks based on the comments, treating them as named strings. No db entanglement required, just a simple way to organize queries in sql files. You would use it more like this:    import sqlite3
    import project_queries as queries  # a module that loads queries from local .sql files as strings in module namespace

    conn = sqlite3.connect('myapp.db')
    
    cursor = conn.cursor(queries.get_all_users)
    #                    ^^^^^^^^^^^^^^^^^^^^^
    
    users = cursor.fetchall()
    # >>> [(1, ""nackjicholson"", ""William"", ""Vaughn""), (2, ""johndoe"", ""John"", ""Doe""), ...]

aiosql may add some features to help with passing values to the query. I see `^` used with `:users` in"	jdnier	13.575231	-5.5970263	comment	4.0	22.0	1597343079	9.860617
24162172	I’ve heard (way) more than one story	I’ve heard (way) more than one story about MongoDB mysteriously annihilating all the data. Launched into oblivion.The worst imaginable outcome for a database.	jointpdf	13.691945	-5.3053565	comment	4.0	13.0	1597433016	9.893509
24233975	Placeholder – Offline Coarse Geocode	Placeholder – Offline Coarse Geocoder Backed by SQLite	alixaxel	13.616461	-5.570184	story	4.0	84.0	1598009697	9.857123
24283971	I couldn’t imagine doing anything in	I couldn’t imagine doing anything in MongoDB or understand why that is desirable.We have used Postgres from day 1 in March and are now 1200 people. Managing growth with a  JSON blob sounds absolutely insane.You need _more_ guarantees, not fewer.	tyre	13.57314	-5.4447255	comment	4.0	14.0	1598458980	9.817431
24334079	I am not sure why UUID is really not	"I am not sure why UUID is really not that ""secure"" since the security properties are coming mostly from used PRNG. v4 is mostly just random 16 bytes that is the same as key length for AES-128."	ex3ndr	13.996157	-5.2097325	comment	4.0	16.0	1598896526	-13.666453
24333545	Cracking Phobos UUID	Cracking Phobos UUID	tux1968	14.005764	-5.2122326	story	4.0	52.0	1598893811	-13.665471
24338748	> I wonder if I’ll ever be able to g	> I wonder if I’ll ever be able to get this done.I can’t help but be extremely pessimistic. This is an insanely challenging project. Looking at the author’s other side projects: https://euandre.org/about.htmlI’d guess this project is about 10,000x-100,000x as challenging as the Songbooks one. And the author has no obvious experience writing DBs, that I can see?This project seems at least as ambitious as CockroachDB. Development started on CockroachDB 6.5 years ago, was founded by a group of Google alums with relevant distributed systems experience (working on GFS), and it since became well funded and has had a sizeable team working on it full time for years. This project would be almost impossible to make significant progress against without a strong, well funded team working on it for yea	yashap	13.568096	-5.2393804	comment	4.0	28.0	1598937072	9.853011
24338881	> SQLite [...] assumes a POSIX files	> SQLite [...] assumes a POSIX filesystem that would have to be emulated.No it does not. It has a pluggable storage interface that makes no such assumption: https://www.sqlite.org/vfs.html	cafxx	13.600484	-5.566098	comment	4.0	12.0	1598938598	9.862801
24388155	Ask HN: Why are you using MongoDB?	Ask HN: Why are you using MongoDB?	tehlike	13.620285	-5.363419	story	4.0	4.0	1599354597	9.863614
20168652	Looking back, it was unbelievable to	"Looking back, it was unbelievable to see how huge the storm caused by Intel's ""processor serial number"" in Pentium 3 was, that even forced Intel to withdrew it.Meanwhile, nobody has ever said anything about the serial numbers of hard drives, GPUs, motherboards, RAM modules, Ethernet MAC address, etc, etc, etc. Nowadays, basically everything comes with one UUID.Pretty illogical, isn't it?> We've long lost the war on privacy.Agree. I understand UUID is important in engineering for many purposes, but the fact that nobody is talking about it anymore (because they are nothing when compared to more severe issues like fingerprinting) indicates we've long lost the war on privacy."	segfaultbuserr	13.964153	-5.2029815	comment	4.0	27.0	1560369561	-13.704287
20493878	RethinkDB, SageMath, Andreessen-Horo	RethinkDB, SageMath, Andreessen-Horowitz, Basecamp and Open Source (2016)	tosh	13.65955	-5.3062215	story	4.0	78.0	1563745721	-12.82982
20600726	I feel like the article misses out o	"I feel like the article misses out on two crucial truths:1. Most of the new tools are pure nightmare to maintain. RoR has breaking API changes often enough that you need multiple people to maintain a large codebase, whereas in PHP you'd only need one person because things don't magically break that often. And MongoDB is so convoluted and complicated that almost nobody can deploy it correctly. And then there's ""new"" container techniques, which are basically just an admission that you have no f*ing clue on how to make your new tool set secure. In most cases, the loud new technology is just over-funded hipster stuff, but not ready for the real world yet.2. Posting things online (e.g. Source Code) will not only attract the attention of peers. You might also get flooded with rather demanding em"	fxtentacle	13.641011	-5.2878723	comment	4.0	30.0	1564844519	9.755006
20776778	This looks like a dead project that 	This looks like a dead project that just bundles together the built-in sqlite3 And another wrapper library APSW which itself is more active than this project. Why is this on hn?	nabdab	13.600832	-5.561453	comment	4.0	13.0	1566563234	9.839792
20862132	What are the best alternatives to mo	What are the best alternatives to mongo db going forward?Are there any forks with momentum?	worldsayshi	13.650121	-5.327639	comment	4.0	12.0	1567462733	9.888428
13612168	PostgreSQL outperforms MongoDB how ?	PostgreSQL outperforms MongoDB how ?Because as someone who has tried to update JSON documents (1M/s) in both PostgreSQL and MongoDB I would strongly disagree. MongoDB with WiredTiger was at least 10x faster per node and in terms of pure updates one of the fastest databases I've ever seen. And before the trolls yes I was fsyncing to disk.	threeseed	13.62432	-5.367007	comment	4.0	19.0	1486684724	9.88054
13662090	Plus I found that people using Mongo	"Plus I found that people using MongoDB tend to not formalize their data schema because the tool doesn't enforce it. But they do have a data schema.Only:- it's implicit, and you have to inspect the db and the code to understand it.- there is no single source of truth, so any changes better be backed up by unit tests. And training is awkward. If some fields/values are rarely use, you can easily end up not knowing about them while ""peeking at the data"".- the constraints are delegated to dev, so code making checks is scattered all around the place. Which makes consistency suffers. I almost ALWAYS find duplicate or invalid entries in any mongo storage I have to work on. And of course again, changes and training are a pain. ""Is this field mandatory ?"" is a question I asked way to often in those "	sametmax	13.643301	-5.3461094	comment	4.0	13.0	1487268306	9.858221
13666769	Never looked at DocumentDB before. S	Never looked at DocumentDB before. So if I get this straight, I can get a fully managed DB that can scale easily, but still have all the advantages and compatibility of a regular NoSQL like Mongo?I think that's a first, right?	dirkg	13.57714	-5.3205614	comment	4.0	20.0	1487319735	9.831964
13669458	SQLite usage makes me wonder how wil	SQLite usage makes me wonder how will it behave over time with millions of commits. Also makes me wonder how will it handle distribution.	maxpert	13.583413	-5.54269	comment	4.0	14.0	1487349153	9.836527
13840434	What is this article, I can't. In wh	What is this article, I can't. In what world do we live in where we paint a $425m exit in a bad light?> They built their servers on top of Node and used MongoDB to store data so that the web app would load really fast.I stopped reading here.	rco8786	13.686133	-5.3114977	comment	4.0	17.0	1489167930	9.856057
13926907	NoSQL developers can command higher 	NoSQL developers can command higher pay because there are fewer of them. Same with any other shiny new tech, really.	superioritycplx	13.529114	-5.3930655	comment	4.0	13.0	1490135554	9.843768
13927118	Although he author doesn't take into	Although he author doesn't take into account that not all web apps are created equal and the SQL/NoSQL argument isn't black and white... I do find myself slightly nodding in agreement with what he says.NoSQL doesn't reduce development effort. What you gain from not having to worry about modifying schemas and enforcing referential integrity, you lose from having to add more code to your app to check that a DB document has a certain value. In essence you are moving responsibility for data integrity away from the DB and in to your app, something I think is quite dangerous.NoSQL has its place, but I do feel that it is a bit more hyped up than it should be.	DoubleGlazing	13.551176	-5.4382453	comment	4.0	14.0	1490137775	9.825521
14371996	"""God forbid, SQLite""? It's honestly "	"""God forbid, SQLite""? It's honestly a great product and a wonderful stepping-stone. I wish more new projects used it rather than half-measures like Mongo."	STRML	13.615953	-5.53763	comment	4.0	18.0	1495151393	9.884782
14524703	The ultimate problem with natural ke	The ultimate problem with natural keys is that their uniqueness is a property of business rules. Unless you live in some magical fairytale land where business rules are stable, sensible, or both, depending on them for uniqueness is asking to have problems.	awj	13.879385	-5.237263	comment	4.0	43.0	1497043430	-13.636497
30877816	Postlite author here. I'm glad to se	Postlite author here. I'm glad to see the interest in this project. This project really only has one use case and that is being able to connect to a remote SQLite database using GUI database administration tools like DBeaver. The idea came out of this Twitter thread:https://twitter.com/benbjohnson/status/1508927916561743872It's a recurring theme with SQLite. Many developers are on-board with using it as a database but when you tell them that they also have to SSH in and use a CLI exclusively then they are turned off. Postlite is meant to alleviate that pain.	benbjohnson	13.628513	-5.5393815	comment	4.0	23.0	1648819362	9.819811
30887410	Not commenting on tailscale, but for	"Not commenting on tailscale, but for the state of databases.Sometimes boring is the right choice.
PostgreSQL has worked for decades now, and seems to have regained much of the performance that MySQL once boasted.If you do this for the money, investing in tried and true (but boring) software should be the default solution.I watched with dread how the MongoDB fiasco played out a decade ago. Meanwhile, I kept using PostgreSQL and had a good ride."	alophawen	13.521935	-5.3519773	comment	4.0	33.0	1648899078	9.776301
30895332	This has been shared without context	"This has been shared without context but I guess the SQLite team is starting to modularize the btree code in order to facilitate work like SQLightning: https://github.com/LMDB/sqlightningAt the time SQLightning greatly improved SQLite performance but due to LMDB's requirement to have keys fit in 2/3 of a page it wasn't really useful as a general purpose replacement of SQLite's internal b-tree implementation.EDIT: It looks like SQLightning got adopted and has been worked on by the SQLite team under the name LumoSQL. Here's the project's readme: https://lumosql.org/src/lumosql/doc/trunk/README.md which contains at the end ""A Brief History of LumoSQL"""	plq	13.569656	-5.5848145	comment	4.0	16.0	1648973514	9.728706
30894913	SQLite B-Tree Module	SQLite B-Tree Module	rdpintqogeogsaa	13.58783	-5.587448	story	4.0	177.0	1648967354	9.723154
30933688	> and you can't blame engineersI thi	"> and you can't blame engineersI think you can definitely blame them and in fact I'd expect CTO's and managers to discourage employees from doing that. A small silly decision can later cost millions in rewrites or maintenance. 
In the end we'll all benefit if not every brochure website needs to have 50 micro services and use the latest nosql solution. We're the ones who end up maintaining these systems."	weatherlite	13.531274	-5.376969	comment	4.0	23.0	1649260642	9.838445
30939096	How do you feel about SQLite? Becaus	How do you feel about SQLite? Because when I read this architecture description, it mostly vibes with me, until I think about what happens to the data in the event of a power cut.Is there logic in your app to potentially throw the last line away (incl. truncating it from the file) if it's invalid due to being the result of a non-atomic write? If so, seems a bit Not-Invented-Here compared to just using a (runtime-embedded) library that does that for you :)	derefr	13.579014	-5.5404377	comment	4.0	14.0	1649290526	9.776194
31040561	> Then it is a lot of engineering wo	> Then it is a lot of engineering work to update existing SQL queries. SQLite (similar to MySQL) dialect uses the question mark parameters while PostgreSQL uses positioned parameters for prepared statements.Many database engines, including SQL Server for instance, also support question marks. Surely PostgreSQL also supports this?	sebazzz	13.540486	-5.554873	comment	4.0	13.0	1650032423	9.845931
31153207	One of my previous employers was usi	"One of my previous employers was using SQLite as a large distributed database - they had their own custom sharding strategy, but essentially the idea was to shard A accounts * B tables * C num_of_days with a .db file for every shard.When I first came and saw it, it...did not sound right. But I didn't want to be the guy who comes in and says ""you are doing it wrong"" month 1. So I went along with it.Of course, eventually problems started to pop up. I distinctly remember that the ingestion (happening via a lot of Kafka consumers) throughput was high enough that SQLite started to crumble and even saw WAL overruns, data loss etc. Fortunately, it wasn't ""real"" production yet.I suggested we move to Postgres and was eventually able to convince everyone from engineers to leadership. We moved to a c"	manish_gill	13.523252	-5.401628	comment	4.0	13.0	1650887397	9.796766
31153228	Question for people using SQLite in 	Question for people using SQLite in prod: how do you cope if your app is running on a platform like Heroku or Cloud Run, rather than a proper server or VM? Have you found a solution for the fact that those environments, and disk, is ephemeral?	memset	13.580493	-5.5220294	comment	4.0	13.0	1650887514	9.798628
31155636	I'm using SQLite for a small persona	I'm using SQLite for a small personal project that's live in production and so far I love it (both for its simplicity in development and for its performance).But I've run into on prod that didn't exist in dev on my MacBook M1, and I'm curious if anyone has any suggestions:My app is basically quiet and serves requests in the dozens (super easy to run on a tiny instance), but for a few hours a day it needs to run several million database transactions, N+1 queries, etc.  Because of the high number of IOPS needed, a small instance falls down and runs suuuuuper sluggishly, so I've found myself needing to shut everything down, resize the instance to something with more CPUs, memory, and IOPS ($$$), doing the big batch, then scaling down again.  That whole dance is a pain.Were I using a more trad	nlh	13.541168	-5.4395766	comment	4.0	16.0	1650898065	9.791824
31216015	I recently saw SQLite used (and writ	I recently saw SQLite used (and written to) in a Docker container, with the database file on a mounted volume.That made me nervous!I don't know enough about how Docker implements volumes under the hood to know how likely (or not) it is to break filesystem behavior that SQLite depends on for its transactional guarantees.Perhaps someone here does?	davepeck	13.571603	-5.53494	comment	4.0	12.0	1651326105	9.802486
31319240	Wow Litestream sounds really interes	Wow Litestream sounds really interesting to me. I was just starting on an architecture, that was either stupid or genius, of using many SQLite databases on the server. Each user's account gets their own SQLite file. So the service's horizontal scaling is good (similar to the horizontal scaling of a document DB), and it naturally mitigates data leaks/injections. Also opens up a few neat tricks like the ability to do blue/green rollouts for schema changes. Anyway Litestream seems pretty ideal for that, will be checking it out!	paulhodge	13.556109	-5.4646564	comment	4.0	17.0	1652127839	9.782608
31319935	Each user's account gets their own S	Each user's account gets their own SQLite file.So now you need one database connection per user...	Scarbutt	13.570931	-5.5166364	comment	4.0	12.0	1652131380	9.77759
31319968	@dang, the actual title is “ I'm All	@dang, the actual title is “ I'm All-In on Server-Side SQLite”Maybe I missed it but where in the article does it say Fly acquired Litestream?EDIT: Ben Johnson says he just joined Fly. Nothing about Fly “acquiring” Litestream.https://mobile.twitter.com/benbjohnson/status/15237489883352...	tiffanyh	13.636078	-5.5113554	comment	4.0	27.0	1652131505	9.755295
31340088	Have any of the problems that led pe	Have any of the problems that led people to use Postgres instead of SQLite actually been solved? Are we doomed to repeat the same mistakes?Also, any plans to support PATCH x-update-range so SQLite can be used entirely in the browser via SQLite.js?Can someone enlighten me with the types of use cases this would be better for vs say Postgres?	endisneigh	13.578771	-5.5209618	comment	4.0	22.0	1652277815	9.837183
31449149	I just want my entire file system st	I just want my entire file system stored in Sqlite so I can query it myself	reactjavascript	13.577455	-5.5580606	comment	4.0	23.0	1653062102	9.79568
31473796	Although that affidavit is still a p	Although that affidavit is still a problem for some. Both German and Australian citizens cannot revoke their human rights and as such cannot put things into public domain. Hence cannot ever contribute to sqlite.This may be seen as advantageous however.	boyter	13.647996	-5.608063	comment	4.0	18.0	1653261683	9.854128
31531266	This is the first issue of the new A	This is the first issue of the new Architecture Notes publication (website and newsletter) run by Mahdi Yusuf.Mahdi interviewed me about the architecture of https://datasette.io/ - topics we covered include:- Building a modern Python app using ASGI- Benefits of SQLite- Designing plugin hooks- Safely allowing SQL injection- Using SQLite from asyncio- The Baked Data architectural pattern- Bundling a Python web application in Electron- Packaging a Python for WebAssembly	simonw	13.541995	-5.589865	comment	4.0	18.0	1653667893	9.889396
31639360	And pic was slightly extended and mo	And pic was slightly extended and modernized by the SQLite author(s?) to become https://pikchr.org, for use in SQLite docs. (All the SQL syntax diagrams are drawn with pikchr, IIUC.)If you want to embed pikchr SVGs in your statically generated HTML content, you may find https://soupault.app/ useful.(Not affiliated with either, fan of both.)	akavel	13.63662	-5.571601	comment	4.0	13.0	1654516786	9.825296
31689408	How is crypto any better at doing th	How is crypto any better at doing this than say, Western Union?Ultimately, as someone who finds blockchain technology really cool, what I struggle with is, in which scenarios is blockchain better than Postgres?	thawaya3113	13.594303	-5.3634424	comment	4.0	14.0	1654829298	9.858041
31716751	I can't see a case where an UUID PK 	I can't see a case where an UUID PK is better than an INT (or BIGINT). Why would you do that?	marcos100	13.991556	-5.218488	comment	4.0	12.0	1655057326	-13.661454
31717170	How would one go about trying to use	How would one go about trying to use UUID 7 in a Postgres database / python codebase now?	canadiantim	13.985937	-5.220565	comment	4.0	13.0	1655059899	-13.668452
31719190	Is there a way to verify a UUID was 	Is there a way to verify a UUID was created by me? I want to avoid database lookups of UUIDs from malicious/manipulated URLs.	tqkxzugoaupvwqr	13.988137	-5.206275	comment	4.0	12.0	1655075927	-13.652997
28845957	Is anyone able to comment on the ext	Is anyone able to comment on the extent to which Cloud Spanner and CockroachDB are in competition with each other? (CockroachDB is also wire-compatible with Postgres and originates as an implementation of something similar to Spanner)	da39a3ee	13.560806	-5.2254786	comment	4.0	12.0	1634078121	9.918514
28995389	I really enjoy examples like this, t	I really enjoy examples like this, thanks, I’ll be exploring it.As an aside… I would truly love to explore a collection of interesting ways to use SQLite. It’s such an impressive piece of technology that I’d like to use more often. Please share if you have something similar!	dvdhnt	13.6060295	-5.584123	comment	4.0	23.0	1635212072	9.87756
28999264	> You need a unique identifier / der	> You need a unique identifier / derivative of itWhat prevents anyone from mass-generating unique identifiers?	danuker	13.921401	-5.203795	comment	4.0	16.0	1635249508	-13.648287
29000949	One database per user. And even disr	One database per user. And even disregarding the obvious inability to natively join information across tables, it still was a mess to subscribe to changes across all of them and all the other things you take for granted with a relational database. And to me, it looks like couchdb is on life support as a technology. It's a great idea and revolutionary in it's time, putting everything as documents with views, etc. But, too many gaps and unclear direction.	xrd	13.57583	-5.223328	comment	4.0	16.0	1635258958	9.679462
29072388	"Really they should call this ""PongoD"	"Really they should call this ""PongoDB"", it's less similar than mango and it's got a hint that this is backed by pg..."	d--b	13.59707	-5.2864084	comment	4.0	17.0	1635797580	10.050516
29083301	What I don't get is why they wouldn'	What I don't get is why they wouldn't just use MongoDB.  MongoDB is web-scale.	Imnimo	13.664818	-5.3290076	comment	4.0	24.0	1635869441	9.920156
29126051	Well, whatever the article says, isn	"Well, whatever the article says, isn't the actual reason ""we have this other one we built using SQLite""?"	emodendroket	13.623555	-5.579685	comment	4.0	16.0	1636157165	9.8499365
29164344	Yeah I recognize the arguments for U	"Yeah I recognize the arguments for UUID keys:  - Avoids people being able to just iterate through records, or to discover roughly how many records of a thing you have
  - Allows you to generate the key before the row is saved

I think I default to auto-increment ID's due to:  - Familiarity bias
  - They have a temporal aspect to them (IE, I know row with ID 225 was created before row with ID 392, and approximately when they might be created)
  - Easier to read (when you have less than +1,000,000 rows in a table)

I agree and think you're right in that UUID's are probably a better default.Though you can never find a ""definitive"" guide/rule online or in the docs unfortunately."	gavinray	13.9613695	-5.2226334	comment	4.0	31.0	1636477913	-13.660072
29164670	> They have a temporal aspect to the	> They have a temporal aspect to them (IE, I know row with ID 225 was created before row with ID 392, and approximately when they might be created)UUIDv7 (currently a draft spec[0]) are IDs that can be sorted in the chronological order they were createdIn the meantime, ulid[1] and ksuid[2] are popular time-sortable ID schemes, both previously discussed on HN[3][0] https://datatracker.ietf.org/doc/html/draft-peabody-dispatch...[1] https://github.com/ulid/spec[2] https://github.com/segmentio/ksuid[3] ulid discussion: https://news.ycombinator.com/item?id=18768909UUIDv7 discusison: https://news.ycombin	spiffytech	13.967232	-5.213483	comment	4.0	16.0	1636479483	-13.675636
29167840	Something I always liked but have ne	"Something I always liked but have never done -- start auto-increment IDs at some number other than 1.  I worked on a system where account IDs started with 1000000, invoice IDs started with 2000000, etc.  That way, if you saw a random number laying around like ""1001234"", you knew it was an account ID. ""2000123"", an invoice!  I don't remember how often it helped things, but it was more than 0 times, and it always ""felt"" good.  I never loved the implicit upper bound, but it was also never a problem.(And remember, the values are in different tables, so the only disadvantage is that your millionth user has ID 2000000.  To the trained eye they look like an invoice; but there is no way for the system itself to treat that as an invoice, so it's only confusing to humans.  If you use auto-increment "	jrockway	13.942169	-5.195147	comment	4.0	13.0	1636493919	-13.706906
29269746	Ask HN: Using SQLite for server/clie	Ask HN: Using SQLite for server/client web apps?	vanilla-almond	13.625347	-5.5562954	story	4.0	6.0	1637265797	9.811231
29402702	Sure, but if the thing you are specu	Sure, but if the thing you are speculating with doesn't matter, why not just use something completely arbitrary instead?For example here is an random UUID: 6f50fde3-a7f0-433b-a9b1-8ef6d665905b. How much money would you put on it?	atoav	13.984494	-5.208997	comment	4.0	24.0	1638357455	-13.686244
29460458	SQLite is the most underrated databa	SQLite is the most underrated database of all time.I know it's popular, but nowhere near to the level it should be.	Lhiw	13.552076	-5.522208	comment	4.0	20.0	1638802718	9.829361
29460770	I would say this sums it up:> the SQ	"I would say this sums it up:> the SQLite library consists of approximately 143.4 KSLOC of C code. (KSLOC means thousands of ""Source Lines Of Code"" or, in other words, lines of code excluding blank lines and comments.) By comparison, the project has 640 times as much test code and test scripts - 91911.0 KSLOC.How does SQLite compare for bugs in comparison to other DBs? How much are the other players paying out in bug bounties?"	kingcharles	13.644139	-5.616977	comment	4.0	15.0	1638804103	9.877077
29461959	SQLlite has also got probably the mo	SQLlite has also got probably the most well-tested code of conduct of any open source project in the world (aside from the other open source projects which use this CoC)https://sqlite.org/codeofethics.html	thepasswordis	13.573495	-5.5847554	comment	4.0	18.0	1638808829	9.850162
29484378	That was a good name, but too close 	That was a good name, but too close to MongoDB. FerretDB does seem to follow the rule that databases need to have terrible names.	Narretz	13.587178	-5.319852	comment	4.0	41.0	1638969754	9.820894
29656495	Ash HN: Is there a concurrent databa	Ash HN: Is there a concurrent database that fits between SQLite and PostgreSQL?	vanilla-almond	13.537066	-5.4781623	story	4.0	2.0	1640213288	9.804294
34176958	We should consider the following pro	We should consider the following properties when evaluating ID formats and generation algorithms:1. Private: you shouldn’t be able to gain information about the system using the IDs from an ID alone. E.g. document enumeration attacks like what happened with Parler (https://www.wired.com/story/parler-hack-data-public-posts-im...)2. B-tree/cache friendly: newly created IDs should all exist in a narrow range of values. This is helpful for databases.3. Stateless: ideally you shouldn’t need to know the current state of the system to create a new ID.4. Human-friendly: IDs should be easily dictated, copied, pasted, etc. This means they should be encodable as text that is short and does not include ambiguous characters. Bonus points for error detection like with credit cards.Some of the these prop	vlmutolo	13.951708	-5.2057557	comment	4.0	14.0	1672342929	-13.608998
34209576	I don't understand the use case? Fro	I don't understand the use case? From the docs [https://sqlite.org/wasm/doc/trunk/demo-123.md], the database disappears on page reload on top of requiring using workers for longer running processes.	NeutralForest	13.6169	-5.576157	comment	4.0	19.0	1672600050	9.839433
34268231	I have a couple of questions...- So 	"I have a couple of questions...- So LiteFS turns sqlite into a client server database. But SQLite being embedded is what gives it its low latency in the first place. So, I kind of have to ask - what's point? Just prefering the way sqlite does SQL over postgres?- What language is that database model under ""Evaluating the existing data""?"	LAC-Tech	13.58248	-5.5411615	comment	4.0	22.0	1672959756	9.7505455
34317359	I've been using this for about six m	I've been using this for about six months now and I absolutely love it.Make never stuck for me - I couldn't quite get it to fit inside my head.Just has the exact set of features I want.Here's one example of one of my Justfiles: https://github.com/simonw/sqlite-utils/blob/fc221f9b62ed8624... - documented here: https://sqlite-utils.datasette.io/en/stable/contributing.htm...I also wrote about using Just with Django in this TIL: https://til.simonwillison.net/django/just-with-django	simonw	13.592526	-5.572576	comment	4.0	50.0	1673303599	9.889014
34435802	Postgres focuses more on this use ca	Postgres focuses more on this use case. It's probably still going to do a better job with concurrency, or at least have more features. It'll also cost more to pay for as a service, so you decide if it's worth. Whereas HC-tree is an obvious win if you're already using SQLite. It's fine for two things to approach similar use cases from different sides.Personally I want the opposite direction, a sort of Postgres-lite that uses a single flat file and lives inside a lib, for things where the power of the full thing isn't needed yet but I want to design my backend code against a Postgres interface. I've seen Wasm Postgres examples, and maybe there are others, but nothing mainstream. And yes there was this SQL standard that everything was supposed to conform to, but that went out the window long 	hot_gril	13.520402	-5.4471235	comment	4.0	28.0	1674093297	9.788854
34453105	One thing I don’t see being mentione	One thing I don’t see being mentioned in this thread (I only skimmed the article, so I don’t know if it’s mentioned there) is that you can run out of numbers when using serial, as they have a max, so if you are planning to have a table which will have over 2147483647 rows, then you might look into other types to use as a unique identifier.	PestoDiRucola	13.91778	-5.2306175	comment	4.0	17.0	1674222752	-13.64032
34561607	Array foreign keys and indexes on ar	Array foreign keys and indexes on arrays/JSON nested fields. When using MongoDB, having this eliminates most need for join tables. (*This may have already been implemented, I haven't used SQL recently.)	dudeinjapan	13.533574	-5.4527364	comment	4.0	12.0	1674938487	9.859888
34563278	The first and maybe the only time I 	The first and maybe the only time I saw UUID PKs was in a multi-tenant solution. If your customers are potentially competitors to each other, you absolutely do not want people to be able to walk IDs sniffing for other stuff. I wasn't the biggest fan of this solution, but I really didn't have a better suggestion.On that same project we ran afoul of Javascript's 10^53 floating point limit with IDs, but I think that was a separate issue.	hinkley	13.980116	-5.202732	comment	4.0	17.0	1674950091	-13.650003
34754133	What about tables without primary ke	What about tables without primary keys?	dewey	13.695067	-5.374098	comment	4.0	12.0	1676135436	-13.6418495
34812802	> I have run SQLite as a web applica	> I have run SQLite as a web application database with thousands concurrent writes every second, coming from different HTTP requests, without any delays or issues.Is this with nodejs or something single threaded as the webserver?I would kind of assume you'd run into issues with something like PHP.	onlypositive	13.5781145	-5.514492	comment	4.0	16.0	1676505367	9.7704735
34814168	I agree. Most uses of databases defi	"I agree. Most uses of databases definitely don't need to grow larger than, say, a single filesystem, or a single application, or a single host, or a single network, or a single geographical region, or a single customer, or a single organization, or a single global network of customers in organizations in regions on networks on hosts on applications on filesystems.There could not be any features of any other database that SQLite might not have, or that an application might need, or want.We definitely should not, like, read a book on databases, or read the manual of another database, or something else crazy like that. There's no reason we might learn about other databases. They are just ""shiny stuff"", meaning, there's something going on with them that I can't see, because of all the glare.Ho"	0xbadcafebee	13.556967	-5.52614	comment	4.0	13.0	1676514323	9.776013
34830263	Opening this and then searching for 	"Opening this and then searching for ""\.db$"" reveals all of the processes that are (probably) using SQLite, which is fun for finding things you can poke around in.Try ""\.sqlite"" too.This is fun:    brew install datasette
    datasette ~/Library/Calendars/Calendar.sqlitedb"	simonw	13.585044	-5.5546193	comment	4.0	21.0	1676603735	9.854498
34859806	I've been really happy with CouchDB 	I've been really happy with CouchDB + PouchDB at https://financier.ioYou can do unique things like offer a trial period without syncing (database wholly in browser), which allows for ridiculously quick onboarding. And then when the user signs up for a paid plan, you just hook up CouchDB and the data syncs right on over.The sync mechanism works so damn well. It's really cool how easy it is to implement a Google Docs-like sync mechanism with conflict resolution baked in.	hardcopy	13.5578375	-5.2020793	comment	4.0	12.0	1676828353	9.642809
34872664	So sad. So the choice is closed sour	So sad. So the choice is closed source platform lock-in, a single Linux server with SQLite as database, or kubernetes?-an old man yelling at the cloud.	glutamate	13.550798	-5.44261	comment	4.0	18.0	1676925879	-7.914939
34960931	What? No. NoSQLs don't help with joi	"What? No. NoSQLs don't help with joins, as they don't have them at all. Meaning every ""join-like"" has to be client side and entails transmitting stuff to the client, which is even worse than temporary tables.There are multiple reasons to use NoSQL and non of them is this one.Having said that - cool, I like relational databases and love my multi-joins going faster."	globalreset	13.535002	-5.4825044	comment	4.0	13.0	1677526878	-11.887056
16839638	This may be helpful to you: https://	This may be helpful to you: https://sqlite.org/whynotgit.html, especially the links to other comparisons at the very bottom.	oomkiller	13.61195	-5.576051	comment	5.0	17.0	1523741502	9.8473
16947118	Basically saying that don't use numb	Basically saying that don't use numbers because somebody might write crap code and it'll get run on your deployment database?!If getting such dangerously awful code deployed to production is likely then sequential IDs are just one of your many problems!Sequential IDs for key data can be good to avoid for a few good reasons but awful code isn't one of them. Testing, code reviews and not having bad programmers should be in place to fix that.	dominicr	13.929134	-5.206999	comment	5.0	16.0	1524914058	-13.646304
17091877	A SQLite Tutorial with Node.js	A SQLite Tutorial with Node.js	ScottWRobinson	13.595288	-5.574105	story	5.0	70.0	1526569355	9.874147
17136027	Wow, I had no idea it could store js	Wow, I had no idea it could store jsonb. Any obvious advantages to using mongodb for nosql that I should consider? I’m way more comfortable with Postgres and would rather stick to that	heyoni	13.593648	-5.4106064	comment	5.0	25.0	1527096374	9.828501
17438618	The people who write the business lo	The people who write the business logic and the people who do the analytics have different concerns. It's sometimes better to make different database choices for those two systems and just copy the data into the analytics system, rather than make a substandard choice of database to try to accommodate both.If the devs want to use Mongo, it's their problem -- it shouldn't matter much to the analytics people, because they can just copy the data into a different database that fits their needs.	twblalock	13.667241	-5.302629	comment	5.0	22.0	1530492723	9.91951
17552863	For auth, Eliot argues that develope	For auth, Eliot argues that developers need to take responsibility for exposing MongoDB on public serversThat’s like selling a car without preinstalled seat belts and then saying it is the responsibility of the driver if they take it on the road like that. It’s technically true, but it’s sort of missing the point.	Joeri	13.733069	-5.206365	comment	5.0	35.0	1531858350	9.950935
17764596	SQLite guys, please add FDW support 	SQLite guys, please add FDW support ala Postgres and easy foreign function support for Python and R, and you’ll corner most of analytics and data science.	usgroup	13.54334	-5.530654	comment	5.0	26.0	1534323423	9.818944
17764895	A bit offtopic but has anyone tried 	"A bit offtopic but has anyone tried to replicate sqlite databases? Using rqlite 
https://github.com/rqlite/rqlite
or something else?"	yread	13.566512	-5.4834547	comment	5.0	28.0	1534328216	9.814477
17767768	It's scales so perfectly we are depl	It's scales so perfectly we are deploying it across 3 datacenters, each with four 384 core machines with 3 terabytes of RAM.  I can't speak highly enough about sqlite and the team behind it.	quinthar	13.563525	-5.494625	comment	5.0	38.0	1534353251	9.775564
17769953	Good thing you don't need 64bit inte	Good thing you don't need 64bit integers.Seriously, as impressive as SQLite is for what it is, people shouldn't be given the impression that it doesn't come with some massive and often surprising caveats when viewed as a general purpose database.	ris	13.607543	-5.6083307	comment	5.0	19.0	1534368657	9.828465
17770151	Because SQLite is often the right to	"Because SQLite is often the right tool for the job, more so than Postgres and MySQL. It scales insanely well and requires minimal configuration and near zero administration. I try to use SQLite for as long as is feasible in my projects purely because it ""just works"".Don't let the ""Lite"" fool you. Depending on your needs, you can scale to 10s of thousand of users using just SQLite. Or not! It is all about knowing your system and properly evaluating your options. I choose to use SQLite because it often fits the use case of small to medium projects the best."	andrewguenther	13.570185	-5.508044	comment	5.0	20.0	1534370459	9.838712
17771572	I don't understand why SQLite would 	I don't understand why SQLite would be used instead of writing a data structure. To me going through SQL (& ORMs) is a hindrance.Why use a database if you only have one process?	rb808	13.590854	-5.5525966	comment	5.0	16.0	1534388440	9.819614
19085785	What’s the use case for a random UUI	What’s the use case for a random UUID? I’ve never had a need for them to be random just unique.	wil421	13.974527	-5.210727	comment	5.0	17.0	1549378696	-13.657998
19159761	For most languages and frameworks, u	For most languages and frameworks, using Postgres as opposed to sqlite is barely a higher cost if you’ve got the ops skills. I’ve yet to see an app that straddled this local/web-scale line where SQLite was a better choice or Postgres wasn’t the obvious choice.There isn’t some massive cost to using Postgres instead, is there some desktop divide I’m missing here?	kevinmgranger	13.5391445	-5.4729056	comment	5.0	16.0	1550120933	9.831809
19160293	A silly, genuine question: when I'm 	"A silly, genuine question: when I'm writing a NodeJS app, and I need to store a JSON in a DB that looks like this:{
""a"" : ""b"",
""c"" : {
    ""ca"":""cb"",
    ""cd"":""ce""
  },
 ""d"": {
    ...
  }
}How do I store it? To me, NoSQL seemed like the choice in the past.This is not difficult in relational DBs, but it requires rather long SQL commands, and SQL table design. It seems to me that ""MongoDB.insert(obj)"" seems like the way to go, as it is much simpler.How do experienced Node devs solve this issue? Is it simply relational all the way? Is it Postgress's JSON field..?"	BossingAround	13.558162	-5.445531	comment	5.0	32.0	1550129960	9.821612
19498801	Why not just use a SQL db that handl	Why not just use a SQL db that handles json and stick everything in a couple columns? Changing databases is a lot of work, and as far as I can tell, mongo isn’t really providing much value over SQL dbs that already support schemaless json columns.	mruts	13.548779	-5.456259	comment	5.0	22.0	1553673006	9.821898
19498918	Off course it was, prototyping speed	Off course it was, prototyping speed on mongodb was (and probably still is) always excellent.Some features that don't scale are very nice to have when you don't have scaling issues. For example, if you add tags to your documents and you want to query on those tags (find all documents containing tag A and B), it's nice that's just a builtin.I haven't found a single datastore that is as developer friendly that supports that use case, so for now, I'm sticking with mongodb for my pet project.(if you know of a datastore that has support for this query out of the box, please let me know)	gnur	13.621983	-5.332356	comment	5.0	17.0	1553674725	9.888155
19500299	As with anything, it depends on the 	As with anything, it depends on the project. I’m working on an internal service that uses Mongo as a single merged cache for a lot of mostly unchanging data from various data stores with different credentials for each, which are distributed around the world, that we otherwise have to fetch through multiple comparatively slow API calls. For this, Mongo is perfect: no messing with schemas as they change, unannounced, from upstream; I can index just the fields I want to search on; Mongo will expire things for me on a TTL; the query API is simpler than the API we’re caching from; and we get results 20-50x faster. We looked into FoundationDB and Postgres, but they require a lot more initial setup. ElasticSearch is the closest solution, but it needs a lot more info about the schema up front and 	skywhopper	13.599017	-5.341821	comment	5.0	21.0	1553691007	9.869306
19690854	Leaflet – social media platform buil	Leaflet – social media platform built with Node.js and MongoDB	undefined_void	13.645859	-5.33805	story	5.0	26.0	1555594388	9.850055
19786346	> Often UUIDs are used as keys to th	> Often UUIDs are used as keys to things...IMO most data in DBs has a natural key. Why add a fake key? If it's to enforce uniqueness then that uniquness is spurious because it's a GUID which has no meaning to the data to which it's attached eg. you could have the same row 10000000 times but falsely uniquified with a different GUID.Only exceptions I've encountered to my 'natural key' claim are addresses, which are a sod to canonicalise (in fact, seemingly impossible, I'd welcome any pointers).Also UUIDs are bloody big keys, so fattening up tables and impairing disk/memory bandwidth. This matters if you have gazillion-row DBs, surely? I dealt with a near-billion row DB and shaving a few bytes off a row would matter to us bigly.For the sake of argument I'll assert that you should never use UU	tempguy9999	13.9543	-5.2291226	comment	5.0	18.0	1556616349	-13.660661
37595737	MongoDB:a) has a proven, supported, 	MongoDB:a) has a proven, supported, easy-to-use horizontal scaling solution. PostgreSQL doesn't.b) is ridiculously faster than PostgreSQL at per-tuple document updates.c) has clients which are tailored for operations and data structures around documents.d) is easier to install, configure and manage.	threeseed	13.59109	-5.341273	comment	5.0	53.0	1695292609	9.834175
37614193	Been feeling a little miffed about t	Been feeling a little miffed about this recently. Litestream is excellent but if you have multiple writers your db gets corrupted. Quite easy to do with rolling deploys.LifeFS was announced and is intended to help this. Now seems like (https://fly.io/docs/litefs/getting-started-fly/) it requires an HTTP proxy so that the application can guess about sqlite write/read usage by reading the HTTP request method. This seems... to introduce a different (maybe better?) set of gotchas to navigate.There are now SQLite cloud offerings but you pay the network overhead and avoiding that was so much of the appeal of using SQLite.Are people successfully using SQLite in a work or production setting with a replication and consistency strategy that they like? I've had trouble getting a setup to the point wh	maxmcd	13.569989	-5.4856086	comment	5.0	15.0	1695400589	9.781441
37676130	It says people are using sqlite for 	It says people are using sqlite for production.  How big can you grow your database before it becomes a problem ?	angryasian	13.555783	-5.5102797	comment	5.0	17.0	1695828663	9.797075
37733859	He writes all this philosophy and th	He writes all this philosophy and then concludes with using PostgreSQL instead of mongoDB or nodeJS (? I'm not sure how that was in the same category). PostgreSQL is the opposite of boring technology; I've been using it for over 10 years and am still discovering new and surprising features with new and surprising failure modes; PostgreSQL today is very different from PostgreSQL 10 years ago, but setting it up for true master-master replication is still a clusterfuck and you still have zillions of moving parts in real world use.I'm lead inevitably to the conclusion that philosophising about tech choices and principles is pointless. Everyone will nod and agree with the principles and tradeoffs and then pick their personal pet technology anyway.	lmm	13.634428	-5.3343863	comment	5.0	21.0	1696219465	9.911231
37738531	UUID v4 isn't large enough to preven	UUID v4 isn't large enough to prevent collisions, that is why segment.io created https://github.com/segmentio/ksuid which is 160bit vs the 128bit of a UUIDv4.	Xeoncross	13.992703	-5.2112203	comment	5.0	17.0	1696256616	-13.683996
37769633	Show HN: Sqinn-Go is a Golang librar	Show HN: Sqinn-Go is a Golang library for accessing SQLite databases in pure Go	cvilsmeier	13.596168	-5.618435	story	5.0	113.0	1696444606	9.904285
37918029	Honestly, a good showcase of how exp	Honestly, a good showcase of how expensive UUIDs are. If you can perform a mapping to integers you should really consider it. Not only will your UUIDs take up 2x the space of a 64bit integer, they'll compress horribly by comparison. Integer compression is so good these days you can compress integers such that they basically end up taking up ~1/2 a byte instead of 8. Doing that with UUID v4s is fundamentally not going to work.The article mentions RLE, which is also incredibly good for integer IDs if you diff-encode them, since ids are typically sequential with no or small gaps. Diff + RLE can turn your encoded structure into ~1 byte.Also, incredible website. The interactivity is so fun.I did something similar to this very recently where I took a dataset and just continuously applied data en	insanitybit	13.983329	-5.2131934	comment	5.0	34.0	1697561892	-13.668428
37957518	It is shocking, but what's more shoc	"It is shocking, but what's more shocking is that doing it correctly is kind of rocket science. MySQL simply isn't built for picking a truly random row performantly (I'm not sure if any of the common relational databases are?).If you do something naive like ""ORDER BY RAND() LIMIT 1"" performance is worse than abysmal. Similarly, doing a ""LIMIT 0 OFFSET RAND() * row_count"" is comparably abysmal. While if you do something performant like ""WHERE id >= RAND() * max_id ORDER BY id LIMIT 1"", you encounter the same problem where the id gaps in deleted articles make certain articles more likely to be chosen.There are only two ""correct"" solutions. The first is to pick id's at random and then retry when an id isn't a valid article, but the worry here is with how sparse the id's might be, and the fact "	crazygringo	13.854589	-5.2504034	comment	5.0	32.0	1697815869	-13.66984
38038002	Just let the HN hype wave wash over 	Just let the HN hype wave wash over you my friend :)I see the sqlite hype as a (legitimate) pendulum swing away from defaulting to 'web scale' everything to a realization that most of the systems we design don't need it.On the other hand, when you start mixing in new tech like litefs to paper over shortcomings in the fundamental nature of an alternative, I start to question the sanity of the choice.We have screwdrivers, hammers, wrenches, let's not select a wrench and wrap it in a 'screwdriver adapter as a service'.	gorjusborg	13.623261	-5.550895	comment	5.0	15.0	1698412438	9.85242
38038149	> sqlite is awesome when you run it 	> sqlite is awesome when you run it in one instance on a VM or something,This article really needs to be taken in the context of the author’s target audience: He sells courses that primarily target web dev juniors doing learning projects and small projects. That’s why he includes the “most of you reading this” disclaimer in the article:> So, can you use SQLite? For the vast majority of you reading this, the answer is “yes.” Should you use SQLite? I’d say that still for the majority of you reading this, the answer is also “yes.”Pushing strong contrarian opinions is part of his social media marketing style. He’s also pushing a “why I won’t use next.js” article and opinion on his social media, while conveniently omitting the obvious conflict of interest that he sells courses that don’t happen	Aurornis	13.61141	-5.570847	comment	5.0	32.0	1698413195	9.876479
38540726	Is this just a data type, or did SQL	Is this just a data type, or did SQLite put in a JSON interpreter?	Animats	13.5241785	-5.6006794	comment	5.0	17.0	1701840246	9.771853
33275645	Me!I'm often exploring data where ei	"Me!I'm often exploring data where either there's no defined standard or the use of the data has drifted from the standard.  Now, I could go over this line-by-line, but instead my go-to has been ""Hey, let's throw this into SQLite, then run stats on it!""  See what shakes out.  SQLite kindly and obediently takes all of this mystery data, which ends up being nothing like what I was told, and just accepting it.  Then I can begin prodding it and see what is actually going on.This is something that has come up for me for at least a decade: chuck it in SQLite, then figure out what the real standard is."	at_a_remove	13.580995	-5.5781918	comment	5.0	36.0	1666277581	9.838661
33296244	I’m flabbergasted by how often HN co	I’m flabbergasted by how often HN commentators who should know better keep refusing to acknowledge the trade-offs in the technical implementations of crypto. What SQLite database running on raspberry pi is immune from seizure by relevant government authorities for helping with criminal transactions? Compare and contrast with Tornado Cash, which still works fine despite being OFAC sanctioned.Now, you may not care for law evasion, and that’s fine. But it’s asinine to pretend that crypto tech is not better for such purposes than “an SQLite database running on a raspberry pi.”	selestify	13.5988455	-5.559219	comment	5.0	15.0	1666423474	9.84033
33518705	4 load balancers with local caches +	4 load balancers with local caches + 5 replica databases.I don’t want to discredit the achievement but the 1MM/sec seems less exciting when you learn they horizontally scaled the architecture.Especially when SQLite, in a client/server config (BedrockDB), achieved 4MM/sec from a single server.https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-q...	alberth	13.605258	-5.4791794	comment	5.0	26.0	1667914171	9.793177
33621558	Isn't it happening all the time? Web	Isn't it happening all the time? Web3, crypto, AI, kubernetes, microservices, docker, server side rendering, SPA, react, graphql, backend in frontend, DevOps, DevSecOps, fullstack, mongodb, new features in mongodb that mimic sql, Restful, mobile, django/rails, agile, kanban. Some of them make sense, some of them make sense for some of the people, some will be forgotten from history. And those forgotten, will reemerge as a newfoundland	a_c	13.653432	-5.305775	comment	5.0	15.0	1668598368	9.88477
33700898	> Something I don't understand: how 	> Something I don't understand: how are UUIDs not safe given that they are probably better than 99.9999% of passwords generated by users?UUIDs are 128 bits. Which is beat by a 5 character a-z random string.It's certainly possible that they're better than the median password - especially if there isn't a check against a common password list. But it's pretty easy for user chosen passwords to be much, much better.I strongly doubt that your 6 9s estimate is accurate.	nordsieck	13.989407	-5.2090945	comment	5.0	15.0	1669082863	-13.645051
33742781	SQLite doesn't have hardware drivers	SQLite doesn't have hardware drivers (that IIRC are still majority of kernel bugs) that need actual hardware to test (as hardware mocks are at best mildly useful, coz real hardware can be... weird)And unit testing is relatively useless, what would be useful are end to end tests that start with userspace API but that's much harder task, altho hopefully those tests wouldn't need to be changed that often.	ilyt	13.656661	-5.646013	comment	5.0	24.0	1669387357	9.831396
33742685	Isn't SQLite a counterexample? They 	Isn't SQLite a counterexample? They have more code that has tests than their actually running code. https://www.sqlite.org/testing.html	zitterbewegung	13.6441345	-5.6188297	comment	5.0	34.0	1669386747	9.868903
33803420	How do you get more than 86,400 uniq	How do you get more than 86,400 unique “identifiers” when they only change every second?	jagged-chisel	13.9407015	-5.2120523	comment	5.0	15.0	1669826891	-13.647856
33897716	I'd like to avoid writing boilerplat	I'd like to avoid writing boilerplate CRUD code. Is there an equivalent of PostgREST but for SQLite? Essentially, a standard binary would read the schema metadata, and generate standard CRUD APIs: https://postgrest.org/en/stable/api.htmlThe APIs can even support authentication and authorization with the help of JWT tokens. SQLite may not have row-level security, but even a convention (eg: if a row has user_id column, the JWT must have the same user_id value to get access to a row) would go a long way.	nileshtrivedi	13.5425005	-5.482096	comment	5.0	18.0	1670436047	9.815164
33944271	Richard Hipp Speaks Out on SQLite (2	Richard Hipp Speaks Out on SQLite (2019) [pdf]	pncnmnp	13.621297	-5.585024	story	5.0	129.0	1670774400	9.822654
33945919	I've been trying to use SQLite3 in a	I've been trying to use SQLite3 in an embedded (ESP32 -- dual core 240MHz w/ qspi NOR flash) project and the performance has been surprisingly bad. Seems like the minimum amount of time to make a query (even for example, selecting from a table that does not exist, takes a minimum of 5ms). For a simple table with 10 short columns I'm getting 10s of milliseconds per record to SELECT. I can parse whole JSON files with the same data to RAM faster then I can query SQLite which seems wrong. SQLite is performing ~10x worse than I'd expected it would.Anyone had experience running SQLite on low-power embedded platforms? Is this expected performance?	johnboiles	13.554893	-5.529249	comment	5.0	22.0	1670783617	9.779958
34032990	SQLite internals: How the most-used 	SQLite internals: How the most-used database works	cube2222	13.586883	-5.5560117	story	5.0	244.0	1671316532	9.853471
28157435	I'm going to build a business that o	I'm going to build a business that offers SQLite as a web service. It will be backed by a P2P network of browser instances storing data in IndexedDB. Taking investment now.	leros	13.55789	-5.5159087	comment	5.0	20.0	1628781603	9.8464365
28157545	The excuse was that a standard needs	The excuse was that a standard needs to have multiple implementations otherwise we are standardising implementation details and bugs.Hindsight shows that was entirely correct, as SQLite bugs were then found that could be exploited directly via WebSQL, Firefox of course was not vunerable. (https://hub.packtpub.com/an-sqlite-magellan-rce-vulnerabilit...)As a sidenote, I worked a lot with the WebSQL API and it was not a very good API in the slightest, immaturity may excuse some of its flaws, and it isnt like Safari did a much better job with IndexedDB, its just a buggy browser and thats where WebSQL was used most, but a large part of the problem is that it was bolting an API that assumed a single threaded client when that is not the reality with web pages where multiple tabs exist	daleharvey	13.529041	-5.5335813	comment	5.0	42.0	1628782133	9.80536
28182051	Show HN: SQLite-S3-query – Python fu	Show HN: SQLite-S3-query – Python function to query a SQLite database on S3	michalc	13.584226	-5.5540066	story	5.0	38.0	1628959522	9.796886
12544399	I remember CouchDB when it was initi	I remember CouchDB when it was initially released, it was one of the most promising and innovative DB's around. It's a shame it didn't live up to the hype.	desireco42	13.604088	-5.2170672	comment	5.0	17.0	1474416155	9.664151
12579265	The one thing missing from SQLite is	The one thing missing from SQLite is stronger type casting...however, SQLite does have a solid, cross-platform GUI in DB Browser [0]. It's not as nice as Sequel Pro and some of the commercial clients for MySQL. Postgres, unfortunately, doesn't have near the variety of reliable clients that MySQL and SQLite do.However, SQLite follows most of the standard syntax that Postgres does, so having students move right into CartoDB, which lets you run raw Postgres, has never been a problem.its just the self hosting that's a pain :).One more thing that I wish I could have from Postgres as a teacher: how it returns an error when you include non-aggregated columns in the SELECT clause. In MySQL and SQLite, selecting extra columns won't throw an error, and the results look close enough to correct to be 	danso	13.586947	-5.538902	comment	5.0	18.0	1474864535	9.884052
12613797	I tried using and liking pgAdmin 4 b	I tried using and liking pgAdmin 4 beta for a few months. Even simple things like copy-paste from clipboard using Cmd-C/V, exporting/importing data to/from my local machine, etc were a hassle. Add to that the slow startup, sluggishness, and poor UX. I'm happily using Valentina Studio now. A small data point for others who may come to this thread looking for PostgreSQL GUI tools.	sinatra	13.519869	-5.440089	comment	5.0	18.0	1475256189	9.865769
12623887	In my experience, most people who us	In my experience, most people who used MySQL simply hadn't heard of PostgreSQL (which isn't hard to install either and probably performed well enough for everybody's requirements - at least everybody I talked to).I used to ask, because I found it baffling that someone would choose an RDBMS that wouldn't even check the size of a column.	forinti	13.525893	-5.434631	comment	5.0	16.0	1475437573	9.819429
12652798	Please dont make excuses for their f	"Please dont make excuses for their failure. ""Developer experience"" and ""performance"" are never reasons for failure. What does lead to failure is- lack of mass adoption - they didnt solve a problem everyone had- lack of nitch adoption - they didnt solve a problem a few people had badlyI can tell you 4 features that I view more important than change subscription- can run in any ecosystem - pouchdb/couchdb and waterline are examples of single apis in different environments. Even being able to use the database 100% in memory as a redis alternative would be nice.- supports transactions across shards natively - this is a difficult but important feature that mongodb is missing- supports document id transaction and table transaction - if Im only updating two documents, I have no interest in making"	formula1	13.621492	-5.313705	comment	5.0	26.0	1475764737	9.851568
12983852	> RethinkDB is something we were loo	> RethinkDB is something we were looking at for a large projectFrom the comments in HN it feels like this was always the case for RethinkDB; folks looking at it, admire it, thinking about using it in their next project but, for one reason or the another, never ending up using it. Which is really a pity.I don't know about the others, but I am really curious to know why you ended up not picking RethinkDB for your project.	kinkdr	13.668283	-5.291846	comment	5.0	27.0	1479436383	-12.815254
13102437	Is the project sponsored by Couchbas	Is the project sponsored by Couchbase? If not, have you thought about publishing a storage API that the replication protocol calls so that it could be adapted to work with any backend db? What about P2P sync - (eg. serverless) has anyone thought of making PouchDB do that?	grizzles	13.5617285	-5.2028565	comment	5.0	17.0	1480895488	9.664803
13103026	We've been running PouchDB in produc	We've been running PouchDB in production for ~15 months now. We chose it because it was a greenfield project and it gave us 2 things: Easy offline support and real-time syncing that makes it easy to create collaboration a-la Google Docs. Because the entire thing is a web app with app cache manifest deploying new versions is very little hassle.In terms of architecture we have about 250 tenants with separate Couch databases per each. We're still running Couch 1.6. We have yet to evaluate Couch 2.0.It's been mostly smooth ride for the most part but this being a very unusual architecture we had to tackle few interesting problems that came along.1. Load times. Once you get over certain db size the initial load time from clean slate takes ages due to PouchDB being super chatty. I'm talking about	ojanik	13.575266	-5.20708	comment	5.0	19.0	1480905435	9.6722145
13102198	I've been using PouchDB in a React N	I've been using PouchDB in a React Native app for about 6 months with SQLite as its backing store so that we can use more than 50MB of storage on the device. It has been working pretty well to persist data into an offline cache and then sync to a CouchDB 2.0 database in Digital Ocean.Getting it to work inside React Native was initially very challenging. Keeping our shim up to date with the recent changes to PouchDB has also been challenging. We are currently using PouchDB 5.4.5 because there was a breaking change in 6.x and I haven't had a chance to dive into it to figure out what is going wrong.The PouchDB community (especially Nolan Lawson) does a great job of showing examples, answering questions, and responding to feedback.	PaulMest	13.523001	-5.2308435	comment	5.0	33.0	1480891760	9.680797
13102546	Did you also consider Couchbase Lite	Did you also consider Couchbase Lite? I'd be interested in your decision making.	m_mueller	13.635551	-5.1871705	comment	5.0	20.0	1480896986	1.2429113
13185076	MongoDB will not prevent NoSQL injec	MongoDB will not prevent NoSQL injections in your Node.js app	ecares	13.666143	-5.328802	story	5.0	36.0	1481814790	9.911281
13346481	Absolutely ridiculous that MongoDB i	Absolutely ridiculous that MongoDB is this insecure by default.	tkyjonathan	13.713398	-5.2403364	comment	5.0	32.0	1483821568	9.888197
13374932	In production deployments, unsecured	In production deployments, unsecured remote connections might be fine, because security would be handled at the network layer (e.g. by deploying MongoDB on a VLAN which only was accessible by your MongoDB clients which were on separate servers).	richardwhiuk	13.742761	-5.2341857	comment	5.0	20.0	1484151177	9.915067
13433934	RethinkDB: why we failed	RethinkDB: why we failed	kiyanwang	13.686796	-5.2844357	story	5.0	58.0	1484812334	-12.805446
13569303	Don't use sqlite for that. Or any ot	Don't use sqlite for that. Or any other application specific format that only one application can read.There is no application that has a 30 years lifespan. Expect to already have massive issues in 10 years. If you depend on a single application, you're screwed.You want a readable long term format, you use a good old txt/csv/xml. Whatever fancy computer may come up in 2050, it's guaranteed they will ship with applications to read that.If needs be, gzip it to save space.	user5994461	13.551519	-5.5614853	comment	5.0	18.0	1486245121	9.816714
13580195	You never heard of anybody using Mon	You never heard of anybody using MongoDB?	SamReidHughes	13.691164	-5.314629	comment	5.0	26.0	1486394525	9.896712
13590837	MongoDB receives a fair amount of cr	MongoDB receives a fair amount of criticism here but the company is a fantastic place to work. I'm proud that I was able to learn and grow as a developer alongside all of those who have been trying (and succeeding) to make a great database.The team at MongoDB really cares a lot about making the best database product possible. I knew it when I was there and still think so after I've left.	tbrock	13.687742	-5.3092346	comment	5.0	22.0	1486487840	9.9341545
27542524	Do you have any opinions on ArangoDB	Do you have any opinions on ArangoDB or Dgraph? My new tech lead is talking about switching from MongoDB to one of those.	feu	13.658166	-5.325269	comment	5.0	24.0	1623953130	9.866629
27551570	It's rare in practice but occasional	It's rare in practice but occasionally rows have natural unique identifiers that are useable.The textbook case would be student IDs in a university database where each row corresponds to a single student. However some universities view the student id as sensitive information (kind of like a ssn in the US) and so in that scenario it should be aliased to some other key to prevent the student id from being present in multiple tables as a foreign key.	turbocon	13.693437	-5.4173884	comment	5.0	33.0	1624031171	-13.576561
27614263	Glad someone else highlighted this o	Glad someone else highlighted this old ticket.I bet this, in combination with the extremely irresponsible solution to ship mongodb without auth as default has caused countless of data leaks and destruction events. We just haven't heard about most of them. Elastic provides the same foot-gun.Last year someone deleted almost 4000 open mongodb and elastic databases in what was called the Meow attack [1].In my opinion it's as irresponsible as HW manufacturers shipping with default passwords, something which finally got the attention of regulators[2]. So I wouldn't be surprised if we at some point see some attempts to keep sw-developers accountable for what they give out.I have for some time been using the data-oil analogy to describe where we are at. If data is the new oil, and a database is a 	gnyman	13.700789	-5.228504	comment	5.0	40.0	1624512550	-9.589675
27665254	I'm building an open source Anki clo	"I'm building an open source Anki clone, and lemme tell you shit's surprisingly hard. Getting syncing working without resorting to uploading entire SQLite databases is nontrivial. You're basically doing multi-master database replication... but you gotta build it yourself  (there's no easy way to sync sqlite with some serverside database (ignoring firebase/couchdb/pouchdb for various technical reasons)): https://en.wikipedia.org/wiki/Multi-master_replicationThe lack of ""worth-it"" alternatives is due to the fact that there's no money in this market. Students are very unwilling to buy software, and if you use ads you end up like Quizlet. YC funded a startup in this area (Hickory) and they're... not doing well.The main reason why everyone still uses Anki despite its issues is because it is stil"	dharmaturtle	13.563577	-5.453354	comment	5.0	27.0	1624903294	9.761459
27876027	> battletestedIs software that is al	"> battletestedIs software that is always evolving battletested ? A new version could break something.I'm aware that sqlite has one of the best test suite in all of open source, I just wonder if something that was ""battletested"" is still battletested after a new release."	simlevesque	13.641106	-5.622998	comment	5.0	15.0	1626637734	-3.3401258
27897924	No idea what's with the sqlite artic	No idea what's with the sqlite articles making the front page every other day. This one is pretty old as well.  The measurements in this article were made during the week of 2017-06-05 using a version of SQLite in between 3.19.2 and 3.20.0.	xxs	13.617862	-5.571668	comment	5.0	18.0	1626808381	9.832103
27909580	SQL relies on joins. Joins are fine 	"SQL relies on joins. Joins are fine for reasonably sized databases, but on internet scale joins have miserable performance. ""Document"" based databases such as Mongo are designed to avoid joins.MongoDB has automatic sharding, which is very important for horizontal scaling of writes. For MySQL you have to do manual sharding which is extremely hard.And finally, document oriented databases are schemaless, which means there is no downtime when you add/remove fields."	flowerlad	13.545955	-5.419801	comment	5.0	20.0	1626889838	9.8722105
12135925	I was skeptical too, but the guy has	I was skeptical too, but the guy has 500,000 users on a $100/mo server. It's not even up for debate anymore, Node.js is fast and scalable. You might not like MongoDB, but it also works.	nathan_f77	13.635256	-5.308663	comment	5.0	15.0	1469097333	9.918081
12233263	Don't you think that teaching how to	Don't you think that teaching how to use it with mysql or postegres would be more useful than sqlite?	bezzi	13.597327	-5.5685077	comment	5.0	18.0	1470412460	9.841814
12534568	How to Run CockroachDB on a Raspberr	How to Run CockroachDB on a Raspberry Pi	orangechairs	13.684249	-5.203071	story	5.0	43.0	1474318197	10.02381
22426412	Reducing max document size from 4GB 	Reducing max document size from 4GB down to 8MB seems hyper-restrictive.For those interested, looks like the guts of CouchDB are going to be swapped out for FoundationDB.https://blog.couchdb.org/2020/02/26/the-road-to-couchdb-3-0-...	hajile	13.597896	-5.20888	comment	5.0	25.0	1582745629	9.678953
22507500	I know these kinds of tutorials are 	"I know these kinds of tutorials are just for getting a flavor of a framework or paradigm. Nice so see it.As someone who's used Mongo for nearly a decade, I always feel compelled to note: Mongo will NOT scale with relational data like this. Sure, it can handle a lot of records. It'll have fast basic inserts or queries. It can scale with replicaSets and sharding. But it is NOT designed for relational data. Doing relational data is so painful in Mongo, with any sort of scale. Save yourself so much migration headache by using a ""regular"" SQL database, until it doesn't work (rare)."	ruffrey	13.634146	-5.3356066	comment	5.0	18.0	1583530281	9.914642
23191439	Jepsen: MongoDB 4.2.6	Jepsen: MongoDB 4.2.6	aphyr	13.69891	-5.3122425	story	5.0	159.0	1589546304	9.913735
23270912	No. Every time I've used mongodb we'	No. Every time I've used mongodb we've ended up regretting it for one reason or another. And migrating to a different database after launch is a huge hassle.I've done a couple projects where we kicked off with postgres using JSONB columns for early iteration. Then we gradually migrated to normal SQL columns as the product matured and our design decisions crystallized. That gave us basically all the benefits of mongodb but with a very smooth journey toward classical database semantics as we locked down features and scaled.	josephg	13.623758	-5.376052	comment	5.0	42.0	1590146884	9.88783
23272137	All of these replies are for Mongo's	All of these replies are for Mongo's product 5+ years ago. MongoDB has changed A LOT since then. Has anyone used MongoDB IN THE PAST 2 YEARS?	randtrain34	13.69946	-5.310415	comment	5.0	16.0	1590156134	9.909327
23282561	For our B2B application, we've been 	"For our B2B application, we've been using SQLite as the exclusive means for reading and writing important bytes to/from disk for over 3 years now.We still have not encountered a scenario that has caused us to consider switching to a different solution. Every discussion that has come up regarding high availability or horizontal scaling ended at ""build a business-level abstraction for coordination between nodes, with each node owning an independent SQLite datastore"". We have yet to go down this path, but we have a really good picture of how it will work for our application now.For the single-node-only case, there is literally zero reason to use anything but SQLite if you have full autonomy over your data and do not have near term plans to move to a massive netflix-scale architecture. Perform"	bob1029	13.54141	-5.4743137	comment	5.0	26.0	1590238830	9.78051
23287412	I was floored by this comment yester	"I was floored by this comment yesterday from one of their Developer Relations people:> Did any of you actually read the article? We are passing the Jepsen test suite and it was back in 2017 already. So, no, MongoDB is not losing anything if you know what you are doing.https://twitter.com/MBeugnet/status/1253622755049734150?s=20Can you imagine saying the phrase ""if you know what you are doing,"" in public, to your users, as a DevRel person? Unbelievable."	kyllo	13.689025	-5.3174386	comment	5.0	42.0	1590275152	6.2810464
23357406	Stack Overflow Research: MongoDB Is 	Stack Overflow Research: MongoDB Is the Database Most Wanted by Developers	krnaveen14	13.607226	-5.3289285	story	5.0	3.0	1590799649	9.884427
26749737	SQLRite – SQLite clone from scratch 	SQLRite – SQLite clone from scratch in Rust	ibraheemdev	13.624987	-5.653609	story	5.0	63.0	1617971746	9.810561
26769383	"""Tokutek claims to improve MongoDB p"	"""Tokutek claims to improve MongoDB performance 20x. It is unclear if this also means losing 20x as many documents.""ROFL."	toolslive	13.699702	-5.3298516	comment	5.0	23.0	1618138787	9.896215
26817320	SQLlite is awesome right up to the p	"SQLlite is awesome right up to the point where it corrupts everything and leaves you in an unrecoverable state.  At that point you need to have working backups and a plan to migrate to a real DB server.  Actually, if ""working backups"" is a thing that makes sense for your use case just figure out how to use PostgreSQL now."	yaur	13.5358305	-5.4756474	comment	5.0	23.0	1618472541	9.808706
27017317	The main restriction is that the DB 	The main restriction is that the DB really needs well fitting indexes, otherwise querying is really slow and fetches a lot of data.Regarding writing:You could of course implement a writing API with POST requests for changing pages of the database - but then you would lose most of the benefits of this (not requiring any special kind of server).I also thought about implementing a kind of overlay filesystem, where chunks that are written to the file are stored in a local storage so the modified data is available locally while still reading everything else from the remote database.Interestingly in SQLite that's already exactly what the WAL mode does: It's a second file next to the database that's just a set of pages that are overlaid over the main file when read queries happen - which allows c	phiresky	13.558632	-5.480167	comment	5.0	16.0	1619978397	9.768096
27179909	Geocode-sqlite: Geocode rows in an S	Geocode-sqlite: Geocode rows in an SQLite database table	chmaynard	13.607667	-5.575056	story	5.0	123.0	1621223687	9.861439
27220725	PostgreSQL 14 Beta 1 Released	PostgreSQL 14 Beta 1 Released	jkatz05	13.533118	-5.40324	story	5.0	49.0	1621516686	-13.128856
27324669	Collection of public datasets packag	Collection of public datasets packaged as SQLite databases	roperzh	13.598013	-5.5536103	story	5.0	126.0	1622289334	9.827628
27347007	UUIDs are great when you use the id 	"UUIDs are great when you use the id ""publicly"" but using an incremental value would be too revealing for different reasons.So it's good to know that performances are not bad."	conradfr	13.976616	-5.2093835	comment	5.0	39.0	1622486819	-13.657525
27347351	I use a ulid[1] as a uuidv4 replacem	I use a ulid[1] as a uuidv4 replacement:https://github.com/ulid/spec	hermanradtke	13.992555	-5.2130604	comment	5.0	17.0	1622489197	-13.67095
14712390	Why wouldn't you always use somethin	Why wouldn't you always use something that is tried-and-true? MongoDB is relatively new compared to something like postgresql or even mysql.	epmaybe	13.683907	-5.319426	comment	5.0	41.0	1499364011	9.900032
14727572	>  User own resource id should be av	>  User own resource id should be avoided. Use /me/orders instead of /user/654321/ordersCan somebody explain this?	philip1209	13.6735935	-5.2506714	comment	5.0	21.0	1499554189	9.732592
14728652	I still don't understand why Cockroa	I still don't understand why CockroachDB doesn't just use Spark as the compute layer. Spark seems perfectly capable as a platform for performing arbitrary distributed computations on distributed data sources. It even has a full-fledged distributed SQL engine!As it stands, it seems to me that CockroachDB is mostly just reinventing Spark from scratch, except maybe from a more OLTP-centric perspective.	elvinyung	13.522268	-5.216289	comment	5.0	33.0	1499582017	9.821532
14791925	Announcing RethinkDB 2.3.6: the firs	Announcing RethinkDB 2.3.6: the first release under community governance	TheMissingPiece	13.691333	-5.2816367	story	5.0	128.0	1500322374	-12.81606
14950060	CouchDB 2.1.0	CouchDB 2.1.0	tropshop	13.618252	-5.2074046	story	5.0	101.0	1502131321	9.685751
14957351	Bit of a confusing name, when there 	Bit of a confusing name, when there is already an extremely popular mongodb node.js framework called Mongoose	robinduckett	13.660591	-5.3370075	comment	5.0	20.0	1502197386	9.826738
15024690	I worked with one of the largest ad 	I worked with one of the largest ad publishing companies.  They wanted to track data about every client served an ad.  This generated over 1.2 Terabyte per hour of data when the MySQL master started to max out.  We had the largest possible multiple core system.  It was going to cost my client $30k to upgrade to SSD drives to get more out of MySQL.  Also note we had to store this data on an expensive SAN in order to feed the data at a reasonable rate to MySQL or PostgreSQL.I had just learned of MongoDB and went to school at 10gen for their sys admin class.  I talked to the developer about storing the data in NoSQL using a small sharded cluster on a Friday.  Monday morning he asked me to setup a MongoDB cluster.  Tuesday we moved over from MySQL.  They ended up using much smaller servers, go	dsmithatx	13.559409	-5.2939506	comment	5.0	27.0	1502853383	9.811844
15124904	Is MongoDB the leader in NoSQL?  I s	Is MongoDB the leader in NoSQL?  I stopped using them years ago because of scaling issues.  With things like Elastic Search and Dynamo DB, I see no reason to use MongoDB anymore.	jasonrhaas	13.61632	-5.301115	comment	5.0	20.0	1504020449	9.888681
15183096	I haven't been following this, but f	I haven't been following this, but from what I can gather:- They raised $60mil (the last round being a Series G for $25mil!)- They're being sold for what I can only this is a pittance / acquihire by Bet365- Bet365 is buying them because they're heavily invested in Riak internally- They're open sourcing the code (likely because they need help)I'm not trying to disparage anyone here, but this makes my blood run cold.Is Riak so critical to Bet365 that the right move was to _buy the company_ versus switching to a different storage system?Is there a NoSQL vendor that's doing well out there?Should we all just be using Postgres anyway?	michaelbuckbee	13.551228	-5.336316	comment	5.0	23.0	1504701320	9.843533
15384233	Does anyone else see it as an issue 	Does anyone else see it as an issue that the decentralized website solution to databases is to create a copy of a SQLite database on every user's machine?	eberkund	13.60177	-5.5043106	comment	5.0	28.0	1506956213	9.808534
15401193	I can't find any documentation on ho	I can't find any documentation on how, exactly, ACID is achieved across all these partitions. It's impossible to reason about performance characteristics in the absence of documentation.For example, if they use two-phase commit, what is the granularity of locks ( table, row, etc )during an open transaction? Table locks during two-phase commit with, say, 50ms coast-to-coast latency would be an immediate dealkiller.Or, if it's eventually consistent as most asynchronously distributed DBs are, they can't claim AC.I really wish Cockroach had better documentation - not so much how to use it, but how it works so as to let engineers reason about performance characteristics.	daxorid	13.549225	-5.235522	comment	5.0	23.0	1507131236	9.797067
15500439	"From their blog: ""TiKV is a distribu"	"From their blog: ""TiKV is a distributed key-value database. It is the core component of the TiDB project and is the open source implementation of Google Spanner."" I think the Cockroach DB guys would take offence at that.So how do they use a Spanner-like design without specialized hardware? I had to really dig but the answer is ""We are using the Timestamp Allocator introduced in Percolator, a paper published by Google in 2006. The pros of using the Timestamp Allocator are its easy implementation and no dependency on any hardware. The disadvantage lies in that if there are multiple datacenters, especially if these DCs are geologically distributed, the latency is really high.""Using Spanner's design but without the real hardware that makes it practical seems like a step backward. A Calvin[1] b"	eloff	13.552683	-5.1886687	comment	5.0	25.0	1508343657	9.692065
28707104	We currently use MongoDB and while P	"We currently use MongoDB and while Postgres is attractive for so many reasons, even with Amazon Aurora's Postgres we still need legacy ""database maintenance windows"" in order to achieve major version upgrades.With MongoDB, you're guaranteed single-prior-version replication compatibility within a cluster. This means you spin up an instance with the updated version of MongoDB, it catches up to the cluster. Zero downtime, seamless transition. There may be less than a handful of cancelled queries that are retryable but no loss of writes with their retryable writes and write concern preferences. e.g. MongoDB 3.6 can be upgraded to MongoDB 4.0 without downtime.Edit: Possibly misinformed but the last deep dive we did indicated there was not a way to use logical replication for seamless upgrades. "	bmcahren	13.575265	-5.2804866	comment	5.0	49.0	1633013898	9.8338785
28828918	I really don't get why Mozilla argue	I really don't get why Mozilla argued that they would have to re-implement SQLite for WebSQL, but then used SQLite for IndexedDB. Why were they so opposed to using SQLite for WebSQL?	thayne	13.581334	-5.548688	comment	5.0	23.0	1633963687	9.820087
28836904	"One of the key benefits of ""Best Pra"	"One of the key benefits of ""Best Practices"" is, when provided by the documentation of something you're using, you can reliably consider it as good advice and follow it, even if you don't necessarily understand why it is the best practice.An instance of this would be ""Best Practices for Cloud Firestore""[1] which spends a whole lot of time discussing different ways of avoiding ""hotspotting"" without really going into any detail about what it is or what specifically causes it, other than that it adds latency. If my project manager asks me why we're not using sequential IDs, and I say it's a best practice according to the documentation, he'll happily accept that answer even if neither of us understand why it's a best practice.[1] https://firebase.google.com/docs/firestore/best-practices"	djrockstar1	13.918129	-5.197415	comment	5.0	16.0	1634022443	-13.645213
28998208	Wow, yeah, good point.Rewrites in ge	"Wow, yeah, good point.Rewrites in general are usually a terrible idea, unless the original is horribly broken (and beyond fixable).If you wrote your app in C++, instead of rewriting it for the next decade in Rust just to get to the same point, slap some AddressSanitizer, ThreadSanitizer, -fanalyzer, cppcheck, etc. on it. You will get 98% of the way there.Instead of spending 8+ years(!) rewriting[1] the GNU coreutils in Rust, you could spend half that time to ensure full coverage (branch-coverage, condition-coverage) in the existing ones. I will actually have a breakdown if someone tries to rewrite SQLite in Rust[2].1: https://github.com/uutils/coreutils
2: https://sqlite.org/testing.html"	lionkor	13.589733	-5.7724867	comment	5.0	22.0	1635240575	9.862085
29312880	Postgres is awesome technology but f	Postgres is awesome technology but for a lot of applications SQLite will do the job just fine. This gets you a single binary with zero external dependencies.	pstuart	13.534606	-5.447371	comment	5.0	27.0	1637624057	9.825892
29365821	STRICT tables forbid the use of any 	STRICT tables forbid the use of any other types besides INT/INTEGER, REAL, TEXT, BLOB (and ANY).What about TIMESTAMP? DATETIME? You can't use that as a type name anymore. Either pick INT, REAL or TEXT for that. What about JSON? You can't use it as a type name anymore. Pick TEXT. Basically type names, even if SQLite didn't have explicit support for that type, were helpful documentation hints in what the column contained. Now everything devolves to either INT or TEXT. I have UUID fields, I can't even call them UUID or BINARY(16), just BLOB.	SPBS	13.604674	-5.611211	comment	5.0	38.0	1638068716	9.858077
29462053	Those tend to fall out of the “activ	Those tend to fall out of the “active use” category not long after entering it, so it’s probably not a big factor.On a more serious note, had there been something special about SQLite supporting military use of their project that prompted this? Otherwise that’s the point of free software, people are free to do (mostly) whatever they want with it. Including building weapons. SQLite is so prevalent, it’s almost like pointing out you have to include cruise missiles in the count of active x86 chips, or $insert_bad_guy as an active user of roads and electricity.	ntumlin	13.615377	-5.576255	comment	5.0	15.0	1638809168	9.835436
29461268	Then one day a better embedded db co	Then one day a better embedded db comes along and people forget about sqlite.	postalrat	13.5945015	-5.552031	comment	5.0	21.0	1638806188	9.837281
25463094	The problem I have with sqlite for b	The problem I have with sqlite for being a general purpose file format is that it’s difficult to take a sqlite file in any language and work with it without linking against code.I kind of wish that there were native implementations of sqlite in every language.	sargun	13.5654745	-5.571921	comment	5.0	29.0	1608258193	9.859028
25463293	While I generally agree with the poi	"While I generally agree with the points they make I'm not sure I would want a (stock) sqlite being used for ""less"" trusted files.While sqlite has a very comprehensive test suite there had been more than one attack with ""manipulated"" database files and as far as I know (I might be mistaken) the test suite(s) are not focused on testing that case much.Through I'm positive that it would be fine with a ""hardened"" sqlite where certain features are not compiled in at all and in turn the attack surface is reduced."	dathinab	13.622174	-5.613184	comment	5.0	49.0	1608260233	9.857146
25464221	This reminds of the WebSQL spec bein	This reminds of the WebSQL spec being dropped because the only implementations used SQLite:> The W3C Web Applications Working Group ceased working on the specification in November 2010, citing a lack of independent implementations (i.e. using database system other than SQLite as the backend) as the reason the specification could not move forward to become a W3C Recommendation.-- Wikipedia> This document was on the W3C Recommendation track but specification work has stopped. The specification reached an impasse: all interested implementors have used the same SQL backend (Sqlite), but we need multiple independent implementations to proceed along a standardisation path.-- W3CI wonder how much of their reasoning applies here.	danellis	13.58488	-5.563317	comment	5.0	18.0	1608269874	9.824399
25551390	So if I understand this correctly, t	So if I understand this correctly, they didn’t have the correct understanding/skills to manage a Mongo DB, so they switched to one they were more familiar with.I wonder what this ultimately cost. Migrating from a document model to a relational DB requires code change in pretty much every single location it’s used. That’s a lot of engineer time to develop, test, and do the data migration.	KMnO4	13.675719	-5.3252287	comment	5.0	17.0	1609080651	9.888508
25628110	For the record, I've used CouchDB mu	For the record, I've used CouchDB multiple times and it was a mistake every one of them. Moving to Postgres never takes as much time as you'd think, and having a database which is rock solid, understood, and performant is a great idea. Choose a DB which you will be happy with when there's an issue at 4AM, not the one fun to use at 4PM.	sfeng	13.595646	-5.228042	comment	5.0	50.0	1609737153	3.979888
25871211	Now I'm even more baffled. What kind	"Now I'm even more baffled. What kind of stupid logger logs a uuid without a clue as to what kind of object it identifies? Why would you need to communicate uuids to higher management?This makes me think of Douglas Adams. You know the answer is 42 but you forgot what the question was. I really can't imagine how this could ever happen in a business. ""Yes, sir, there was a problem with 1087."" ""1087 what?"" ""I don't know, but it was number 1087."""	globular-toast	13.995382	-5.211963	comment	5.0	28.0	1611319538	-13.627688
25872887	I just open-sourced a streaming repl	I just open-sourced a streaming replication tool for SQLite called Litestream that does physical replication (raw pages) instead of logical replication (SQL commands). Each approach has its pros and cons. Physical replication logs tend to be larger than logical logs but I agree that you avoid a lot of issues if you do physical replication.https://github.com/benbjohnson/litestream	benbjohnson	13.568058	-5.489401	comment	5.0	34.0	1611331981	9.773299
25991094	Mongo and other nosql databases are 	Mongo and other nosql databases are still the absolute fastest way to get started particularly you don't know what your data is eventually going to look like.	offtop5	13.618574	-5.3366213	comment	5.0	29.0	1612201736	9.859208
26101311	Are these things really better than 	Are these things really better than just opening a sqlite3 database with python?	swiley	13.548958	-5.616077	comment	5.0	25.0	1613050581	9.8510275
26416621	The SQLite R*Tree Module	The SQLite R*Tree Module	mpsq	13.543765	-5.620912	story	5.0	110.0	1615412371	9.707194
26440716	"Oh that ""returning"" is nice; in curr"	"Oh that ""returning"" is nice; in current SQLite I'm doing a second query to get that:  SELECT last_insert_rowid()"	4ec0755f5522	13.611838	-5.5844374	comment	5.0	23.0	1615582157	9.888136
26440737	> Column removalWow, finally. I Love	> Column removalWow, finally. I Love SQlite. It saved my a* in so much projects where I had to implement an ETL, I just spawned some in memory SQLite database instead of writing some painful custom code in Language X or Z over and over again. Also used it to generate static search results in a flat file blogging platform since it does have some full text search capabilities. And let's not even talk about custom functions, including custom aggregation functions, in any client language, directly in your application code...	throw_m239339	13.561939	-5.563201	comment	5.0	41.0	1615582251	9.856389
26441125	What's the best way to run a service	What's the best way to run a service that uses SQLite in a serverless / container environment (e.g. Cloud Run).I'd love to use this for my personal projects and I'm not sure how to set this up in a container given their ephemeral nature.	krat0sprakhar	13.578482	-5.500275	comment	5.0	16.0	1615584216	9.832378
13611162	Do I understand correctly that the a	Do I understand correctly that the author went from a distributed database to a single-master scenario? That's a valid tradeoff, but I'd clearly describe it as such.My experiences with RethinkDB have been rather positive, but my load is nowhere near that of what the article describes. I agree that ReQL could be improved, I found that there are too many limitations in chaining once you start using it for more complex things.But the two most important advantages remain for me:* changefeeds (they work for me),* a distributed database that I can run on multiple nodes.I do agree that PostgreSQL is fantastic and that SQL is a fine tool. In my case the above points were the only reasons why I did not use PostgreSQL.EDIT: after thinking about this for a while, I wonder if the RethinkDB changefeed 	jwr	13.5376425	-5.295451	comment	5.0	25.0	1486675759	9.674003
13661532	I agree completely. I love reading a	I agree completely. I love reading about databases, but apparently have been skipping reading about CockroachDB for that same reason subconsciously. I took a deep dive the other day and was amazed that I've seen the name dozens of times and have never bothered to ask what was special about it. It really is a fascinating database.	finder83	13.590935	-5.293476	comment	5.0	16.0	1487264722	1.9781932
13700421	SQLite backendBecause comments are n	SQLite backendBecause comments are not Big Data.Yep, you got it.Also MIT licensed.Please go ahead and kill Facebook comments.I strongly dislike realname policies in this day and time where a single remark can cost you your job.	reitanqild	13.607253	-5.554334	comment	5.0	26.0	1487714154	-12.179822
14091036	Competitor here, please don't become	"Competitor here, please don't become an ""open core"" company - ""Open Core"" = ""Crippleware"".Here is my thoughts/arguments around it, dealing with the RethinkDB and Parse shut down as well: https://hackernoon.com/the-implications-of-rethinkdb-and-par...Plus, was invited to speak about it on the Changelog Podcast: https://changelog.com/podcast/236Please stay truly open :) that way we can still compete. ;) Or else we'll be the only company that is fully Open Source (replication, auto failover, etc.)!"	marknadal	13.648772	-5.213446	comment	5.0	22.0	1491935709	-12.764886
14223195	I know PostgreSQL meant to defend th	I know PostgreSQL meant to defend themselves, but it just made the matter worse.1) I didnt even know Uber switched database, now I know. I also know the reasons.2) Comes across as unprofessional, you don't see Microsoft defending MSSQL this way. They let the users see it for themselves.	grezql	13.574372	-5.4462776	comment	5.0	17.0	1493414844	-13.229878
14232793	It sounds like you're not so much in	"It sounds like you're not so much in ""the"" industry but a subset of the industry that doesn't consider free open source software to be an option.If you're fighting the attitude that the only viable option is one that costs a ton of money instead of a decision based on technical merit, additional facts about Postgres won't help.Sometimes the decision gets made on a golf course and not after reading very long texts."	gdulli	13.543482	-5.31481	comment	5.0	44.0	1493574255	9.795513
14293804	Interesting that they managed to fin	Interesting that they managed to find 8 security bugs in SQLite, which is renowned for having a test suite with ~100% code coverage - yet more evidence for the Dijkstra dictum that testing cannot prove the absence of bugs.https://sqlite.org/testing.html	the_why_of_y	13.649631	-5.615953	comment	5.0	20.0	1494265355	9.8641405
14510369	Why would you ever want to use UUID 	Why would you ever want to use UUID format, which only has 122 bits, versus just making a random 128 bit number? In which realistic scenario would simply reading 16 bytes from urandom not be fine and actually cause issues that removing 6 of those bits to identify the UUID type help?Also, 32 bit timestamp + 128 random? I guess, but that sounds sort of overkill-ish - if you're going to go to 20 bytes (and thus not fit in a DB's UUID type, require more than 2 registers, etc.), why not make it 24 or 32 bytes and have a proper timestamp? Or if 32-bit timestamp is really acceptable, are you sure that 96-bits of randomness are not?	MichaelGG	13.985075	-5.2148004	comment	5.0	18.0	1496874633	-13.654128
14550681	I know that SQLite performs exceptio	I know that SQLite performs exceptionally on embedded devices including most phones, IoT devices, and more. However, for better or worse, it's a flat file. Does anyone know of a TCP/IP-speaking SQL database that would work well on an embedded device? PostgreSQL/MariaDB seem kinda heavy, and the net couplers for SQLite look pretty unsupported.	wyc	13.594528	-5.5553017	comment	5.0	20.0	1497415072	9.808703
14550593	Prompting the question: why isn't th	Prompting the question: why isn't the whole disk just a SQLite database?	paulddraper	13.597703	-5.55424	comment	5.0	16.0	1497413249	9.911667
23412799	"      c = pMem->flags;
      sqlite3"	"      c = pMem->flags;
      sqlite3VdbeMemRelease(pMem);
      pMem->flags = MEM_Str|MEM_Term|(c&(MEM_AffMask|MEM_Subtype));

'pMem->flags' is a u16[1]. Shouldn't it be copied to 'c'. How can 'sqlite3VdbeMemRelease' alter the value of 'c'.[1]https://github.com/smparkes/sqlite/blob/8caf9219240123fbe6cf..."	fctorial	13.618279	-5.6017475	comment	5.0	17.0	1591248206	9.900013
23507518	I've worked contracts in UK banks fo	I've worked contracts in UK banks for a number of years now. Nothing on the mainframes but I know some of the guys that do work on those and, despite the constant stream of flavour-of-the-month tech that we talk about constantly in places like HN, the mainframes work well and will not be replaced any time soon.The dev cycle for releases and whatnot is incredibly long due to testing and, lets be honest, fear, in case something breaks but when it comes to battle-tested technology, mainframes and DB2 are right up there.I do know of some code that's over 40 years old and still runs at the core of one of the big banks...MongoDB, despite its capabilities, is... an odd choice imo! Not trying to second-guess but if I was in that meeting I would have certainly raised an eyebrow.Good luck to them.	_Understated_	13.6567545	-5.319385	comment	5.0	29.0	1592032572	9.906609
23507624	Lots of negative comments about Mong	Lots of negative comments about MongoDB for folks who don't use it, but perhaps give NoSQL a chance and keep an open mind? there is no need to structure the data into tables and schema does not need to be enforced at the DB level.Google has been running its entire infrastructure on a NoSQL database for years.Perhaps folks need to keep some open mind and see if that works instead of dismissing a new trend?	aogaili	13.633581	-5.3435407	comment	5.0	20.0	1592033869	9.902174
23507490	I'm not in the banking industry but 	I'm not in the banking industry but this sounds like the type of industry where you really need strong DB schemas in place and not something mongo-like ...	realusername	13.62799	-5.328791	comment	5.0	26.0	1592032199	9.866293
23511166	Combined with the correctness fuzzin	Combined with the correctness fuzzing results by SQLancer [1] where SQLite had 179 issues revealed (vs. 11 in PostgreSQL), I think the 100% coverage is a lot less meaningful than I had thought.Robustness is not necessarily correctness and if the unit tests are just mirror images of the code, their results may help against regressions but little for correctness.[1]: https://www.manuelrigger.at/dbms-bugs/	ysleepy	13.621787	-5.6001196	comment	5.0	20.0	1592070345	9.885516
23519885	For a long time I've been running ma	"For a long time I've been running many apps with a wrapper to disable fsync in SQLite integrations. Its a harsh solution.Am I correct that out of the box it's implementing a full integrity around ""commit"" -- ie. The data has to fully hit the disk before the call returns?For most applications I don't want this. Browser history for example is fine if the most recent transactions are lost on a power failure. Of course I do not want the file to be corrupted and lost.At a previous employer we had similar issues with Chrome's internal SQLite database (Linux) in an environment with network mounted home directories. It was dealt with by a Chrome wrapper to change one of the internal flags on the user's SQLite database.Possibly we may just have a case of a bad default here. Particularly in the cont"	zbuf	13.549689	-5.567498	comment	5.0	19.0	1592158495	9.684006
23536647	I'm having trouble imagining who wou	I'm having trouble imagining who would want to use this. What's the environment where you would have curl and a need for generating UUIDs, but wouldn't have access to uuidgen or similar?	tkfu	13.987088	-5.214871	comment	5.0	28.0	1592291413	-13.6479645
23540996	Cool hack, but probably wouldn't ins	Cool hack, but probably wouldn't install a separate kernel or run an entire notebook just for sqlite work.What would be useful is for the kernel of your language of choice to provide a magic for sqlite and return results of queries in language-native data structures.Something like this: https://pypi.org/project/ipython-sql/	seemslegit	13.601139	-5.5913515	comment	5.0	20.0	1592324683	9.906546
23779131	> Striving for 100% test coverage is	> Striving for 100% test coverage is nonsenseTell that to SQLite guy.	alecco	13.645371	-5.620586	comment	5.0	24.0	1594295223	9.901803
23898980	> it's impossible to remember 32 ran	> it's impossible to remember 32 random characters in UUIDIs it, though?Plenty of folks memorise 16-digit credit card numbers - I've known retail employees who can recite those back after reading them just once.Back when I was a sysadmin, I taught myself to type 25-digit Windows product keys from memory.32 digits doesn't seem an unreasonable stretch, given time and practice.	swiftcoder	13.987022	-5.2109942	comment	5.0	17.0	1595260083	-13.662868
24193822	SQLite feels like this to me.  It's 	SQLite feels like this to me.  It's more than one person, and it's not thankless work (at least, I hope).  But still it is critical to a surprising amount of technology, and maintained by a very few people.	banana_giraffe	13.608027	-5.5856647	comment	5.0	17.0	1597709459	9.829359
24259514	> sqLite - This is described as bein	"> sqLite - This is described as being unsuitable for 
> production by it's makers.I would doubt that is what the creators of SQlite intend one to take away from their documentation:""SQLite works great as the database engine for most low to medium traffic websites (which is to say, most websites). The amount of web traffic that SQLite can handle depends on how heavily the website uses its database. Generally speaking, any site that gets fewer than 100K hits/day should work fine with SQLite. The 100K hits/day figure is a conservative estimate, not a hard upper bound. SQLite has been demonstrated to work with 10 times that amount of traffic.> The SQLite website (https://www.sqlite.org/) uses SQLite 
> itself, of course, and as of this writing (2015) it handles 
> about 400K to 500K HTTP reque"	sdoering	13.593371	-5.529033	comment	5.0	36.0	1598267533	9.812112
24379755	"The ""Mongo DB is Web Scale"" video ju"	"The ""Mongo DB is Web Scale"" video just turned 10 years old. I'm pretty sure that was a big factor in MongoDB not being taken seriously by many people.https://www.youtube.com/watch?v=b2F-DItXtZs"	slyall	13.691827	-5.3231487	comment	5.0	21.0	1599260415	9.924202
24379857	I never got a definite answer: What 	I never got a definite answer: What problem does MongoDB even try to solve?	numlock86	13.724529	-5.315241	comment	5.0	34.0	1599261194	9.890451
20862138	Should I sell MongoDB? In around $29	Should I sell MongoDB? In around $29 last year and have seen 450% return... The concern was always it becomes next X	whoevercares	13.690127	-5.318765	comment	5.0	16.0	1567462850	9.917225
20862425	A lot of companies got lured into us	A lot of companies got lured into using mongodb because it was so developer friendly. It cost nothing and it was easy bring in the back door and alleviated the need for thought.Then their sales people started coming around and asking for insane sums of money (like $10,000 per instance per year plus 100% markup on hardware to run in AWS - support is extra). They were worried about amazon and others offering a better so next they changed the license.If it had been SQL it would have been easy to drop in another database. But Mongodb is so different from anything else that you need a major rewrite to get away from it. Postgres has some similiar functionality but it’s not drop in. Amazon has a more or less public beta of DocumentDB which as far as I can tell is a mongodb compatible interface to	zxcvbn4038	13.65019	-5.1986594	comment	5.0	55.0	1567466181	9.8510065
31153237	> For device-local storage with low 	> For device-local storage with low writer concurrency and less than a terabyte of content, SQLite is almost always better.Isn't MySQL MyISAM faster and this way constitute a better choice for a scientific number crunching application? I mean near 4GB DB, very simple schema, heavy reading load, little/no inserts and no updates.	qwerty456127	13.559648	-5.5089498	comment	5.0	29.0	1650887589	9.8205
31214653	"""Backup or restore while a transacti"	"""Backup or restore while a transaction is active""Is it possible to turn off transactions alltogether in SQLite? So they function like a MyIsam table in MySql or a Aria table in MariaDB?I have crunched many billions of queries over the last years in MySql and then MariaDB. I like MariaDB because it offers tables that are way faster due to no transaction overhead.I know this goes against the popular opinion to use transactional tables for everything. But depending on the task at hand, the performance gain can be very well worth turning transactions off.I consider trying SQLite. But if you cannot switch off transactions, performance will probably not be up to par."	TekMol	13.556644	-5.5094357	comment	5.0	23.0	1651311905	9.754281
31340409	Has anyone tried to write a new mode	Has anyone tried to write a new modern SQLite?	vaughan	13.61518	-5.5778265	comment	5.0	19.0	1652279114	9.822277
31342984	SQLite is great but it's way overhyp	SQLite is great but it's way overhyped and abused on HN. People are very eager to turn SQLite into a durable, distributed database and it's really not meant for that, and by going down that road instead of using something like MySQL or Postgres you're missing out on lots of important functionality and tooling.I only say this because I have made this mistake at my previous startup. We built these really cool distributed databases on top of a similar storage engine (RocksDB) plus Kafka, but it ended up being more trouble than it was worth. We should have just used a battle-tested relational database instead.Using SQLite for these applications is really fun, and it seems like a good idea on paper. But in practice I just don't think it's worth it. YMMV though.	peterhunt	13.566545	-5.541707	comment	5.0	20.0	1652289402	9.812594
31398546	WordPress should be on SQLite by def	WordPress should be on SQLite by default. Most installations run only on one sever and are rather small (less than a few GB database size). And not a lot of inserts/updates to the DB.In those cases SQLite will probably have much better speed and a lower memory footprint.	andix	13.579143	-5.5234227	comment	5.0	30.0	1652713693	9.801677
31398949	I figured out how this works. The se	I figured out how this works. The secret sauce is this code, which uses regular expressions to rewrite the MySQL SQL queries for compatibility with SQLite!https://github.com/aaemnnosttv/wp-sqlite-db/blob/14f9e917c55...	simonw	13.603916	-5.5885634	comment	5.0	27.0	1652715200	9.861358
31518619	Richard Hipp, of sqlite fame, just a	"Richard Hipp, of sqlite fame, just announced the project's new WASM-based ""fiddle"" app in the sqlite forum (https://sqlite.org/forum/forumpost/5cfd681451), providing a way for users to run a slightly-hacked build of the sqlite3 shell app in their browsers (with no server-side backend).(Edit: this was my first-ever HN post and i _thought_ that this comment was going to ""stick"" up top with the link to serve as an introduction/explanation. Didn't realize that it would be ""just another comment."")"	sgbeal	13.609255	-5.57629	comment	5.0	18.0	1653574719	9.824968
31530133	Here's an absolutely crazy idea that	Here's an absolutely crazy idea that I had the other day... Since Zig has comptime, couldn't a Zig reimplementation of SQLite use comptime for compile-time query compilation? Including generating native code for fixed queries? So far I haven't been able to come up with any counterargument for why this wouldn't work.	jhgb	13.624417	-5.66625	comment	5.0	28.0	1653662111	12.498918
31716809	UUIDs have a few distinct advantages	UUIDs have a few distinct advantages: you'll never run out, you don't need a roundtrip to find out what they are after saving them, they often make a good partitioning key and it makes things easier if you ever need to combine multiple data sources together in migration and recovery type scenarios. I also quite like how they're unique across all data sources and tables, so if you just encounter a random contextless UUID in the wild, for example in a support ticket, you can probably still find what it refers to.They are quite unwieldy though. There are a few compact representations you can use in URLs which make it a bit less ugly, but they can make your database and logs quite bloated, in particular if you've got a large number of small records.	cameronh90	13.974205	-5.2118144	comment	5.0	40.0	1655057597	-13.654476
31716987	It's actually worse than that. The f	It's actually worse than that. The first 3 groupings (textually) of the uuid might be little endian while the other 2 are big endian.  Learning this cost me more time than I care to admit.https://en.wikipedia.org/wiki/Universally_unique_identifier#...	firebird84	13.984675	-5.210311	comment	5.0	16.0	1655058729	-13.707819
31721983	Don’t UUIDs as primary keys totally 	Don’t UUIDs as primary keys totally destroy the performance because UUIDs aren’t sortable and thus wreak havoc with the index for the primary key?	vlovich123	13.9690275	-5.224273	comment	5.0	15.0	1655102063	-13.667027
35544499	At one company we had one-off reques	"At one company we had one-off requests to run get some statistics from our mongodb.Writing the proper queries proven pretty tricky whenever GROUP BY/JOINs were involved, so I used online converters between SQL -> mongo query.But then I realized that PostgreSQL has nice JSONB type (supports indices for subfields). So I put all the mongo data into tables with a single JSONB column (or two columns id+data, if you prefer).Turned out that was much faster to run analytical queries :)""document"" is just row""collection"" is just table"	deepsun	13.522916	-5.4365425	comment	5.0	42.0	1681324250	9.811633
35550530	Running Dolly 2.0 on Paperspace	Running Dolly 2.0 on Paperspace	l2dy	13.557788	-5.220466	story	5.0	73.0	1681356393	-5.536121
35879425	Can I use it to backup SQLite? Like 	Can I use it to backup SQLite? Like an alternative to Litestream? Are there any negative implications for doing this?	alexbezhan	13.585494	-5.5156956	comment	5.0	17.0	1683661297	9.746481
35928166	I'm constantly resisting the urge to	"I'm constantly resisting the urge to write ""MongoDB is webscale"" whenever these threads show up.For the uninitiated: https://news.ycombinator.com/item?id=1636198. The original video is gone but it lives on YouTube: https://m.youtube.com/watch?v=b2F-DItXtZs."	probably_wrong	13.68087	-5.3212705	comment	5.0	19.0	1683984549	9.896306
35951639	Exactly I will never ever try MongoD	"Exactly I will never ever try MongoDB because of that.
A database that do not fsync should not be called a database."	skyde	13.660535	-5.3341346	comment	5.0	27.0	1684171893	9.89163
36054521	SQLite builds for WASI since 3.41.0	SQLite builds for WASI since 3.41.0	rapnie	13.622344	-5.59035	story	5.0	111.0	1684907170	9.824189
36431163	I actually have been using a combina	I actually have been using a combination of a numeric integer ID as the PK and a UUID as a lookup field to do routing lookups etc. for this purpose in Postgres backed app I'm working on.I found this approach to be more trouble than it's worth and plan on switching to a UUID PK key and doing away with the integer sequence.Here are the complications I ran into:The libraries I'm using for the ORM and API are designed to work with a primary key for single record get access. For example they want you to do `resource.get(ID)` where ID is the primary key, however, I now have to do `resource.find({ where: { uuid: 'myuuid' }})`. This is for all resources on all pages.In Postgres, the integer PK sequence has a state that keeps track of what number it's at. In certain circumstances it can get out of 	babbledabbler	13.96571	-5.224086	comment	5.0	25.0	1687437199	-13.653609
36476099	I wish sqlite was performance focuse	I wish sqlite was performance focused. Perf is pretty much always worse than a db server, even after tuning the pragmas (the way it locks tends to limit single threaded perf and concurrency). Main benefit of sqlite is just its portability since you can easily embed it. It's nice for slapping a db backend on a client installed app, where trying to spin up a db server would be problematic.There's probably an extension for permissions in sqlite but out of the box the db files are plaintext (you need an extension for that).Good starting point for extensions: https://antonz.org/sqlean/	eyegor	13.583157	-5.538976	comment	5.0	15.0	1687758074	9.853523
36509861	I have some complaints about UUIDs. 	I have some complaints about UUIDs. Why not just combining time + random number without the ceremony of UUID versioning. And for when locality doesn't matter, just use a 128bit random number directly.And in my experience most people somehow think a UUID must be stored into the human friendly hex representation, dashes included. Wasting so much space in database, network, memory.	bombela	13.981113	-5.2055855	comment	5.0	24.0	1687973976	-13.66401
34148593	From a fun / teaching / learning poi	From a fun / teaching / learning point of view - I get it.  As others are saying however, the secondary learning that you want is that sometimes a database is the right solution.For example, a student could learn that they need to use a API (with all of the API problems: latency, server down, throttling, blah blah blah) when all they really need to do is download a sqlite file, hook up sqlite to their application, run one query - and have a vastly simpler application.  This could be as little as 10-50 lines of code.  Never underestimate the power of shipping data via sqlite files.	harshaw	13.574579	-5.551033	comment	5.0	15.0	1672149115	-12.110969
34209589	A pretty boring and stable year in S	"A pretty boring and stable year in SQLite land, which is just how I like it.The JSON -> and ->> operators introduced in 3.38 are my personal favorites, as these really help in implementing my ""ship early, then maybe iterate as you're starting to understand what you're doing"" philosophy:1. In the initial app.sqlite database, have a few tables, all with just a `TEXT` field containing serialized JSON, mapping 1:1 to in-app objects;2. Once a semblance of a schema materializes, use -> and ->> to create `VIEW`s with actual field names and corresponding data types, and update in-app SELECT queries to use those. At this point, it's also safe to start communicating database details to other developers requiring read access to the app data;3. As needed, convert those `VIEW`s to actual `TABLE`s, so I"	PreInternet01	13.530734	-5.587982	comment	5.0	27.0	1672600115	9.7665
34222340	Something interesting to consider wi	"Something interesting to consider with N+1 queries, these warnings only really apply to remote database servers, as in not on the same machine.If you are using SQLite, or another in process database, N+1 isn't an issue at all. So with the increased use of SQLite as an ""edge"" database it's something to consider.""Many Small Queries Are Efficient In SQLite"": https://www.sqlite.org/np1queryprob.html"	samwillis	13.60554	-5.5762196	comment	5.0	26.0	1672687098	9.800704
34326583	A contrary anectdotal exemple. We us	A contrary anectdotal exemple. We use MongoDB where I work and the only justification is it was the new fad at the time. Now it bites us because we use it as a relational DB. PostgreSQL would’ve been much more suitable in our case but it wasn’t in vogue.	ibizaman	13.593568	-5.358904	comment	5.0	47.0	1673365681	9.850308
34326638	Is there any regret in technology se	Is there any regret in technology selection more widespread and common than having picked MongoDB during its bizarre new hotness phase? That phase where SQL database administrators where crying, thinking they'd lose their jobs tomorrow and many people claimed SQL was now absolutely deprecated.	Traubenfuchs	13.660473	-5.333099	comment	5.0	17.0	1673365831	9.9048195
34435376	The only real difference between SQL	The only real difference between SQLite and something like Postgres or MySQL is that Postgres and MySQL bundle a networking layer on top of their embedded DB engines.If you are worried about high availability, chances are you too are building a networking layer on top of a database, so what do you need two networking layers for?	randomdata	13.576253	-5.498813	comment	5.0	20.0	1674089894	9.82518
34452017	While this is a good overview of the	While this is a good overview of the options for primary key generation, there's no silver bullet here. Most projects that are using SQL should just use the gold standard: an auto-incrementing integer for an internal primary key. And then decouple the public-facing primary key from it into a separate column, whether it be ULID, UUID, or a random-project-slug-123.Also, during debugging, it's a lot nicer to look at short primary keys than to have UUIDs flooding the screen.	ammmir	13.962782	-5.2266436	comment	5.0	39.0	1674216844	-13.663069
34603871	Running sqlite in memory as a test d	Running sqlite in memory as a test db speeds up your test runner as crazy. You can do this if you use an sql query builder library, because it can translate your queries to the specific database.	ddyevf635372	13.588464	-5.573505	comment	5.0	26.0	1675207625	9.80399
35120106	Why do projects that are meant to be	Why do projects that are meant to be lightweight use Postgres instead of SQLite? The latter is much easier to deploy (you, well, just don't need to), and does 99% of what anyone needs, and definitely 100% of what small projects need.	stavros	13.567729	-5.4915953	comment	5.0	25.0	1678629612	9.854303
39444384	I wonder how many people have built 	I wonder how many people have built failed businesses that never had enough customer data to exceed the DDR4 in the average developer laptop, and never had so many simultaneous queries it couldn't be handled by a single core running SQLite, but built the software architecture on a distributed cloud system just in case it eventually scaled to hundreds of terabytes and billions of simultaneous queries.	LeifCarrotson	13.555364	-5.482165	comment	5.0	32.0	1708451538	9.770763
39502461	Sqlite is embedded, so how do you ac	Sqlite is embedded, so how do you actually build it into your app? Is there a C file somewhere, an amalgamation published? I haven't been able to find it, but surely it exists.I'd like to build a Go binary with mattn/go-sqlite3 with osquery vtables included.	infogulch	13.617168	-5.622813	comment	5.0	16.0	1708880644	-5.766622
39593165	Ask HN: Why aren't more companies us	Ask HN: Why aren't more companies using ScyllaDB	callumvanengel	13.534903	-5.2255464	story	5.0	6.0	1709573450	9.825099
38602175	If you're interested in this, here a	If you're interested in this, here are some related projects that all take slightly different approaches:- LiteSync directly competes with Marmot and supports DDL sync, but is closed source commercial (similar to SQLite EE): https://litesync.io- dqlite is Canonical's distributed SQLite that depends on c-raft and kernel-level async I/O: https://dqlite.io- cr-sqlite is a Rust-based loadable extension that adds CRDT changeset generation and reconciliation to SQLite: https://github.com/vlcn-io/cr-sqliteSlightly related but not really (no multi writer, no C-level SQLite API or other restrictions):- comdb2 (Bloombergs multi-homed RDBMS using SQLite as the frontend)- rqlite: RDBMS with HTTP API and SQLite as the storage engine, used for replication and strong consistency (does not scale writes)- 	summarity	13.534868	-5.432008	comment	5.0	16.0	1702313310	9.796808
38662900	Structure of FTS5 Index in SQLite	Structure of FTS5 Index in SQLite	ellieh	13.533159	-5.5068226	story	5.0	95.0	1702717747	9.719312
38667848	Irrelevant but curious if MongoDB is	Irrelevant but curious if MongoDB is still being picked up for Greenfield projects given it's licensing.	wg0	13.727658	-5.225708	comment	5.0	41.0	1702762008	9.892398
38791614	why though? this is exactly what dat	why though? this is exactly what databases have been invented for! One could simply store a mapping of numbers to their classifications as 'even' or 'odd' in an SQLite database. This approach has the added benefit of not requiring program updates whenever a number's classification changes from odd to even.	BillyTheKing	13.598401	-5.6087627	comment	5.0	20.0	1703755354	9.843073
32559860	Honest question, if I have PostgreSQ	Honest question, if I have PostgreSQL containerized in docker such that it's trivially easy to spin up a new database, what then is the use-case for SQLite? I frequently hear people talk about it with such rosy tone, but I just don't see the reason to actually set it up when the alternatives today are so easy to use, what am I missing?	bluejellybean	13.556881	-5.515834	comment	5.0	15.0	1661221428	9.79147
15729099	There are projects that are close to	"There are projects that are close to bugfree, though. You can use a 3 year old version of sqlite without any difficulty. I don't know what version of ""ls"" or ""mkdir"" my machine runs, but I never worry about these simple utilities being out of date or behaving differently in release/staging. These utilities are essentially done, and 30 years from now they'll still work fine.There is no software without bugs in the same sense that there exists no hardware that cannot fail. But you can create software that is so close to perfect that hardware failures outnumber software failures 100:1, so there is no point in pursuing perfection any further."	gizmo	13.62003	-5.59095	comment	5.0	20.0	1511016150	9.869316
15815584	I really like UUIDs for all of the r	I really like UUIDs for all of the reasons described in the article. But can there can be significant performance related drawbacks:UUIDs are double the size of 64 bit integers. Which could mean fewer rows on data and index pages, leading to memory pressure, leading to I/O pressure.UUIDs are also random. I'm not an expert when it comes to PostgreSQL internals. But for MSSQL it's common and recommended to use your PK as a clustered index. The randomness can wreck havoc on the clustered index, causing severe fragmentation due to page splitting. There are some techniques to mitigate the effects of this (decreasing page fill factor, using incrementing UUIDs, using a surrogate IDENTITY clustered key), but each has significant tradeoffs	daigoba66	13.981446	-5.2195187	comment	5.0	21.0	1512049229	-13.671086
15970896	What is the advantage over SQLite?	What is the advantage over SQLite?	DenisM	13.598178	-5.5643654	comment	5.0	26.0	1513786746	9.841535
15987369	ArangoDB 3.3 GA: DC2DC Replication, 	ArangoDB 3.3 GA: DC2DC Replication, Encrypted Backup, Server-Level Replication	pluma	13.60112	-5.2523384	story	5.0	26.0	1513950650	9.739329
15994504	There is absolutely no good reason f	There is absolutely no good reason for anyone to use MongoDB ever, its just such an amazingly rotten database that its astounding how much hype it generated.	larrykwg	13.682121	-5.310784	comment	5.0	30.0	1514043235	9.893349
16358678	Sadly the lack of a decimal type com	Sadly the lack of a decimal type complicates monetary calculations sufficiently for me to stay with postgresql even for small projects that could easily be done with SQLite.	fauigerzigerk	13.583529	-5.5558877	comment	5.0	51.0	1518445184	9.8246355
16385224	Epic had a post mortem blog post her	"Epic had a post mortem blog post here that mentioned in passing they had stumped all the experts they could find to look at unsolveable issues they had with MongoDB.
https://news.ycombinator.com/item?id=16340462  I kind of assumed the fix is going to be a rewrite with Postgres or MySQL."	stevenwoo	13.707148	-5.3065863	comment	5.0	28.0	1518711913	9.913371
16561879	Why do you want SQLite for developme	Why do you want SQLite for development? Running Postgres on your dev machines is a docker one-liner that you can put in the README.md for your devs to copy paste.Most sane CI services also offer Postgres.	elnygren	13.556667	-5.5005393	comment	5.0	27.0	1520748071	9.793987
16596212	I was interested in this topic becau	I was interested in this topic because people were telling me that SQLite (and other databases) have more sophisticated methods of preventing corruption to database files than just calling fsync (or the platform equivalent) on the DB and hoping that the OS and disk controllers behave appropriately. What this document shows is that while SQLite has a somewhat sophisticated mechanism for allowing rollback of transactions in the case that they are not completed, it does not have a better means of ensuring data actually gets to disk than relying on fsync.In fact, this document explicitly calls out that the DB can be corrupted if the OS and disks do not implement flushing properly. Further, when I was looking at how SQLite does testing I noticed that there are no power failure or actual disk cr	jeffreyrogers	13.617171	-5.579979	comment	5.0	24.0	1521145263	9.766868
16770807	Damn it, I was going to work on exac	Damn it, I was going to work on exactly this -- my goals were slightly different but basically the same paxos/raft/gossip + sqlite and see how far I could take it.Note for those who are interested in cool-stuff-with-SQLite, there's a similar project called RQLite (mentioned in the README):https://github.com/rqlite/rqliteThe main differences are laid out in the README, but IMO it really all boils down to the fact that since it's single-writer quorum'd there's only one node actually doing writes, and they've just chosen to replicate right-before (right after?) the WAL commit (I think this is what they're calling frames, basically one chunk of the WAL content), not at the point of receiving a query. This is more like having a read secondary more than anything (I also assume writes are redirec	hardwaresofton	13.564128	-5.467197	comment	5.0	23.0	1522987646	9.761745
21164331	"So, I've heard SQLite described as """	"So, I've heard SQLite described as ""Postgres for people not paying attention"", because it ignores data type errors.A lot of people in the HN community like types. Me included. I really don't want my database to ignore type errors. I basically want Postgres but embedded like a library. I cannot think of any reason why that couldn't work. Perhaps just no one has built it yet."	etaioinshrdlu	13.581966	-5.550755	comment	5.0	17.0	1570262773	9.857855
21189311	Exposing auto incrementing IDs also 	Exposing auto incrementing IDs also lets your partners and competitors both see how big your tables are and make estimates at your growth rate.Always assign random identifiers.	echelon	13.93642	-5.2108307	comment	5.0	25.0	1570515607	-13.664508
21378519	> All the code is in one file (sqlit	"> All the code is in one file (sqlite.c), and there are no weird dependencies! It’s amazing.This is because the author of SQLite publishes it this way as a convenience to integrators; the actual day-to-day coding is not done in a single C file.In fact, the README[1] calls out twelve ""key files"", and explicitly warns that SQLite ""will not be the easiest library in the world to hack.""https://sqlite.org/src/doc/trunk/README.md"	thomascgalvin	13.6247015	-5.5970125	comment	5.0	30.0	1572280606	9.851543
21402663	Why would anyone use Access in 2019 	Why would anyone use Access in 2019 when they can use SQLite instead? Is it because Access has a graphical interface?	matheusmoreira	13.546419	-5.5395727	comment	5.0	19.0	1572469224	9.821048
21405047	I wonder how much effort it would ta	I wonder how much effort it would take to build a desktop application providing a similar user experience to Access, using SQLite.	jdfellow	13.591312	-5.564043	comment	5.0	24.0	1572487846	9.8381405
21686868	Uses MongoDB?Has anyone used this be	"Uses MongoDB?Has anyone used this before? It has a bunch of nice features but I don't understand what separated it into a ""Enterprise"" category.They also seem to have migrated to a completely different platform from 1.5 to 2 (PHP -> NodeJS). So that doesn't really scream stable Enterprise to me."	dubcanada	13.65289	-5.330475	comment	5.0	21.0	1575320411	9.842297
39258654	UUIDv1 is generally not recommended 	UUIDv1 is generally not recommended since it leaks MAC addresses	dtech	13.992379	-5.211994	comment	5.0	32.0	1707121889	-13.670828
39261319	"Can someone ELI5 what that ""UUID v7 "	"Can someone ELI5 what that ""UUID v7 support"" actually means in the title?I don't know how to navigate commitfest (nor would I probably understand the source code to begin with), but the reason I'm confused is that you can already use all the proposed draft UUID implementations in Postgres (as long as you generate the ID application-side). In fact, PG will happily accept any 128 bit ID to be inserted into a UUID column, as long as it's hex encoded – even the dashes are optional."	s4i	13.986228	-5.216878	comment	5.0	38.0	1707141991	-13.6714115
39262286	Word to the wise: be very careful ab	Word to the wise: be very careful about adding semantics to unique ids that aren't inherent to the identity of the thing being identified.Over time conflicts between the id's primary job (uniquely identifying something) and the extra semantics can arise, and the solutions tend to get pretty messy.Here we have a unique id that embeds a timestamp. The classic conflict here is with privacy/security. A UUIDv7 user id tells you when the user was created. A UUIDv7 of a medical record tells you when some medical event occurred.There are things whose identity is inherently time-based and not private, so I'm not giving a blanket recommendation to not use these. Just understand what you are signing up for.For a database, you can use bigints for primary ids but only internally. Then you also have an 	jmull	13.967835	-5.216096	comment	5.0	49.0	1707147674	-13.648412
39289907	I would have appreciated some more d	I would have appreciated some more details on the benchmark. SQLite has notoriously slow writes in the default journal mode, but proper configuration and WAL/WAL2 mode[0] should be a starting point for any comparison.It's the first time I've heard of Isar[1] though. I'm always surprised at how many solid-but-underused Apache projects are out there, chugging along.[0] https://phiresky.github.io/blog/2020/sqlite-performance-tuni...[1] https://isar.dev/	jzebedee	13.5789585	-5.5041356	comment	5.0	23.0	1707320643	9.823149
39290155	Doesn't pass the sniff test. 19 seco	Doesn't pass the sniff test. 19 seconds sounds like the performance of 100,000 separate transactions. I bet a crisp $10 bill they've forgotten to wrap all of this in a transaction. In SQLite it makes a huge difference. I struggle to think of a way that you could make SQLite take 19 seconds to write and read 100,000 rows otherwise.	electroly	13.57157	-5.532092	comment	5.0	51.0	1707321766	9.787311
18230414	Did the MongoDB pay for their Linux 	Did the MongoDB pay for their Linux distros? GCC? Git? How much are they paying to the FOSS projects they used to build their software for sale?	kstrauser	13.73529	-5.2214155	comment	5.0	15.0	1539705566	9.909929
18273501	What has God to do with SQLite?	What has God to do with SQLite?	harianus	13.632815	-5.5869727	comment	5.0	28.0	1540204322	-8.54045
18273748	I don't understand the purpose of th	I don't understand the purpose of this. I hope it's an elaborate joke, but it is surprisingly unprofessional.A few years ago I spent some time in their dev mailing list and proposed a patch. I doubt I'd still do this in this context. This code of conduct that requires members to honor th Christ, even as a joke, would make me reluctant to interact with SQLite.	idoubtit	13.643907	-5.598021	comment	5.0	32.0	1540207703	-8.847394
18283466	Jepsen: MongoDB 3.6.4	Jepsen: MongoDB 3.6.4	aphyr	13.704867	-5.317792	story	5.0	231.0	1540303590	9.90036
18302261	Remind me of that one time when they	Remind me of that one time when they went berserk on every tooling vendor using the name « Mongo » in their product name :RoboMongo,MongoGUI etc... they all received a legal notice to remove the name mongo from their product.This was probably one of the most evil thing have seen in the open source industry .Most of those vendors were open source with paid  premium features or donation.After receiving their legal notice most of those vendors deprecated or sold their project to a company feeling betrayed by Mongo.As a result Mongo Compass became the de facto GUI for MongoDB and is advertise as sold with MongoDB Enterprise.	asien	13.741071	-5.203268	comment	5.0	17.0	1540485644	9.950763
18458275	I doubt the competition (e.g. IBM or	I doubt the competition (e.g. IBM or Microsoft) has any better code quality. Even PostgreSQL is 1.3M lines of code, so let's get something deliberately written for simplicity. SQLite is just 130k SLoC, so another order of magnitude simpler.And yet, even SQLite has an awful amount of test cases.https://www.sqlite.org/testing.html	forthy	13.610449	-5.560965	comment	5.0	23.0	1542278361	9.838811
18717922	The creator of Envoy had some choice	The creator of Envoy had some choice words about Mongo a few days ago. https://twitter.com/mattklein123/status/1074717204224999427Plenty of people here like to dish on Mongo and the product seems to have been re-architected a few times since I used it seven years ago. By what metrics can we say the product is one worthy of passing a HN smell test? Passing Jepsen was seemingly not enough. https://www.mongodb.com/jepsen	elevenworth	13.677591	-5.309445	comment	5.0	19.0	1545243784	9.902454
18773836	> First, the main benefit of ULID is	> First, the main benefit of ULID is that you can generate the IDs within your own software rather than rely on the database. We can queue them or even reference them before they land in the database. The traditional roundtrip has been eliminated.No you cannot, unless you're running a single threaded server process on a single machine.  What you can do is _gamble_ that you probably won't have a collision, which is the same thing you could do with regular UUIDs and you'd be (nearly) guaranteed to never hit a conflict with UUID4 (or probably UUID1/2 if you trusted your mac address uniqueness).You may find this gamble acceptable and many people do, but you should be aware that pre-generation of UUIDs on independent systems without coordination is not a solvable problem - all attempts to do so	munk-a	13.9839	-5.213223	comment	5.0	24.0	1545956065	-13.66066
18920365	I had hopes for MongoDB back 10 year	I had hopes for MongoDB back 10 years ago, but it just let me down.I'm thinking of trying out ArangoDB next. OrientDB is just riddled with bug and their docs are lack luster.	xellisx	13.656093	-5.3245525	comment	5.0	37.0	1547643314	9.90711
29724769	They're not running a dependency-rid	They're not running a dependency-ridden NodeJS backend with MongoDB and random cloud services? How are they even able to get to space?	sgt	13.638152	-5.31583	comment	5.0	32.0	1640785930	9.864648
29728428	I use SQLite exclusively on a high p	I use SQLite exclusively on a high performance crypto sniper project - https://bsctrader.app and I could not be happier with it.Performs much better then postgres in terms of query latency which is ultra important for the domain we operate in.I take machine level backups every 2 hours, so in the event of an outage, just boot the disk image on a new vm and it's off.I would never do this on my professional job due to the stigma, but for this side project, it has been incredible	greatjack613	13.560663	-5.4955683	comment	5.0	21.0	1640804117	9.843465
29728672	SQLite is great, but it's not a more	SQLite is great, but it's not a more simple drop in replacement for DB servers like HN often suggests it is.My team at work has adopted it and generally likes it, but the biggest hurdle we've found is that it's not easy to inspect or fix data in production the way we would with postgres.	pgwhalen	13.558321	-5.5034695	comment	5.0	27.0	1640805030	9.802569
29846105	That sounds like a major, incredibly	That sounds like a major, incredibly dangerous update to the DB driver. Their 7.1, 7.2, 7.3 versions seem to all have breaking changes [1].Yet they are in obvious violation of SemVer expectations, which they declare to follow [2]:> Mongoid follows versioning guidelines as outlined by the Semantic Versioning Specification, so you can expect only backwards incompatible changes in major versions [sic][1] https://docs.mongodb.com/mongoid/current/tutorials/mongoid-u...[2] https://mongoid.github.io/old/en/mongoid/docs/upgrading.html	ricardobeat	13.696338	-5.327736	comment	5.0	97.0	1641596344	9.900394
29852798	Length isn't the primary issue.  Loc	Length isn't the primary issue.  Locality is.UUIDs are generally generated randomly.  This results in terrible insert performance into B+tree-based indexes, and terrible (= no) lookup locality with basically any database.  In a large table, successive entries ends up in separate disk pages.Even with time-based UUIDs, the time fields are ordered backward, which produces the same issue.One way to fix this (beside the methods outlined in the article) is to create time-based UUIDs with fields sorted the other way around.  Or reverse the time fields during indexing (slower, but still not as slow as an unnecessary disk read!).	colanderman	13.977099	-5.21929	comment	5.0	23.0	1641657274	-13.663419
29990122	It remains an open legal question (a	It remains an open legal question (at least in the United States) whether or not an author even can voluntarily release something into the public domain. Hwaci could theoretically decide that, actually, that they never really put SQLite in the public domain and in fact possess full copyright over it and would like not only current and future licensing fees, but also retroactive fees from everyone who's used it over the past 20 years without legal permission. Lawsuits ensue, pandemonium happens, etc.However, if you actually did acquire a license from them beforehand (when it was still theoretically free), they'd have no ground to sue and such a case brought against you would be thrown out of court immediately.	sb057	13.65003	-5.588208	comment	5.0	22.0	1642568182	9.860998
30446530	sqlite-utils - CLI & Python utility 	sqlite-utils - CLI & Python utility functions for manipulating SQLite databases	punnerud	13.601169	-5.6087484	story	5.0	134.0	1645650816	9.864445
30653954	So what's the deal with the unpopula	So what's the deal with the unpopularity of CouchDB?It's seems like a compelling database, but i've yet to run into it in the wild.	elitepleb	13.612471	-5.2147593	comment	5.0	22.0	1647112440	9.672519
32757727	> Still, you didn't define it. What'	> Still, you didn't define it. What's the data schema? What is the application? I don't know what to say, if your app is a TODO list app that's wildly popular, then I guarantee I can do what you want with SQLite easily. If it's Spotify-level stuff with special aggregation and data analysis, maybe not?sigh. any app based on SQLite with more than 1 million concurrent users, 75% reads.	endisneigh	13.56064	-5.5115004	comment	5.0	20.0	1662588735	9.791649
32854776	The index is the least of the issue 	The index is the least of the issue with the SQLite implementation.  It's calling one INSERT per each record in that version, so the benchmark is spending something like 99.8% of its time opening and closing transactions as it sets up the database.Fixing that on my machine took the sqlite3_file_open benchmark from 16.910 seconds to 1.033 seconds.  Adding the index brought it down to 0.040 seconds.Also, I've never really dug into what's going on, but the dbm implementation is pretty slow on Windows, at least when I've tried to use it.	banana_giraffe	13.539161	-5.517433	comment	5.0	17.0	1663260529	9.814532
32927622	LiteFS/Litestream author here. You b	LiteFS/Litestream author here. You bring up a lot of great points that I'll try to address.> What I'd like to have seen is how this compares to things like rqlite or Cloudflare's D1 addressed directly in the articleI think a post comparing the different options is a great idea. I'll try to summarize a bit here though. LiteFS aims to be an analogue to Postgres replication but with built-in failover. Postgres uses log shipping to copy database state from a primary to its replicas, as does LiteFS. LiteReplica is probably the closest thing to LiteFS although it uses a dual GPL/commercial license model. LiteFS uses Apache 2.There are Raft-based tools like rqlite or dqlite. These have higher consistency guarantees, however, they tend to be more complex to set up -- especially in an ephemeral env	benbjohnson	13.537351	-5.438771	comment	5.0	22.0	1663778082	9.758506
32961656	Storage and transaction in mvSQLite,	Storage and transaction in mvSQLite, the distributed SQLite on FoundationDB	losfair	13.52272	-5.438213	story	5.0	79.0	1664020415	9.763154
36549808	Sqlpkg – SQLite Package Registry	Sqlpkg – SQLite Package Registry	amadeuspagel	13.665809	-5.6241946	story	5.0	136.0	1688217666	9.879069
36583554	I thought one of the main attraction	I thought one of the main attractions of SQLite was that it was embedded, so specifically didn't need an HTTP round trip to query the DB.It seems like this project removes that benefit, so what is it solving for or adding instead? What's the upside?	zknill	13.605895	-5.559223	comment	5.0	29.0	1688457008	9.853617
36611338	This adds more cache consistency iss	"This adds more cache consistency issues, concurrency issues, network blocking issues, authn+z issues, daemon process supervision issues, ... for what? To store your SQL data in a remote data store? I would rather my app shell out to gsutil (or curl!) than deal with all of this.Simple hack: mount a tmpfs filesystem and write your sqlite database there. Every 30 seconds, stop writing, make a copy of the old database to a new file, start writing to the new file, fork a process to copy the database to the object store and delete the old database file when it's done. Add a routine during every 30 second check to look for stale files/forked processes.Why use that ""crazy hack"", versus the impeccably programmed Cloud Backed SQLite solution?- Easier to troubleshoot. The components involved are all "	0xbadcafebee	13.558846	-5.494235	comment	5.0	30.0	1688618230	9.74104
36811177	I frankly don't understand how it's 	"I frankly don't understand how it's good. UUID originally was intended as something you use very sparingly, to name, say, a product SKU maybe, an organization, something like that. Not literally content that collides commonly at the same nanosecond, in the same application, in the same platform/org.At some point we have to question the sanity of using one single flat address space for everything from the tiniest identifier to the... well, ""Universe"", as if it makes sense.We can have registrars for global ids, and we can nest local ids inside them, we can have a hierarchy, and we can have local compact ids, 32, 64 or 128 bit, which will never collide, and be locally cohesive.So why aren't we doing this? Is it ignorance? Is it because magic is easier than actually figuring out the synchroniz"	3cats-in-a-coat	13.973474	-5.1988916	comment	5.0	21.0	1689925947	-13.654327
36869330	Off topic: is there a way to use one	Off topic: is there a way to use one of the LLMs and have it ingest data from a SQLite database and ask it questions about it?	oaththrowaway	13.587785	-5.574483	comment	5.0	15.0	1690318388	9.826766
36885416	> And if your hosting server does no	> And if your hosting server does not support SQLite ...I thought SQLite was file based. What's there to support?	CodeCompost	13.589388	-5.5648313	comment	5.0	21.0	1690407378	9.842317
36959263	> MongoDB has zero use cases. Just U	> MongoDB has zero use cases. Just Use Postgres.I kinda am on that bandwagon but at a new job we're using mongoose and mongo for our database, because the consultors that implemented the webapp before us decided so.How do I convince mgmt that we might want to switch that? When? Is it even worth it or possible now that it's already our default?	tough	13.679958	-5.3175926	comment	5.0	15.0	1690910842	9.871897
37086900	With a feature like this is there st	With a feature like this is there still a good reason to use MongoDB?Honest question, I know Oracle and Postges well, but not their JSON features. I'm just starting to learn MongoDB seriously because of a current project.	weinzierl	13.601906	-5.404415	comment	5.0	18.0	1691747889	9.852714
37120510	A C parser for CREATE and ALTER TABL	A C parser for CREATE and ALTER TABLE SQLite statements	marcobambini	13.625485	-5.597599	story	5.0	58.0	1692017947	9.866818
37129944	Huh, weirdly enough I've been hoping	"Huh, weirdly enough I've been hoping for exactly this kind of thing - albeit easily called from Python.My use-case is that with SQLite there are aspects of the table - things like generated columns - which aren't yet available via the regular SQLite PRAGMAs for introspecting tables.For those things, the only way to introspect them is to read the CREATE TABLE statement out of the ""sqlite_master"" table and parse it.But you need a very robust parser!I've been investigating tree-sitter recently for this, notes here: https://til.simonwillison.net/python/tree-sitterIf anyone needs an implementation of that advanced ALTER TABLE mechanism (where you create a new table with the new schema, copy the data cross from the old one and then swap the names) my sqlite-utils CLI tool and Python library impl"	simonw	13.565778	-5.5881886	comment	5.0	17.0	1692071321	9.813125
37141291	UUID Collision	UUID Collision	sandes	13.991247	-5.209919	story	5.0	14.0	1692146388	-13.686323
37336095	It uses NextAuth that in my experien	It uses NextAuth that in my experience works well only on Vercel (and they don't care)Also please stop using mongodb	audessuscest	13.689696	-5.293162	comment	5.0	18.0	1693484753	9.900175
37386154	It's pretty objectively a big deal.(	It's pretty objectively a big deal.(Feature-limited) Photoshop was ported to WASM in 2021.https://web.dev/ps-on-the-web/With the deprecation and imminent removal of WebSQL, the official (Google) recommendation for SQL-in-browser is WASM SQLite.https://sqlite.org/wasm/doc/trunk/index.md	CottonMcKnight	13.542298	-5.555506	comment	5.0	43.0	1693869744	9.720486
37470461	> Does it make the URL in the URL ba	> Does it make the URL in the URL bar longer? Yeah, but does that matter?Yes. That's one of the author's arguments.) A simple ID like 3c6n63N is more than enough to represent any product while keeping it readable and making communication easier. A UUID alternative like a73ba12d-1d8b-2516-3aee-4b15e563a835 is just wasteful from an user’s perspective.	richbell	13.976741	-5.197466	comment	5.0	21.0	1694452943	-13.661551
37470419	> A simple ID like 3c6n63N is more t	> A simple ID like 3c6n63N is more than enough to represent any product while keeping it readable and making communication easier. A UUID alternative like a73ba12d-1d8b-2516-3aee-4b15e563a835 is just wasteful from a user’s perspective.I would challenge the premise we appear to be starting from, that the average end user cares to be dealing with any random string of numbers and digits. GUIDs work well, they’re implemented everywhere, and you won’t find out long after you go into production you made some mistake that is going to make it so you have to migrate away from them.	emodendroket	13.985281	-5.2081137	comment	5.0	44.0	1694452795	-13.710047
37491263	I was exploring an interesting local	I was exploring an interesting local-first component earlier today: cr-sqlite, which adds CRDTs to SQLite so you can have multiple databases that receive writes and then sync up and merge their changes later on.My notes here: https://til.simonwillison.net/sqlite/cr-sqlite-macos	simonw	13.553863	-5.437667	comment	5.0	16.0	1694570184	9.803492
24494929	They're using SQLite which is single	They're using SQLite which is single threaded and single user by design. So this website will not be able to service that much traffic.	samsquire	13.581303	-5.5015197	comment	5.0	26.0	1600277170	9.791011
24991030	Developers increasingly pair MongoDB	Developers increasingly pair MongoDB with PostgreSQL, survey finds	ta_varez	13.620463	-5.3722034	story	5.0	15.0	1604510626	9.859936
25009396	Who doesn't have an auto increment I	Who doesn't have an auto increment Id field on every table? Ok I know its not a 100% perfect solution for a user id.The other gotcha is using ss on ni numbers as identifiers	C1sc0cat	13.9172	-5.2174563	comment	5.0	18.0	1604684131	-13.675394
25232783	Ask HN: How do you use SQLite?	Ask HN: How do you use SQLite?	jlelse	13.610046	-5.5771337	story	5.0	12.0	1606512975	9.860812
31799147	Show HN: WarcDB: Web crawl data as S	Show HN: WarcDB: Web crawl data as SQLite databases	fforflo	13.542435	-5.5442395	story	5.0	171.0	1655645161	9.826725
31867335	How does this compare with SQLite ap	How does this compare with SQLite approaches shared recently?	wahnfrieden	13.610609	-5.5676184	comment	5.0	24.0	1656095754	9.815428
31909931	Plus PG and SQLite3 have fundamental	Plus PG and SQLite3 have fundamentally different approaches to types.SQLite3 has very few types, you cannot create new types, and is duck-typed.PG has many built-in types, you can create new types, and is (mostly) statically typed.You really have to know this going in.  If you have to support both, you'll probably have to write two versions of your SQL -- or you'll end up using an ORM that supports the two RDBMSes, and then you may get stuck with the ORM.SQLite3 is amazing, but it's mainly amazing because of how easy it is to embed in apps.  If that's what you need, use SQLite3.  If you need more power, if you're building a server, then think long and hard about why not just go straight to PG.EDIT: SQLite3 is amazing for other reasons too.	cryptonector	13.568997	-5.5175967	comment	5.0	27.0	1656434268	9.841153
31909571	If you say using SQLite, there is al	If you say using SQLite, there is always risk of losing that data file in disk right. How is that managed. is this a dumb question , which PostgreSQL do not ??	rammy1234	13.541094	-5.4638667	comment	5.0	17.0	1656432670	9.778204
32043219	This is pretty cool! Didn't know you	This is pretty cool! Didn't know you can query SQLite databases from s3. I recently tried out PMTiles[1] to do something similar but it requires an extra processing step. Would anybody know the pros and cons of this vs PMTtiles?[1] https://github.com/protomaps/PMTiles	jtmiclat	13.583055	-5.49646	comment	5.0	24.0	1657446404	9.743312
32148667	Regarding 2: I've had problems with 	Regarding 2: I've had problems with this strategy. Even though I used the swap technique instead of overwriting, files easily get corrupted on common file systems, and if it's just the user force quitting the application during the operation. (I mostly use Ext4 for testing.) Whatever Sqlite does under the hood is way more resilient to such problems. I guess that's because the Sqlite developers have been testing ACID compliance extensively.In one of my Racket applications with high integrity demands I've resorted to writing the temp file, swapping it with the original, then opening it read-only and verifying all of its contents. That is very reliable but obviously slow. But in another application written in Go I've switched entirely to Sqlite even for simple settings files and had no proble	jonathanstrange	13.593176	-5.559671	comment	5.0	19.0	1658216882	9.7932005
32184354	SQLite 3.39.2	SQLite 3.39.2	marcobambini	13.636684	-5.602787	story	5.0	82.0	1658434316	9.858199
32184950	Why do so many websites urge readers	Why do so many websites urge readers to avoid using sqlite as a production database? From what it looks like sqlite can handle a million daily users	orangepurple	13.58894	-5.525456	comment	5.0	22.0	1658437095	9.819326
22099123	I have found that corruption of SQLi	"I have found that corruption of SQLite files in practice is a very difficult thing to achieve. On Windows, the worst I've ever seen is a wall of ""Database File is Locked"" which was resolved with a rewrite of the DB access logic. After much experimentation, I have found that the happy path for SQLite is as follows:1. Use a SQLite distribution that is compiled or otherwise configured for serialized threading mode (this is the default in most cases).2. Use a single connection from a single process to access the SQLite database file. This connection can be safely shared between multiple threads with optional locking as required (due to the guarantees offered by #1 above).3. Transactions are handled with locking in the application code (i.e. on the SQLiteConnection instance), not in the databas"	bob1029	13.624622	-5.544968	comment	5.0	33.0	1579531572	9.782166
22099933	> Systems that run automatic backups	> Systems that run automatic backups in the background might try to make a backup copy of an SQLite database file while it is in the middle of a transaction. The backup copy then might contain some old and some new content, and thus be corrupt.I am surprised by this! Is it really not entirely safe to take a backup while some software is running, has a SQLite database open, and might be writing to it?That limitation is fine for a big database that has someone knowledgeable administering it who will take care to follow any required backup procedures. But SQLite is often included in software that nontechnical end users will use without even knowing that there's a SQLite file. For example, Firefox and Google Chrome use it.This seems to mean that if a regular end user is browsing the web while 	adrianmonk	13.593992	-5.516428	comment	5.0	22.0	1579537833	9.769938
22227464	Why Go Was the Right Choice for Cock	Why Go Was the Right Choice for CockroachDB (2015)	tshannon	13.699183	-5.222498	story	5.0	18.0	1580755571	10.078407
36581989	I'd like to see a fork of SQLite tha	"I'd like to see a fork of SQLite that ""supports the PostgreSQL wire protocol and the majority of PostgreSQL syntax"" (to quote another popular db)."	rch	13.548358	-5.4775333	comment	6.0	23.0	1688442493	9.850063
36582061	>The first thing I've come to apprec	">The first thing I've come to appreciate about SQLite is its documentationI've told this story before, but the first time I used sqlite, years ago, I needed to store a floating point value, so I read the documentation: https://www.sqlite.org/datatype3.html>REAL. The value is a floating point value, stored as an 8-byte IEEE floating point number.I parsed this as ""an 8-bit floating point number"". Wow, I thought. That's weird as hell. Oh well, I guess it's sql lite, ha ha. I went on to implement storing numeric values as text strings, which worked exactly as well as you'd expect. Only months later did I find out that it's a normal regular IEEE double, 64 bits long."	sbierwagen	13.605745	-5.5953016	comment	6.0	34.0	1688443031	9.831052
36811024	"I was going to post about ""use a UUI"	"I was going to post about ""use a UUID"", but I was surprised to learn that no UUID uses both timestamp + a random component. You can either get fully random with UUID4, or have a time + MAC based UUID with UUID1. Strange, I would have thought there would exist a UUID that uses time + random to minimize collisions like described in the post."	getmeinrn	13.982285	-5.2126765	comment	6.0	23.0	1689924612	-13.673029
36905064	Realistically which production DB ta	Realistically which production DB tables don't have a unique id? Genuine question, never used one in my life.	EddieJLSH	13.8457985	-5.253297	comment	6.0	23.0	1690541002	-13.645568
37077146	Those should obviously be UUIDs. Lab	Those should obviously be UUIDs. Labels and titles should be a simple changeable, internationalizable attribute.Like usernames. You don’t use usernames as primary keys for anything, do you? What happens when people marry?	eastbound	13.951442	-5.2190127	comment	6.0	19.0	1691680208	-13.654948
23499342	What does this really mean? I just m	What does this really mean? I just migrated from mongo to Pg.	popotamonga	13.671714	-5.3050766	comment	6.0	26.0	1591970804	9.918015
23509677	Would such an app hold the sqlite da	"Would such an app hold the sqlite database open while the user has the document ""open"", and live-write user changes back to the database immediately? Or would it follow the traditional model of the user choosing to ""Save""?I worked on an app that did the former many years ago (to an Access database, not sqlite), and it did not go well because this broke user expectations on the usual ""open/save/save as"" model."	rlpb	13.583154	-5.532776	comment	6.0	19.0	1592059180	9.723954
23856213	I don't understand the first one:   	"I don't understand the first one:    a shared database table’s
    auto-incrementing ID column
    exceeded the size that can
    be represented by the MySQL
    Integer type

Followed by:    GitHub’s monitoring systems
    currently alert when tables
    hit 70% of the primary key
    size

So why was there no alert?"	TekMol	13.916756	-5.2320757	comment	6.0	20.0	1594878965	-13.621083
23939155	SQLite is incredible. If you are str	"SQLite is incredible. If you are struggling to beat the ""one query per second"" meme, try the following 2 things:1. Only use a single connection for all access. Open the database one time at startup. SQLite operates in serialized mode by default, so the only time you need to lock is when you are trying to obtain the LastInsertRowId or perform explicit transactions across multiple rows. Trying to use the one connection per query approach with SQLite is going to end very badly.2. Execute one time against a fresh DB: PRAGMA journal_mode=WALIf at this point you are still finding that SQLite is not as fast or faster than SQL Server, MySQL, et.al., then I would be very surprised.I do not think you can persist a row to disk faster with any other traditional SQL technology. SQLite has the lowest ac"	bob1029	13.548742	-5.5076475	comment	6.0	51.0	1595597081	9.791342
24178013	SQLite 3.33 also increases the maxim	"SQLite 3.33 also increases the maximum size of a SQLite database file from 140TB to 281TB: https://www.sqlite.org/releaselog/3_33_0.htmlI asked about this on the SQLite forum and D. Richard Hipp said ""This change was in response to a customer request. They still have a factor of 4 before reaching the old upper limit, but asked for additional headroom."" https://sqlite.org/forum/forumpost/8e40a7f588428077d7f073c00..."	simonw	13.564578	-5.5301223	comment	6.0	63.0	1597587477	9.782696
20006331	I also don't think using UUIDs as a 	I also don't think using UUIDs as a security (by obscurity) strategy is valid. But there are other reasons someone may choose to use UUIDs. For instance, it's convenient to generate identifiers in a decentralized manner. I want to counter your one bad experience with my (equally anecdotal) many-multiple good experiences. Databases do just fine with UUIDs. Though we may be working on different kinds of systems, and optimizing for different things. I don't frown upon using integers (well, longs) for identifiers, but I personally prefer UUIDs.	sverhagen	13.980119	-5.2126846	comment	6.0	33.0	1558743280	-13.661316
20097786	Maybe a good time to change the name	Maybe a good time to change the name as well? Funny names are cute and all but if you want to gain mainstream acceptance for your database product CockroachDB is not the one I would have picked.Downvoters: if you think names for products do not matter you are mistaken.	jacquesm	13.70804	-5.1888666	comment	6.0	25.0	1559672643	-4.5903854
19737949	MongoDB and Realm make it easy to wo	MongoDB and Realm make it easy to work with data, together – MongoDB	metheus	13.602349	-5.2887144	story	6.0	43.0	1556111519	9.8391
19763427	> The assert() macro in C is roughly	> The assert() macro in C is roughly just if ... { panic() } in GoThe article very clearly says that (unlike normal C behaviour) it's a no-op in release builds of SQLite, because otherwise they get a ~3x slowdown. Does Go compile away those `if` statements?	repsilat	13.652767	-5.643501	comment	6.0	33.0	1556332833	-5.9486113
19877084	One idea I like is to have a normal 	One idea I like is to have a normal internal database ID, but also have a public UUID column to use for URLs, APIs and that sort of thing.This way you can change the record's UUID at any time to display different data without having to worry about updating a bunch of internal foreign keys.  You don't have to worry about a user making easy edits to the UUID in the URL to find nearby records (although you still need real protections if you need to restrict data by user).	Jwarder	13.950975	-5.2048864	comment	6.0	31.0	1557491650	-13.652543
18229914	Speaking as a lawyer:There was no ab	"Speaking as a lawyer:There was no abuse, there was only mongo not being able to make money in all cases they wanted to.
That's what they see as abuse.  It isn't.While they complain of bad actors, bad actors always act bad.
This will not disincentivize them (they are also often in  a lot of interesting jurisdictions that would make it hard anyway).Instead, this is really about making it completely unpalatable for normal actors to not pay mongo in every single case.Otherwise, one has to believe that mongo is going to go off and sue a bunch of people now, which would be a horribly stupid business model."	DannyBee	13.725964	-5.2312417	comment	6.0	30.0	1539702068	-1.3562564
18611000	Thanks to these engines and extensio	"Thanks to these engines and extensions, Postgres has become that rare tool for me where I have to ask ""why use ___ instead of Postgres?""If they got their clustering story to be as easy as MongoDB's was 5 years ago (From what I read, Citus does this well), it's yet another excuse to stick with it."	atonse	13.54986	-5.409022	comment	6.0	43.0	1544034511	9.837404
18720807	It's not a great article tbh, it's w	"It's not a great article tbh, it's well written but it shows the clear lack of knowledge running a backend. The title should be ""we didn't know what we were doing so we switched to a managed DB""I mean yeah who knew that blocking NTP therefore time drifting would break everything...For those criticizing MongoDB, Fortnite generates $3B/year and runs on MongoDB, you should tell them it's a mistake and that they should use PG instead."	Thaxll	13.680384	-5.3178725	comment	6.0	23.0	1545260894	9.890762
18720415	> IMO, the reason is that newer deve	> IMO, the reason is that newer developers faced the choice of learning SQL or learning to use something with a Javascript API.The thing I dislike about this type of comment – although I now notice yours doesn't explicitly say this – is the implication that devs don't like SQL because they're lazy or stupid. Well, sometimes that is probably true! But there are some tasks where you need to build the query dynamically at run time, and for those tasks MongoDB's usual query API, or especially its aggregation pipeline API, are genuinely better than stitching together fragments of SQL in the form of text strings. Injection attacks and inserting commas (but not trailing commas) come to mind as obvious difficulties. For anyone not familiar, just look at how close to being a native Python API pymon	quietbritishjim	13.579876	-5.4322553	comment	6.0	40.0	1545258280	9.844949
18774927	> No you cannot, unless you're runni	> No you cannot, unless you're running a single threaded server process on a single machine. What you can do is _gamble_ that you probably won't have a collisionThis seems like a pointless distinction.If I did the math right, you can generate 1,000,000 ULIDs per second (1000 per millisecond) for around 50 million years before you can expect to hit your first collision.I don't know about you, but I'm pretty sure any system I build won't be running 50 million years from now. Not to mention that the timestamp portion of the ULID will overflow in a mere 9000 years.	bearmcbearsly	13.94794	-5.211085	comment	6.0	19.0	1545972336	-13.671022
29728512	I love to see that more projects are	I love to see that more projects are using SQLite as their main database.One thing that I always wondered though: does anyone knows a big project/service that uses Golang and is backed by SQLite? This because SQLite would require CGO and CGO generally adds extra complexities and performance costs. I wonder how big Golang applications fare with this.	brunoluiz	13.604492	-5.589946	comment	6.0	20.0	1640804452	9.847773
29728795	I've always thought it interesting t	I've always thought it interesting that there was a time when large(ish) websites were hosted using servers that would struggle to outperform a modern smart toaster or wristwatch, and yet modern web applications tend to demand a dramatic distributed architecture. I like the examples in this article showing what a single modern server can do when you're not scaling to Google's level.As an aside, what about distributed derivatives of sqlite, like rqlite, as a response to the criticism that sqlite requires your database server to also be your web server. Could something like rqlite also provide a way for an sqlite database to grow into a distributed cluster at a later point?https://github.com/rqlite/rqlite	bonyt	13.556162	-5.4816008	comment	6.0	26.0	1640805507	9.821265
29830214	SQLite 3.37.2 fixes potentially data	SQLite 3.37.2 fixes potentially database corruption bug	marcobambini	13.602495	-5.5557675	story	6.0	69.0	1641503477	-10.13331
29898600	The author seems to assume that ever	The author seems to assume that everybody is using SQLite, but SQLite for a production database is an extremely niche choice.  Attempting to expose more popular options like PostgreSQL or MySQL as SQLite would be extremely difficult because SQLite only supports a subset of SQL, whereas PostgreSQL and MySQL both implement their unique superset (for the most part) of SQL.But it doesn't matter.  The API doesn't matter.  Web 3.0 was never about APIs, it was about data.  A standardized API is only useful if it outputs standardized data.  Having a bunch of bespoke SQLite tables scattered across the web gets us no closer to the ideal of Web 3.0.	luhn	13.5657015	-5.555247	comment	6.0	43.0	1641938054	9.853958
29902345	Many Small Queries Are Efficient in 	Many Small Queries Are Efficient in SQLite	radus	13.583903	-5.537297	story	6.0	67.0	1641962031	9.842353
30135401	Embeddable, replicated and fault tol	Embeddable, replicated and fault tolerant SQL engine based on Sqlite	KingOfCoders	13.563427	-5.5334563	story	6.0	89.0	1643535665	9.819018
30347655	Could you use EFS to host a horizont	Could you use EFS to host a horizontally scalable relational database by using finely sharded SQLite dbs? Like if you had 1 db per user, for example.	ryeguy	13.52412	-5.433677	comment	6.0	20.0	1644938727	9.763014
30369664	You're not the only commenter saying	You're not the only commenter saying this, so I gotta ask: whatever VM that SQLite DB is on, is your business cool with a business disruption, dataloss, or both when that VM goes down, when that AZ goes down, or that disk fails? Or am I missing something? If you have some sort of fail-over-to-last-backup plan, is that not just a distributed database with more steps, and why not something like RDS, or CockroachDB?(From mine, it is an explicit requirement that we weather such events. I keep trying to keep global outages from our platforms off the requirements list…; so, IDK, perhaps your requirements allow different a different approach.)	deathanatos	13.586021	-5.493014	comment	6.0	23.0	1645073984	9.826738
30431600	I don't understand what is difficult	I don't understand what is difficult or non trivial about these types of databases and when people try to explain it, it usually just gets more confusing.  Filtering values over time is just the same operations that you would find in an audio editor or a one dimensional version of what you find in an image editor (weighted averages of values). I wonder how many customers could just use sqlite but don't know anything about computers and end up buying some sort of subscription to a 'new kind of database'.The web page just drops as many buzzwords as possible - web3, crypto, nfts, monitor soil to fight global warming - it looks like a disaster to anyone who understands the basics of programming.	CyberDildonics	13.575174	-5.5473866	comment	6.0	23.0	1645554743	9.816152
30433810	SQLite 3.38 Released	SQLite 3.38 Released	crawshaw	13.632923	-5.593825	story	6.0	65.0	1645564064	9.870234
30463659	This is exciting:> ...This log archi	This is exciting:> ...This log architecture is optimized for raft consensus-based replication allowing the implementation of active-active multimaster.I'm a developer but manage 2 PostgreSQL  instances each with an async replica. I also manage 1 three-node CockroachDB cluster. It's night and day when it comes to any type of ops (e.g. upgrading a version). There's a lot of reasons to use PostgreSQL (e.g. stored procedures, extensions, ...), but if none of those apply to you, CockroachDB is a better default.I just finished interviewing someone who went into detail about the difficulty they're having doing a large scale migration or a mission critical large PG cluster (from one DC to another)..it's a multi-team, year long initiative that no one is comfortable about.In my experience, PG is alw	latch	13.534853	-5.2717547	comment	6.0	55.0	1645762591	9.782677
30652742	While I don’t have enough knowledge 	While I don’t have enough knowledge of the wider implications of this, it does impact something I was experimenting with last year.The FoundationDB rewrite would introduce a size limit on document attachments, there currently isn’t one. Arguably the attachments are a rarely used feature but I found a useful use case for them.I combined the CRDT Yjs toolkit with CouchDB (PouchDB on the client) to automatically handle sync conflicts. Each couch document was an export of the current state of the Yjs Doc (for indexing and search), all changes done via Yjs. The Yjs doc was then attached to the Couch document as an attachment. When there was a sync conflict the Yjs documents would be merged and re-exported to create a new version. The issue being that the FoundationDB rewrite would limit the siz	samwillis	13.57501	-5.203589	comment	6.0	27.0	1647104406	9.656436
16358506	Sadly, in the browser SQLite has bee	Sadly, in the browser SQLite has been kicked to the curb, replaced by IndexedDB.It's deeply disappointing to not be able to use SQL on both client and server. Yes, there's Lovefield, which employs its own DSL that has nothing to do with SQL, so you can scrap everything on the server and redo it on the client.Or just give up and go with NoSQL on client and server, that seems to be what the browser vendors are implicitly pushing developers toward.	virtualwhys	13.521037	-5.5090857	comment	6.0	34.0	1518443600	9.814713
16586038	I've commented several times before 	"I've commented several times before that I consider ""C"" and ""C with analysis backing"" to be in practice two different languages. SQLite is the latter: https://sqlite.org/testing.htmlWriting SQLite in ""plain C"" without all that would, well, simply not work.I agree that ""C with analysis backing"" is the best language for SQLite right now. However, it should not be used as an example of ""How C is a great language for programming in"" unless you are also planning on skillfully using a very significant subset of the tools listed in that document. SQLite doesn't prove C is great; it demonstrates how much additional scaffolding is necessary to wrap around C to get that level of quality, and given the quantity and diversity of tools we are talking about, it is not particularly complimentary to ""plai"	jerf	13.638445	-5.618744	comment	6.0	86.0	1521045777	9.863599
16853492	Many UUIDs aren't secure either and 	Many UUIDs aren't secure either and can be trivially enumerated. A better approach might be a long number generated using a secure random number generator and converted to a BASE-64 string.	Someone1234	13.982329	-5.209171	comment	6.0	30.0	1523918153	-13.673455
17620392	I'm interested to see this on the fr	I'm interested to see this on the front page given the number of people trashing Mongo lately.Currently when deciding on a backing store for my python based applications I usually jump straight to PostgreSQL what are the things that Mongo excels at these days that are missing from pg?	haney	13.644373	-5.332005	comment	6.0	19.0	1532634848	9.889062
17764522	Not sure if SQLite is still a 'lite'	Not sure if SQLite is still a 'lite' database	Dinux	13.5982275	-5.5608735	comment	6.0	29.0	1534322164	9.815249
17855045	JSON Changelog with SQLite	JSON Changelog with SQLite	iffycan	13.526063	-5.6132517	story	6.0	113.0	1535408423	9.845855
39121183	Sqlite3 Utility in the Browser	Sqlite3 Utility in the Browser	hochmartinez	13.602102	-5.5654798	story	6.0	45.0	1706122305	9.87336
39299172	Non-IT guy here, can someone explain	Non-IT guy here, can someone explain to me how good/bad of an idea using this simple setup of SQLite + this interface as the core DBMS in a commercial setting would be?The interfaces I have used in my experience were built in-house over Apache Spark and Microsoft SQL, and always felt overengineered and more complicated than it needed to be. For the record I have learnt data retrieval and analysis only on the job and not from any formal training, apologies if I am missing something fundamental.	dartharva	13.58367	-5.5394626	comment	6.0	26.0	1707376106	9.8395605
12650230	Just looking at some of the RethinkD	"Just looking at some of the RethinkDB and ReQL stuff, I certainly wouldn't have used it. Two things hit me immediately:- bad performance- a dearth of types (literally only a single numeric type that is a 64-bit float, so that eliminates entire categories that rely on integer/fixed-precision exact arithmetic. Also, time series are seriously hurt by that decision. I've seen DBs have to move to 64-bit longs because of that  issue alone. Having a pseudo-type layered on top is just going to tie up CPU cycles in the encode/decodes that need to happen. (Plus milliseconds aren't enough in a nano-second world now.)This whole ""let's do everything with as few types as possible"" I hope is a fad that will just die quickly in the DB world.This is with about 20 minutes of looking around and just listing "	jnordwick	13.593737	-5.317283	comment	6.0	45.0	1475727773	-12.768769
12649587	I believe this is because the Node.J	I believe this is because the Node.JS community still recommends MongoDB as the perfect database engine for their projects. There is even a name for their stack — MEAN, MondoDB + Express.JS + Angular.JS + Node.JS — which is kind of ironic because considering the rapid evolution of the JavaScript ecosystem having an acronym like that will make no sense in a couple of months since now people prefer React-like libraries / frameworks. Besides the JavaScript community I don't know of any other that enjoys to use MongoDB — which to be fair it's not that bad for what it offers, but you know — or ships it by default in bundle installers which are preferred by many young and/or newbie developers.	guessmyname	13.644085	-5.3409004	comment	6.0	24.0	1475718698	9.858221
13116621	Note. You cant compare ULID with UUI	"Note. You cant compare ULID with UUID's  - An ulid is ""sortable"". But the whole point of an UUID is a random unique ID. Non guessable. Sortable is not a feature 
    you normally want from an uuid. And still UUIDs are still sortable. But it doesnt have any meaning. 
  - An ulid also encodes Time, an uuid doesn't. 
  - An uuid has less change of clashing: Its 128 bit vs 80 bit for ulid.
  - An uuid is also url safe.
  - An ulid is case insensitive. I don't see how this is an advantage."	TeeWEE	13.980248	-5.2171884	comment	6.0	27.0	1481046575	-13.666349
13165043	Intelligence. Tenacity. Ambition. Ju	Intelligence. Tenacity. Ambition. Judgement.Bonus points for recognizing the bullshit parade that is the current startup world. e.g.: NodeJS has value, but it's mostly the same wheel we've had for 20+ years. Or that MongoDB's changelog has consisted of standard SQL features for the past five years and that pgsql would have been just fine (had people read some boyce-codd anyhow).	meritt	13.643645	-5.3392134	comment	6.0	38.0	1481611753	9.892449
13346702	"Does anyone know of a ""security chec"	"Does anyone know of a ""security checklist"" one could follow for mongodb?I have not used mongodb in any production environment but it would be nice to know what one should do to make it secure."	kennysmoothx	13.730446	-5.250374	comment	6.0	25.0	1483823919	9.922836
13376653	Realistically, insecure defaults are	Realistically, insecure defaults are part of the reason Mongo was adopted in the first place.  Other databases are a hellscape of configuration, meanwhile Mongo is starting to get work done from the moment it's installed.Security and usability are always at odds.  If you make security a pain, people will give up on security.  Mongo is the ultimate manifestation of that principle.  Developers were driven to Mongo by opaque and painful admin tasks.	Pxtl	13.722594	-5.260075	comment	6.0	21.0	1484162262	9.964963
13423546	I don't know, my personal opinion wa	I don't know, my personal opinion was that RethinkDB had its head on straight, MongoDB is garbage and still neither is so much better than PostgreSQL that I will switch away from it.Postgres is the default datastore (because schemas are awesome) for me, and I haven't had a use case yet where I needed something that Postgres wouldn't do. Maybe if you have a very specific need, you'd reach for another datastore (come to think of it, I have successfully used Cassandra for multi-DC deployments of a distributed read-only store), but that's not the norm for me.	StavrosK	13.526237	-5.2782598	comment	6.0	50.0	1484707113	-12.76097
13424728	I am using RethinkDB in PartsBox (ht	"I am using RethinkDB in PartsBox (https://partsbox.io/). I initially picked it because I wanted a JSON document database that has a correctly implemented distributed story. But later on it turned out that the realtime-push (changefeeds) functionality is actually fundamental for me. I used it to build an app where every open sessions gets instant updates.Right now I don't know what other database I could use, because I found no other solution that supports this kind of functionality, especially in a distributed setting.I agree with most of your analysis and I think that the most important part is about ""worse is better"": many of your potential customers won't understand or won't care about correctness or consistency.That said, I really like RethinkDB (oh, it does have its warts, but overall"	jwr	13.583085	-5.2999167	comment	6.0	20.0	1484724418	9.575474
13558119	Though I am a huge fan of SQLite, I 	"Though I am a huge fan of SQLite, I am not sure if the incredible test coverage necessarily leads to success :""Trying to improve software quality by increasing the amount of testing is like trying to lose weight by weighing yourself more often. What you eat before you step onto the scale determines how much you will weigh, and the software-development techniques you use determine how many errors testing will find. If you want to lose weight, don't buy a new scale; change your diet. If you want to improve your software, don't just test more; develop better.""(McConnell, Steve (2009-11-30). Code Complete (Kindle Location 16276). Microsoft Press. Kindle Edition)Another unique aspect of SQLite code base is total sticking to KISS(http://www.jarchitect.com/Blog/?p=2392)"	sAbakumoff	13.655516	-5.617452	comment	6.0	30.0	1486102671	9.872154
13590457	MongoDB 3.4 passes the rigorous and 	MongoDB 3.4 passes the rigorous and tough Jepsen test. Jepsen designs tests to make databases fail in terms of data consistency, correctness, and safety... MongoDB 3.4 passed through their newest tests.I think that this really shows how mature of a Database MongoDB is.	kenwalger	13.651782	-5.304164	comment	6.0	30.0	1486485115	9.8838415
27732418	> Given the extensive tests written 	> Given the extensive tests written against sqlite, rewriting it from scratch in any language, even a more modern/safer one, would ultimately end up with a buggier program.And yet, people keep finding use-after-free bugs in sqlite3 that allow attackers to escalate the memory corruption into arbitrary code execution... bugs that have affected major projects, including iCloud and Chrome; here are a handful: there are lots more even from just the past year :/.https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1363...https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-9327https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1387...https://cve.mitr	saurik	13.622602	-5.6085796	comment	6.0	43.0	1625431016	9.873657
27944065	Inserting 130M SQLite rows per minut	Inserting 130M SQLite rows per minute from a scripting language	mpweiher	13.535365	-5.523664	story	6.0	163.0	1627157510	9.789384
12113681	I'm building a Node.js app where I w	"I'm building a Node.js app where I was thinking of using MongoDB but I'm reconsidering it after reading the comments here.The database's only job is to keep persistence between server restarts. On server start I fetch the a collection from the database and populate a variable with it, which I use for any direct access.When a user updates something it will update the variable as well as updating the collection in the database.Something like this:    var foo = readFromDB();

    socket.on('connection', function() {
        this.emit(foo);
    });

    socket.on('update', function(data) {
        foo[data.id] = data.val;

        updateDB(data.id, data.val);
    });

(In my real application each collection has sub-arrays etc and not just key-value like in the example.)What should I use instea"	Kiro	13.622955	-5.373358	comment	6.0	30.0	1468827483	9.847813
35489370	If you cross-compile (which everybod	If you cross-compile (which everybody using macOS to developer for Linux servers does), it's annoying to introduce SQLite to your project, because immediately the conventional `GOOS= GOARCH= go build` trick stops working. But, in case it's helpful, it's also really easy to set up a full cross-compiling environment, either with Zig or with Filippo's musl-cross:https://words.filippo.io/easy-windows-and-linux-cross-compil...I debated doing the pure-Go SQLite thing, but musl-cross worked just fine for me, and kept things simpler.	tptacek	13.61472	-5.628724	comment	6.0	43.0	1680916493	-5.7169023
28069694	Before rendering judgment, please re	"Before rendering judgment, please read SQLite's own page on the subject. I think you will see that the choice wasn't sloppy but thoughtfully designed, https://sqlite.org/datatype3.htmlMy takeaway from that is: (1) for many people, SQLite is not your database, but you already knew that, (2) it is nice there exists a database out there with this flexibility, if you want it, and (3) if you choose it, you might consider declaring columns NUMERIC. From the documentation: ""A column with NUMERIC affinity may contain values using all five storage classes. When text data is inserted into a NUMERIC column, the storage class of the text is converted to INTEGER or REAL (in order of preference) if the text is a well-formed integer or real literal . . .  If the TEXT value is not a well-formed integer or"	combatentropy	13.607536	-5.6041727	comment	6.0	47.0	1628135756	9.842047
28090022	A somewhat oversimplified summary of	A somewhat oversimplified summary of the new UUID formats:UUID6: a timestamp with a weird epoch and 100 ns precision like in UUID1, but in a big-endian order that sorts naturally by time, plus some random bits instead of a predictable MAC address.UUID7: like UUID6, but uses normal Unix timestamps and allows more timestamp precision.UUID8: like UUID7, but relaxes requirements on where the timestamp is coming from. Want to use a custom epoch or NTP timestamps or something? UUID8 allows it for the sake of flexibility and future-proofing, but the downside is that there's no standard way to parse the time from one of these -- the time source could be anything monotonic.	pjscott	13.978852	-5.2134953	comment	6.0	91.0	1628269651	-13.669833
28157179	Absurd-SQL – Use sqlite3 on the web 	Absurd-SQL – Use sqlite3 on the web with storage in IndexedDB	timdorr	13.53865	-5.520623	story	6.0	92.0	1628780532	9.761206
28279051	Today I Feel Low	Today I Feel Low	mcs_	13.731038	-5.295977	story	6.0	14.0	1629739071	9.944696
28279426	Less than a year after this was publ	"Less than a year after this was published, Tencent released the Magellan series of sqlite RCEs.I think this is a fine page and it is eminently reasonable that sqlite remains a C codebase. In particular, I think he's right that rewriting sqlite in a memory-safe language would introduce a bunch of bugs and likely result in a couple of years of instability.But the ""security"" paragraphs in this page do the rest of the argument a disservice. The fact is, C is a demonstrable security liability for sqlite. The real position of the project is that memory safety security vulnerabilities are an acceptable tradeoff for an otherwise reliable database engine; in practice, people will deal with the exposure either by treating it as an externality (ie: baking sqlite into products where it is directly exp"	tptacek	13.631158	-5.6378636	comment	6.0	73.0	1629740684	9.818863
28500027	This is quite an interesting point. 	This is quite an interesting point. In data engineering, compression is a key goal -- yet random identifiers are often used.Part of the reason is, presumably, that over a distributed system it's hard to coordinate choosing a deterministic globally unique identifier without a performance cost.Does any one have any thoughts on implementing a globally unique identifier in a compressible/deterministic way?My initial guess is choose some low-collision probability random part, and then glue on timestamp?	mjburgess	13.959989	-5.2122045	comment	6.0	21.0	1631443931	-13.657859
22370376	While everyone's praising SQLite, I 	While everyone's praising SQLite, I want to note that SQLite type system is absolutely horrible. When you can store string in the integer column, you don't have a type system. And it's absolutely not intuitive for people having experience with other databases.	vbezhenar	13.605916	-5.6071773	comment	6.0	28.0	1582148407	9.846936
22370455	My only grievance, and a blocker, is	My only grievance, and a blocker, is that SQLite does not support decimal numbers, making it less practical to work with finance related data.	miohtama	13.636668	-5.5830803	comment	6.0	50.0	1582149003	9.799944
22522106	It still requires the user to instal	It still requires the user to install and admin a postgres instance which already makes it a non-starter for 99% of the target audience, this design choice is tragically stupid - the chance that an instance of pleroma will reach a usage volume that can't be handled by sqlite  and basic caching is not on the horizon, if they ever reach this problem they could then develop a version that works against an actual rdbms.	seemslegit	13.584877	-5.5056934	comment	6.0	28.0	1583717313	9.842697
23076007	RailsConf 2020 Couch Edition	RailsConf 2020 Couch Edition	bdcravens	13.625496	-5.2198653	story	6.0	132.0	1588647895	9.655984
23285946	Is it reasonable to assume that in m	Is it reasonable to assume that in most current deployments of PostgreSQL or MySQL, SQLite would be at least an equally good choice?I was recently choosing a database for a medium-size website and SQLite seemed like an obvious choice. One thing I was worried about was that the database locks for each write - but this is apparently not true anymore with write-ahead log.	RivieraKid	13.61176	-5.5409236	comment	6.0	18.0	1590264605	9.801398
23359023	Has anybody used Sqlite in a server 	Has anybody used Sqlite in a server side, production level capacity....I know it works great on embeded cases, but how about server side with a decent user load?	ardit33	13.582864	-5.5244145	comment	6.0	20.0	1590820599	9.824986
33119873	I want this exact thing for SQLite, 	I want this exact thing for SQLite, nothing good exists	aae42	13.609407	-5.5795608	comment	6.0	22.0	1665142368	9.875042
33185272	Reminder that Mozilla killed off SQL	Reminder that Mozilla killed off SQLite in the browser, to push indexedDB, a much more limited database that they then went and implemented in Firefox with... SQLite.	LAC-Tech	13.567607	-5.541825	comment	6.0	24.0	1665618134	9.809042
33330602	Sqlite is tested so thoroughly I dou	Sqlite is tested so thoroughly I doubt Rust's borrow checker (which is essentially just another test) would benefit it: https://www.sqlite.org/testing.htmlSqlite also has never had a severe CVE, from the parent's link:> All historical vulnerabilities reported against SQLite require at least one of these preconditions:>    The attacker can submit and run arbitrary SQL statements.>    The attacker can submit a maliciously crafted database file to the application that the application will then open and query.The OP's vulnerability requires passing an insanely long string to a C api, which isn't something you'd expect to be secure.	tinalumfoil	13.627431	-5.6374393	comment	6.0	32.0	1666706675	9.836182
33447004	Interesting. What are some good exte	Interesting. What are some good extensions for pg? I have only used UUID and postgis.	mradek	13.662599	-5.269626	comment	6.0	19.0	1667449751	-13.674121
33567954	> Made using SvelteKit + MongoDB and	> Made using SvelteKit + MongoDB and deployed to Vercel (frontend) and AWS (backend).Sounds (over)complicated. Isn't just a static html webpage on php/js backend with sqlite or even without, just grepping logs via cron, do the trick?Having Nginx as a front-end, with static file caching enabled, would handle just fine the load from HN front page  even on a RPi.	nuccy	13.571628	-5.5253716	comment	6.0	31.0	1668207398	9.83361
33628136	SQLite Release 3.40.0	SQLite Release 3.40.0	thefilmore	13.6251545	-5.594472	story	6.0	119.0	1668623627	9.88765
33699609	Yeah I don't really get the point of	Yeah I don't really get the point of this article, if you need random values of a specific size don't use uuid, it's literally specified to be one exact length and format.	corytheboyd	13.988105	-5.204519	comment	6.0	39.0	1669072972	-13.669468
33896223	Hey! I'm the author of the article. 	Hey! I'm the author of the article. Saw a sudden influx of traffic from HN and found the post here.Happy to answer any questions. Although SQLite is so dead-simple-but-awesome that you probably don't have any. :DAnyway, hope you enjoy it and learn a thing or two.Markus	markusw	13.602134	-5.5675297	comment	6.0	43.0	1670430179	9.8402815
33934631	I love postgres for most things, but	I love postgres for most things, but these days (Especially while my product is in early development, embedded, or just not internet-facing) sqlite is amazingly workable.Killer postgres features however: Row-level security (Fantastic when you're using something like postgrest for rapid backend development [1]), and its built in fulltext search engine is 'good enough' for use cases like when you have an enormous users table and need to index something simple enough, like email addresses for quick login.[1] https://postgrest.org/	jamal-kumar	13.533101	-5.458798	comment	6.0	75.0	1670693936	9.839581
34022377	I'm highly in favour of this, but wa	I'm highly in favour of this, but wanted to point out an important implementation detail in case people don't want to look through the code.Since WordPress doesn't have a database abstraction, SQLite integration is done by transforming the SQL query strings meant for MySQL. This not only means doing regexp matches with string replacement, but trying to emulate MySQL functions with either SQLite equivalents, or in the worst case, in PHP application code.	bretthopper	13.597195	-5.5776362	comment	6.0	26.0	1671235130	9.835157
26583422	> SQLite doesn't really enforce colu	> SQLite doesn't really enforce column types[0], the choice is really puzzling to me.This is acknowledged as a likely mistake, but one that will never be fixed due to backward compatibility:> Flexible typing is considered a feature of SQLite, not a bug. Nevertheless, we recognize that this feature does sometimes cause confusion and pain for developers who are acustomed to working with other databases that are more judgmental with regard to data types. In retrospect, perhaps it would have been better if SQLite had merely implemented an ANY datatype so that developers could explicitly state when they wanted to use flexible typing, rather than making flexible typing the default. But that is not something that can be changed now without breaking the millions of applications and trillions of da	haberman	13.637028	-5.6179295	comment	6.0	26.0	1616695519	9.861069
26687871	Dflat: SQLite FlatBuffers	Dflat: SQLite FlatBuffers	tosh	13.572472	-5.579874	story	6.0	123.0	1617526019	9.91639
26817343	it's important to note that the auth	"it's important to note that the author of SQLite wasn't ""competing"" with RDMS engines -- it's competing with flat file access.To that goal, I think it's wildly successful, instead of writing files I almost always reach for SQLite first.When systems share a database, I, like you, reach straight for postgresql. Most people reach for mysql, which I do not prefer."	dijit	13.583193	-5.5229	comment	6.0	49.0	1618472785	9.819312
26821875	Firefox uses SQLite for localStorage	Firefox uses SQLite for localStorage. When Firefox is force quit, the database becomes corrupted. https://bugzilla.mozilla.org/show_bug.cgi?id=1341070This bug has occurred to me personally multiple times.Does it really have advantages over a flat file?	crazypython	13.56679	-5.5289526	comment	6.0	26.0	1618501489	9.812719
27017483	Over high latency links this would b	Over high latency links this would be virtually unusable. Why not just download the entire database into memory over XHR on page load? SQLite databases of pure data usually aren’t over 10MB in size.	CyberRabbi	13.556447	-5.519745	comment	6.0	36.0	1619979489	9.790263
37595822	I thought all those points died alon	"I thought all those points died along with the hype (""MongoDB is web scale""), as all were wrong.Those were the marketing points people mentioned in their ""honeymoon phase"" posts. Then after using it in production, actual benchmarks and comparisons coming in, came the regret  and moving on posts. In fact, most of those mentioned moving from Mongo to Postgres, and there was a full blow ""yeah, NoSQL was a dumb idea for 99% of use cases, and Mongo even more so"" discussion.In the end MongoDB was the butt of a joke, there were whole memes about it.So this comment is like a trip down memory lane, or into an alternate universe, where it's like 2012 and these things never happened."	coldtea	13.669455	-5.325527	comment	6.0	45.0	1695293290	9.8768015
37614888	"SQLite not supporting ""stored proced"	"SQLite not supporting ""stored procedures"" is a deal-breaker for me. The idea for stored procs is not to ""put the process as close to the data"" but simply that we have a single place for language-agnostic encapsulation of data procedures."	ak39	13.581649	-5.5599923	comment	6.0	18.0	1695403574	9.870097
37734487	Thinking that harder-to-guess IDs wi	Thinking that harder-to-guess IDs will mitigate attacks is an example of security by obscurity. It's better to think of any IDs in your database as being public knowledge, because they will leak anyway. Assuming that no one can guess another ID leads to shoddy practices. I generally keep IDs sequential and build security around the basic assumption that IDs are not keys, passwords, sessions, or secrets - they're just the public matching identifier for those things.To that end, I think it's neat to be able to improve indexing on UUIDs, but it's not a security solution.	noduerme	13.964576	-5.2097	comment	6.0	45.0	1696226490	-13.6481695
37770454	If you really want to use SQLite wit	If you really want to use SQLite without anything that isn't Go (since this project involves forking and communicating with a non-Go SQLite in a separate process over pipes), there's a Go translation of SQLite's C source. :)https://gitlab.com/cznic/sqlitehttps://datastation.multiprocess.io/blog/2022-05-12-sqlite-i...	eatonphil	13.620876	-5.6221123	comment	6.0	60.0	1696448181	9.865904
37845818	Quoting the SQLite docs:  The SQL st	"Quoting the SQLite docs:  The SQL standard specifies a large number of keywords which may not be used as the names of tables, indices, columns, databases, user-defined functions, collations, virtual table modules, or any other named object. The list of keywords is so long that few people can remember them all. For most SQL code, your safest bet is to never use any English language word as the name of a user-defined object.


https://www.sqlite.org/lang_keywords.html"	em500	13.612601	-5.6097856	comment	6.0	25.0	1697038476	9.871214
38038025	Yeah. I've gotten into discussions o	Yeah. I've gotten into discussions on HN before about this. sqlite is awesome when you run it in one instance on a VM or something, but solving migration between hosts or backup via the filesystem seems like a mess. Sure LiteFS helps, but is it better than a managed networked database?> One huge benefit to SQLite is the fact that it runs as an embedded part of your applicationBut all production workloads I've been involved with the last ≈5 years have either been containerised apps offloading state to databases/caches/blob storage etc, or have strived towards that.What I do think would be awesome would be an embeddable Postgres library/binary that could use a single state file on your local filesystem for development and use a networked database in production. Getting the benefits I like mo	filleokus	13.528653	-5.4610243	comment	6.0	54.0	1698412558	9.783982
38038280	Tangentially related: my personal op	Tangentially related: my personal open source project (ntfy.sh) is starting to outgrow a one node SQLite-backed setup, and I am now faced with the decision we are talking about here (something I would not have imagined, I might add): do I use some SQLite-replication thing, or do I rewrite it all to work with a RDMS and deal with managing that? It's quite the annoying choice, so I really wish there was a great SQLite backed solution, hehe.	binwiederhier	13.572876	-5.519004	comment	6.0	23.0	1698413942	9.796868
38398305	PostgreSQL on S390x	PostgreSQL on S390x	sbuttgereit	13.520939	-5.399391	story	6.0	57.0	1700778231	9.791072
15126282	> I think the most interesting quest	> I think the most interesting question though is would they be able to get MVP and initial customers that set off this if they were moving (slightly) slower due to SQL and slight overhead that comes with?I've used Postgres and Mongo pretty extensively, and for any reasonably seasoned developer, the startup overhead of an SQL system is a myth. There may upfront cost to learning how an RDMS and SQL work in the first place, but once you're familiar with them, they'll be faster than Mongo on any new project.The schemaless concept of a document database seems to be the major selling factor in velocity of movement, but once you've got a good handle on a migration framework in the vein of ActiveRecord or other popular software, that's negated completely. It also really doesn't take long before s	brandur	13.549271	-5.4204507	comment	6.0	70.0	1504029869	9.860243
15267617	I just wish it had a better name lik	I just wish it had a better name like ResilientDB.	pryelluw	13.567639	-5.2939997	comment	6.0	34.0	1505609299	-12.563655
15308272	Reliability-wise, it sucks. Maybe it	Reliability-wise, it sucks. Maybe it's gotten better recently, but I still probably wouldn't trust it.But is there a document store out there that's faster than MongoDB?	meowface	13.629391	-5.307148	comment	6.0	22.0	1506038025	9.874294
15308214	Obligatory reminder that Mongo is sh	Obligatory reminder that Mongo is shit and you should never use it for data you care about.	djrobstep	13.696749	-5.3204093	comment	6.0	36.0	1506037214	9.9177475
15488113	Kindred and CockroachDB Partner to B	Kindred and CockroachDB Partner to Build a Global Online Gaming Platform	jinqueeny	13.639029	-5.22056	story	6.0	44.0	1508206023	9.932513
15509590	Does anyone use Mongo anymore?Edit: 	Does anyone use Mongo anymore?Edit: Honest to god question. I was surprised when I saw the headline, because I've never seen anyone use mongo in production, and never ran into any articles talking about using mongo.	felipellrocha	13.687683	-5.3149576	comment	6.0	20.0	1508432715	9.911948
15608201	I'm a big fan of SQLite, but this ki	I'm a big fan of SQLite, but this kind of marketing puts me off a bit. ZIP and XML are popular standards with dozens of implementations. The only thing that can read an SQLite DB is SQLite, AFAIK.To be sure, SQLite is very well supported, runs on tons of platforms and is going to be around for a long time. But still, it is less archival quality, and more inherently complex (even though that complexity is very well encapsulated).	btrask	13.52672	-5.5526214	comment	6.0	27.0	1509602964	9.799254
15608385	I don't see how your comment is resp	I don't see how your comment is responsive to the excellent article.doc and xls were proprietary binary formats.sqlite files couldn't be more open - the software to interact with them is in the public domain and ported everywhere.And the article itself doesn't even suggest using sqlite as a binary store. Rather, it suggests using the capabilities of sqlite to augment text-based data.	abtinf	13.550092	-5.58014	comment	6.0	67.0	1509606099	9.801314
15608795	To be fair, you can't read any files	To be fair, you can't read any files without software, you need a text editor even for plaintext.However, all software is not equal. Any OS comes with a text editor and a ZIP utility by default now. The same is not true for SQLite's format.	Drakim	13.543273	-5.5633583	comment	6.0	18.0	1509612756	9.835206
15700576	Remote Code Execution in CouchDB (an	Remote Code Execution in CouchDB (and Privilege Escalation in the Npm Registry)	justicz	13.60112	-5.194089	story	6.0	68.0	1510705960	-10.888404
15712907	MongoDB/NoSQL is deployed and used a	"MongoDB/NoSQL is deployed and used at large scale by companies like Facebook, Ebay and many others. That's quite far from ""no one is actually making that choice nowadays""."	maephisto	13.656451	-5.34037	comment	6.0	21.0	1510843227	9.865941
20730094	Next week on Show HN: `sqlitefs`, th	Next week on Show HN: `sqlitefs`, the SQLite-backed FUSE filesystem?	OJFord	13.672926	-5.6042438	comment	6.0	19.0	1566135979	9.802697
20776756	Interesting pick from one of the lin	"Interesting pick from one of the links in the article:""SQLite has fantastic write performance as well.  By default SQLite uses database-level locking (minimal concurrency), and there is an “out of the box” option to enable WAL mode to get fantastic read concurrency — as shown by this test.  But lesser known is that there is a branch of SQLite that has page locking, which enables for fantastic concurrent write performance.""https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-q..."	dest	13.571604	-5.5004673	comment	6.0	33.0	1566563037	9.775435
13611446	IMO the main advantage for RethinkDB	IMO the main advantage for RethinkDB is its HA story. Last time I had to manage a PostgreSQL cluster (2012-2013) its HA story was pretty bad. It was limited to a master-slave(s) setup with manual failover and manual cluster rebuilding all dependent on incomplete 3rd party tools. Has PostgreSQL improved on this? A quick googling leads me to believe it hasn't and I'd only even consider it again if it were managed by a 3rd party (eg. aws rds).	eikenberry	13.609062	-5.296123	comment	6.0	22.0	1486677857	-12.804736
14308751	Since there's a little side riff abo	Since there's a little side riff about the name going on I thought I'd throw in my 2 cents. Personally I love the name. I think it does a great job of conveying the spirit of the project and provides unlimited pun opportunities. Plus it's memorable, just like a real life roach encounter. Unfortunately I'm sure some people will discriminate against your DB on the basis of name alone. That's ludicrous, but that's our species for ya.	anthonylebrun	13.62685	-5.214678	comment	6.0	31.0	1494428927	-4.523955
14509341	I really like the ideas behind ksuid	I really like the ideas behind ksuid (near the end of the article). However, two quotes:> Those concerned with UUID collision in a properly-configured system would find their time better spent pondering far more probable events like solar flares, thermonuclear war, and alien invasion on their systems.And then further down:> A “custom” epoch is used that ensures >100 years of useful life.Wait, so the last 128 bits of a KSUID won't get me in trouble before the sun explodes, but the first 32 bits (the timestamp) will cause trouble well before my grandkids die?I really wonder why they didn't reserve some more bits for the timestamp, if necessary at the cost of some less randomness. Could've made this stuff last for millenia at no extra collision risk, in practice.	skrebbel	13.995862	-5.208811	comment	6.0	40.0	1496864880	-13.651107
14516100	Local and distributed query processi	Local and distributed query processing in CockroachDB	benesch	13.648098	-5.204818	story	6.0	136.0	1496946866	9.936227
14523751	>The original issue with simple auto	">The original issue with simple auto-incrementing values is that they are easily guessable as I noted above.I don't think this is a real problem. If you're relying on your ID's being ""unguessable"" (and introducing engineering complexity to that end) for security you've already failed."	wcummings	13.922392	-5.204741	comment	6.0	21.0	1497036367	-13.638107
14524019	I've been using natural keys in a pr	I've been using natural keys in a project recently without even knowing they were called that, or even that it was a pattern.Is there a book or any other reading you would recommend to be more familiar with these sorts of details? The longest text I could find about this was the c2 wiki. I'd like to know what else I don't know.	squeaky-clean	13.857118	-5.249613	comment	6.0	57.0	1497038349	-13.635797
14588639	Introduction to MongoDB	Introduction to MongoDB	praveenscience	13.666735	-5.3338733	story	6.0	22.0	1497893104	9.921139
31340253	All this recent hype around sqlite..	All this recent hype around sqlite...sqlite is a great embedded database and thanks to use by browsers and on mobile the most used database in the world by orders of magnitude.But it also comes with lots of limitations.* there is no type safety, unless you run with the new strict mode, which comes with some significant drawbacks (eg limited to the handful of primitive types)* very narrow set of column types and overall functionality in general* the big one for me: limited migration support, requiring quite a lot of ceremony for common tasks (eg rewriting a whole table and swapping it out)These approaches (like fly.io s) with read replication also (apparently?) seem to throw away read after write consistency. Which might be fine for certain use cases and even desirable for resilience, but c	the_duke	13.573521	-5.493497	comment	6.0	50.0	1652278472	9.7541
31423986	Ask HN: Pros and Cons of Using Couch	Ask HN: Pros and Cons of Using CouchDB?	_448	13.605415	-5.2070885	story	6.0	17.0	1652887702	9.682223
31474065	If you open multiple connections to 	If you open multiple connections to an sqlite db from a single app you are a bad developer, full stop.We have server app on a single beefy server servicing ~100,000 simultaneous users with avg user action per second of 0.2 (~20k actions per second) requiring some ~60k sqlite writes per second.A single thread handles that with message passing with little load. We estimate we can handle 5-10 times as much without changing anything. That's with SSD's and standard OS caching. With either an in-memory db or using zstd compressed ramdisks the limits are ridiculous.	rogers18445	13.554388	-5.507897	comment	6.0	23.0	1653264177	9.761532
31537243	Please stop this abuse of language.H	Please stop this abuse of language.Here's serverless sqlite: https://www.sqlite.org/serverless.html	peterkelly	13.588483	-5.520293	comment	6.0	26.0	1653707050	9.818275
31655199	This is a really neat technology, bu	"This is a really neat technology, but I don't understand it's use case. I've worked in HealthTech and currently in the compliance space. I'm skeptical of Mongo's claims (and their familiarity with compliance laws). Kind of feels like a solution in search of a problem.""In use"" implies that you have a need to process that data. It doesn't matter if the end client is submitting queries in plain text (protected in transit) or this fancy encryption, the client (or server) still needs to be authorized to query that data. Translating from plain-text to encryption does not add additional protections from a compliance perspective."	SkyPuncher	13.715614	-5.23555	comment	6.0	24.0	1654613431	9.895296
25593165	After a lot of time spent investigat	After a lot of time spent investigating the different kind of (U)UIDs, I've come to the conclusion that ULIDs[0] are the best kind of (U)UIDs you can use for your application today:* they are sortable so pagination is fast and easy.* they can be represented as UUID in database (at least in Postgres).* they are kind of serial, so insertion into indexes is rather good, as opposed to completely random UUIDs.* 48 bits timestamp gives enough space for the next 9000 years.[0] https://github.com/ulid/spec	sylvain_kerkour	13.976673	-5.2153244	comment	6.0	29.0	1609426427	-13.691155
25843157	https://www.sqlite.org/serverless.ht	https://www.sqlite.org/serverless.html(first published 2007, before the more recent misuse of the term began)	peterkelly	13.5867	-5.413318	comment	6.0	74.0	1611124056	9.799303
25843786	I was thinking of making it possible	I was thinking of making it possible for SQLite to be used with static pages.My idea is to modify SQLite to use ajax with the HTTP Range header to fetch B+ pages from the server as they are needed. SQLite already has a VFS (virtual file system) so this shouldn't be too hard.I am not sure how fast it would be and it would waste a lot of bandwidth. That's why I haven't made it yet.This would only be useful for using it with Github pages.	kuter	13.585929	-5.5595164	comment	6.0	24.0	1611129753	9.854603
26105570	> “But nobody writes production appl	"> “But nobody writes production applications with SQLite, right?""We've been doing it for 5 years now. Basic tricks we employ are:Use PRAGMA user_version for purposes of managing automatic migrations, a. la. Entity Framework. This means you can actually do one better than Microsoft's approach, because you don't need a special unicorn table to store migration info. A simple integer compared with your latest integer and executing SQL in the range is all it takes.Use PRAGMA synchronous=NORMAL alongside PRAGMA journal_mode=WAL for maximum throughput while supporting most reasonable IT recovery concerns. If you are running your SQLite application on a VM somewhere and have RTO which is satisfied by periodic hot snapshots (which WAL is quite friendly to), this is a more than ideal way to manage r"	bob1029	13.582932	-5.492327	comment	6.0	31.0	1613069516	9.772405
26152091	> are there any more fundamental dat	> are there any more fundamental data types other than null, int, real, text and blob?Those type names are just hints, they don't constrain the valid values in any way.https://dbfiddle.uk/?rdbms=sqlite_3.27&fiddle=4634e3821676ed...	hans_castorp	13.601908	-5.609357	comment	6.0	28.0	1613464923	9.8583975
26152851	I have only worked with PostgreSQL a	I have only worked with PostgreSQL and when the wife(Accounting Professor) needed a DB to teach their students SQL, I heartily took her down the SQLite path because of its simplicity. It may not have been the best decision as I see her now fighting with its warts like1. No type checking! Declare a column as int in DDL, and insert a text, SQLite happily stores it without an error :-(2. No full outer join... instead my wife taught the students the standard SQL syntax and told them to use UNION with SQLite because it does not support that syntax. This is where it gets annoying.I can’t recollect, but there were issues with views as well which sounded really weird.I now think the choice of SQLite is more nuanced than I believed it to be.	reacharavindh	13.5999975	-5.5662656	comment	6.0	21.0	1613473723	9.885727
26153714	I've been there. It doesn't work. I'	I've been there. It doesn't work. I've been applying all those tips and tricks, but it didn't improve performance that much, but I have lost data.Sqlite is full of locks, and any writes are single-threaded stop-the-world, and there's no way around it. It's Sqlite's philosophy. Write-heavy databases just need something like MVCC, and Sqlite won't have that.	pornel	13.559352	-5.5209646	comment	6.0	30.0	1613482666	9.814626
26192760	integer ids are still often used int	"integer ids are still often used internally for database primary keys with UUIDs being the done thing for external interfaces.Personally I've never experienced the ""whole class of bugs"" that starting with a big integer is supposed to solve. I'm not using PHP so maybe that's why?"	dkarp	13.94036	-5.2250495	comment	6.0	27.0	1613740445	-13.635295
26218671	I feel like if I am worried about th	I feel like if I am worried about those issues, when would I ever use sqlite instead of Postgres?Sqlite seems like it is only appropriate for the knife’s edge boundary between small data, low reliability, in-memory situations (better served by server applications using tools like pandas or R) and bigger data, transactional structure, reliability constraints (better served by Postgres).I just can’t understand what use cases live in between them and are better served by sqlite.	mlthoughts2018	13.593014	-5.5239897	comment	6.0	29.0	1613952017	9.842195
26421513	There were many questions asking abo	There were many questions asking about recent experience with MongoDB. I have some recent experience so wanted to share with everyone.My background:2007-2010: Used MySQL to run a social network for 50M+ users. Would send 2B messages on peak days. All powered by Mysql.2015-2020: Used Mongo to power a top 5k site. Zero downtime and dataloss in 5 years. Used Postgres for internal non user facing databaseSo I have familiarity with all of these databases at a decent scale. I am going to list pros and cons of each and why I would use. Again a tool is a tool. Just because I love a wrench, doesn't mean that I am going to use it instead of a hammer when I need to put some nails.MongoDB:They have come a long way since I started using them in 2012. If your use case is CRUD, you would be fine. There i	technosamay20	13.639583	-5.3372016	comment	6.0	30.0	1615449875	9.865866
26444094	MongoDB's stock price is quite remar	MongoDB's stock price is quite remarkable, given how dismissive a lot of people (including myself) on HacherNews have been of their offering.It goes to show that HackerNews consensus != reality.I do wonder where/how Mongo makes their money - if anybody has some insight, please share.	alexashka	13.717179	-5.287937	comment	6.0	38.0	1615611448	9.913161
26473525	I once joked with a colleague that m	I once joked with a colleague that my sqlite3 install is faster than his Hadoop cluster for running a report across a multi-gig file.We benchmarked it, i was much, much faster.Technically though once that multi-gig file becomes many hundreds of gigs, my computer would loose by a huge margin.	cobookman	13.541038	-5.5039887	comment	6.0	43.0	1615874752	9.746099
35618850	Oh this looks good. I've been using:	Oh this looks good. I've been using: https://sqlitebrowser.org/This seems to offer way more.	account-5	13.592519	-5.5773244	comment	6.0	23.0	1681846192	9.799403
35962213	SQLite 3.42.0	SQLite 3.42.0	nikbackm	13.626387	-5.6001925	story	6.0	250.0	1684246572	9.876538
36055184	https://www.sqlite.org/copyright.htm	https://www.sqlite.org/copyright.htmlTo summarize, instead of using one of the OSS licenses, the copyright holders simply declare the source to be in the public domain. In order to preserve that status they don't accept patches unless you submit some signed document that you agree with that.To make things more complicated, they also use their a relatively niche version management system instead of git. Which would complicate making contributions (if they accepted them).There's a popular fork that fixes all of these issues: https://github.com/libsql/libsql It is MIT licensed, on Github, and open for contributions.Kind of a weird legal situation for a popular project like this that so many people depend on to have. Not judging; but it is odd. Seems like a lot of wasted efforts between users,	jillesvangurp	13.61865	-5.58755	comment	6.0	18.0	1684914316	9.853879
36102058	This. I'm actually surprised the lin	"This. I'm actually surprised the linked Wikipedia article on ""Natural key"" only mentions one potential disadvantage, that somewhen in the future, maybe, at some point, somehow, the other system may change, and then your keys are bust. They even give US SSNs as an example of something that may stop working as unique key in the future.There are no ""natural keys"". They don't exist in nature. They don't exist as a thing in our physical reality. And when it comes to human-assigned identifiers, it should be emphasized much more strongly that whatever external thing you think is a good unique ID, it isn't.Names? Addresses? Dates? Nope - have you heard of the ""Falsehoods programmers believe about...""?Government IDs? Nope. US SSN was not designed to be used as UID from the start, but even when you "	TeMPOraL	13.903421	-5.1908813	comment	6.0	50.0	1685260596	-13.6321
36209447	> It’s borderline impossible to comp	> It’s borderline impossible to compare it against networked database management systems like MySQL or Postgres, because SQLite is a library that operates on a local file — it bypasses all the costs incurred by the network, layers of serialization and deserialization, authentication, authorization, and more.Postgres can run locally, communicating via a Unix socket. You should try benchmarking this before stating that it's so much slower than SQLite.	runeks	13.557136	-5.502889	comment	6.0	30.0	1686036878	9.813741
36209567	"I want to hear ""What's not great usi"	"I want to hear ""What's not great using SQLite compare to PostgreSQL"" instead ."	revskill	13.561876	-5.49638	comment	6.0	27.0	1686037816	9.820643
36329364	It’s amazing that this isn’t a solve	It’s amazing that this isn’t a solved problem, but we have all of this crazy language model stuff.Unfortunately Spanner isn’t open source. Yugabyte and Citus are close but have annoying issues. Cockroach isn’t 100% compatible (and has its own issues) and things like FoundationDB which are truly HA and comparable to Spanner in terms of consistency and fault tolerance are not easily plugged into Postgres as the underlying storage engine since sadly it’s only a key value store.edit: when I say close, I'm talking strictly about HA, not general functionality.lately I've been thinking of using FoundationDB, which is closest to Spanner in terms of ACID and serializability and mvsqlite.Then, I was thinking, since SQLite doesn't have online schema changes (nor does mvsqlite) to have a schema such a	endisneigh	13.555146	-5.384472	comment	6.0	35.0	1686763753	9.7864275
36385057	> Tutorials show harmful patterns.Tr	> Tutorials show harmful patterns.Try to find a sample SQL database, for any vendor, that does not employ artificial table primary keys. This was a requirement in the 1980s so that your queries would execute before the heat death of the universe, but that has not been the case for decades. Microsoft is particularly guilty of this. Artificial keys are an anti-pattern. (And, btw, there's a dearth of literature on why artificial keys are an anti-pattern.)Here's the only sample database I know of that consistently uses natural keys across all tables, created by a SQL educator who knows his stuff.https://github.com/ami-levin/Animal_Shelter	jackfoxy	13.640374	-5.4737835	comment	6.0	21.0	1687126246	-13.633384
36430776	I can't think of many use cases wher	I can't think of many use cases where I would sacrifice the beauty and elegance of UUIDs to optimize access times by a millisecond or two. UUID is totally worth the cost.UUID actually performs much better than I thought based on the author's example with a COUNT query. COUNT queries aren't very efficient because typically, all records are traversed; here we're talking about a 50% slowdown on 10 million records... How often do you need to access 10 million contiguous records? Most of the time, for user-facing apps, you'll be accessing 100 contiguous records at most and, in fact, most queries will access a single record... I suspect that the average per-query performance loss for a typical app is probably less than 5%. Also, you could simply index by a separate date/timestamp field if you ne	jongjong	13.974239	-5.2149153	comment	6.0	97.0	1687435102	-13.671625
36431140	“5” might be the key for a thousand 	“5” might be the key for a thousand different records in your database. A uuid is a key for exactly one. Integer keys permit wrong joins to have the appearance of working.	kogus	13.968346	-5.219364	comment	6.0	22.0	1687437065	-13.697323
29071759	And the other day there was a projec	And the other day there was a project that allowed to use MS SQL wire protocol on PostgreSQL, so my question is:Are we just gonna implement everything on top of PostreSQL?	gizdan	13.521022	-5.424329	comment	6.0	31.0	1635794951	9.848907
29072415	MongoDB is a 12 year old database. A	MongoDB is a 12 year old database. And yet people are still using this disparaging argument that anyone that chooses it is doing so for their resume and not because it meets their needs in any way.But by all means replace your production system with MangoDB which is unsupported, significantly slower, has no built-in HA/clustering and written in Go which is a GC language.	threeseed	13.659975	-5.3255453	comment	6.0	35.0	1635797693	9.885021
29152008	Show HN: Insomnia-like client for SQ	Show HN: Insomnia-like client for SQLite	vdemedes	13.593701	-5.6080666	story	6.0	70.0	1636393920	10.010021
29459985	We need more of these „How project X	We need more of these „How project X is tested” articles. Keep them coming!Here’s one on SQLite: https://www.sqlite.org/testing.html	nathell	13.620514	-5.630455	comment	6.0	29.0	1638800350	9.836816
29572756	Chiselstore: an embeddable, distribu	Chiselstore: an embeddable, distributed SQLite for Rust	patrickdevivo	13.584252	-5.7215533	story	6.0	58.0	1639610065	9.702024
34178725	I wouldn't use ULIDs on a new projec	"I wouldn't use ULIDs on a new project.  The spec doesn't seem like it has much stewardship, the last commit was in 2019 with a bunch of open PRs and issues:
https://github.com/ulid/spec/issuesI went through this exploration a while back for a new project and decided on uuidv7s, which are binary compatible with ULIDs but will likely find more support as they get added to the original UUID RFC.Either UUIDv7 or XIDs seem like better choices than ULIDs for new projects.* Supabase on different primary key considerations: https://supabase.com/blog/choosing-a-postgres-primary-key* Postgres extension for generating various kinds of IDs: https://github.com/VADOSWARE/pg_idkit"	SirensOfTitan	13.986138	-5.2163496	comment	6.0	25.0	1672351896	-13.663451
34247738	WAL Mode in LiteFS	WAL Mode in LiteFS	eatonphil	13.525075	-5.487578	story	6.0	143.0	1672850163	9.82962
34355048	Using SQLite in the browser is great	Using SQLite in the browser is great until you have users that open your app in more then one browser tab.	typingmonkey	13.589649	-5.5560637	comment	6.0	21.0	1673537708	9.828047
34355090	The Web SQL standard was deprecated 	The Web SQL standard was deprecated (by Mozilla) on the grounds of a single implementation.The result today: A single SQL implementation with no standard (beyond SQLite) and therefore no easy way for anyone to create a compatible alternate implementation.	yyyk	13.566975	-5.5674114	comment	6.0	38.0	1673537879	9.817406
34440508	One of the trends on Hacker News rig	One of the trends on Hacker News right now is the assumption that SQLite fixes everything. It's the Flex Tape of the software world.There is zero reason a process would have more than tiny slowdowns with even millions of files in a folder. Finder has problems if you're trying to look at that folder, for obvious reasons, but it's a bit of a self-own for a backup co to claim that 200,000 files causes their solution to break. That speaks to serious algorithmic issues.DISCLAIMER: This comment will be auto-dead because of moderation choices by dang (e.g. his pernicious need to pander to the anti-science, far-right crowd). This is a badge of honor. Never vouch for my comments.	bfgoodrich	13.580782	-5.5539145	comment	6.0	26.0	1674138028	9.785263
34452323	Rather than use an extra column, I’v	Rather than use an extra column, I’ve taken to hashing the internal key (with a salt based on the entity type and some secret) to create the external facing ID.	jetpackjoe	13.957333	-5.2255697	comment	6.0	22.0	1674218600	-13.638304
34519547	Wild stuff- Fork of SQLite with new 	Wild stuff- Fork of SQLite with new features https://github.com/libsql/libsql- And you can embed it in your application and it will really talk to your SQLite/libsql database over the network (subject of this blogpost): https://github.com/libsql/sqld- Oh, and if you're wondering about backup to S3, they have that too: https://github.com/libsql/bottomless- Uh, sqld can integrated with this https://github.com/losfair/mvsqlite, so now your SQLite is backed by FoundationDB!?--- Meanwhile Litestream exists https://github.com/benbjohnson/litestream/- Ben is developing https://github.com/superfly/litefs at Fly so that y	maxmcd	13.561202	-5.476168	comment	6.0	21.0	1674661293	9.811954
34563671	Harder to copy and paste IDs. Discou	Harder to copy and paste IDs. Discourages denormalization since every reference is 128 ~~bytes~~ bits. Reduced throughout for inserts since the primary index pages won’t all be in cache if the keys are randomized. Lose ability to use id as a fast temporal ordering. Encourages uuids generated client-side.All in all not enough good reasons to make a lot of stuff slightly worse.	srcreigh	13.947584	-5.2233686	comment	6.0	31.0	1674953136	-13.649038
34683237	Making SQLite extensions pip install	Making SQLite extensions pip install-able	simonw	13.616968	-5.5913734	story	6.0	161.0	1675713023	9.889786
34804777	Distributed SQLite with Elixir	Distributed SQLite with Elixir	clessg	13.5947485	-5.5544043	story	6.0	77.0	1676473571	9.794226
34812935	>The only time you need to consider 	">The only time you need to consider a client-server setup is: Where you have multiple physical machines accessing the same database server over a network. In this setup you have a shared database between multiple clients.This caveat covers ""most cases"". If there's only a single machine, then any data stored is not durable.Additionally, to my knowledge SQLite doesn't have a solution for durability other than asynchronous replication. Arguably, most applications can tolerate this, but I'd rather just use MySQL with semi-sync replication, and not have to think through all of the edge cases about data loss."	adamkf	13.621123	-5.4755445	comment	6.0	49.0	1676506033	9.815388
34813327	It would probably be harder to bend 	It would probably be harder to bend Django to use SQLite as a backend then it would be to just setup MySQL or PostGRES and use the existing Django tooling for it.	deathclassic	13.584358	-5.599901	comment	6.0	20.0	1676508326	9.918009
37256312	I’ve used SQLite for some small proj	I’ve used SQLite for some small projects and it was a very pleasant experience.Does anyone have examples of the complex/ big projects that use SQLite ? I’m curious what problems they ran into, and how they were addressed.	great_psy	13.604713	-5.5657325	comment	6.0	22.0	1692923228	9.8558445
37555363	As an aside, this blew me away. I ca	"As an aside, this blew me away. I can hardly believe it. No nested query required?> SELECT manifest, versionId, max(checkinTime) FROM version;> ""Aside: Yes, that second query above that uses ""max(checkinTime)"" really does work and really does return a well-defined answer in SQLite. Such a query either returns an undefined answer or generates an error in many other SQL database engines, but in SQLite it does what you would expect: it returns the manifest and versionId of the entry that has the maximum checkinTime.)"""	stareatgoats	13.6191	-5.5963216	comment	6.0	30.0	1695040972	9.87222
24636204	Understanding How UUIDs Are Generate	Understanding How UUIDs Are Generated	aryamansharda	13.996267	-5.2119603	story	6.0	169.0	1601447486	-13.66784
24728369	See also:People finding the curl cop	"See also:People finding the curl copyright notice in an application and blaming Daniel Stenberg for hacking them:https://daniel.haxx.se/blog/2016/01/19/subject-urgent-warnin...Or the reason sqlite no longer uses ""sqlite"" as a file extension for temporary files:https://github.com/endlesssoftware/sqlite3/blob/master/os.h#..."	st_goliath	13.590807	-5.5715747	comment	6.0	20.0	1602237309	-9.062488
25230831	There is no tool that I love more th	There is no tool that I love more than SQLite. It's perfect. It does exactly what it says it will do, it never breaks (NEVER), is so small as to be invisible, is lightning fast, and packs many features a lot of the big guys still lack.It is incredible.	bambax	13.530643	-5.568862	comment	6.0	26.0	1606499216	9.785886
25302296	This is a really bad idea as explain	This is a really bad idea as explained eloquently in this blog:https://tomharrisonjr.com/uuid-or-guid-as-primary-keys-be-ca...	oxfordmale	13.984204	-5.2175565	comment	6.0	24.0	1607090618	-13.696848
25302841	I built something better that's actu	I built something better that's actually secure and performant here: https://github.com/boogerlad/crypt-ids/The issues with this are1) as more IDs are generated, the probability of collision increases2) a non integer primary key is slowFor a single database instance, it's far more performant to leave it as an autoincrementing integer and when it needs to be exposed, encrypt it in the backend before sending it out. Why not hashids.org? It's insecure: https://carnage.github.io/2015/08/cryptanalysis-of-hashids	boogerlad	13.940188	-5.215672	comment	6.0	26.0	1607093645	-13.648271
25365061	Mongo is also proving the success of	Mongo is also proving the success of vendor lock-in: you (or the engineers before you, and the engineers before them) make a mess in Mongo, because there are no relations and no schemas [0], and it becomes really difficult to get off it.The effort required just to get your data in a state that's clean enough to consider moving to the RDBMS you should have started with can be overwhelming.Then you have to rewrite your queries out of their custom query language.Is it Mongo's fault you made a mess in your database? No, of course not. And their dashboard is actually pretty nice. But you are massively locked-in.Source: own a production Mongo DB with years of accumulated mess in it. Desperate to get off it. Paying customer of Mongo's hosting (it's one less Mongo thing to deal with, at least).[0]	vosper	13.669166	-5.32206	comment	6.0	20.0	1607548308	9.906499
25450544	Reminds me about how people don't ev	Reminds me about how people don't even give CockroachDB a chance because of it's name. Every time it's mentioned on HN, people can't help but to bring up it's name.	Keverw	13.721119	-5.1875014	comment	6.0	44.0	1608163639	-4.6125927
38824157	Is there ever a reasonable case for 	"Is there ever a reasonable case for a ""natural ID"" like we were taught in database school? In my working experience, I always use either an autoincrementing integer or a random string / uuid as the primary key."	crabmusket	13.929362	-5.237482	comment	6.0	22.0	1704032012	-13.631971
39006347	Embarrasing question tbh but with al	Embarrasing question tbh but with all the cloud-native sqlite stuff like cloudflare d1 and fly LiteFS I'm seriously thinking of switching from postgres to sqlite.Does anyone have a compare/contrast sort of thing between the two?	jkljsfdasdf	13.565893	-5.487357	comment	6.0	36.0	1705354185	9.837498
31876604	SQLite Release 3.39.0	SQLite Release 3.39.0	sqlsite	13.635258	-5.597823	story	6.0	190.0	1656174784	9.896924
31909149	I really wish WordPress supported us	I really wish WordPress supported using SQLite as it's database instead of MySQL as this could make backups as simple as rsync'ing from prod server to backups.	mikece	13.576277	-5.503359	comment	6.0	24.0	1656430823	9.779047
31909442	For this particular application I di	For this particular application I discuss in the article it would make no difference, since there is only one not heavily used table that uses UUIDs. All the other tables use integer primary keys.Also this may be not a very popular opinion, but I prefer to design the database without using database-specific features. Things such as using SQLAlchemy and sticking to basic types. Sure it may affect performance some, but thanks to having done that I was able to port the app from SQLite to PostgreSQL in like an hour.	miguelgrinberg	13.972182	-5.222043	comment	6.0	25.0	1656432157	-13.658059
31911522	I think it's even more complicated.T	I think it's even more complicated.The reduction in latency brought on by in-process databases, combined with modern NVMe storage, means that SQLite is a substantially faster approach than any other solution which requires a trip through the network stack.I've got services in production for several financial institutions right now that are resolving most SQL queries within 100-1000 micro seconds by simply using SQLite on reasonable hardware.How many more users could you support if the amount of time you had to await IO for each was reduced by ~2 orders of magnitude?Obvious caveats here being the resilience angle. We addressed this with application-level protocols and additional instances.	bob1029	13.554611	-5.511234	comment	6.0	20.0	1656442217	9.7678795
32159000	MongoDB 6 Released	MongoDB 6 Released	Fudgel	13.722504	-5.2943115	story	6.0	54.0	1658270977	9.934823
32191266	Litetree – SQLite with Branches	Litetree – SQLite with Branches	tsujp	13.602138	-5.5721498	story	6.0	98.0	1658493411	-11.693162
32368856	'cookies.sqlite is most definitely n	"'cookies.sqlite is most definitely not a ""text file""'I have a mildly differing opinion. Are not all files, by default, text files? It is just the way the text inside them is structured that determines their actual format?edit: I might be opening a can of worms here, because I have a suspicion people will start pointing to extensions and whatnot."	A4ET8a8uTh0	13.5245695	-5.559435	comment	6.0	22.0	1659799127	9.760166
32479081	It certainly has some good use cases	It certainly has some good use cases and is not a toy, but there are some critical SQL features (like say: `last_at < NOW() - INTERVAL '10 minutes'`) that are not easily compatible with SQLite and are with postgres, that would require a lot of code rewrite in case you need to scale upwards. Testing against multiple databases is hard, so migrating to postgres wouldn't be trivial either. Hosting small postgres databases on things like GCP are ~$8 a month... why not just save yourself from future pain?	latchkey	13.542302	-5.4778204	comment	6.0	31.0	1660622699	9.857039
23509407	Agree, but it also side-steps some c	Agree, but it also side-steps some complex topics like sharding, replication, high-availability, etc. I’m not suggesting those topics should be addressed by SQLite; that simplicity is an asset.Has anyone used SQLite remotely over a network?	TedDoesntTalk	13.572693	-5.5329676	comment	7.0	27.0	1592056984	9.854732
23568323	A Twitch channel from which viewers 	A Twitch channel from which viewers can play with CockroachDB	jordanlewis	13.677681	-5.2019744	story	7.0	77.0	1592516276	3.7429028
23957887	If the databases in question (Elasti	If the databases in question (Elastic, MongoDB, others) make it too easy to set up unsecured access, possibly because they default to an unsecured state on installation, then some good may come of this: The reputation hit to the database vendors should encourage them to mend their ways.If that happens, then the attack can arguably be justified despite the damage — consider all the future database installations which wouldn't otherwise have been secured which are now spared from not only destruction but theft.	rectang	13.623395	-5.199602	comment	7.0	83.0	1595778158	9.901935
23959009	Curious, why do you use Mongo? Does 	Curious, why do you use Mongo? Does it give you something that a JSONB column in Postgres wouldn’t?	tyre	13.573031	-5.429519	comment	7.0	25.0	1595787795	9.825239
24162663	RethinkDB 2.4.1	RethinkDB 2.4.1	gabor-boros	13.672433	-5.290359	story	7.0	203.0	1597435814	-12.791759
24302395	ArangoDB 3.7 – a big step forward fo	ArangoDB 3.7 – a big step forward for multi-model	porker	13.560883	-5.3408976	story	7.0	111.0	1598601051	9.923499
20006242	I once made an app not using sequent	I once made an app not using sequential integers as object ids, as you suggest.It was an absolute nightmare. Maintenance was a nightmare, you're constantly having to generate or replicate these things that add an extra layer of complexity to everything, and almost always unnecessarily.It's also extremely bad for db performance, causes massive page fragmentation, indexes become useless almost straight after rebuilding them, etc.For almost everything, sequential int IDs are fine. It's the things you expose to the users that you need to be careful with, and then don't use the primary key to access them, add another unique key to them, but keep the id in there for the db to use and for your own use.My lesson was to go back to always using int ids, and on a few objects have a separate unique ke	mattmanser	13.937368	-5.2259665	comment	7.0	50.0	1558741880	-13.647511
20097863	(Cockroach Labs founder)The details 	"(Cockroach Labs founder)The details are in the ""additional usage grant"" clause: https://github.com/cockroachdb/cockroach/blob/8acfe8ffd0028c...We decided to draw the line at whether the end user has direct control over table schemas. If users can specify the schema to be used, it's a database service and needs a license. If you're fitting everything into a generic schema (even if the user can specify things that look like new columns in the UI), it's an application and doesn't need a special license."	bdarnell	13.5857	-5.2171006	comment	7.0	24.0	1559673066	9.909039
20776464	> SQLite is extremely reliable and d	> SQLite is extremely reliable and durable for large amounts of data (up to 140TB). It is considered one of the most well-engineered and well-tested software solutions today, with 711x more test code than implementation code.I keep seeing this statement. Why is it considered one of the most well-engineered software?	johnisgood	13.603442	-5.5583615	comment	7.0	35.0	1566560592	9.84267
25551564	previous discussionhttps://news.ycom	previous discussionhttps://news.ycombinator.com/item?id=18717168When is Mongo ever a good fit? so I've heard stuctured logs, but they can be shoved in a dedicated RDBMS themselves, or just a file system. Unstructured data? But PG now has supports for XML or even JSON. I've heard it's also easier to administrate and scale, which I'm sure it is but then why some businesses do go back to MySQL or PG if Mongo is easier?	throw_m239339	13.651441	-5.36173	comment	7.0	42.0	1609082142	9.888869
25872742	It looks like this layers Raft on to	"It looks like this layers Raft on top of SQLite. I don't like when systems replicate high-level changes like ""update users set salary = salary + 1000 where ...;"" Instead, I prefer they replicate low-level changes like ""replace key/block X, which should have contents C_x, with C_x'"".Why? Imagine you're doing a rolling update. Some of your replica are running the newer version of SQLite and some are running the older version. They may not execute the high-level query in exactly the same way. For example, in the absence of an ""order by"" clause, select results' order is unstated. So imagine someone makes a mutation that depends on this: ""insert ... select ... limit"". (Maybe a dumb example but it can happen anyway.) Now the databases start to diverge, not only in underlying bytes and implementa"	scottlamb	13.581897	-5.522496	comment	7.0	52.0	1611331110	9.819813
26190764	That start ids at a gigantic number 	That start ids at a gigantic number idea is great, even though I've never encountered a bug caused by not doing it.	bryanrasmussen	13.913114	-5.1902637	comment	7.0	32.0	1613722292	-13.617628
26217754	Cross-Database Queries in SQLite	Cross-Database Queries in SQLite	chmaynard	13.58583	-5.5612407	story	7.0	197.0	1613945328	9.862153
26421241	I'm a designer and front-end develop	I'm a designer and front-end developer. I'm building a fullstack project by myself in Node and I'm using MongoDB.Can someone tell me why is it so bad?I've searched for concrete answers but I got none for the moment yet from time to time people say these kind of things and I worry.	pedrogpimenta	13.686348	-5.317935	comment	7.0	23.0	1615447138	9.890839
36209896	I extensively used SQLite in a telem	I extensively used SQLite in a telemetry system for an electric race car. The car has an onboard computer, first a Raspberry Pi then a dual core Arm processor. Onboard code logs ~4000 messages a second into three SQLite databases. After a drive session a script merges the three databases into a single SQLite session log. The session log is decoded on a different computer to ~400 columns of time series data again stored in SQLite. This data is then finally converted into a proprietary format for visual analysis.Prior to SQLite I tried CSV files and raw binary formats. None of them could match the flexibility, ease of use, and throughput of SQLite. My setup has been in use for several weeks now and has processed numerous rows of data. As the SQLite project outlines on its website:> SQLite do	xyx0826	13.576813	-5.5625143	comment	7.0	51.0	1686040590	-12.195747
36430514	UUID is also used to avoid leaking i	UUID is also used to avoid leaking information about the underlying system. This includes temporal information that could be used to infer the size of the dataset for all users.If this isn’t a concern, then using a timestamp based approach as recommended in this article is a good approach. That is the default in MongoDB.If it is a concern, one approach is to use random UUIDs to give to end users but then internally to have something like auto increment ids.	gregwebs	13.978789	-5.209319	comment	7.0	45.0	1687433359	-13.6163645
36443596	Around the World with SQLite3 and Rs	Around the World with SQLite3 and Rsync	Liriel	13.553168	-5.46599	story	7.0	112.0	1687502443	9.760721
29071803	"""MangoDB is a proxy which uses Postg"	"""MangoDB is a proxy which uses PostgreSQL as a backend. The proxy translates MongoDB wire protocol commands into SQL queries, and use PostgreSQL as storage.""You don't have to support MongoDB, but you can support apps that were only written with Mongo as backend? That's awesome. I can't imagine it's production-ready yet but it's a great idea."	throwaway20371	13.637274	-5.3328495	comment	7.0	70.0	1635795146	9.877967
29164133	I want to stress the importance of n	"I want to stress the importance of not using  id int SERIAL

If you are on a somewhat recent version of postgres, please do yourself a favor and use:  id int GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY

An ""identity column"", the part here:https://hakibenita.com/postgresql-unknown-features#prevent-s...You might think this is trivial -- but SERIAL creates an ""owned"" (by a certain user) sequence behind the scenes, and so you run into massive headaches if you try to move things around.Identity columns don't, and avoid the issue altogether.https://www.2ndquadrant.com/en/blog/postgresql-10-identity-c..."	gavinray	13.920312	-5.237308	comment	7.0	84.0	1636476881	-13.652118
12578930	"  It's up there with bash

Clearly y"	"  It's up there with bash

Clearly you've just arrived from some wonderful alternate universe where bash means something different than it does on Earth. Welcome traveler!  bash is the world's default shell for a reason

Here on Earth that reason is network effects (""If I write it in bash, it will run anywhere!""). Bash is an bad language. If you've mastered bash you can have the honorable feeling of mastering a difficult, ugly, but practical skill (see also: knife-fighting, driving a motor vehicle, running for office). But there's no need to be mean to SQLite by comparing the two."	seagreen	13.607039	-5.5807767	comment	7.0	39.0	1474858844	9.852554
12663790	To understand what happened to Rethi	To understand what happened to RethinkDB, you want to contrast it with MongoDB.RethinkDB is amazing software and a real breakthrough. And the audience of deep thinking people who can really leverage the event model is ... limited. Today.MongoDB is no breakthrough, but there are legions of people who just want to plug something together with PHP or Node. Given what they're doing, it works fine.I sincerely hope Rethink can turn into a vibrant open source project and I'm willing to donate money to that. Given sufficient time, the world will learn to use it. And until then, it will grant superpowers to people willing to invest a little effort to understand and leverage it.	paulsutter	13.6675825	-5.298784	comment	7.0	56.0	1475873169	-12.806472
12672194	"""Where possible avoid simply using i"	"""Where possible avoid simply using id as the primary identifier for the table.""Has anyone had trouble by using surrogate primary keys?  I've found the opposite of what the author said could be more true: composite keys should be avoided instead."	Dowwie	13.893065	-5.2635617	comment	7.0	32.0	1476034038	-13.628927
12968948	The First Object Database for Node: 	The First Object Database for Node: Introducing Realm Node.js	astigsen	13.52472	-5.251618	story	7.0	74.0	1479315800	9.732594
13423584	Fascinating read, albeit a sad one: 	Fascinating read, albeit a sad one:  I love RethinkDB, and use it personally every day in our particular production deployment.[1] But -- and to Slava's point -- we didn't/don't/wouldn't pay for it, and in that regard, we were part of the problem.  That said, the constraint on that particular problem was that it had to be open source, and if it couldn't have been RethinkDB, it would have been some other open source database -- proprietary software is a non-option for that use case (or indeed, for any of our use cases).So I feel Slava's pain (and feel somewhat culpable as a user of RethinkDB), but I don't entirely agree with the analysis.  Yes, infrastructure is a brutal space because it has been so thoroughly disrupted by open source -- but the dominance of AWS shows that open source can a	bcantrill	13.66048	-5.260857	comment	7.0	24.0	1484707759	-12.8033
27719052	Host Here. Thanks for sharing.Richar	Host Here. Thanks for sharing.Richard is a great story teller and adventures that SQLite has taken him on pretty interesting.  I think he in on hn as well ( @SQLite).One interesting thing I found about how SQLite is developed is the amount of testing that is done. Between unit tests and parameterized tests and fuzzer tests they are doing billions of tests per release and spending days running them before each release. I know I don't like to wait for a long CI build before I deploy a service but something like SQLite needs whole different category of resilience.	adamgordonbell	13.643736	-5.612931	comment	7.0	47.0	1625281758	9.855081
27732105	SQLite is already open source in the	SQLite is already open source in the public domain.https://sqlite.org/src/doc/trunk/README.mdWouldn’t this be more worthwhile to write in [insert favorite modern language]?I get it is to learn. C is a much more difficult language in which to work.  A higher level language would allow one to better abstract the concepts and iterate faster	melling	13.606798	-5.6059175	comment	7.0	57.0	1625428019	-9.419146
12010961	RethinkDB 2.1.5 performance and scal	RethinkDB 2.1.5 performance and scalability	knes	13.612713	-5.2974987	story	7.0	155.0	1467314256	9.653872
18934040	Anyone using this in production? Any	Anyone using this in production? Any thoughts or tips on how to adapt traditional MongoDB workflows to this?	gigatexal	13.650885	-5.3323174	comment	7.0	27.0	1547755212	9.89122
19126495	Doesn't this affect all databases?  	"Doesn't this affect all databases?  Or is it a different issue?https://www.sqlite.org/atomiccommit.htmlSQLite does a ""flush"" or ""fsync"" operation at key points. SQLite assumes that the flush or fsync will not return until all pending write operations for the file that is being flushed have completed. We are told that the flush and fsync primitives are broken on some versions of Windows and Linux. This is unfortunate. It opens SQLite up to the possibility of database corruption following a power loss in the middle of a commit. However, there is nothing that SQLite can do to test for or remedy the situation. SQLite assumes that the operating system that it is running on works as advertised. If that is not quite the case, well then hopefully you will not lose power too often.Also this seems r"	chubot	13.587641	-5.5512714	comment	7.0	89.0	1549776500	9.7918825
19159116	This is a dead horse that's been bea	"This is a dead horse that's been beaten to death over and over again here on HN. MongoDB is garbage. MongoDB doesn't scale. MongoDB is $h!t says HN users.It just feels like an echo chamber. Are you running the latest version of MongoDB in a replica set with journaling enabled and write concern set to one? MongoDB has worked great for my uses, up to moderate write/read scale. Sure, if you are running ""big data"" or enterprise things, it might not be the best choice, but it's not the steaming pile of horse excrement that some HN users try to make it.Second, for those who still insist that MongoDB is crap, what is the best pure document store database then? I used to  champion RethinkDB, but they failed and development has basically stopped. You wouldn't build a business on RethinkDB now a day"	nodesocket	13.646944	-5.318562	comment	7.0	30.0	1550110533	9.881097
19499601	"These ""caveats"" are mostly false, or"	"These ""caveats"" are mostly false, or outdated.> Loss of transactionsMongoDB 4.0 supports ACID transactions: https://www.mongodb.com/transactions> Loss of relational integrity (foreign keys)> Having a database enforce these relationships can offload a lot of work from your application, and therefore from your engineers.I've never seen anyone use MongoDB without also using something like Mongoose where you get all this for free. Zero work for your engineers. https://mongoosejs.com/> Lack of ability to enforce data structureAgain, Mongoose. The work doesn't fall on your engineers, it falls on an awesome, heavily-used, heavily-tested library.> Custom query languageCan you give an example of something that you realistically would want to do in SQL that you can't with a JSON query?> Loss of tool"	a13n	13.63187	-5.371647	comment	7.0	26.0	1553683617	9.836305
15855978	“Follow-The-Workload” Beats the Late	“Follow-The-Workload” Beats the Latency-Survivability Tradeoff in CockroachDB	awoods187	13.579974	-5.215343	story	7.0	78.0	1512507991	9.875928
16358461	I find this page to be somewhat vagu	"I find this page to be somewhat vague.  For example, any data that revolves around dates or time may require some addition hoops to jump through since, as https://www.sqlite.org/datatype3.html points out, ""SQLite does not have a storage class set aside for storing dates and/or times.""As much as I love SQLite, I find this little issue always adding an extra bit of work to deal with.  Not a blocker, but useful to know.   I've found that in some (rare) cases, H2 became a better solution (horrendous start time, slow data load, but ability to use real date and time types reduced errors and improved analyses).Finally, knowing that SQLite is not right for a situation is great, but it wouldn't hurt for them to mention a potential alternative, if the devs or community know of one."	mwexler	13.615292	-5.58148	comment	7.0	31.0	1518442812	9.879295
16440755	CockroachDB Interactive, D3-Powered 	CockroachDB Interactive, D3-Powered Simulations	loiselleatwork	13.6566925	-5.210144	story	7.0	133.0	1519328668	9.9476795
16585768	C is great and SQLite seems doing am	"C is great and SQLite seems doing amazing leveraging its power. Yet I bloody wish there were alternative (yet 100% compatible on the file format and SQL dialect levels) SQLite implementations native to specific languages/platforms (e.g. .Net). In just so many cases the DB speed is the least priority while simplicity and portability are valued much higher (in these particular cases). Every time I build a humble desktop .Net app featuring an SQLite database it turns into in a ridiculous ""try this, google a lot, try that, repeat, .... oh wow, it works!... oh, it doesn't"" nightmare and even if it actually starts working nobody really knows how to deploy such an app on another computer (especially if it runs a different kind of OS) correctly.SQLite is arguably the best of what has happened to t"	qwerty456127	13.64818	-5.5883985	comment	7.0	41.0	1521043677	9.845811
16586157	I agree. SQLite gets away with using	I agree. SQLite gets away with using C because it literally uses military-grade levels of verification. As John Regehr pointed out, SQLite is quite possibly the only piece of software that goes to that level of validation and testing without being required to by law.It's not just a matter of skill, either. The cost in terms of money and time needed to develop software in that way is completely impractical in almost any commercial scenario. Aside from some very specific situations, it's not an economically viable way to produce software.	pcwalton	13.646064	-5.6228185	comment	7.0	31.0	1521046352	9.859389
16755246	I find it very interesting that alth	I find it very interesting that although CockroachDB itself is stable and production ready, all of the client drivers are still 'beta'.https://www.cockroachlabs.com/docs/stable/install-client-dri...That being said, I am really excited to try this out. 2.0 adding JSON support is what converted me to try this out for a project.	udia	13.691457	-5.1850996	comment	7.0	21.0	1522853514	10.026906
17497787	My example is a bit dated, but may b	My example is a bit dated, but may be illustrative:  I chose PostgreSQL over MongoDB for a MEAN webapp (making it PEAN?) project started in 2013 and regretted it.  I was constantly struggling with the poor support for SQL in Node at the time and spent way too much time fixing bugs or adding workarounds for deficiencies in the SQL abstraction libraries and ORMs, or writing bespoke SQL and object mapping.  After switching to MongoDB, I spent significantly less time on storage issues and development speed increased noticeably.Later we did run into several issues caused by MongoDB which could have been avoided by using SQL (mostly related to consistency, constraint enforcement, and problems with MongoDB's aggregation capabilities).  MongoDB got us to market faster, but had higher costs in the 	kevinoid	13.670378	-5.3220944	comment	7.0	56.0	1531228825	9.888125
17516583	Richard Hipp (creator of SQLite) had	Richard Hipp (creator of SQLite) had this to say about Rust and SQLite in the comments:> Rewriting SQLite in Rust, or some other trendy “safe” language, would not help. In fact it might hurt.Prof. Regehr did not find problems with SQLite. He found constructs in the SQLite source code which under a strict reading of the C standards have “undefined behaviour”, which means that the compiler can generate whatever machine code it wants without it being called a compiler bug. That’s an important finding. But as it happens, no modern compilers that we know of actually interpret any of the SQLite source code in an unexpected or harmful way. We know this, because we have tested the SQLite machine code – every single instruction – using many different compilers, on many different CPU architectures a	collinf	13.634157	-5.6597414	comment	7.0	31.0	1531415281	9.864021
17855539	I've seen this pattern a couple of t	I've seen this pattern a couple of times (e.g. for broadcasting changes using Postgres's LISTEN/NOTIFY.)Each time, I wonder why people are recreating the database's journal, within the database, where this meta-journal will itself be getting journaled.Why not just consume the actual DB journal?I'm not sure how that'd work for SQLite—it'd probably require a hack of some sort, since SQLite's journal is an ephemeral part of the DB file. But for more full-fledged RDBMSes, this would just be a matter of hijacking a streaming-replication-based backup system to act as a store of record for events. E.g., in the case of Postgres, you'd just have an ETL pipeline pointed at your WAL-E bucket, parsing through your WAL files either to load into a separate OLAP store, or for stateless map-reduction when	derefr	13.560504	-5.490322	comment	7.0	29.0	1535414526	-10.263237
21462674	Most of the suggestions here is sugg	Most of the suggestions here is suggesting ways of restarting services when they go down, which is a good start, but that doesn't actually solve the issue I hit last night...My system integrates with an external system and what happened is this external system started sending me unexpected data, which my system wasn't able to handle, because I didn't expect it so never thought to test for it -- the issue was that I was trying to insert IDs into a uuid database field, but this new data had non-uuid IDs. Because the original IDs were always generated by me, I was able to guarantee that the data was correct, but this new data was not generated by me. Of course, sufficient defensive programming would have avoided this as this database error shouldn't have prevented other stuff from working, bu	dkersten	13.70343	-5.196005	comment	7.0	26.0	1573049147	-9.077352
39261459	You probably should not use UUIDs to	You probably should not use UUIDs to start with in your database at least not as an ID. UUIDv7 aims solve some of the issues of UUIDv4 that are even less suitable in for databases. 99% of times using BigInt for an ID is better.	sonium	13.972967	-5.220753	comment	7.0	70.0	1707142819	-13.668137
18297514	SQLite Code of Ethics	SQLite Code of Ethics	thrower123	13.65404	-5.5949206	story	7.0	34.0	1540425418	-8.840696
18804341	“The default name prefix is changed 	“The default name prefix is changed to be ‘sqlite’ spelled backwards” (2006)	sidcool	13.622924	-5.586005	story	7.0	157.0	1546406287	9.8895235
29806345	I really liked this article but I fe	I really liked this article but I feel it misses one somewhat important point about using incremental numbers: They are trivially guessable and one needs to be very cautious when exposing them to the outside world.If you encounter some URL like https://fancy.page/users/15 chances are that the 15 is a numeric ID and 1 to 14 also exist. And the lower numbers tend to be admin accounts as they are usually created first. This might be used by an attacker to extract data or maybe gain access to something internal. One could argue that using UUIDs only hides a security hole in this case but thats better than nothing I guess.	elevader	13.94119	-5.2021804	comment	7.0	46.0	1641369542	-13.643692
29850167	Bad for performance as primary keys.	Bad for performance as primary keys.But, still provide strong value as a unique identifier which is what makes them popular.I’ve used integers as primary keys, with UUIDs as alternate keys for external-to-the-data-store queries.	drenei	13.921495	-5.2375364	comment	7.0	43.0	1641635923	-13.647889
30631477	SQLite Online	SQLite Online	belter	13.63485	-5.5927873	story	7.0	118.0	1646941410	9.857064
33275945	Why are people still using Mongo whe	Why are people still using Mongo when you can just set up a jsonb column in Postgres now?Is this just legacy applications that are stuck with Mongo? Certainly nobody is starting new projects on Mongo?Serious question.	cpursley	13.607765	-5.391788	comment	7.0	28.0	1666278710	9.832614
33330179	"Great work!!!""SQLite is extensively "	"Great work!!!""SQLite is extensively tested with 100% branch test coverage. We discovered this vulnerability despite the tests, which raises the question: how did the tests miss it?""Tests only validate known behavior. They didn't have a test that exercised a large string. I don't know how their test suite works but I'm curious if quickcheck might have possibly found this or if the 32-bit viewpoint of the programmer at the time would have also limited possible generated values?"	gregors	13.672862	-5.61639	comment	7.0	82.0	1666704446	9.858542
33339634	Making a change to SQLite source cod	Making a change to SQLite source code	jerryjerryjerry	13.607762	-5.5973835	story	7.0	117.0	1666756585	9.871138
33696837	SQLite 3.40.0 with WASM Support	SQLite 3.40.0 with WASM Support	conductor	13.625433	-5.590118	story	7.0	76.0	1669059251	9.8638735
33699631	My only wish is that UUIDs were sort	My only wish is that UUIDs were sortable and still contained their timestamp. When bug hunting, sometimes things become a little more obvious when there is an exact start and end to ids with issues.	hn_user2	13.984329	-5.2122884	comment	7.0	29.0	1669073085	-13.664183
33946715	“Heavier” and “lightweight” are such	“Heavier” and “lightweight” are such abstract terms in software.If “heavier” just means more LoC — sure, there’s more complexity in more LoC but also more problems solved. There’s a reason people tend to use the latest Linux/macos/Windows as opposed to the very lightweight Apple II OS from 1978.Defaulting to, say, Postgres doesn’t seem so bad to me. It solves more problems than SQLite and “lightweight” is not really a concrete benefit for SQLite. It’s at least one level removed from speaking to a real problem.	eduction	13.57318	-5.522547	comment	7.0	25.0	1670787765	9.841202
33946597	Lots of people saying that SQLite is	Lots of people saying that SQLite is super high quality and finding a bug is so rare. It’s not. I found one on a simple query utilising WHERE EXISTS [1]. Reporting it to a weird forum was also a horrible experience.It’s high quality software, don’t get me wrong, but the infamous 100% test coverage doesn’t make it somehow immune to issues, or imply that the issues you do find are of a certain level of complexity. Nothing is back and white like that.1. https://sqlite.org/forum/forumpost/452888d3b1?t=c&unf	orf	13.650123	-5.605273	comment	7.0	48.0	1670787052	9.888646
26551825	Care to elaborate? I felt strongly t	Care to elaborate? I felt strongly the opposite. It makes me more eager to move away from SQLite. I'm very far from religious, and this seems to be very strongly suggesting atheism is synonymous with immorality.	pcthrowaway	13.634835	-5.5752544	comment	7.0	29.0	1616481987	-8.772557
26581197	SQLite is very limited because of it	SQLite is very limited because of its threading model, imo it's not usable outside of the single app model where you have a single user.https://sqlite.org/threadsafe.htmlhttps://sqlite.org/lockingv3.html	Thaxll	13.601746	-5.5458097	comment	7.0	48.0	1616684949	9.796541
26582756	So if you're saying everything does 	"So if you're saying everything does support a web database... then what's the reason people aren't using it for websites?Why do you say it works for ""small"" websites but presumably not large ones? If it's not transactions, concurrent reading, backups, or administrative tasks... then what's the issue you run into?Genuinely curious... I'm wondering if everything I've heard about ""don't use SQLite for websites"" is wrong, or when it's right?"	crazygringo	13.588818	-5.5307136	comment	7.0	40.0	1616692167	-10.523162
26857490	I just use a UUID for every variable	I just use a UUID for every variable name to make sure the codebase never has any ambiguity.No one is going to confuse e7693160-b5cf-4761-9202-de019cfd0fc9 with c3d8b9ac-d0da-4bbc-912b-025ce4e47f62	ineedasername	13.988771	-5.211	comment	7.0	26.0	1618788042	-13.666495
26918288	> Existing formats like MBTiles are 	> Existing formats like MBTiles are based on SQLite. This limits the ability to self-host maps to those confident running a server in production.Is that comical, or is there a deeper meaning I don't understand?	Tomte	13.556436	-5.5675755	comment	7.0	31.0	1619206251	9.829825
27237919	SQLite in production with WAL	SQLite in production with WAL	manjana	13.573748	-5.4844384	story	7.0	83.0	1621621482	9.808052
27248960	Show HN: ClangQL – Query C++ codebas	Show HN: ClangQL – Query C++ codebases using SQLite	frabert	13.602144	-5.576746	story	7.0	73.0	1621707322	9.853407
27324704	Show HN: Monty, Mongo tinified. Mong	Show HN: Monty, Mongo tinified. MongoDB implemented in Python	davidlatwe	13.65878	-5.3859286	story	7.0	65.0	1622289811	9.823604
27346837	I don't think I've ever seen this me	"I don't think I've ever seen this mentioned anywhere, but if
you need a unique ID for an entity with not a lot of records
planned (≤10,000,000), why not use a random int64 with
a simple for loop on the application side to catch
the occasional collisions?  Are there any downsides besides
making the application side a tiny bit more complex?"	ainar-g	13.932824	-5.213527	comment	7.0	39.0	1622485513	-13.648993
27348761	> Now, sometimes a table has a natur	> Now, sometimes a table has a natural primary key, for example the social security number of a country’s citizens.You know, you think that, but it's never that simple. The field was added incorrectly and nobody noticed until the value is in countless tables that you now need to simultaneously update or the value is something that's supposed to be semi-secret, so now a low level support staff can't reference the row when dealing with a request. Or the table's requirements change and now you need to track two different kinds of data or data that is missing the field.Me, I always just have the table make its own ID. It is just simpler, even when you think it is overkill.	3pt14159	13.850206	-5.2976203	comment	7.0	34.0	1622500117	-13.627558
27347045	Mentioned this in a sibling comment:	"Mentioned this in a sibling comment:There's another benefit to UUID - You can generate them anywhere including application side.
Doing this on application side would have tremendous batching benefits or inserting objects with relationships at the same time (Vs waiting first insert to return an ID to be used in the FK)."	tehlike	13.966894	-5.21244	comment	7.0	36.0	1622487083	-13.650917
37733890	> first component (prefix) of the id	> first component (prefix) of the identifier is a sortable timestamp> values generated are practically sequentialThese statements aren’t strict enough to be relied on. Maybe you have engineered the hell out of your distributed clock scheme, and your IDs actually are completely monotonic, which is great. But you probably haven’t done that, which means conflicts will surely happen and you must handle them gracefully.	erik_seaberg	13.95289	-5.215569	comment	7.0	32.0	1696219744	-13.642277
38120240	DoorDash manages high-availability C	DoorDash manages high-availability CockroachDB clusters at scale	orangechairs	13.617554	-5.215852	story	7.0	52.0	1698959612	9.8739395
38171986	"What do they mean by ""Since SQLite d"	"What do they mean by ""Since SQLite does not support concurrent transactions"" - it supports them, as long as you don't access the .db file through a file share (UNC, or NFS, etc) - https://www.sqlite.org/wal.htmlI've been using this to update/read db from multiple threads/processes on the same machine. You can also do snapshotting with the sqlite backup API, if you want consistent view, and to not hold on transaction (or copy in-memory).But maybe I'm missing something here... Also haven't touched sqlite in years, so not sure..."	malkia	13.582508	-5.5392823	comment	7.0	24.0	1699320877	9.802879
38285435	EDIT: It looks like something that m	"EDIT: It looks like something that mostly addresses my problem, “strict tables”, was added in 2021. Thank you everyone.It seems this rewrite would not have addressed my biggest gripe with SQLite: Surprisingly, it is not actually type safe.    SQLite uses a more general dynamic type system. In SQLite, the datatype of a value is associated with the value itself, not with its container.
https://www.sqlite.org/datatype3.htmlThat’s right, the type you give to a column when creating a table is merely a suggestion. This means at some point, TEXT may make it into a column where a NUMERIC is expected.This actually caused a large scale problem in production once.I still love SQLite, it’s the very best at what it does, but I’m a bit more careful now. The same documentation says SQLite uses dynamic ty"	anyfoo	13.599753	-5.605652	comment	7.0	22.0	1700103721	9.860392
15608586	> sqlite files couldn't be more open	> sqlite files couldn't be more openYes, actually they could. They could be readable without any software at all. Like XML.All of the improvements suggested in the article could be implemented by extending the XML format to allow including by other XML files by reference.	mseebach	13.581008	-5.577261	comment	7.0	56.0	1509609123	9.818847
35318905	I wrote a similar tool in Python a f	I wrote a similar tool in Python a few weeks ago, which uses AppleScript to liberate the data and saves it to a SQLite database: https://datasette.io/tools/apple-notes-to-sqliteI didn't actually know AppleScript before writing this tool... but it turned out ChatGPT knew it well enough to unblock me and provide me with exactly the code I needed to build the rest of the project! https://til.simonwillison.net/gpt3/chatgpt-applescriptApple Notes Liberator creates a copy of the SQLite database and then runs queries against that directly to extract the data.I chose not to do that (despite being all-in on SQLite for everything) because I worry about future changes to the software baking my script - I figured the AppleScript interface was less likely to have breaking changes in the future.	simonw	13.566388	-5.5721483	comment	7.0	27.0	1679860838	9.884756
28017279	I can’t fully put my finger on why e	I can’t fully put my finger on why exactly, but I feel that this is a transformative idea. What’s to stop me from emulating a private SQLite DB for every user of a web app, and use that instead of GraphQL?	manmal	13.55756	-5.5472794	comment	7.0	24.0	1627732257	9.85835
28076572	I'm always amazed at the amazing rev	I'm always amazed at the amazing reviews SQLite gets, particularly in a thread about PostgreSQL. I get the angle of SQLite competing with fopen(). If what you need is a file format you can do a lot worse than SQLite. But I've worked on multiple desktop apps where the only reason SQLite gets used for the internal database is that PostgreSQL doesn't have a mode where you can ship it as part of the app easily and asking the user to setup a database is a non-starter. If not for that the performance benefits of the swap would be very significant. I suspect if PostgreSQL shipped such a mode a very large percentage of SQLite uses would switch over.	pedrocr	13.577031	-5.5318813	comment	7.0	34.0	1628183490	9.846336
28092737	>> but the downside is that there's 	>> but the downside is that there's no standard way to parse the time from one of theseIMHO that should not be a concern. The goal of UUID is to create a Unique Identifier, not to record the time something was created. Maybe we should all have quantum random number generators, but with that I don't think 128 bits is enough for a UUID. Might be enough for specific applications though.First rule of database design: Your unique IDs should not have a real-world meaning.	phkahler	13.977923	-5.213349	comment	7.0	40.0	1628283929	-13.66983
28331769	As a developer, I have to say that s	"As a developer, I have to say that sqlite gives me the best experience.Everything else pales in comparison.Create a database?    sqlite3 mydata.db

Where is the database?    In the current directory

How is it structured on disk?    It's a single file

How do I backup the DB?    cp mydata.db /my/backups/mydata.db

Do I have to install a server?    No

Do I have to configure anything?    No

During setup and deployment I usually I dabble a while with the whole GRANT *.* ON localhost IDENTIFIED BY PASSWORD or something. How do I do that with sqlite?    It just works

Do I have to close / protect any specific ports?    No, it's just a file

Which field types should I use for ... ?    None. It just works."	TekMol	13.573461	-5.523216	comment	7.0	42.0	1630091177	9.800501
28425809	CockroachDB is getting a lot of inte	CockroachDB is getting a lot of interest these days.It has broad PGSQL language (and also wire I think) compatibility yet has a clustered peer architecture well suited to running in a dynamic environment like cloud or k8s. Nodes can join dynamically and it can survive them leaving dynamically as long as there's a quorum. Data is distributed across the nodes without administrator needing to make any shard rebalance type interventions.PGSQL is designed for deployment as a single server with replica servers for HA. It's not really designed for horizontal scalability like Cockroach. You can do it - the foreign data wrappers feature and table partitioning can give you poor man's scale out. Or you can use Citus which won itself a FOSS license earlier this year. And there are other Foss and propr	grobbie	13.551902	-5.2462378	comment	7.0	70.0	1630861602	9.808522
22369011	For all the great things about SQLit	"For all the great things about SQLite there are some concerning things around the project.First off, even though the source code is public domain, you can't contribute since it is closed source: https://sqlite.org/copyright.htmlThere are 3 developers who maintain the project https://www.sqlite.org/crew.html and operate under a ""code of ethics"" that used to be called their ""code of conduct"" https://sqlite.org/codeofconduct.htmlWhile it succeeded in getting widely adopted I have trouble believing that this is sustainable."	hharnisch	13.639895	-5.586303	comment	7.0	27.0	1582140063	9.856924
22834879	While I think it's easy to poke fun 	While I think it's easy to poke fun at this article - relational database better at handling relational data, more at 10 - it does make me want to understand why one would choose mongo over postgres?	stepbeek	13.657546	-5.3918996	comment	7.0	48.0	1586537782	9.889038
22868286	Apache Druid vs. Time-Series Databas	Apache Druid vs. Time-Series Databases	wochiquan	13.561997	-5.2680264	story	7.0	150.0	1586883213	9.817928
23058070	Show HN: AvionDB: A Decentralised Da	Show HN: AvionDB: A Decentralised Database with MongoDB-like Developer Interface	Alex-Potsides	13.574157	-5.335293	story	7.0	104.0	1588500691	9.843601
23261198	Apache Druid 0.18	Apache Druid 0.18	wochiquan	13.996203	-5.212204	story	7.0	40.0	1590080883	-13.668941
23282466	As a non-dev intruder I have to say 	As a non-dev intruder I have to say that I love SQLite. I do a lot of data-analysis and it makes everything easy, from fast SQL Wizardry to sharing the DB just coping a file! Just how amazing is that?!It must sound naive to some of you, but the first time stumbled upn sqlite I was so excited!	iagovar	13.567859	-5.544072	comment	7.0	70.0	1590237820	9.828865
23284267	There's no reasonable way to share a	There's no reasonable way to share a SQLite database between processes on separate machines or VMs.. What website doesn't use at least 2 instances for HA?How do you make sure you don't lose data in a SQLite DB?	qes	13.591991	-5.537294	comment	7.0	21.0	1590251416	9.878314
23285835	MongoDB started life as a database d	MongoDB started life as a database designed for speed and ease of use over durability.  That's not a good look for a database.People have told me that they have since changed, but the evidence is overwhelmingly and repeatedly against them.They seem to have been successful on marketing alone.  Or people care more about speed and ease of use than durability, and my assumptions about what people want in a database are just wrong.	jedberg	13.661237	-5.3218684	comment	7.0	31.0	1590263796	9.895686
23291779	Scaling SQLite to 4M QPS on a Single	Scaling SQLite to 4M QPS on a Single Server (EC2 vs. Bare Metal)	based2	13.602908	-5.456742	story	7.0	133.0	1590330739	9.7883415
23291649	May I suggest alternative perspectiv	May I suggest alternative perspective on the matter?Compared to a product like Oracle, transactions on MongoDB are very new, very niche functionality. Even MongoDB consultants do openly suggest not to use it.MongoDB is really meant to store and retrieve documents. That's where the majority read/write concern guarantees come from.As long as you are storing and retrieving documents you are pretty safe functionality.Your article presents the situation as if MongoDB did not work correctly at all. That is simply not true, the most you can say is that a single (niche) feature doesn't work.Have you ever tried distributed transactions with relational databases? Everybody knows these exist but nobody with sound mind would ever architect their application to rely on it.Any person with a bit of exper	lmilcin	13.643925	-5.3280435	comment	7.0	25.0	1590329644	9.87317
29363297	The biggest news, of course, is the 	The biggest news, of course, is the addition of the long-awaited STRICT mode which fixes SQLite's biggest shortcoming (at least from a particular perspective) by turning into a proper, strongly-typed datastore.https://www.sqlite.org/stricttables.html	ComputerGuru	13.617703	-5.582899	comment	7.0	73.0	1638046320	9.849958
29403661	SQLite in a PWA (Anita) with FileSys	SQLite in a PWA (Anita) with FileSystemAccessAPI	ildon	13.602447	-5.5709586	story	7.0	81.0	1638367315	9.826335
34281969	ULID – Sortable Unique Identifier	ULID – Sortable Unique Identifier	orobinson	13.942346	-5.22832	story	7.0	33.0	1673042943	-13.661037
34434871	the fact that SQLite is a library (e	the fact that SQLite is a library (embedded DB) means only one node can access the DB at a time. This would not be appropriate for many apps that require HA.	fierro	13.58586	-5.5294843	comment	7.0	95.0	1674086172	9.817067
34451891	Honestly that's a poor blog post.Ran	"Honestly that's a poor blog post.Randomly concludes ""the best time-based ID seems to be xid"" without saying why or comparing to others e.g. ksuid, UUIDv7 etc (""xid"" is only mentioned twice in the entire blog, first in the above statement and second a link to the reference implementation).  Equally unfortunate that they picked ""xid"" as their supposed ""best"" because Postgres has an internal identifier that is also called ""xid"" and is very much NOT to be used as a primary key !Downplays the many issues with ""serial"", including somehow thinking the word might ""might"" has a place next to the words ""not want to expose them to the world though"" .... you DON'T, full stop. Exposing predictable identifiers to the world is never a good thing.I'm not really sure what that blog post is supposed to be a"	traceroute66	13.95228	-5.1920877	comment	7.0	65.0	1674216158	-13.633595
34775290	780KB for sqlite.wasm is not exactly	780KB for sqlite.wasm is not exactly small.  Might be acceptable for a heavy weight app, but not a general website.	halapeenio	13.581878	-5.5307508	comment	7.0	23.0	1676304390	9.829584
34813226	Why learn SQLite when you could just	Why learn SQLite when you could just learn Postgres and have a database that is virtually guaranteed to be enough in almost all cases?	xwdv	13.58476	-5.5342236	comment	7.0	29.0	1676507702	9.83645
13645303	I wonder how this will affect adopti	I wonder how this will affect adoption of CockroachDB [1], which was inspired by Spanner and supposedly an open source equivalent. I'd imagine that Spanner is a rather compelling choice, since they don't have to host it themselves. As far as I know, CockroachDB currently does not support providing CockroachDB as a service (but it is on their roadmap) [2].[1] https://www.cockroachlabs.com/docs/frequently-asked-question...[2] https://www.cockroachlabs.com/docs/frequently-asked-question...	karlding	13.6451435	-5.188202	comment	7.0	42.0	1487093614	9.9405155
13658203	Ask HN: Where do you host your db's 	Ask HN: Where do you host your db's for your side projects?	aerovistae	13.642583	-5.2490973	story	7.0	3.0	1487228606	9.855042
14523883	"sounds like the author thinks ""uuids"	"sounds like the author thinks ""uuids are a pain"" and wants the benefits of them but with a smaller representation. but doesn't provide any reasonings why uuids are a pain other than not being able to remember them or say them out loud. these are not things anyone does with primary keys!you'll never say this out loud : 7383929. you may be able to remember it, maybe. in a uuid you'll match the last few and first few letters just as fast in your headuuids are fine. sorting is an issue but at scale (the entire point of this article) how often do you need to sort your entire space of objects by primary key? you'll have another column to sort onhiding primary keys and having 2 keys seems like a great way to make all queries and debugging 2x as complicated"	foolfoolz	13.977052	-5.222982	comment	7.0	27.0	1497037347	-13.666238
14626488	"Regarding ""SQL is better suited to t"	"Regarding ""SQL is better suited to this use case because it has transactions"" comments:Before we had 3-tier architectures, people would have designed a shopping cart use-case as a single SQL transaction that would last maybe 10 minutes. The DB would make sure everything stays consistent until the final commit. The GUI would keep an open connection to the DB the whole time.In the web age, you want stateless services and HA. It means a transaction can't last more than a single web page. It becomes more challenging to design a shopping cart, because the DB can't handle a long-running transaction anymore.Writing a correct system that reserves the items you put in a shopping cart and doesn't leak items and doesn't sell the same item twice is not easy. A transaction Rollback will not do the clea"	weddpros	13.590296	-5.351171	comment	7.0	32.0	1498325503	9.896367
31089723	SCRU128: Sortable, Clock and Random 	SCRU128: Sortable, Clock and Random number-based Unique identifier	andrenth	13.955129	-5.2218056	story	7.0	49.0	1650404882	-13.676009
31154575	What is the point of using SQLite un	What is the point of using SQLite under a web service?I thought people complained how MySQL sucks and PostgreSQL rocks for being right and SQLite was nowhere near being right or performant. (Things seem to be getting better with strict column types these days.)I've recently migrated a smallish service from MySQL to PostgreSQL and figured it's quite a work if you're not careful writing by the SQL standard which means if the service had gotten bigger, your chance of moving away from SQLite kind of walks away.So, why not use a safer choice to begin with? Nothing is complicated running MySQL/PostgreSQL unless you've sold yourself to AWS to care for the cost and don't know how to run a DB instance yourself.	mekster	13.56001	-5.508835	comment	7.0	54.0	1650894282	9.810002
31324556	Uhm... experience from a large proje	Uhm... experience from a large project that used SQLite was that we where hit with SQLite only allowing one write transaction at a time. That is madness for any web app really.Why do everyone seem so hyped on this when it can't really work properly IRL? If you have large amounts of data that need to be stored the app would die instantly, or leave all your users waiting for their changes to be saved.What am I missing?	dsincl12	13.569261	-5.5158553	comment	7.0	50.0	1652168611	9.780124
31339550	wow SQLite getting a lot of love the	wow SQLite getting a lot of love these dayshttps://tailscale.com/blog/database-for-2022https://fly.io/blog/all-in-on-sqlite-litestreamhttps://blog.cloudflare.com/introducing-d1	kurinikku	13.551646	-5.5527744	comment	7.0	45.0	1652275161	9.846398
31716406	Fortunately this is a bit less relev	"Fortunately this is a bit less relevant today as Windows loses market share in database and server applications, but:UUIDs have historically massively screwed up endian handling. While this new draft discusses sorting UUIDs as strings of octets (bytes) and the text of RFC4122 is fairly explicit about most significant bytes coming first, the C UUID structure in RFC 4122 appendix A is entirely misguided:    typedef struct {
        unsigned32  time_low;
        unsigned16  time_mid;
        unsigned16  time_hi_and_version;
        unsigned8   clock_seq_hi_and_reserved;
        unsigned8   clock_seq_low;
        byte        node[6];
    } uuid_t;

Those aren’t bytes — they’re integers of various sizes. (Hint: do not use integer types in C code for portable data structures. ntohl, etc are a me"	amluto	13.981188	-5.211074	comment	7.0	44.0	1655055206	-13.684035
36583317	One thing missing from this:There ar	One thing missing from this:There are massive performance gains to be had by using transactions.  In other RDBMSs transactions are about atomicity/consistency.  But in SQLite, transactions are about batching inserts for awesome speed gains.  Use them!	mrkeen	13.568758	-5.5248427	comment	7.0	25.0	1688455141	9.754817
36612772	I don't know much about SQLite inter	I don't know much about SQLite internals, but on the face of it it sounds hacky as hell (pardon if I'm wrong).Wouldn't it be better to make a proper client-server API similar to traditional SQL databases, but on top of SQLite?	eterevsky	13.575997	-5.541058	comment	7.0	29.0	1688631072	9.804376
36811040	This is why you should use ids that 	This is why you should use ids that combine both a time component and a sequence.Eg UUIDv7 has a milliseconds time component and then a field that increments for each event in the same millisecond, and then enough random bits to make collisions between ids generated on different machines astronomically unlikely.Of course there are only so many bits so you might generate too many events in the same time slice so the sequence overflows, and you might actually get collisions between machines, and you are limiting your event generation speed by forcing your cpu to sync on the increment etc.But in practice UUIDv7 works great at scale.	wood_spirit	13.96215	-5.215756	comment	7.0	134.0	1689924826	-13.671443
36811167	If you want unique identifiers, use 	If you want unique identifiers, use version 4 (random) UUIDs. Problem solved.The probability of a collision is roughly the same as the probability of a fully grown dinosaur spontaneously manifesting in your bedroom due to quantum fluctuations.	p-e-w	13.981788	-5.207955	comment	7.0	51.0	1689925860	-13.666188
36811464	Why do you need the time component a	Why do you need the time component anyway?  It's just eating up bits in your UUID without contributing much entropy.	eru	13.983227	-5.2115273	comment	7.0	102.0	1689928569	-13.67011
36914612	SQLite-Utils	SQLite-Utils	dedalus	13.5962515	-5.583731	story	7.0	142.0	1690585757	9.850433
37503322	I've been doing this for a long time	"I've been doing this for a long time and all I can say this after reading this multiple times ... ""I don't get it"".I mean, I get it, from a technical standpoint.  Ok, so you're going to send read-only Sqlite databases to everybody.Is it missing what the API (that you still need) is updating when you insert or update something and all client DBs are now stale?  Is there a central database?  How often are you pushing out read-only database replicas across the wire to all clients?  Is that really less ""chatty""? If so, how much bandwidth is that saving to push an entire database multiplied by the number of clients?None of this seems logical.  Maybe I'm missing the real-world use-case.  Are we discussing tiny Sqlite databases that are essentially static?   Because in the last 30 years I've not "	EMM_386	13.598494	-5.5382442	comment	7.0	63.0	1694650498	9.758112
37554027	Coupling a file format to SQLite sme	Coupling a file format to SQLite smells wrong.SQLite is good, but it is also fairly unique in this space. Why? Because it’s hard to replicate everything it does, because it does a lot.But… for this case, do we need it do a lot? No, not really. We don’t need the full SQL standard, a query optimiser, etc etc for basic (+ safe) transaction semantics and the ability to store data in a basic table structure.Perhaps there is a better file format we can use, but it would be better if it was decoupled from SQLite.	orf	13.529641	-5.5601993	comment	7.0	58.0	1695029327	9.797974
25008308	SQL.js: SQLite Compiled to JavaScrip	SQL.js: SQLite Compiled to JavaScript	chmaynard	13.58955	-5.576729	story	7.0	183.0	1604676800	9.85055
25010718	SQLite has a system that abstracts v	SQLite has a system that abstracts various low-level storage operations called VFS - this is the layer that allows SQLite to be portable across different operating systems and environments: https://www.sqlite.org/vfs.htmlRecently I’ve wondered how possible it would be to implement a SQLite VFS on top of IndexedDB - and, would such a VFS be competitive in speed to using IndexedDB directly? Or, would it be equivalent to use Emscripten’s existing POSIX-ish filesystem backed by IndexedDB?An IndexedDB VFS would allow sql.js to durably persist data in the browser.	jitl	13.521988	-5.4777246	comment	7.0	42.0	1604693682	9.789298
25168554	Does someone know if there is someth	Does someone know if there is something like an SQLite server, so that it could be used like a 'normal' database server?Why? Well, for benchmarking for example, or if the application you are using has a bad multi-user implementation and you don't want to migrate to another database...	arendtio	13.573909	-5.515485	comment	7.0	25.0	1605948693	9.809988
38627870	In my personal opinion and usage, th	In my personal opinion and usage, the performance doesn't matter. Only one driver is written in pure go, and can be easily statically compiled and/or cross-compiled.> modernc, modernc.org/sqlite, a pure Go solution. This is a newer library, based on the SQLite C code re-written in Go.Unless I'm mistaken, this is not a re-write in Go. This is a transpilation of the the SQLite C library into go, using https://gitlab.com/cznic/ccgo	acatton	13.628009	-5.6345906	comment	7.0	37.0	1702477898	-5.7517357
38999359	> In wal2 mode, the system uses two 	"> In wal2 mode, the system uses two wal files instead of one. The files are named ""<database>-wal"" and ""<database>-wal2"", where ""<database>"" is of course the name of the database file. When data is written to the database, the writer begins by appending the new data to the first wal file. Once the first wal file has grown large enough, writers switch to appending data to the second wal file. At this point the first wal file can be checkpointed (after which it can be overwritten). Then, once the second wal file has grown large enough and the first wal file has been checkpointed, writers switch back to the first wal file. And so on.Looks so logical that I don't understand why WAL mode was not implemented like this from the get go. Probably an optimization wrongly dismissed as premature?Anywa"	miroljub	13.5398855	-5.403746	comment	7.0	54.0	1705315468	9.794306
39057395	SQLite or PostgreSQL? It's Complicat	SQLite or PostgreSQL? It's Complicated	nnx	13.5545435	-5.499796	story	7.0	33.0	1705682255	9.831148
32808177	I can see that the difficulty will b	"I can see that the difficulty will be the plethora of plugins that for whatever reason won't end up being compatible, and the Wordpress community will quickly consider SQLite a ""broken database"" or similar.For example, one of the most common plugins is Yoast, I'm sure somewhere in this spaghetti something will be MySQL specific.https://github.com/Yoast/wordpress-seo/blob/0efeda377ea09931..."	technion	13.534099	-5.521495	comment	7.0	57.0	1662979036	9.792369
32927920	> Developing against a relational da	"> Developing against a relational database requires devs to watch out for ""N+1"" query patterns, where a query leads to a loop that leads to more queries. N+1 queries against Postgres and MySQL can be lethal to performance. Not so much for SQLite.This is misleading AFAICT. The article(s) is actually comparing remote RDBMS to local RDBMS, not Postgres to SQLite.Postgres can also be served over a UNIX socket, removing the individual query overhead due to TCP roundtrip.SQLite is a great technology, but keep in mind that you can also deploy Postgres right next to your app as well. If your app is something like a company backend that could evolve a lot and benefit from Postgres's advanced features, this may be the right choice."	pphysch	13.533399	-5.488495	comment	7.0	70.0	1663779322	9.7950945
31824385	  sqlite3 :memory: -cmd '.mode csv' 	"  sqlite3 :memory: -cmd '.mode csv' ...

It should be a war crime for programs in 2022 to use non-UNIX/non-GNU style command line options. Add it to the Rome Statute's Article 7 list of crimes against humanity. Full blown tribunal at The Hague presided over by the international criminal court. Punishable by having to use Visual Basic 3.0 for all programming for the rest of their life."	throwaway892238	13.631587	-5.607769	comment	7.0	30.0	1655821962	9.862915
31994953	"Bun won my heart because:
- it uses "	"Bun won my heart because:
- it uses Zig and not Rust
- it uses JavaScriptCore and not V8
- it has built-in support for my favorite database: sqlite
- it is all-in-one"	akagusu	13.584998	-5.7688484	comment	7.0	63.0	1657063246	9.75433
32253274	I love this.I have been a fan of SQL	I love this.I have been a fan of SQLite for years, and it makes me genuinely happy to see other people have the same enthusiasm for the software.A couple of years ago, during a job search, I came across a couple of companies that I thought were a good match. I went through the interview process with all of them and, due to similarities in the interview process, we ended up talking about the same thing: databases. Oh the horror in the interviewers’ eyes whenever I mentioned SQLite. Experienced software engineers from The New York Times, for example, went as far as to mock my engineering choices in 3 out of 5 interviews, despite the success of the products my team built on top of SQLite.The experience made me feel awful and I stopped talking about SQLite for a couple of years. Instead, whene	guessmyname	13.583376	-5.5244093	comment	7.0	46.0	1658942129	9.82022
22066031	Show HN: SQLSite – serve simple webs	Show HN: SQLSite – serve simple websites, APIs and files directly from SQLite	j4mie	13.562106	-5.5404854	story	7.0	52.0	1579192059	9.770116
23510209	The great thing about applications t	The great thing about applications that use sqlite as their application file format is that you can write secondary apps and utilities to supplement the applications themselves.For example, Adobe's Lightroom uses sqlite as their application file format, which means that it's almost trivial to write an application to help it do things it's either really bad/exceedingly slow at (like removing images from a catalogue that no longer exist on disk) or literally can't do (like generating a playlist of files-on-disk for a specific collection or tag), without being locked into whatever janky scripting solution exists in-app. If there even is one to begin with.All you need is a programming language with a sqlite connector, and you're in the driving seat. And sure, you'll need to figure out the tabl	TheRealPomax	13.552603	-5.5684404	comment	8.0	92.0	1592062919	9.830261
23938266	I love that sqlite article. It seems	"I love that sqlite article. It seems like ""everyone"" is certain that sqlite can only be used for up to a single query per second, anything more and you need to spin up a triple sharded postgres or Hadoop cluster because it 'needs to scale'.I love being able to show that study, if you properly architect your sqlite system and am willing to purchase hardware,  you can go a long long way, much further than almost all companies go, with your data access code needing nothing more than the equivalent of System.Data.Sqlite"	Multicomp	13.53797	-5.52322	comment	8.0	73.0	1595590701	9.809862
24373439	MongoDB History	MongoDB History	jaysonqpt	13.734732	-5.3003683	story	8.0	34.0	1599213167	9.924493
39415231	The point about the storage size of 	The point about the storage size of UUID columns is unconvincing. 128 bits vs. 64 bits doesn't matter much when the table has five other columns.A much more salient concern for me is performance. UUIDv4 is widely supported but is completely random, which is not ideal for index performance. UUIDv7[0] is closer to Snowflake[1] and has some temporal locality but is less widely implemented.There's an orthogonal approach which is using bigserial and encrypting the keys: https://github.com/abevoelker/gfc64But this means 1) you can't rotate the secret and 2) if it's ever leaked everyone can now Fermi-estimate your table sizes.Having separate public and internal IDs seems both tedious and sacrifices performance (if the public-facing ID is a UUIDv4).I think UUIDv7 is the solution that checks the mo	zetalyrae	13.974351	-5.217224	comment	8.0	31.0	1708219437	-13.65831
39684618	Chyrp Lite – An Ultra-Lightweight Tu	Chyrp Lite – An Ultra-Lightweight Tumblelogging Engine Using PHP and SQLite	mikae1	13.529904	-5.5414953	story	8.0	30.0	1710275796	9.808014
36611619	I've been (proudly) noting these ele	"I've been (proudly) noting these elegant one-liners for ... 18 years now:  pg_dump -U postgres db | ssh user@rsync.net ""dd of=db_dump""

  mysqldump -u mysql db | ssh user@rsync.net ""dd of=db_dump""

... but what is the equivalent command for SQLite ?I see that there is a '.dump' command for use within the SQLite console but that wouldn't be suitable for pipelining ... is there not a standalone 'sqlitedump' binary ?"	rsync	13.597086	-5.5740933	comment	8.0	39.0	1688621056	9.837529
36893193	SQLite Begin Concurrent	SQLite Begin Concurrent	fauigerzigerk	13.595175	-5.536982	story	8.0	168.0	1690464670	9.8056555
24474384	Some people choose nosql alternative	Some people choose nosql alternatives because they've spent time analyzing the performance of a proper relational model and have determined that an RDBMS will generate too much overhead for their data load and consciously accept the tradeoffs involved in giving up automated referential integrity.Most people, though, choose nosql alternatives because they're too lazy to learn how to model data.	commandlinefan	13.535109	-5.4639335	comment	8.0	52.0	1600113335	9.818294
25423142	How we built scalable spatial indexi	How we built scalable spatial indexing in CockroachDB	orangechairs	13.613906	-5.2212725	story	8.0	153.0	1607979247	9.833874
25439878	Why CockroachDB and PostgreSQL Are C	Why CockroachDB and PostgreSQL Are Compatible	gesaint	13.588493	-5.2722416	story	8.0	160.0	1608102339	9.862303
38837870	Litestream – Opensource disaster rec	Litestream – Opensource disaster recovery and continuous replication for SQLite	selvan	13.564573	-5.481588	story	8.0	94.0	1704167303	9.794817
39039240	I don't see any mention of sqlite. I	I don't see any mention of sqlite. Is a sqlite file not the same thing they're talking about here? Pretty sure it has a spec and hasn't changed formats in many years so if you wanted to read it out in something that isn't sqlite, I imagine it wouldn't be too hard.	8n4vidtmkvmk	13.588171	-5.580337	comment	8.0	36.0	1705565368	9.850657
32557672	SQLite has pretty limited builtin fu	SQLite has pretty limited builtin functions	youngtaff	13.607045	-5.5886865	story	8.0	43.0	1661204541	9.847522
32581075	Someone recently observed that SQLit	"Someone recently observed that SQLite would be used a lot more in production if it didn't have the word ""lite"" in its name. I've personally been amazed by what it can do. Really great piece of tech with an unfortunate name."	jef_leppard	13.597663	-5.579015	comment	8.0	37.0	1661356351	-5.1253667
32628367	Show HN: Versioning Filesystem for S	Show HN: Versioning Filesystem for SQLite	devnull3	13.586178	-5.5611424	story	8.0	110.0	1661694563	9.841734
32676455	SQLite vs Postgres for a local datab	SQLite vs Postgres for a local database (on disk, not over the network): who wins? (Each in their most performance oriented configuration)	rafale	13.609155	-5.5404053	comment	8.0	64.0	1662041533	9.845795
32752366	I see so many SQLite posts these day	I see so many SQLite posts these days, but which companies with a lot (>1M) concurrent users are using SQLite in a non embedded fashion?It just seems so academic. I’d like to use a web service or app backed primarily by SQLite and see how it goes.	endisneigh	13.578983	-5.519015	comment	8.0	55.0	1662566351	9.8380375
31886977	Before I got to talk with Richard, I	"Before I got to talk with Richard, I found many things online about his Christian values and public domain license and how odd it was.And I thought this was THE fascinating thing about Richard that led to the database and other things.But then I talked to him. He's a great engineer but a regular guy running a business around a thing he built.He gets to be a bit whimsical because he can. He can use his own source control and license, and he can certainly make up a code of ethics, to check a check box on some form somewhere.The cool thing about SQLite is that he built this thing and gets to do things his way.This is just a specific instance of that.Shameless plug:
https://corecursive.com/066-sqlite-with-richard-hipp/"	adamgordonbell	13.6471195	-5.588491	comment	8.0	31.0	1656270939	-8.832349
31909011	The fact that the performance is so 	The fact that the performance is so close between a database that requires NO SERVER and one that requires a dedicated server + ops management is a signal to me that all projects should start on SQLite unless there is a compelling reason not to.	ed25519FUUU	13.599352	-5.546097	comment	8.0	84.0	1656430269	9.850414
32276649	If I was to reimplement it, I would 	If I was to reimplement it, I would not let any app read the DB directly.Instead I would make an HTTP like interface where you talk to a service that provides the get/set functionality and which always use a text format like an extended JSON with native support for date, int32, etc.This also enabled much easier and better backwards compability as you can specify app-version in the requests, so a version 5 server can respond in version 4 format.With a service it doesn't matter if things are stored as a single sqlite DB or as multiple files.	silvestrov	13.545524	-5.5277686	comment	8.0	30.0	1659101623	9.780235
32417632	Don't get me wrong, I run SQLite in 	"Don't get me wrong, I run SQLite in production with millions of records, but it seems people have discovered it just very recently.
All of the sudden, there's always a post about it with hundreds of comments.What changed?"	pachico	13.61041	-5.563922	comment	8.0	28.0	1660161812	9.87506
32479349	I like SQLite (use it for android ap	I like SQLite (use it for android apps), but there’s no reason to use it for apps over a network. SQLite is meant to be embedded (also works great with desktop apps and local-only web apps).In fact, I’d argue there’s no networked use case in which SQLite is cheaper, easier to deploy, maintain or run than Postgres.All that being said, absurdsql is great. There should be some optimizations in mirroring network state to IndexedDB that could be queried via SQl(ite).The SQLite documentation literally says use Postgres and not it for networked use cases (unless you use WAL or rollback, in which case why not just use Postgres?)https://www.sqlite.org/useovernet.html—-As an aside, I think we need a new storage primitive. In the 2000s desktop apps were rampant and SQLite was more or less the standar	endisneigh	13.572559	-5.490021	comment	8.0	41.0	1660625886	9.817096
22151323	Why even write this? It's yet anothe	"Why even write this? It's yet another convoluted use of the term and meaningless for SQLite of all things.Re: downvotes - what are people disagreeing with? That the term is not convoluted? That it's actually useful? That it helps to have more sub-definitions in an industry known for overloaded terms? I guarantee not a single person here has used ""classic serverless"" over ""in-process"" or ""embedded"" in their entire career."	manigandham	13.585515	-5.4572024	comment	8.0	39.0	1580032610	9.766306
22154054	With the ubiquity and general awesom	With the ubiquity and general awesomeness of sqlite I see no real reason usecase for these toolset over sqlite.	jsilence	13.598212	-5.566356	comment	8.0	42.0	1580066318	9.835051
14168187	The SQL layer in CockroachDB	The SQL layer in CockroachDB	ivank	13.613719	-5.2256846	story	8.0	85.0	1492800305	-10.741371
14290407	European Investment Bank announces €	European Investment Bank announces €25M funding for MariaDB	hpaavola	13.555087	-5.342563	story	8.0	117.0	1494238069	9.900414
14411000	Serena Williams Joins SurveyMonkey's	Serena Williams Joins SurveyMonkey's Board with Intuit's Smith	rayuela	13.59388	-5.559365	story	8.0	21.0	1495641713	1.7023157
14539948	Self-confidence as a programmer is w	Self-confidence as a programmer is when starting a new project, storing the transaction ID as a long rather than an int...	cm2187	13.729271	-5.2325706	comment	8.0	52.0	1497293737	-6.93925
30896129	OK I love SQLite but there has been 	OK I love SQLite but there has been a long-standing misconception, or issue, that I'd like to get clarification on: Is using SQLite from multiple processes safe?For a long while, either SQLite itself or the Python bindings weren't safe for concurrent access, is this still the case? Can I use SQLite for my Django app? With the backup system on the Tailscale post yesterday, the operational burden is much much lower than Postgres for many use cases.	stavros	13.596994	-5.5375824	comment	8.0	43.0	1648986131	9.780873
31214496	I read this as a damnation of POSIX 	"I read this as a damnation of POSIX filesystem semantics. File descriptors getting reused, insane locking semantics on close, allowing you to delete an open file and providing no means to prevent it, fork causing problems, unspecified behavior of sync() (is it barrier or ""full"" sync).Though: Multiple copies of SQLite linked into the same application. Weird and rare scenario, but why not keep the global list of open sqlite files in a global shared memory segment?"	zvrba	13.540766	-5.544639	comment	8.0	96.0	1651309526	9.720387
31527559	How I Built Zig-SQLite	How I Built Zig-SQLite	Sphax	13.597286	-5.624475	story	8.0	225.0	1653643009	12.5263405
25551681	I started doing a demo rewrite of my	I started doing a demo rewrite of my app in Postrgres from Mongodb. The reality is that even though Portgres seems more stable etc, making queries in Mongodb is much easier and fun.Postgres JSON operators are cryptic and made my head hurt every time I wanted to accomplish something more complex.To express it differently, if mongo and postgres where identical operationally, I would choose mongo every day. More friendly and fun. But there are so many horror stories that I am still not sure that it is the right choice for a safe production environment.	lexx	13.616536	-5.3994217	comment	8.0	28.0	1609083292	9.857642
25991563	Your post implies that there is no t	"Your post implies that there is no tool on earth that ""sucks"" and that it's not the tool, it's the person.It's impossible for EVERY tool to be good. This isn't reality. There has to be tools that are patently bad to use and people have used these bad tools to build great things. But it doesn't change the fact that a tool can be horrible to use.I would argue that at the time the article was written, Mongo was definitively a bad tool. Things have changed, but not all things."	Geminidog	13.708548	-5.303721	comment	8.0	47.0	1612203786	9.927488
25991422	Despite having used document oriente	Despite having used document oriented databases for many years(largely because they were shoved down my throat and I inherited someone else's architecture), I never really managed to figure out why people find them so compelling. There has been a shift in the last two years and people have started running away from them. Specifically the web-dev crowd adored them and I guess it's easy to fetch a document in the exact structure you need it but sooner or later you inevitably reach the point where you have to analyze data. And here mongo(and all the similar alternatives) become the biggest pain in the a...neck you can think of. Couchbase tried to tackle this issue with n1ql to a certain degree but at large scale it is still not particularly useful. To my mind, having a relational database whi	axegon_	13.581937	-5.3683224	comment	8.0	35.0	1612203036	-2.5786011
26158302	> The go command now supports includ	> The go command now supports including static files and file trees as part of the final executable, using the new //go:embed directiveCan this be used to imbed a dynamically growing SQLiteDB? If so that would be a killer feature.Unfortunately SQLite with Go still requires the remote host to have a c compiler (must use CGO), which makes even a static binary much less portable.	ed25519FUUU	13.625056	-5.6185703	comment	8.0	24.0	1613506769	-5.8011093
26474396	No you cannot, you cannot infinitely	No you cannot, you cannot infinitely scale SQLite, you can’t load 100 G of data into a single SQLite file in any meaningful amount of time. Then try creating an index on it and cry.I have tried this, I literally wanted to create a simple web app that is powered by the cheapest solution possible, but it had to serve from a database that cannot be smaller than 150GB. SQLite failed. Even Postgres by itself was very hard! In the end I now launch redshift for a couple days, process all the data, then pipe it to Postgres running on a lightsail vps via dblink. Haven’t found a better solution.	ramraj07	13.554785	-5.4852424	comment	8.0	36.0	1615885140	9.774705
36521226	Goodbye MongoDB	Goodbye MongoDB	zulban	13.70132	-5.315753	story	8.0	60.0	1688050478	9.924392
28995375	So glad to see PouchDB included. We 	So glad to see PouchDB included. We use it and have generally had a great experience! We use it with CouchDB on the backend, and Couch seems like a fantastic way to go for use cases involving syncing data between devices with an offline mode and syncing between clients. It was built from the ground up with replication in mind.Biggest bummer of CouchDB? If you’re not hosting it yourself, there’s only one major player in the market that I know of: IBM Cloudant. They contribute much to Apache CouchDB though, and hosting it yourself doesn’t seem too difficult, especially for small, simple use cases.Anyone else using CouchDB?	karmelapple	13.560971	-5.1972713	comment	8.0	55.0	1635211966	9.677123
34451916	My opinion. Always if in any way pos	"My opinion. Always if in any way possible pick a semantic key. There is usually something defining the thing you are working on. If there isnt work on your normalisation.Main benefits to this:
Avoids accidental duplication (happens so much). Avoids additional round trips to fetch the id to make a mutation.Of course if you work on something where you don’t know what it is yet (actually humans are a good example for that) uuid or int might make sense but I hear so many times picking non semantic as a default."	lysecret	13.96417	-5.225479	comment	8.0	31.0	1674216302	-13.662194
35113213	Regarding the usage of `crypto.rando	Regarding the usage of `crypto.randomUUID()` to generate unique `key` properties for list items, such a technique should only be necessary if the items don’t come with unique and stable ids on their own. This is the case for the example in the article, but in my experience, list items often do have some differentiator on their own, which you can either use directly, or otherwise derive for that purpose. If that’s the case, this is what I usually would prefer by default.One other aspect that I find important to understand about the `key` property is that it only has to be unique among its direct siblings, but it doesn’t have to be unique globally.	jotaen	13.974703	-5.211616	comment	8.0	30.0	1678571934	-13.662554
19262438	In terms of etcd3 vs sqlite3, it is 	"In terms of etcd3 vs sqlite3, it is as reliable as most airplane systems that depend on it.https://www.sqlite.org/famous.htmlI think the ""high availability by redundancy"" story is oversold."	omeid2	13.597553	-5.55202	comment	8.0	25.0	1551265497	9.8104315
19877113	This argument seems backwards.As far	This argument seems backwards.As far as I know, no database has ever had any of the problems he mentions with IDs not round-tripping properly during backup/restore. (Please correct me if I'm wrong! But why do I think this is true? Because any database that doesn't roundtrip primary keys would break all foreign keys on backup/restore. Databases with broken backup/restore tend to either fix it real fast, or go away.)On the contrary, it's much easier to keep IDs stable over time, than any other field. The problem with using a different field as an identifier (e.g. a URL component) is that almost any property with an objective meaning, might change over time or become non-unique. This is why it's a best practice not to use, e.g., user email as a primary key.For instance, Stack Overflow allows 	benkuhn	13.87945	-5.233257	comment	8.0	67.0	1557491789	-13.655325
16384880	> MongoDB has successfully played th	"> MongoDB has successfully played the 'hype first, features later' strategy. Now it is well on the way to being a decent swiss-army-knife database.I have no idea how capable MongoDB is these days, as I haven't used Mongo in years (and even then it was not for long).However, I do not know any developers who, after living through the ""hype first, features later"" strategy, have been left with a positive enough opinion of MongoDB to ever want to use it again."	SCdF	13.672653	-5.3184443	comment	8.0	62.0	1518709379	9.896047
16763966	Distributed SQLite for Go applicatio	Distributed SQLite for Go applications	ofrzeta	13.623756	-5.591368	story	8.0	241.0	1522929738	9.879524
21643794	Ask HN: Have you ever used SQLite as	Ask HN: Have you ever used SQLite as a client/server DB for a high volume site?	vanilla-almond	13.589788	-5.5134473	story	8.0	46.0	1574810840	9.786011
39254871	UUID Benchmark War	UUID Benchmark War	todsacerdoti	13.992986	-5.2132177	story	8.0	133.0	1707083453	-13.639212
39274451	> [...] sqlite is the 80% case and i	> [...] sqlite is the 80% case and is also dead simple to get going and genuinely performant.I don't understand this.  PostgreSQL is ALSO dead simple to get going, either locally or in production.  Why not just start off at 90%?I mean, I get there are a lot of use cases where sqlite is the better choice (and I've used sqlite multiple times over the years, including in my most recent gig), but why in general?	Ensorceled	13.586811	-5.535186	comment	8.0	66.0	1707229394	9.845521
18037867	SQLite.and for this reason alone!htt	"SQLite.and for this reason alone!https://www.sqlite.org/testing.html    As of version 3.23.0 (2018-04-02), the SQLite library consists of approximately 
    128.9 KSLOC of C code. (KSLOC means thousands of ""Source Lines Of Code"" or, in 
    other words, lines of code excluding blank lines and comments.) 

    By comparison, the project has 711 times as much test code and test scripts - 
    91772.0 KSLOC."	tzury	13.639435	-5.6107135	comment	8.0	54.0	1537515397	9.8404875
18685748	SQLite is the most thoroughly tested	SQLite is the most thoroughly tested codebase I'm aware of [1]. It has seven times more test code than non-test code. 100% branch coverage. If even SQLite can have a RCE vulnerability, I'm convinced that it is not feasible for anybody to write safe C code.[1] https://www.sqlite.org/testing.html	modeless	13.649131	-5.630184	comment	8.0	93.0	1544828868	9.860113
18925570	MongoDB should not be part of a stab	MongoDB should not be part of a stable release	giancarlostoro	13.706475	-5.316631	story	8.0	107.0	1547674588	9.955598
29728408	There are some important things that	There are some important things that SQLite does not do.It is not client/server; a process must be able to fopen() the database file. NFS and SMB are options  that can convey access to remote systems, but performance will not likely be good.Only a single process can write to the database at any time; it does not support concurrent writers.The backup tools do not support point-in-time recovery to a specific past time.If your application can live with these limitations, then it does have some wonderful features.	chasil	13.613444	-5.5149536	comment	8.0	59.0	1640804068	9.780504
29728702	I believe SQLite is about to explode	I believe SQLite is about to explode in usage into areas it’s not been used before.SQL.js[0] and the incredible “Absurd SQL”[1] are making it possible to build PWAs and hybrid mobile apps with a local SQL db. Absurd SQL uses IndexedDB as a block store fs for SQLite so you don’t have to load the whole db into memory and get atomic writes.Also I recently discovered the Session Extension[2] which would potentially enable offline distributed updates with eventual consistency!I can imagine building a SAAS app where each customer has a “workspace” each as a single SQLite db, and a hybrid/PWA app which either uses a local copy of the SQLite db synced with the session extension or uses a serveless backend (like CloudFlare workers) where a lightweight function performs the db operations. I haven’t 	samwillis	13.543396	-5.4429955	comment	8.0	40.0	1640805166	9.753199
29859869	As someone who's used MySQL for 17 y	As someone who's used MySQL for 17 years and dabbled a little in Mongo is there any reason to try and switch to Postgres?Obviously I love learning new things, but I've just never felt inclined to try it out, whereas I'm always jumping between other languages and frameworks within them. Not sure why that is.	12907835202	13.560556	-5.386714	comment	8.0	24.0	1641700414	9.860966
29919660	One unmentioned con: no updates, no 	One unmentioned con: no updates, no new torrents can be added (or, updates require re-deployment of full new .sqlite db, together with a new website). I think there's a space for decentralized database format. Something that would have immutable rows (not the whole db), ranges and search, indexes, etc. Maybe there's something like this already?	lekevicius	13.559203	-5.477779	comment	8.0	35.0	1642074442	-8.484222
12542095	The 5 Stages of NoSQL	The 5 Stages of NoSQL	soofaloofa	13.523973	-5.415	story	8.0	33.0	1474397026	9.817692
12656278	RethinkDB (the company) spent 7 year	RethinkDB (the company) spent 7 years creating amazing value by building RethinkDB (the database) from scratch.Compose.io probably only spent 1 or 2 months to incorporate it as part of their 'as-a-service' offerings...Guess which company actually survives and profits from all the value which was created?!... And this 'news release' from Compose.io is the business equivalent of a vulture feasting on the carcass of its own mother.	jondubois	13.676855	-5.290746	comment	8.0	40.0	1475789437	-12.799966
13493311	Open-RethinkDB meeting notes #4	Open-RethinkDB meeting notes #4	deepanchor	13.680565	-5.283097	story	8.0	137.0	1485451880	-12.757017
28296811	Well... we have 3 node MongoDB clust	Well... we have 3 node MongoDB cluster and are processing up to a million trades... per second. And a trade is way more complex than a chat message. Has tens to hundreds of fields, may require enriching with data from multiple external services and then requires to be stored, be searchable with unknown, arbitrary bitemporal queries and may need multiple downstream systems to be notified depending on a lot of factors when it is modified.All this happens on the aforementioned MongoDB cluster and just two server nodes. And the two server nodes are really only for redundancy, a single node easily fits the load.What I want to say is:-- processing a hundred million simple transactions per day is nothing difficult on modern hardware.-- modern servers have stupendous potential to process transacti	lmilcin	13.562245	-5.278593	comment	8.0	86.0	1629852158	9.826482
22426335	At this point why would you use Couc	At this point why would you use CouchDB over something like MongoDB?Seriously asking...Over the past 5 years MongoDB has gotten a great storage engine, transactions, distributed transactions, multi master replication, first class change streams and is very very solid as a foundational piece of infrastructure you can rely on while CouchDB has languished. I can’t imagine reaching for it in my tool belt when I need a document store over MongoDB but I’m obviously biased so I’m wondering if there is a lot I’m missing.Obviously it’s cool from a more open source databases standpoint — I love learning about how things are built and evolve over time.	tbrock	13.616612	-5.239597	comment	8.0	42.0	1582745164	9.729139
23273178	I can't help noticing that the major	"I can't help noticing that the majority - not all, but the majority - of ""No."" responses here summarize identically: someone used MongoDB a long time ago (between 5 and 11 years) and ran into a problem, so they stopped using it and will never try or re-evaluate it again.I'm a bit surprised that developers and systems engineers  get burned to the point that they disconnect from the daily reality of their occupation, that software is often shaky in its infancy but almost always improves over time."	daneel_w	13.708557	-5.284467	comment	8.0	28.0	1590161607	9.883918
33275472	> The key point is that SQLite is ve	"> The key point is that SQLite is very forgiving of the type of data that you put into the database. For example, if a column has a datatype of ""INTEGER"" and the application inserts a text string into that column, SQLite will first try to convert the text string into an integer, just like every other SQL database engine. Thus, if one inserts '1234' into an INTEGER column, that value is converted into an integer 1234 and stored. But, if you insert a non-numeric string like 'wxyz' into an INTEGER column, unlike other SQL databases, SQLite does not throw an error. Instead, SQLite stores the actual string value in the column.wtf. who would ever want that?"	ajkjk	13.648814	-5.63446	comment	8.0	59.0	1666277004	9.866145
26582824	Two major gripe I had with SQlite1. 	Two major gripe I had with SQlite1. SQLite doesn't really enforce column types[0], the choice is really puzzling to me. Since schema enforced type check is one of the strong suit of SQL/RDMBS based data solution.2. Whole database lock on write, this make it unsuitable to high write usages like logging and metric recording. WAL mode will help but it will only alleviate the issue, you will need row based lock solution eventually.Just like the offical FAQ said, SQLite competes with fopen[1] instead of RDBMS systems.--[0]: https://sqlite.org/datatype3.html[1]: https://www.sqlite.org/whentouse.html	doomleika	13.612052	-5.5300293	comment	8.0	42.0	1616692590	9.838181
26685294	Could you please tell me how did you	Could you please tell me how did you convert it to sqlite? I've got a huge 1 GB txt file that crashes my comp every time I try to search for myself there :( Thank you!	b212	13.588861	-5.577557	comment	8.0	26.0	1617488724	9.826732
27111058	Probably going to get downvoted for 	Probably going to get downvoted for this, but I feel like MongoDB should get more love in these subs.We use it all the time and their aggreations can get really advanced and perform well to the level where we run most analytics on demand. Sure we're not pushing to “big data” levels, max a few 100k records, but in reality I believe that's the average size of the majority of business datasets (Just an estimate, I have nothing to back this up)Been building with it for 5 years now and it's been a breeze. Especially with Atlas. I think our team has not spent more that 3 days in total on DB dev ops. And with Atlas Lucene text search and data lakes, querying data from S3. What's not to love.	gervwyk	13.579058	-5.292193	comment	8.0	24.0	1620681901	9.862316
27177957	I’m always surprised when people hav	I’m always surprised when people haven’t heard of Xapian which is also in this space.I tell people Xapian is the SQLite of search.https://xapian.org/	leetrout	13.587019	-5.5276675	comment	8.0	29.0	1621205983	9.772967
37583147	MongoDB’s new query engine	MongoDB’s new query engine	subset	13.642074	-5.360466	story	8.0	135.0	1695211496	9.867386
37734024	Given that a UUID identifier fits in	Given that a UUID identifier fits in a single cipher block, and the whole point is that these are unique by construction (no IV needed so long as that holds true), it seems like a single round of ECB-mode AES-128 would enable quickly converting between internal/external identifiers.128 bits -> 128 bits	oconnore	13.98758	-5.2058544	comment	8.0	77.0	1696221220	-13.683659
38037637	SQLite is not easy to use with migra	SQLite is not easy to use with migrations, because it doesn't support many ALTER TABLE options [1]: you need to create a new table instead of modifying a column, for example. Also, foreign keys are ignored by default and you need to explicitly enable them after connecting.Also, column types are not checked and you can easily insert a string into numeric column.Also it doesn't allow you to use multiple application servers.So it can be used only with small, simple sites.[1] https://www.sqlite.org/lang_altertable.html	codedokode	13.608144	-5.593787	comment	8.0	45.0	1698410221	9.844536
15511416	Which NoSQL would you prefer over mo	Which NoSQL would you prefer over mongo?	hamandcheese	13.581008	-5.355673	comment	8.0	37.0	1508446096	9.83264
15616644	The Future of RethinkDB	The Future of RethinkDB	williamstein	13.673104	-5.2845054	story	8.0	128.0	1509682512	-12.76795
15619557	What is the primary use case for ret	What is the primary use case for rethinkdb (vs other databases) ?	tarr11	13.6574745	-5.2870793	comment	8.0	43.0	1509720412	6.171003
20047918	Multi-threaded SQLite without the Op	Multi-threaded SQLite without the OperationalErrors (2017)	throwaway1492	13.596691	-5.5421734	story	9.0	76.0	1559184413	9.808796
14232521	Even with the inclusion of JSONB, I 	Even with the inclusion of JSONB, I think Postgres is still lagging behind MongoDB by enforcing schema. After so many years doing web apps, I am seeing very little interest to have to enforce 2 times the schema: one time in the DB via migtations and one time in the app itself via ORMs. Maybe I am missing something really obvious.ps: I don't mind the downvoting. I am truly looking for answers.	hartator	13.526537	-5.4529824	comment	9.0	74.0	1493571732	9.789257
14240111	What to Expect in CockroachDB 1.0	What to Expect in CockroachDB 1.0	manigandham	13.688434	-5.190283	story	9.0	70.0	1493663207	9.984806
18938737	Building CockroachDB on top of Rocks	Building CockroachDB on top of RocksDB	bandwitch	13.682453	-5.200207	story	9.0	180.0	1547813553	10.0006075
16616374	Better-sqlite3: A faster Sqlite libr	Better-sqlite3: A faster Sqlite library for Node.js	jeswin	13.56917	-5.539751	story	9.0	59.0	1521438190	9.770937
17264629	VFS shim that allows a SQLite databa	VFS shim that allows a SQLite database to be appended to another file	blacksqr	13.584871	-5.5667787	story	9.0	176.0	1528460878	9.823911
21608429	Removing WebSQL Support	Removing WebSQL Support	bzbarsky	13.53961	-5.5431166	story	9.0	68.0	1574447403	9.860046
18555150	Progress in performance and scalabil	Progress in performance and scalability with CockroachDB	awoods187	13.615383	-5.212035	story	9.0	105.0	1543435701	9.90066
18718364	The Guardian example was heavily use	"The Guardian example was heavily used by MongoDB as a case study to pitch their database to others in 2011:https://www.mongodb.com/customers/guardianhttps://www.mongodb.com/presentations/mongodb-guardianhttps://www.slideshare.net/tackers/why-we-chose-mongodb-for-...And reupping my previous, three-part series on MongoDB:On MongoDBNoSQL databases were the future. MongoDB was the database for ""modern"" web engineers and used by countless startups. What happened?https://www.nemil.com/mongo/index.html"	nemild	13.655077	-5.331503	comment	9.0	137.0	1545246539	9.866273
18771806	See also Firebase push IDs:https://f	See also Firebase push IDs:https://firebase.googleblog.com/2015/02/the-2120-ways-to-ens...Lexicographically sortable identifiers are critical for any distributed data store if you want anything close to consistency.  I've run into the issue of not having them and having to settle for some kind of <autoincrement_id><UUID> key and it's a huge PITA.  How this wasn't considered database 101 decades ago just blows my mind.I'd like to see a spec included in this for synchronizing clocks or using RAFT/Paxos for generating ULIDs with strong guarantees on sort order.Also a minor gripe - I wish that the ULID spec checked for microsecond collisions instead of millisecond, because that would be more useful for realtime networked gaming and simulations.	zackmorris	13.924922	-5.215314	comment	9.0	38.0	1545938684	-13.67521
29758613	Using the SQLite-over-HTTP “hack” to	Using the SQLite-over-HTTP “hack” to make back end-less, offline-friendly apps	sekao	13.572491	-5.5229135	story	9.0	94.0	1641048142	9.813479
29848327	Three easy lessons:1. Don't use Mong	Three easy lessons:1. Don't use MongoDB.2. Don't use high level ORMs. Stay (reasonably) close to SQL. And yes, it should be SQL. Almost certainly Postgres.3. Especially don't use Mongoid.	kurtbuilds	13.613127	-5.367813	comment	9.0	39.0	1641612245	9.860547
29850569	Isn't this easily solved by supporti	Isn't this easily solved by supporting 128 bit keys and using UUIDs as intended, i.e. as integers and not in their string serialization? This is as nonsensical as storing IPv4 as strings instead of 32 bit integers.	qalmakka	13.982555	-5.195024	comment	9.0	48.0	1641640025	-13.789428
30652281	Cloudant/IBM back off from Foundatio	Cloudant/IBM back off from FoundationDB based CouchDB rewrite	jFriedensreich	13.597518	-5.201791	story	9.0	137.0	1647101162	9.646172
12649609	RethinkDB is one of the developer to	RethinkDB is one of the developer tools that we at Stripe most looked up to.[1] The team had so many good ideas and rigorous, creative thoughts around what a database could be and how it should work. I'm really bummed that it didn't work out for them and have enormous respect for the tenacity of their effort.I'm also excited to have them join us here at Stripe. As we've gotten to know Mike, Slava, and the other Rethinks -- and shared some of our plans with them and gotten their feedback -- we've become pretty convinced that we can build some excellent products together in the future. I'm looking forward to learning from all of them.[1] (And, for me, even before Stripe -- I started learning Haskell with Slava's Lisp-interpreter-in-Haskell tutorial back in 2006... http://www.defmacro.org/ram	pc	13.57337	-5.3304644	comment	9.0	84.0	1475718900	-12.792932
12873443	ArangoDB 3.1 – A Solid Ground to Sca	ArangoDB 3.1 – A Solid Ground to Scale Part II	panagios	13.649801	-5.2736087	story	9.0	62.0	1478274185	9.943399
13262504	Secure your MongoDB, Redis, etc	Secure your MongoDB, Redis, etc	shahinism	13.676388	-5.237392	story	9.0	88.0	1482836853	9.94301
13583107	Realm is a mobile database: an alter	Realm is a mobile database: an alternative to SQLite and key-value stores	viebel	13.526656	-5.2520075	story	9.0	54.0	1486409967	9.795787
27736216	SQLite: Vulnerabilities	SQLite: Vulnerabilities	tosh	13.6197	-5.5834537	story	9.0	108.0	1625479463	9.853268
27909041	Just another reason why mongodb is t	Just another reason why mongodb is trash - does it even go without saying anymore?Every single company I've ever worked for was crushed by the unreliability of mongo.  They're ultra-expensive consulting is also a ripoff - in one case the guy came, suggested a bunch of stuff w.r.t. changing up our queries and indexes, left, then a day later the database exploded and we had to roll back everything he suggested.  We tried again piecemeal, which eventually lead to the same thing happening again.  Eventually spending the cash to train the engineers and admins to be able to do the tuning ourselves - which ended up being completely different than the garbage the consultant suggested.  Let me emphasize that this consultant was from the MongoDB company - not some third party.  Completely incompeten	rubyist5eva	13.699654	-5.2631245	comment	9.0	41.0	1626887469	9.911823
28089866	I'm a bit confused as to what the us	I'm a bit confused as to what the use case for UUIDs are compare to incrementing integer IDs. I assume there are some big upsides (aside from the primary key issue which seems to  have quite a few solutions at this point), but I'm just not aware of them.	jjice	13.963514	-5.2129655	comment	9.0	33.0	1628269022	-13.657265
28408682	SQLite-TUI: A TUI for viewing SQLite	SQLite-TUI: A TUI for viewing SQLite databases, written in Go	gjvc	13.594707	-5.582051	story	9.0	180.0	1630699147	9.837502
22367572	I remember listening to this when it	"I remember listening to this when it was recorded and I still remember details from it years later – probably my favorite Changelog podcast ever. It's obviously very foolish to make software choices based on how much you like its creator as a person. But Richard Hipp comes off as a guy so likable that goshdarnit, I hope his little project succeeds. Jokes aside, though, I don't think it's entirely coincidence that SQLite, something that is so good and reliable, was made by someone who seems so conscientious and thoughtful.Though I have to admit, I was and am still disappointed to learn that the official way to pronounce SQLite is ""S-Q-L-ite"", i.e. ""like a mineral""."	danso	13.601462	-5.5883045	comment	9.0	71.0	1582132436	-4.932128
33558814	My prediction: SQLite will keep gain	My prediction: SQLite will keep gaining popularity.Especially among pragmatic software builders who run their own business and do not work for the man. A demographic that I expect to grow.Talking about SQLite: Is there any downside to partitioning an SQLite db into multiple files?For example one of my systems has a table 'details' which is not vital for the system to work. It's just a nice to have, to have data in this table. And it is pretty big, growing fast.When I copy the DB over to another system, I don't need that table. So it would be nice to have like primary.db and secondary.db. With 'details' in secondary.db. Any downside to this approach? Are JOINS slower across two files than across two tables in the same file?	Timja	13.572	-5.5362315	comment	9.0	56.0	1668160351	9.794987
33699575	If you're using them for unguessable	If you're using them for unguessable random strings then yeah, they're not ideal.If you're using them for providing a unique id in a distributed system, with very little chance of collision & fitting them in a db column, then they are great.	cetra3	13.940436	-5.231213	comment	9.0	122.0	1669072713	-13.654146
33973888	SQLite-loadable-rs: A framework for 	SQLite-loadable-rs: A framework for building SQLite Extensions in Rust	petercooper	13.631029	-5.6526604	story	9.0	196.0	1670957662	9.724125
38095239	SQLite 3.44: Interactive release not	SQLite 3.44: Interactive release notes	marcobambini	13.608629	-5.584989	story	9.0	162.0	1698820744	9.870594
38289867	I don't think most people today real	"I don't think most people today realize how wasteful modern software engineering is. They think, it's fine to be inefficient, I'll just get a bigger X. And we are now blessed with technology and solutions that make that a possibility, when for the longest time it wasn't.But you don't want to have to optimize when you don't expect to. It takes time away from your features and quality, and is risky. You want to predict when you'll need to grow and how much effort it might take, and control costs. That's why software development should be efficient from the start. By only using what you need, you don't run into situations where you have to optimize to survive.Anyone who says to me ""I'll just put everything in PostgreSQL and optimize later"" sounds just as naive as the person who says ""let's bu"	throwawaaarrgh	13.536109	-5.383275	comment	9.0	43.0	1700144725	9.789887
15188321	Ask HN: Should I not use MongoDB?	Ask HN: Should I not use MongoDB?	nikkwong	13.542122	-5.3252463	story	9.0	15.0	1504745005	9.840374
15303662	SQLite is such a fantastic database.	SQLite is such a fantastic database. I've always wondered, is anyone using it at scale in a client server application? How do people handle syncing online/offline in mobile apps?	le-mark	13.566996	-5.4929514	comment	9.0	64.0	1506003624	9.808777
15308375	I'm asking this in good faith. What 	I'm asking this in good faith. What are the best use cases nowadays for Mongo? I've read that it still makes sense when you are dealing with truly self-contained documents. But even then, what is the advantage over just using Postgres or MySQL and their native JSON types?I've read plenty of negative comments on Mongo. I'd like to hear the other side of the story, if possible.	dguo	13.611099	-5.3904176	comment	9.0	57.0	1506039156	9.840553
14524174	One of the post's points is that UUI	"One of the post's points is that UUIDs will scatter your writes across the database, and that for this reason you want a (more or less) sequential key as your primary key. This crucially depends on both your database technology and your query patterns.In a single-node database or even a manually-sharded one, this post's advice is good (For Friendfeed, we used a variation of the ""Integers Internal, UUIDs External"" strategy on sharded mysql: https://backchannel.org/blog/friendfeed-schemaless-mysql).But in a distributed database like CockroachDB (Disclosure: I'm the co-founder and CTO of Cockroach Labs) or Google Cloud Spanner, it's usually better to get the random scattering of a UUID primary key, because that spreads the workload across all the nodes in the cluster. Sometimes query patterns"	bdarnell	13.937923	-5.233334	comment	9.0	48.0	1497039516	-13.6445055
14524346	This article is so poorly written it	This article is so poorly written it's hard to take it serious. The entire paragraph about the size of a UUID takes reading it three or four times before you can actually understand what the author means...In what context would a primary key change, even when sharding? In my entire career I have yet to see it. Also any sane person would never sort random values. If you need sorting in your table, provide some kind of indexed timestamp.	dimgl	13.962949	-5.227726	comment	9.0	37.0	1497040718	-13.664434
30884110	So to recap their timeline:  * Inste	"So to recap their timeline:  * Instead of an actual database use a JSON file.
  * Write a blog post about how that didn't scale.
  * Instead of an actual database hand-roll something else.
  * Write a blog post about how that didn't scale.
  * Instead of a database with built-in replication which is tailor built for key-value storage use SQLite with a single table containing key-value pairs and some fresh glue to make it replicate.

I'm sorry, but what the fuck? Just writing the blog posts alone might have consumed more work-hours than what it would have taken to set a database up in the first place.Are we supposed to expect another blog post somewhere around a year down the road titled ""SQLite didn't scale"" or ""The new library for replication that was released a few months ago contained a"	musjleman	13.595093	-5.3910046	comment	9.0	70.0	1648853456	2.9929986
31039949	> it's a database for localhost only	> it's a database for localhost onlyThis is sticking so hard to Sqlite, but it's really no longer true I think. Given WAL mode and tools like litestream, it's even feasible to run Sqlite in serverless offerings like Cloud Run. The schema change constraints are annoying though, even when there are known workarounds.And, this is off topic, but Tailwind is really becoming the new Bootstrap. I open a page and it's instantly visible that this has been implemented with Tailwind (and often Tailwind UI).	config_yml	13.569918	-5.5124235	comment	9.0	42.0	1650029043	9.831338
31153130	Here's an all-time great post about 	Here's an all-time great post about why you might consider SQLite in production with data about performance: https://blog.wesleyac.com/posts/consider-sqliteI use SQLite in production for my SaaS[1]. It's really great — saves me money, required basically no setup/configuration/management, and has had no scaling issues whatsoever with a few million hits a month. SQLite is really blazing fast for typical SaaS workloads. And will be easy to scale by vertically scaling the vm it's hosted on.Litestream was the final piece of the missing puzzle that helped me use it in production — continuous backups for SQLite like other database servers have: https://litestream.io/ With Litestream, I pay literally $0 to back up customer data and have confidence nothing will be lost. And it took like 5 minutes t	Glench	13.577647	-5.49504	comment	9.0	94.0	1650886777	9.805917
31189341	You Shouldn't Use SQLite	You Shouldn't Use SQLite	Existenceblinks	13.615144	-5.58923	story	9.0	5.0	1651127425	9.853219
31708179	I thought that SQLlite databases are	I thought that SQLlite databases are not suitable for large multi user websites. Something got to do with only being able to handles one transaction at a time. Isn’t that right?	bazmattaz	13.579356	-5.518432	comment	9.0	41.0	1654980149	9.799105
26151491	If you haven't tried SQLite, please 	If you haven't tried SQLite, please do. For years I ignored SQLite and used MySQL (it does the job) but once you see how fast SQLite is, and advantages of having a DB contained in a single file... just go play around with SQLite instead of ignoring it for years like me. It's neat.	Laminary	13.541815	-5.534755	comment	9.0	233.0	1613456968	9.788282
26191780	Things you should never do: use inte	Things you should never do: use integers as ID's. This is literally a solved problem, and the solution is UUIDs, which were invented for exactly this job.	marcus_holmes	13.978197	-5.214247	comment	9.0	74.0	1613732632	-13.659255
34162001	SQLite's Automatic Indexes	SQLite's Automatic Indexes	preetamjinka	13.535857	-5.5601344	story	9.0	216.0	1672241757	9.744506
34267434	I Migrated from a Postgres Cluster t	I Migrated from a Postgres Cluster to Distributed SQLite with LiteFS	Fudgel	13.588079	-5.53534	story	9.0	129.0	1672955985	9.800305
36699961	Why do I see so much discussion abou	Why do I see so much discussion about SQLite on HN? I've literally never seen it used in production, my usage of it is purely as a database for local testing	shortrounddev2	13.592849	-5.5576167	comment	9.0	34.0	1689188312	9.848818
37048409	Blueprint for a distributed multi-re	Blueprint for a distributed multi-region IAM with Go and CockroachDB	oporquinho94	13.571877	-5.1847954	story	9.0	141.0	1691499953	9.837444
37063653	Following the PostgreSQL logical rep	"Following the PostgreSQL logical replication stream to update a local SQLite database copy is definitely a neat trick, and feels very safe to me (especially since you track the Log Sequence Number in a postgres_pos table).The bit that surprised me was that this thing supports writes as well!It does it by acting as a PostgreSQL proxy. You connect to that proxy with a regular PostgreSQL client, then any read queries you issue run against the local SQLite copy and any writes are forwarded on to ""real"" PostgreSQL.The downside is that now your SELECT statements all need to be in the subset of SQL that is supported by both SQLite and PostgreSQL. This can be pretty limiting, mainly because PostgreSQL SQL is a much, much richer dialect than SQLite.Should work fine for basic SELECT queries though.I"	simonw	13.5602	-5.4919405	comment	9.0	49.0	1691592885	9.793924
37255022	SQLite 3.43	SQLite 3.43	justinclift	13.6226845	-5.601715	story	9.0	174.0	1692913888	9.863268
37470412	The crux of this argument seems to b	The crux of this argument seems to be that UUIDs are too long? Which I disagree with. I can't memorize them, no, and it would be cumbersome to try to say one aloud, but these aren't situations I've ever found myself in.Does it make the URL in the URL bar longer? Yeah, but does that matter?	iaaan	13.968274	-5.2003818	comment	9.0	69.0	1694452760	-13.668352
37553874	I'm currently working on an applicat	I'm currently working on an application where I use SQLite as the file format. I want to keep a usual workflow for users where you can make edit to your document and it only changes the file when you save it.So to open a file I copy it into the :memory: database [1], then the user can do whatever manipulation they want and I can directly make the change in the database I don't need to have a model of the document other than its database format. And to save the document I VACUUM [2] it back to the database file. It works quite well, at least for reasonably sized file (which is always the case for my app) :).[1] https://www.sqlite.org/inmemorydb.html[2] https://www.sqlite.org/lang_vacuum.html	p4bl0	13.562081	-5.5412655	comment	9.0	88.0	1695027776	9.705456
32852478	Show HN: WunderBase – Serverless OSS	Show HN: WunderBase – Serverless OSS database on top of SQLite, Firecracker	jensneuse	13.580203	-5.542211	story	9.0	179.0	1663251729	9.804802
31785170	The Design of SQLite4	The Design of SQLite4	harporoeder	13.59659	-5.564308	story	9.0	120.0	1655504525	9.853399
32263914	Martin Kersten, creator of MonetDB, 	Martin Kersten, creator of MonetDB, has died	greghn	13.702433	-5.311554	story	9.0	177.0	1659014534	9.92467
32288165	A SQLite extension for reading large	A SQLite extension for reading large files line-by-line	polyrand	13.566894	-5.5707026	story	9.0	157.0	1659199502	9.841498
32417410	SQLite-HTTP: A SQLite extension for 	SQLite-HTTP: A SQLite extension for making HTTP requests	b_mc2	13.574484	-5.5502987	story	9.0	65.0	1660160628	9.819043
22100097	With how widespread both SQLite and 	With how widespread both SQLite and WD are wouldn't half the world have apps crashing left and right, if just the hard drive brand was the cause of the problem?	pilsetnieks	13.585664	-5.543461	comment	9.0	38.0	1579539118	9.881507
23508772	Ask HN: What is your preferred NoSQL	Ask HN: What is your preferred NoSQL database?	srameshc	13.535897	-5.368128	story	10.0	8.0	1592049052	9.832174
14301932	Hello everyone! Author here. I didn'	"Hello everyone! Author here. I didn't expect anyone to find this repo, much less post it on Hacker News!This project is inactive for two main reasons:- SQLite is not a great general-purpose SQL engine. Poor performance of joins is a serious problem that I couldn't solve. The virtual table support is good but not quite good enough; not enough parts of the query are pushed down into the virtual table interface to permit efficient querying of remote tables. Many ""ALTER"" features are not implemented in SQLite which is a tough sell for experimental data manipulation.- T-SQL, the procedural language I chose to implement atop SQLite, is not a great general-purpose programming language. Using C# in LINQpad is a more pleasant experience for experimentally messing around with data.  R Studio is a go"	electroly	13.587949	-5.573892	comment	10.0	72.0	1494350176	9.861025
31256704	Sqldiff: SQLite Database Difference 	Sqldiff: SQLite Database Difference Utility	thunderbong	13.583712	-5.5853086	story	10.0	210.0	1651637843	9.85348
31433113	Serious Bug in MongoDB Geospatial di	Serious Bug in MongoDB Geospatial distance calculation	mtmail	13.693387	-5.3155255	story	10.0	66.0	1652959725	9.858498
25551122	Bye Bye Mongo, Hello Postgres (2018)	Bye Bye Mongo, Hello Postgres (2018)	mathattack	13.679883	-5.321741	story	10.0	198.0	1609078166	9.944736
35528128	> Even the most unoptimized database	"> Even the most unoptimized database should be able to handle this.Anybody had any success running a queue on top of... sqlite?With the way the sqlite file locking mechanisms work, are you basically guaranteed really low concurrency? You can have lots of readers but not really a lot of writers, and in order to pop a job off of the queue you need to have a process spinning waiting for work, move its status from ""to do"" to ""in progress"" and then ""done"" or ""error"", which is sort of ""write"" heavy?> An EXCLUSIVE lock is needed in order to write to the database file. Only one EXCLUSIVE lock is allowed on the file and no other locks of any kind are allowed to coexist with an EXCLUSIVE lock. In order to maximize concurrency, SQLite works to minimize the amount of time that EXCLUSIVE locks are held"	MuffinFlavored	13.539886	-5.5099177	comment	10.0	57.0	1681233432	9.738721
35981828	Code Generator for SQLite	Code Generator for SQLite	luu	13.63268	-5.5941963	story	10.0	128.0	1684360949	9.870406
36438367	Analyzing New Unique Identifier Form	Analyzing New Unique Identifier Formats (UUIDv6, UUIDv7, and UUIDv8) (2022)	BerislavLopac	13.988932	-5.212781	story	10.0	107.0	1687465469	-13.667664
29154461	DBCore	DBCore	omarfarooq	13.522205	-5.553014	story	10.0	223.0	1636406598	9.830588
34137264	Use LibreOffice Base as a GUI for an	Use LibreOffice Base as a GUI for an SQLite Database in OS X (2016)	MonkeyClub	13.5653305	-5.554944	story	10.0	92.0	1672059203	-11.706926
34265261	LiteSync – Easy synchronization of S	LiteSync – Easy synchronization of SQLite databases	thunderbong	13.56551	-5.496198	story	10.0	102.0	1672947256	9.820678
24843643	SQLite now allows multiple recursive	SQLite now allows multiple recursive SELECT statements in a single recursive CTE	thunderbong	13.620125	-5.59579	story	10.0	398.0	1603239127	9.775535
25130458	Why I Left IBM to Work on CockroachD	Why I Left IBM to Work on CockroachDB	orangechairs	13.674499	-5.2010846	story	10.0	141.0	1605650167	9.972389
38650570	Show HN: My Go SQLite driver did poo	Show HN: My Go SQLite driver did poorly on a benchmark, so I fixed it	ncruces	13.5730715	-5.5450563	story	10.0	234.0	1702608263	9.778842
32579866	How SQLite scales read concurrency	How SQLite scales read concurrency	pkilgore	13.628551	-5.5657024	story	10.0	240.0	1661351094	9.761153
39600968	Interactive SQLite Documentation: Ex	Interactive SQLite Documentation: Experiment with Queries in Real-Time	marcobambini	13.612644	-5.5727115	story	10.0	123.0	1709629092	9.840459
22008218	I’d like to look into the features o	I’d like to look into the features of notion more, but I can’t help but wonder why it isn’t more common to see people using a local SQLite database, or any other self hosted database, to serve as a personal knowledge base management system. A lot of the paid solutions I’ve seen seem to bend over backwards to offer a limited subset of the features that are trivially available in an actual database.Has anyone tried out using a personal database like this?	bnj	13.54854	-5.5197315	comment	10.0	31.0	1578628924	9.719381
19159016	I’ll allow it. Years later, I’m stil	I’ll allow it. Years later, I’m still miffed at Graylog (centralized logging engine) for having required MongoDB for a small bit of auth and meta storage that could’ve easily been done in MySQL or PostgreSQL (RDS even), forcing the need for that much more ops work for a small Mongo cluster for HA. Everyone deprecating the use of Mongo is a welcoming turn of events.I shall recall these dark days to the next generation as “NoSQL Madness”, or more colloquially, “my schema is my app layer”.	toomuchtodo	13.63691	-5.3332224	comment	10.0	135.0	1550109321	9.884296
19762955	The Use of assert() in SQLite	The Use of assert() in SQLite	henning	13.637715	-5.653897	story	10.0	139.0	1556325235	-5.9755664
16050910	At what scale does all this stuff st	At what scale does all this stuff start to actually matter?  I have an database with ~100 tables and ~500M rows driving a medium-traffic web app and various back-end systems.  We use auto-incrementing integers as primary keys and try not to expose them externally.  Indexes are added as necessary to enable specific queries.  We don't enforce any other constraints (e.g. not-null or foreign keys) at the database level.... and it all works and performs just fine?  The considerations the author mentions all make some sense to me in theory, but when do they actually matter in practice in a modern system?	foreigner	13.779009	-5.3508897	comment	10.0	46.0	1514885952	-13.639761
16755408	I am genuinely interested in using C	I am genuinely interested in using CockroachDB as a primary datastore but feel like I have been burned too many times by hopping on board with a young database.I tried lucene based databases that offered amazing search capability but were riddled with data corruption issues. Then there was RethinkDB which was very promising but ran out of funding.I am skeptical that a networked database with multiple nodes can match the performance of a single master database such as MySQL, PostgreSQL, or SQL Server. I did a quick benchmark of CockroachDB 1.x and MySQL last year and found that CockroachDB was 5-10x slower on simple CRUD queries: https://github.com/caleblloyd/MySqlCockroachBench/wiki/Concu... Are there any good independent benchmarks of performance?According to crunchbase, Cockroach Labs ha	caleblloyd	13.616135	-5.222437	comment	10.0	70.0	1522854409	9.924795
17392688	MongoDB 4.0 will add support for mul	MongoDB 4.0 will add support for multi-document transactions	cyberfart	13.668072	-5.3248534	story	10.0	82.0	1529937102	9.897093
17966329	I think most of us agree that SQLite	I think most of us agree that SQLite is close to the gold standard for stability and testing.  This  post reminds us that even SQLite has  critical bugs.But looking at https://www.sqlite.org/cgi/src/rptview?rn=7 I see a few Core Crash Bugs every month (April has 7).  Most of them are not 'critical', to be clear, plenty of 'severe' and 'important' in the list.I don't want to disparage SQLite.  They have a free, fantastic product, go to great lengths to have stability no matter what, and document their processes.  I learned a lot of them.But clearly, our gold standard is not perfect.  So now what?* We might turn to theorem proving.  But is it possible at SQLite scale?  Are the proofs themselves enough?  I remember about a critical piece of software with a proof no incorrect answers would com	hyperman1	13.6439705	-5.6197977	comment	10.0	47.0	1536738476	9.853871
18340078	Managed CockroachDB: Geo-Distributed	Managed CockroachDB: Geo-Distributed Database as a Service	louis-paul	13.585884	-5.216631	story	10.0	151.0	1540925270	9.863694
18555952	Slightly off-topic, but: has Postgre	Slightly off-topic, but: has PostgreSQL largely replaced MySQL for new projects? I'm seeing larger numbers of positions advertising for Postgres, even here in the Midwest.Postgres seems so chock-full of features now - is there a reason to prefer MySQL? Easier replication?	mr_overalls	13.538934	-5.425605	comment	10.0	49.0	1543441410	9.856527
18718791	I think you're asking the wrong ques	I think you're asking the wrong question. The question should be: How did MongoDB become so successful?IMO, the reason is that newer developers faced the choice of learning SQL or learning to use something with a Javascript API. MongoDB was the natural choice because they excelled at being accessible to devs who were already familiar with Javascript and JSON.Not only that, their marketing/outreach efforts were also aimed at younger developers. When was the last time you saw a Postgres rep at a college tech event?	csytan	13.667503	-5.325346	comment	10.0	82.0	1545248676	9.896968
18920212	It seems[0] the new MongoDB license 	It seems[0] the new MongoDB license is basically non-free and it would make no sense to include it in RHEL8. I hope Debian and other distros follow suit as a result if they come in agreement. It's sad that the license change all resorts to greed basically, as if Oracle took over MongoDB.If I were to ever use a NoSQL database for a new project I'd aim for MIT / 2-clause BSD based projects instead. PostgreSQL has no issue being BSD-like licensed (all this time I thought it was BSD or MIT, turns out it's a similar license instead). It saddens me RethinkDB couldn't compete more with MongoDB.[0]: https://news.ycombinator.com/item?id=18919728	giancarlostoro	13.708856	-5.2351274	comment	10.0	134.0	1547641645	9.915601
30072997	Store SQLite in Cloudflare Durable O	Store SQLite in Cloudflare Durable Objects	jgrahamc	13.536848	-5.434175	story	10.0	244.0	1643125227	9.809942
30486052	New JSON query operators in SQLite 3	New JSON query operators in SQLite 3.38.0	xtreak29	13.531162	-5.6451154	story	10.0	397.0	1645945057	9.797021
12578569	SQLite works great as the database e	SQLite works great as the database engine for most low to medium traffic websites (which is to say, most websites)...Generally speaking, any site that gets fewer than 100K hits/day should work fine with SQLite.Do people agree with this? I was under the impression you should not use SQLite for production websites for some reason. Django has this to say, for instance [1]:When starting your first real project, however, you may want to use a more robust database like PostgreSQL, to avoid database-switching headaches down the road.[1] https://docs.djangoproject.com/en/1.10/intro/tutorial02/	Lxr	13.578894	-5.525542	comment	10.0	50.0	1474853221	9.845377
12649713	Why does nobody seem to have any int	Why does nobody seem to have any introspection on why RethinkDB failed? Clearly there are some major problems that people re ignoring. If my favorite DB (I must mention Kx Systems once a month) folded, I could give you a laundry list of issues where things went sideways, but all I see is glowing praise and comments about the best tech not always winning (KDB knocks the socks off of everything, but I sure can give you a list of places it fails).This isn't meant to be harsh, but these are times to learn, not simply pat each other on the back.	jnordwick	13.669585	-5.285	comment	10.0	78.0	1475720372	-12.806416
13498611	SQLite and Android N (2016)	SQLite and Android N (2016)	luu	13.626388	-5.584953	story	10.0	82.0	1485508082	9.866301
27673359	We're currently transitioning from a	We're currently transitioning from a multi-tenant 2TB postgres DB hosted on AWS RDS to using sqlite instead, a separate database for each client.We're doing this for multiple reasons: a) As our DB grew the service became very expensive, one of the biggest items in our AWS invoice; b) Keeping the PG servers up to date is a pain, we simply don't have time for this; c) We wanted to be able to migrate to other clouds and even be able to offer a self-hosted version of our platform.	ciconia	13.528337	-5.3617773	comment	10.0	62.0	1624956056	9.811727
27873058	Hey all, author here. I didn't expec	Hey all, author here. I didn't expect this to reach front page of HN. I came here to submit and it was here already! I am looking for more ideas to experiment. Here's one idea which someone from another forum gave me: exploring recursive queries and using SQLite random methods to do the insertions.Another crazy idea is to learn about SQLite file format and just write the pages to disk.	avinassh	13.632126	-5.594871	comment	10.0	42.0	1626617635	9.762094
35469897	> All you need to store this kind of	"> All you need to store this kind of data is a simple file.You mostly likely need a WAL Mode SQLite database. Most of the time, it's way simpler that handling state handling in concurrent situations yourself. (also, bindings are often available - if not outright bundled by default - under most common languages)The ""easy"" way is all fun and games until your file is accessed in a concurrent fashion, and then your options are:a) flat out die when concurrent things happens (file locks; default sqlite3 behaviour);b) just write blindly to file and pretend concurrecy doesn't exist, but randomly lose data - (write to files directly like a crazy person; sqlite3 PRAGMA schema.synchronous = OFF)c) allow reading at anytime, but serialize writing somehow (file locks + write + move atomic file operation"	ElectricalUnion	13.570744	-5.563362	comment	10.0	44.0	1680795576	9.813463
23287675	As someone that uses SQLite a bit fo	As someone that uses SQLite a bit for analytics, I feel like the elevator pitch on the github and the website ( https://www.duckdb.org/ ) is missing something.I'm sure there's some great reason, but I don't see it:  Why would I want to use this over SQLite?  Is it considerably faster?  Does it handle large scale better?  I suppose I could try and throw it some use cases I could come up with, but I'd worry I'm missing the best use case for this tool.	banana_giraffe	13.564134	-5.5467315	comment	10.0	56.0	1590277438	9.84066
33606311	Crsql – Multi-writer and CRDT suppor	Crsql – Multi-writer and CRDT support for SQLite	faizshah	13.535349	-5.485013	story	10.0	198.0	1668497437	9.79817
26581100	Does anyone use SQLite as their dail	Does anyone use SQLite as their daily-driver in lieu of R or pandas for data analysis? I don't think I can use the sqlite command-line since I'd want a fully-developed plotting utility, and it seems less convenient to do the actual analysis part through a sqlite connection in python, say.	tgb	13.547571	-5.5567555	comment	10.0	31.0	1616684385	9.807713
26581291	With no sense of overstatement here,	With no sense of overstatement here, SQLite is one of my favorite creations in the entire world, so I have a bunch of links some of you might find interesting if you want to dig further:https://github.com/sql-js/sql.js - SQL.js lets you run SQLite within a Web page as it's just SQLite compiled to JS with Emscripten.https://litestream.io/blog/why-i-built-litestream/ - Litestream is a SQLite-powered streaming replication system.https://sqlite.org/lang_with.html#rcex3 - you can do graph-style queries against SQLite too (briefly mentioned in the article).https://github.com/aergoio/aergolite - AergoLite is replicated SQLite but secured by a blockchain.https:&	petercooper	13.578335	-5.545771	comment	10.0	52.0	1616685400	9.806745
26685156	SpatiaLite: A Spatial Extension to S	SpatiaLite: A Spatial Extension to SQLite	chippy	13.646294	-5.570949	story	10.0	191.0	1617487509	9.835359
37614511	I hope fly is able to make it. I’m r	I hope fly is able to make it. I’m rooting for them - however - I’m starting to wonder if the SQLite push isn’t more “this is fun and interesting to build” and less “customers want this”.Don’t get me wrong - this is neat - but I’d never suggest anyone to actually use this outside of a fun experiment. The problem with existing SQL dbs isn’t really the architecture - its the awful queries that do in memory sorting or make temporary tables for no reason or read-after-write, etc, not network latency. SQLite won’t fix your current production problems.If it turns out they’re building this for customers throwing cash at them, awesome. I just somehow doubt it. I think Planetscale has the better approach: a drop in replacement for MySQL/RDS with a smarter query planner. As a production engineer tha	erulabs	13.570596	-5.5288944	comment	10.0	62.0	1695402033	9.854617
15509415	Is it me..or does Mongo not seem as 	Is it me..or does Mongo not seem as relevent and 'hip' as it once was... I mean I feel postgres is much more solid, and you can combine some of the aspects of document store via the json data types they added... of course I'm not really a DBA and don't have a lot of Mongo experience ... but personally I feel rdbms make more sense for growth/scaling..	gremlinsinc	13.625948	-5.364316	comment	10.0	110.0	1508431315	9.911338
15509799	MongoDB isn't usually seen favorably	MongoDB isn't usually seen favorably but everyone must admit that it's an unlikely success story that deserves admiration. Think about it. Bringing a database to the market with a completely different paradigm, growing it to the enterprise-production-ready level, and creating a billion-dollar business around is no small deal. Yes, they did ride the NoSQL zeitgeist but they survived when others had no major success.Undeniably, they did have their fuck-ups in the start, but I think they have done a good job fixing them.	shubhamjain	13.682952	-5.3126736	comment	10.0	150.0	1508434217	9.902127
15607365	I think it's not used widely enough 	I think it's not used widely enough yet. For example, 99% of websites could benefit from using SQLite instead of MySql or (god forbid) PostgreSQL.I mean Postgres is a fine piece of software but if your website gets 500 visits a day, you don't need Postgres; just use SQLite.	hasenj	13.528386	-5.4675446	comment	10.0	78.0	1509589736	9.864835
23511093	This is surprising. SQLite is known 	This is surprising. SQLite is known for having 100% code coverage, fuzzy testing, and a 644:1 tests to code ratio. If even that cannot stop this kind of attack then we really need to rethink computers from the ground up...https://sqlite.org/testing.html	jiofih	13.645513	-5.6077023	comment	11.0	99.0	1592069746	9.921058
23539541	A Jupyter Kernel for SQLite	A Jupyter Kernel for SQLite	Tomte	13.582733	-5.5718937	story	11.0	266.0	1592317884	9.84657
31473373	I've yet to see how you can use SQLi	I've yet to see how you can use SQLite for a multi-user multi-write app effectively. Unless we're all going back to single tenant, single user applications SQLite seems overhyped for the new usecases.Don't get me wrong, there are plenty of uses for SQLite, but I think the hype is getting out of hand IMHO.If you are making an app that only a single person is going to use at a time, then there are plenty of options, including SQLite. Heck, IndexedDB is sufficient. CouchDB tried the whole DB-per-user thing and it didn't end super well.Happy to be proven wrong though. If anyone has an example of a site with more than say, 10K concurrent writers (edit: changed from users) running on a single SQLite DB I'd probably change my mind.---Now, what would be interesting is a way to architect an app suc	endisneigh	13.534761	-5.451099	comment	11.0	70.0	1653257936	9.781488
26105410	Awesome! I built a side-business tha	Awesome! I built a side-business that runs completely on Crystal + SQLite. Very light, fast service and makes ~$200k/mo.I just cp my sqlite file to S3 every 2 hours.From my app, i have a page[1] where i can load any snapshot database saved on S3. I can backup at anytime too with a click, which i do before deployment.[1]: https://i.imgur.com/Ls1Tnxc.png	devmunchies	13.553936	-5.454811	comment	11.0	61.0	1613068736	9.796519
35718481	I must admit as a web practitioner s	I must admit as a web practitioner since 1994 I have a bit of an issue with this:> In the 2000s, the conventional wisdom selected MySQL because rising tech stars like Google and Facebook were using it. Then in the 2010s, it was MongoDB because non-durable writes made it “webscale“. In the last five years, PostgreSQL has become the Internet’s darling DBMS. And for good reasons!Different DB's, different strengths and it's not a zero sum came as implied. MySQL was popular before Google was born - we used it heavily at eToys in the 90s for massive transaction volume and replacing it with Oracle was one of the reasons for the catastrophic failure of eToys circa 2001. MongoDB gained traction not because it's an alternative to MySQL or PostgreSQL. And PostgreSQL's marketshare today is on a par wi	mmaunder	13.571793	-5.358278	comment	11.0	61.0	1682535982	9.87576
36303064	Somewhat related - I’m very very cur	Somewhat related - I’m very very curious to hear a detailed account of someone who uses SQLite for a production app with high traffic.For the embedded use case I think it’s a slam dunk, but there are many interesting use cases for server side but they all seem to be toyish.The locking behavior of SQLite is somewhat problematic unless you use WAL and even then not perfect	endisneigh	13.58496	-5.5257163	comment	11.0	47.0	1686613599	9.827542
28668615	SQLite Archive Files (2018)	SQLite Archive Files (2018)	alfonsodev	13.555955	-5.559582	story	11.0	166.0	1632733869	9.818292
29460240	How SQLite Is Tested	How SQLite Is Tested	thunderbong	13.635637	-5.6081805	story	11.0	164.0	1638801667	9.851864
29461127	There are over one trillion SQLite d	There are over one trillion SQLite databases in active use	nothrowaways	13.573013	-5.5289526	story	11.0	148.0	1638805594	9.814003
34477615	SQLite Code of Conduct: First of all	SQLite Code of Conduct: First of all, love the Lord God with your whole heart	vinnyglennon	13.690609	-5.596783	story	11.0	34.0	1674397142	-8.702965
34969491	sqlean: A set of SQLite extensions	sqlean: A set of SQLite extensions	chmaynard	13.598783	-5.575368	story	11.0	236.0	1677593654	9.84142
36582255	SQLite-based databases on the Postgr	SQLite-based databases on the Postgres protocol? Yes we can	thunderbong	13.538354	-5.439635	story	11.0	202.0	1688445027	9.807457
36612192	I've just been exploring serving lar	I've just been exploring serving large SQLite databases in chunks and querying them with http range requests to prevent downloading the entire database. It's pretty awesome!I found a really interesting library called sql.js-httpvfs[0] that does pretty much all the work. I chunked up my 350Mb sqlite db into 43 x 8Mb pieces with the included script and uploaded them with my static files to GitHub, which gets deployed via GitHub Pages.[1]It's in the very rough early stages but you can check it out here.https://transcript.fishI recommend going into the console and network tab to see it in action. It's impressively quick and I haven't even fine-tuned it at all yet. SQLite rules.[0] https://github.com/phiresky/sql.js-httpvfs[1] https://github.com/noman-land/transcript.fish	noman-land	13.53986	-5.5176535	comment	11.0	61.0	1688625884	9.749109
37555812	The problem with SQLite is that it's	The problem with SQLite is that it's not a standardized file format. It's well-documented and pretty well understood for sure, but there's no ISO standard defining how to interpret an SQLite file in excruciating detail. Same goes for competing implementations, Zip and XML have a much smaller API surface than SQLite, whose API, apart from a bunch of C functions,  is the SQL language itself. Writing an XML parser is not a trivial task, but it's still simpler than writing an SQL parser, query optimizer, compiler, bytecode VM, full-text search engine, and whatever else Sqlite offers, without any data corruption in the process. If Open Office used SQLite, its programmers would inevitably start using its more esoteric features and writing queries that a less-capable engine wouldn't be able to op	miki123211	13.585765	-5.5776515	comment	11.0	65.0	1695043741	9.810453
24473846	My least favorite part of database d	My least favorite part of database design is the bit where you have to pick lengths for your char columns.Twenty years in and I'm still picking these pretty much by guessing. And when I guess wrong it causes really annoying problems further down the line.I love how SQLite doesn't make me do this - it just has a TEXT type which is always unlimited in length.	simonw	13.552814	-5.581024	comment	11.0	48.0	1600110340	-4.889557
38600743	Marmot: Multi-writer distributed SQL	Marmot: Multi-writer distributed SQLite based on NATS	summarity	13.594826	-5.5448356	story	11.0	120.0	1702303742	9.821683
38668282	I never used/tried MongoDB, what are	I never used/tried MongoDB, what are the reasons people choose MongoDB over other DBs?	goenning	13.657327	-5.3245916	comment	11.0	64.0	1702765147	9.877893
38887252	Show HN: Hashmap.me – Simple HTTP-Ba	Show HN: Hashmap.me – Simple HTTP-Based Data Storage and Retrieval	MrRowTheBoat	13.583101	-5.3308263	story	11.0	37.0	1704503522	9.82348
32682068	In 2018, folks were getting 4M queri	In 2018, folks were getting 4M queries per second using SQLite (BedrockDB) [0].This was also accomplished from just 1 server, not needing 40 shards like blog post.[0] https://blog.expensify.com/2018/01/08/scaling-sqlite-to-4m-q...	tiffanyh	13.582181	-5.4971504	comment	11.0	47.0	1662061772	9.78293
32750676	How the SQLite virtual machine works	How the SQLite virtual machine works	danielskogly	13.614551	-5.5856023	story	11.0	390.0	1662558915	9.856069
32752243	I wonder how an alternate timeline m	"I wonder how an alternate timeline might have played out if Richard Hipp had not named it ""SQLite"" and instead called it ""SQLightning"" or ""SQLExpress"" or something like that. For much of its lifetime, SQLite wasn't taken seriously despite being an extraordinary technology and part of me is convinced it was in large part due to ""Lite"" being in the name."	avl999	13.639884	-5.576523	comment	11.0	76.0	1662565798	-5.046721
32195541	SpatiaLite: Extends SQLite core to s	SpatiaLite: Extends SQLite core to support Spatial SQL capabilities	thunderbong	13.603464	-5.5462537	story	11.0	164.0	1658514845	9.823073
32240230	LiteFS a FUSE-based file system for 	LiteFS a FUSE-based file system for replicating SQLite	sysbot	13.527886	-5.4959917	story	11.0	241.0	1658852068	9.714074
22262512	I’m sorry but the name of the databa	I’m sorry but the name of the database needs to change. It’s like if I named my company “Disgusting Bug Company” then expected everyone to ignore the fact I named my company after a gross creature. Call it “RockSolidDB” and you get the same point across without invoking gross bugs.	seibelj	13.671207	-5.2145767	comment	11.0	37.0	1581040553	-4.6698647
12578509	> People who understand SQL can empl	"> People who understand SQL can employ the sqlite3 command-line shell to analyze large datasets.And a bit further down:> SQLite database is limited in size to 140 terabytes [...] if you are contemplating databases of this magnitude [use something else]Yeah no. ""Large datasets"" here means a few megabytes. I figured that out the hard way:I had a database of about 70 megabytes and ran a query with ""COUNT(a)"" and ""GROUP BY b"" on it. This makes it write multiple gigabytes to /tmp until it goes ""out of disk space"" (yeah /tmp on my ssd isn't large).I heard nothing but awesome and success stories about SQLite until a few weeks ago when this fiasco happened. I still like SQLite for its simplicity and last week I used it again for another project, but analyzing ""large"" datasets? Maybe with a simple "	lucb1e	13.551368	-5.4973516	comment	11.0	37.0	1474852543	9.797619
12660533	RethinkDB needs a new home	RethinkDB needs a new home	chrisabrams	13.693734	-5.283841	story	11.0	302.0	1475847357	-12.803872
19069553	A brief history of the UUID (2017)	A brief history of the UUID (2017)	tosh	13.993971	-5.2127323	story	11.0	113.0	1549202047	-13.663939
15795543	The biggest thing MongoDB got right 	The biggest thing MongoDB got right was putting developer first, optimize for initial experience and development speed.Most database systems came from relation theory background and optimize for performance, operations, data safety, but often developer convenience was sacrificed.Did anybody liked writing data migration? Try explaining value of table migration to some Product Manager of early startup :-).You can argue if that's were the right tradeoffs, but that's how MongoDB get a lot of steam.	jakozaur	13.67957	-5.320233	comment	11.0	66.0	1511859752	9.887481
16050449	"""For instance, a database of hobbyis"	"""For instance, a database of hobbyist club members could include uniqueness on the two columns first_name, last_name of members. Duplicates are likely unintentional at this scale, and if necessary the constraint can be dropped. Until an actual conflict happens the key is a reasonable precaution.""Absolutely do not do this.People have names that are duplicates. A situation where someone is unable to join a club because their name clashes with an existing member is not OK.Expecting a club administrator to be able to drop a uniqueness key from their database in order to resolve this situation is not a reasonable solution!"	simonw	13.6457205	-5.4025207	comment	11.0	76.0	1514878097	4.1124496
17135430	The article contains a footnote abou	The article contains a footnote about UUIDs as primary keys.> UUID as a primary key is a terrible idea, by the way — cryptographic randomness is utterly designed to kill locality of reference, hence the performance penaltyIs there anyone who can go a little bit more in detail?We planned to migrate our database to use UUIDs as primary keys. This will allow creating new rows on clients knowing the new primary key before sending them to the server (simplifying client and server code).	foxylion	13.973074	-5.2231293	comment	11.0	74.0	1527092838	-13.658588
21163614	Glad to see SQLite on then front pag	"Glad to see SQLite on then front page -- it's one of the  silent workhorses of the modern programming/database world. It is the most widely deployed database[0]. If you haven't given it a look/aren't interested in it since it seems to be a ""toy"" database (often the ""test"" or ""local"" db for frameworks like rails or django), you owe it to yourself to see what it can really do. Easy to use full text search[1][2], CTEs[3], JSON support via extension[4] (also the extension system is worth looking at[5]) and much much more. There are certainly things that SQLite does not do, and that's well documented too[6].If all this doesn't convince you to use SQLite, it's also one of the most well documented large C codebases that is fantastic to learn from.I'd go as far as to say that many modern startups "	hardwaresofton	13.597439	-5.530438	comment	11.0	76.0	1570245532	9.824536
21353243	Having client state just be a replic	Having client state just be a replica of server state solves so many problems I don't understand why the concept never caught on. Pouchdb/couchdb are still the only ones doing it afaik.Instead we have a bajillion layers of CRUD all in slightly different protocols just to do the same read or write to the database.	throwaway_bad	13.563918	-5.2156467	comment	11.0	52.0	1571995706	9.663084
17964243	SQLite: Infinite loop due to the ‘or	SQLite: Infinite loop due to the ‘order by limit’ optimization	ScottWRobinson	13.599705	-5.548163	story	11.0	144.0	1536707530	9.7917185
18284544	This is off topic, and I might get d	"This is off topic, and I might get downvoted, but I realized I am teed up waiting for the ""mongoDB hate"" comments to role in... seems to be not a lot of love on HN for MongoDB.I wonder what positive use cases people have used Mongo for? I've used it for a few small/medium sized projects without problem myself."	wiremine	13.6816435	-5.3148284	comment	11.0	56.0	1540310509	9.892011
29728975	We've been using SQLite in productio	We've been using SQLite in production as our exclusive means for getting bytes to/from disk for going on 6 years now. To this day, not one production incident can be attributed to our choice of database or how we use it.We aren't using SQLite exactly as intended either. We have databases in the 100-1000 gigabyte range that are concurrently utilized by potentially hundreds or thousands of simultaneous users. Performance is hardly a concern when you have reasonable hardware (NVMe/SSD) and utilize appropriate configuration (PRAGMA journal_mode=WAL).In our testing, our usage of SQLite vastly outperformed an identical schema on top of SQL Server. It is my understanding that something about not having to take a network hop and being able to directly invoke the database methods makes a huge diffe	bob1029	13.570815	-5.5028076	comment	11.0	79.0	1640806285	9.77824
29846074	Mongoid docs[1] seem to be pretty co	"Mongoid docs[1] seem to be pretty cool about this change:""As of Mongoid 7.1, logical operators (and, or, nor and not) have been changed to have the the same semantics as those of ActiveRecord. To obtain the semantics of or as it behaved in Mongoid 7.0 and earlier, use any_of which is described below.""Is it just me or is this one of the most terrible breaking changes in a popular, official library ever?[1] https://docs.mongodb.com/mongoid/current/tutorials/mongoid-q..."	warpech	13.6748	-5.3783946	comment	11.0	54.0	1641596227	9.9166765
30417411	Show HN: Google Drive to SQLite	Show HN: Google Drive to SQLite	simonw	13.589871	-5.5960045	story	11.0	305.0	1645459939	9.8108635
30429280	Do Not Recommend: User Provided Prim	Do Not Recommend: User Provided Primary Keys	tempodox	13.850599	-5.2525935	story	11.0	81.0	1645544585	-13.641493
30636796	Ws4sqlite: Query SQLite via HTTP	Ws4sqlite: Query SQLite via HTTP	thunderbong	13.583119	-5.558478	story	11.0	132.0	1646978316	9.864562
27909489	Out of curiosity, why did Mongo get 	Out of curiosity, why did Mongo get so popular? I used it in university when it was hyped and it was pleasant to get started with. The ability to query your data is so inconvenient though, I switched to SQL and I'm confused about what made experienced developers switch from SQL to mongo in the past. Is it just because you can scale up more easily when your database gets massive?Like NodeJS and many web technologies, almost everything I read about it years ago turned out to be hype and not based on facts (eg, nodejs being faster for large numbers of requests than traditional backends is not true, but it was widely repeated on the first 10 pages of google search results)edit: very well said, thanks for all the replies!	gentleman11	13.66193	-5.3326206	comment	11.0	48.0	1626889448	9.916676
12111403	A Postgres Perspective on MongoDB	A Postgres Perspective on MongoDB	tdurden	13.624547	-5.370565	story	11.0	138.0	1468783910	9.889373
22368841	SQLite is a wonderful database. We u	SQLite is a wonderful database. We use it in production many times over for all of our clients. Not having to worry about whatever arbitrary SQL Server installation is available in a particular environment has saved us so much time and frustration. Combine SQLite with .NET Self-Contained Deployments means that we (our automated tools) now copy our software distribution zip to target, extract to path, run executable as administrator and walk away. Without SQLite we could not do this.Migrations are also hilariously easy with SQLite if you use the user_version pragma. We have a monotonically-incrementing number to indicate each version. Our migrator first queries this upon startup and runs all the migrations that exist between current user_version and whatever our highest sequence # is (defin	bob1029	13.589336	-5.5511603	comment	11.0	103.0	1582139087	9.844305
22834036	Comparison of Joins: MongoDB vs. Pos	Comparison of Joins: MongoDB vs. PostgreSQL	ahachete	13.622823	-5.362036	story	11.0	62.0	1586532675	9.892599
23185658	Ask HN: What is your opinion on mong	Ask HN: What is your opinion on mongo db?	kamalkishor1991	13.608778	-5.361757	story	11.0	12.0	1589491293	9.908112
23282791	While I love SQLite as much as the n	While I love SQLite as much as the next person (and the performance and reliability is really quite remarkable), I can’t understand all the effusive praise when you can’t do basic things like dropping columns. How do people get around this? Do you just leave columns in forever? Or go through the dance of recreating tables every time you need to drop a column?	ha470	13.599936	-5.575711	comment	11.0	48.0	1590240837	9.853404
33182417	Hosting SQLite databases on any stat	Hosting SQLite databases on any static file hoster (2021)	punnerud	13.568561	-5.51646	story	11.0	199.0	1665605565	9.864253
33329184	Stranger Strings: An exploitable fla	Stranger Strings: An exploitable flaw in SQLite	eatonphil	13.642437	-5.586301	story	11.0	337.0	1666698043	9.866836
33700077	I had a database table where I used 	I had a database table where I used UUID as primary key. Big mistake. Haunts us to this day.Not sortable. Takes a lot of space. Table relationships are annoying. Etc.What we do instead is have a secondary UUID key and keep Bigint as primary keys. Then use the UUID column in the external context instead.UUIDs are fine for 99.99999% of the time in your own domain.Don’t expect universal uniqueness across all domains.	eric4smith	13.966546	-5.2215137	comment	11.0	61.0	1669076069	-13.663238
37595578	Serious question: Why use MongoDB wh	Serious question: Why use MongoDB when Postgres supports indexed dynamic json?	romanovcode	13.540067	-5.4614697	comment	11.0	97.0	1695291100	9.840101
37850833	Evolving ArangoDB's Licensing Model 	Evolving ArangoDB's Licensing Model for a Sustainable Future	hnbad	13.651213	-5.2639923	story	11.0	45.0	1697061683	9.941144
14797522	Mondo 2000 Issue 2 (1990)	Mondo 2000 Issue 2 (1990)	Famicoman	13.708737	-5.2787676	story	11.0	55.0	1500393369	14.157809
15236096	OT: Postgres is an incredible piece 	OT: Postgres is an incredible piece of open source software, but the official admin UI pgAdmin is in a state of complete chaos. Any suggestions for an OSS replacement?	danmaz74	13.520039	-5.4186115	comment	11.0	37.0	1505285817	9.934132
23412482	Clang-11.0.0 Miscompiled SQLite	Clang-11.0.0 Miscompiled SQLite	marcobambini	13.642214	-5.6073947	story	12.0	302.0	1591245559	9.843129
23508026	Jepsen's latest analysis of MongoDB 	Jepsen's latest analysis of MongoDB -- https://jepsen.io/analyses/mongodb-4.2.6 -- finds that it doesn't even preserve snapshot isolation when set at the highest consistency level. This seems like a pretty terrible decision.I've never wanted to short a company more in my life.	sohamsankaran	13.621675	-5.289732	comment	12.0	114.0	1592039382	9.861191
20775992	SuperSQLite: SQLite library for Pyth	SuperSQLite: SQLite library for Python (2018)	jkldotio	13.601833	-5.5928206	story	12.0	135.0	1566554984	9.853149
20862123	Would love to see an overview of com	Would love to see an overview of companies that fell into the mongoDB trap and have / are migrating to another DB store.	thiscatis	13.700892	-5.2884674	comment	12.0	135.0	1567462578	9.862134
14304618	Ask HN: Posgresql JSON or MongoDB?	Ask HN: Posgresql JSON or MongoDB?	ssijak	13.532971	-5.4570055	story	12.0	37.0	1494371100	9.851574
14548805	Daisy: A private blockchain where bl	Daisy: A private blockchain where blocks are SQLite databases, in Go	syncopate	13.61859	-5.5456467	story	12.0	105.0	1497389259	-2.4455047
31519097	I've noticed a large number of stori	I've noticed a large number of stories on HN related to SQLite over the past few weeks. Maybe it's just random or I'm only now just noticing it, but is there some renewed/newfound interest in SQLite lately? If so, what's behind that?	xwowsersx	13.624352	-5.574935	comment	12.0	45.0	1653576969	9.831774
31716494	I used to be a big proponent of usin	"I used to be a big proponent of using UUIDs for database PKs but I've found them inherently difficult to work with.  It's much easier to remember/recognize an integer based PK when troubleshooting a data problem.This isn't to say you shouldn't use UUIDs at all, but I much prefer to use an ""ExternalId"" column of UUID type if you don't want to expose your integer based PKs externally."	GiorgioG	13.98123	-5.210681	comment	12.0	101.0	1655055670	-13.662503
26162115	Command Line Shell for SQLite	Command Line Shell for SQLite	happy-go-lucky	13.561954	-5.563242	story	12.0	155.0	1613530588	9.847224
35547819	SQLite performance tuning: concurren	SQLite performance tuning: concurrent reads, multiple GBs and 100k SELECTs/s	Maksadbek	13.558169	-5.5142198	story	12.0	219.0	1681337995	9.744807
35862177	"I hate to be the guy who says ""you a"	"I hate to be the guy who says ""you aren't doing services right,"" but... you aren't doing services right.> Each service has to be maintained and deployed and increases the boilerplate needed for shared data structures, complicated communication protocols and infrastructure. By the time we released our app, the common library used by most services has been updated over a hundred times. And every service has to follow suit eventually.Shared data structures? Common library? Services have an API. If you are sharing data structures and a common ""core"" library across services, yes, you are officially doing it wrong. From the architecture diagram it also looks like there's only one MongoDB instance, which, if you have multiple services talking to the same database[0], is also a major sign that you"	mjr00	13.605457	-5.3140445	comment	12.0	101.0	1683557575	9.872728
29002377	To any who might see this, I'm the a	To any who might see this, I'm the author of the blog post, and led the engineering team that built CockroachDB Serverless. I'll be monitoring this thread in case there are any questions you'd like to ask me about it.	andydb	13.676806	-5.191745	comment	12.0	56.0	1635265510	9.92325
29164215	I'll stop short of giving a recommen	"I'll stop short of giving a recommendation or using the word ""should"", but ill give encouragement to consider using uuid's for keys. I have used them in several systems and have never had any issues with them, and they solve so many issues. The ability to generate a key on the client or on the server or in the database is great for one. And the fact that keys are unique not only in a table but in the system (or many systems) is a huge advantage."	netcraft	13.967638	-5.2171626	comment	12.0	76.0	1636477268	-13.660336
34517474	SQLite-based databases on the Postgr	SQLite-based databases on the Postgres protocol	matesz	13.563595	-5.4763885	story	12.0	259.0	1674649910	9.825353
34774357	SQLite WASM: Something subtle in the	SQLite WASM: Something subtle in the browser	zainab-ali	13.611033	-5.569871	story	12.0	90.0	1676301138	9.8478775
36831789	I think SQLite is fantastic and Rich	I think SQLite is fantastic and Richard is obviously a genius. But I always found his obsession with single binary monoliths odd.As you mentioned it goes against the Unix philosophy of do one thing and do it well. To me it's obviously cleaner to divide a system into components that can later be swapped or modified independently.	jayski	13.584488	-5.552365	comment	12.0	87.0	1690076403	9.859857
39051760	Text Processing Practice Expt: 27 SE	Text Processing Practice Expt: 27 SERP Types to SQLite (yy084)	1vuio0pswjnm7	13.588355	-5.5720334	story	12.0	3.0	1705640769	9.838843
32675861	SQLite: Past, Present, and Future	SQLite: Past, Present, and Future	chrstr	13.605149	-5.5793123	story	12.0	282.0	1662038455	9.871531
32159339	Who are the large Mongo customers? I	Who are the large Mongo customers? It “seems” like it died 10-15 years ago, but clearly they’re still going.	cmer	13.720046	-5.281813	comment	12.0	73.0	1658273485	9.936228
22153390	I think a good under-appreciated use	I think a good under-appreciated use case for SQLite is as a build artifact of ETL processes/build processes/data pipelines. Seems like lot of people's default, understandably, is to use JSON as the output and intermediate results, but if you use SQLite, you'd have all the benefits of SQL (indexes, joins, grouping, ordering, querying logic, and random access) and many of the benefits of JSON files (SQLite DBs are just files that are easy to copy, store, version, etc and don't require a centralized service).I'm not saying ALWAYS use SQLite for these cases, but in the right scenario it can simplify things significantly.Another similar use case would be AI/ML models that require a bunch of data to operate (e.g. large random forests). If you store that data in Postgres, Mongo or Redis, it beco	nicholaides	13.532352	-5.5390687	comment	12.0	75.0	1580060289	9.764643
19499142	I would argue that MongoDB is not—an	"I would argue that MongoDB is not—and has never been—the best choice for solving any particular technical problem. But it had some other ""advantages"" over other, better solutions – in that it was easier to set up, didn't require schema definition, had a passable clustering story etc.I have worked with at least one company that had been built using MongoDB as a primary data store from day one. This caused untold pain later on, but the trade-off is that it likely allowed the company to exist at all – the founder being more of a domain expert than a technical expert, but being able to use it to scale their idea pretty quickly without having to pay much attention to all that tedious ""reliability"" and ""safety"" nonsense :)That said, it's not something that an experienced developer should be usin"	matthewmacleod	13.662469	-5.321946	comment	12.0	64.0	1553677975	9.8786
19867943	PostgreSQL 11.3 and 10.8	PostgreSQL 11.3 and 10.8	oskari	13.523275	-5.3978643	story	12.0	281.0	1557407647	-13.109176
18313131	SQLite updated Code of Conduct	SQLite updated Code of Conduct	Daviey	13.671054	-5.604805	story	12.0	41.0	1540592628	9.872735
29728786	Am I the only one who thinks SQLite 	Am I the only one who thinks SQLite is still too complicated for many programs? Maybe it's just the particular type of software I normally work on, which tends towards small, self-hosted networking services[0] that would often have a single user, or maybe federated with <100 users. These programs need a small amount of state for things like tokens, users accounts, and maybe a bit of domain-specific things. This can all live in memory, but needs to be persisted to disk on writes. I've reached for SQLite several times, and always come back to just keeping a struct of hashmaps[1] in memory and dumping JSON to disk. It's worked great for my needs.Now obviously if I wanted to scale up, at some point you would have too many users to fit in memory. But do programs at that scale actually need to e	anderspitman	13.598865	-5.5257344	comment	12.0	55.0	1640805476	9.820333
29852828	I recently read a book by Google’s h	I recently read a book by Google’s head guy on API design that was specifically about designing APIs and it had a big section on what makes a good identifier and why people reach for UUIDs and why specifically it is a problem on multiple levels.The thing that he ended up recommending however was super interesting in that I had never seen it mentioned before but it was basically to use this instead http://www.crockford.com/base32.html	mhoad	13.974156	-5.2043314	comment	12.0	64.0	1641657413	-13.655052
13374885	I have never used MongoDB so I admit	I have never used MongoDB so I admit I'm talking blind here, but can someone explain how/why a piece of highly popular software gets to version 2.6 allowing unsecured remote connections by default?  Further to that is that type of thinking you want in the development process of something as critical as a database engine?  It just seems amazing to me that it got so far before the community in general pushed back that this was really bad design?  Hopefully someone with MongoDB history can explain if this was a long term sticking point, etc.  Thanks.	51Cards	13.720448	-5.2610974	comment	12.0	90.0	1484150787	9.938152
13376487	When our sysadmin set up our Mongo c	When our sysadmin set up our Mongo cluster, he firewalled out all IPs except our production systems, turned on authentication, set things up to ensure we used SSL, and configured backups.He didn't do this because he's an amazing sysadmin. He did it because he's competent, knows how to put a service on the Internet, and RTFM.I mean. If you can connect to something and use it without having to authenticate yourself, wouldn't it naturally cross your mind to check that others can't do the same? It's just common sense.	mike-cardwell	13.717961	-5.2469563	comment	12.0	75.0	1484161210	9.961066
33082589	I don't like how the 'manifesto' pre	"I don't like how the 'manifesto' presents SQLite's code of ethics as nefarious:    We take our code of conduct seriously, and unlike SQLite, we do not substitute it with an unclear alternative. We strive to foster a community that values diversity, equity, and inclusion. We encourage others to speak up if they feel uncomfortable.

It seems in bad faith to imply that SQLite is some sort of toxic, anti-diversity space. It's not. it's just a closed-to-contributions open source project. Richard is pretty friendly guy and I'm not certain if efforts have been made to reach out to him here.https://github.com/libsql/libsql/blob/main/README.md"	adamgordonbell	13.648865	-5.5941586	comment	12.0	97.0	1664900334	-8.868438
33099222	LibSQL is an open source, open contr	LibSQL is an open source, open contribution fork of SQLite	rmason	13.648543	-5.572499	story	12.0	38.0	1664993911	5.5945077
33204347	Litestream live replication has been	Litestream live replication has been moved to the LiteFS project	hardwaresofton	13.557718	-5.5006337	story	12.0	90.0	1665759236	9.735968
33894995	Go and SQLite in the Cloud	Go and SQLite in the Cloud	subomi	13.611524	-5.599405	story	12.0	145.0	1670424979	9.849018
34021320	Is there any reason to want to use S	Is there any reason to want to use SQLite for Wordpress? Its always great to have more options, but Im unclear as to why someone would use that instead of MySQL	danjoredd	13.608992	-5.5631437	comment	12.0	48.0	1671229136	9.811647
14729239	Elevate your C programming skills by	Elevate your C programming skills by exploring the SQLite codebase	cpprepository	13.634283	-5.6055274	story	12.0	105.0	1499599004	9.878162
14812070	ArangoDB 3.2 GA  RocksDB, Pregel, Fa	ArangoDB 3.2 GA  RocksDB, Pregel, Fault-Tolerant Foxx and Satellite Collections	bjerun	13.58855	-5.279686	story	12.0	124.0	1500555751	9.931733
15303210	Anko SQLite, a library to simplify w	Anko SQLite, a library to simplify working with SQLite on Android	andraskindler	13.616128	-5.57393	story	12.0	108.0	1506001107	9.851385
15525715	Getting the Most Out of Sqlite3 with	Getting the Most Out of Sqlite3 with Python	pythux	13.602758	-5.580406	story	12.0	191.0	1508659996	9.864101
15605669	A Minimalist Guide to SQLite	A Minimalist Guide to SQLite	craigkerstiens	13.60668	-5.582252	story	12.0	472.0	1509572095	9.825977
23510515	Select Code_execution from * Using S	Select Code_execution from * Using SQLite; (2019)	porker	13.626951	-5.606539	story	13.0	170.0	1592065375	9.839417
13614110	>Everything is an order of magnitude	">Everything is an order of magnitude more efficient using PostgreSQL than it was with RethinkDB.A large part of the sales pitch of ""NoSQL"" was that traditional RDBMSs couldn't handle ""webscale"" loads, whatever that meant.Yet somehow, we continue to see PostgreSQL beating Mongo, Rethink, and other trendy ""NoSQL"" upstarts at performance, one of the primary advantages they're supposed to have over it.Let's be frank. The only reason ""NoSQL"" exists at all is 20-something hipster programmers being too lazy to learn SQL (let alone relational theory), and ageism--not just against older programmers, but against older technology itself, no matter how fast, powerful, stable, and well-tested it may be.After all, PostgreSQL is ""old,"" having its roots in the Berkeley Ingress project three decades ago. C"	living-fossil	13.521029	-5.4070945	comment	13.0	59.0	1486716555	9.826885
14625702	Inventory management in MongoDB: A d	Inventory management in MongoDB: A design philosophy I find baffling	douche	13.660774	-5.337914	story	13.0	127.0	1498314645	9.87965
36590834	Show HN: MongoDB Protocol for SQLite	Show HN: MongoDB Protocol for SQLite	aleksi	13.556566	-5.465043	story	13.0	147.0	1688495711	9.8417
16713685	Wapp – a single-file web framework b	Wapp – a single-file web framework by the creator of SQLite	networked	13.56685	-5.5408926	story	13.0	411.0	1522384205	9.835237
17766799	SQLite – The “server-process-edition	SQLite – The “server-process-edition” branch	yread	13.588193	-5.549215	story	13.0	236.0	1534346972	9.79889
21378319	SQLite is easy to compile	SQLite is easy to compile	nikbackm	13.616585	-5.5864906	story	13.0	192.0	1572279655	9.8458
18366385	Why you should never, ever, ever use	Why you should never, ever, ever use MongoDB	wheresvic1	13.69301	-5.3241134	story	13.0	98.0	1541190048	9.887704
18749385	Sqlite – Most Deployed Database in t	Sqlite – Most Deployed Database in the World	gitgud	13.601236	-5.5526004	story	13.0	148.0	1545611062	9.826468
30073605	Whenever SQLite comes up, always hav	Whenever SQLite comes up, always have to link to this post about using SQLite in production: https://blog.wesleyac.com/posts/consider-sqlite :)I'm running https://extensionpay.com off SQLite and a $5/month DigitalOcean box and it's serving around 3 million requests a month with absolutely no issues and seriously low CPU load. I'm kind of astonished, frankly.	Glench	13.598955	-5.516337	comment	13.0	71.0	1643127477	9.80279
12617853	Sleepless nights with MongoDB WiredT	Sleepless nights with MongoDB WiredTiger and our return to MMAPv1	kiyanwang	13.691784	-5.3208547	story	13.0	51.0	1475330226	9.895006
12630682	Is RethinkDB shutting down?	Is RethinkDB shutting down?	nodesocket	13.675796	-5.2850685	story	13.0	135.0	1475523953	-12.816821
13599803	The AWS and MongoDB Infrastructure o	The AWS and MongoDB Infrastructure of Parse	DivineTraube	13.615528	-5.266543	story	13.0	223.0	1486573164	9.881323
27551444	I have never understood why RDBs hav	I have never understood why RDBs have such general concepts of primary keys, where you can for example let date of birth be a primary key, when in every schema I have ever designed or seen, all rows get unique integer IDs anyway.	whatshisface	13.838513	-5.272281	comment	13.0	97.0	1624030467	-13.646856
26683832	SQLite Plus: Missing SQLite function	SQLite Plus: Missing SQLite functions	tosh	13.628335	-5.59437	story	13.0	214.0	1617477236	9.863031
27343026	You Don't Need UUID	You Don't Need UUID	henvic	13.991819	-5.2120028	story	13.0	33.0	1622461483	-13.668913
24644765	After discovering ULIDs [0] I can't 	After discovering ULIDs [0] I can't see ever using UUIDs ever again.ULIDs are sortable (time component), short (26 chars) and nearly human readable, and good enough entropy/randomness for everything I'd ever be working on.Does anyone have any criticisms of ULIDs? I can't see how they don't take over general purpose use of unique ids in the future except where a more guarantee of uniqueness is needed. (ie, bajillion records a second unique...)[0] https://github.com/ulid/spec	Vanderson	13.984395	-5.215031	comment	13.0	75.0	1601504844	-13.671068
36302805	Why sqlite3 temp files were renamed 	Why sqlite3 temp files were renamed 'etilqs_*' (2006)	bsmith89	13.621118	-5.58933	story	14.0	396.0	1686612028	9.874744
34689624	OpenAI-to-SQLite	OpenAI-to-SQLite	thunderbong	13.611404	-5.5733914	story	14.0	203.0	1675753060	9.859977
25167423	SQLite briefing for Linux kernel hac	SQLite briefing for Linux kernel hackers (2019)	symisc_devel	13.623872	-5.6161914	story	14.0	301.0	1605925391	9.833735
25226260	SQLite as a Document Database	SQLite as a Document Database	JNRowe	13.564095	-5.557265	story	14.0	239.0	1606461706	9.837224
38988949	SQLite: Wal2 Mode	SQLite: Wal2 Mode	finallyy	13.5792675	-5.5019097	story	14.0	444.0	1705225338	9.804933
32408334	I worked at a startup (now fairly po	I worked at a startup (now fairly popular in the US) where we had tables for each thing (users, companies, etc) and a “relationship” table that described each relationship between things. There were no foreign keys, so making changes were pretty cheap. It was actually pretty ingenious (the two guys who came up with the schema went on to get paid to work on k8s).It was super handy to simply query that table to debug things, since by merely looking for a user, you’d discover everything. If Mongo was more mature and scalable back then (2012ish), I wonder if we would have used it.	withinboredom	13.618243	-5.3630896	comment	14.0	114.0	1660112143	9.855198
22151431	> Of those that are serverless, SQLi	> Of those that are serverless, SQLite is the only one known to this author that allows multiple applications to access the same database at the same time.IIRC, MS Access allowed that, which explained a lot of its popularity.	oldgradstudent	13.528605	-5.4778895	comment	14.0	88.0	1580034923	9.801022
18991099	In the latest world of Postgres:- we	"In the latest world of Postgres:- we now have closed source Amazon Aurora infrastructure that boasts performance gains that might never see it back upstream (who knows if it's just hardware or software or what behind the scenes here)- we now have Amazon DocumentDB that is a closed source MongoDB-like scripting interface with Postgres under the hood- lastly, with this news, looks like Microsoft is now doubling down on the same strategy to build out infrastructure and _possibly_ closed source ""forked"" wins on top of the beautiful open source world that is PostgresPlease, please, please let's be sure to upstream! I love the cloud but when I go to ""snapshot"" and ""restore"" my PG DB I want a little transparency how y'all are doing this. Same with DocumentDB; I'd love an article of how they are u"	cdbattags	13.543113	-5.191067	comment	14.0	106.0	1548352791	9.763273
17764340	SQLite Release 3.25.0 adds support f	SQLite Release 3.25.0 adds support for window functions	MarkusWinand	13.639354	-5.6046214	story	14.0	333.0	1534319183	9.864472
39289246	SQLite vs. ObjectBox vs. Isar	SQLite vs. ObjectBox vs. Isar	vishnumohandas	13.6111965	-5.5731554	story	14.0	46.0	1707317544	9.844592
30630568	"Why would anyone try to ""hide their "	"Why would anyone try to ""hide their deep knowledge of Postgres""? Like, I could easily see someone having to hide their deep knowledge of MongoDB--lest they be branded forever as ""damaged""--but I've been under the impression that PostgreSQL skills are considered a really good thing this past decade or so... were they just really hoping to avoid becoming a database engineer, or were they maybe under threat of becoming an ""on call"" asset?"	saurik	13.554849	-5.3595767	comment	14.0	84.0	1646937177	9.826523
12723633	Open Source is not dead: On the rece	Open Source is not dead: On the recent demise of RethinkDB	EpicWaligora	13.674438	-5.2739472	story	14.0	117.0	1476696373	-12.808874
12901356	See a problem. Figure out how many p	See a problem. Figure out how many people it is a problem for. Figure out why no one else has solved that problem. Figure out if you know how to solve the problem. Figure out how much folks would be willing to pay for a solution to the problem. If you asses you are able to be fairly compensated (over long periods of time) for solving the problem after all your costs of solving it are reconciled: Commit to spending vast amounts of your resource to exploring and productizing the solution to said problem. This isn't the advice the author gives. However, here is another post written by the same author: https://rethinkdb.com/blog/rethinkdb-shutdown/	neom	13.668817	-5.2692785	comment	14.0	55.0	1478621396	-12.807067
13590385	MongoDB 3.4.0-rc3	MongoDB 3.4.0-rc3	aphyr	13.70514	-5.3202457	story	14.0	226.0	1486484496	9.91842
12158004	The Road to CouchDB 2.0	The Road to CouchDB 2.0	g4k	13.604918	-5.206744	story	14.0	98.0	1469447548	9.650441
12290931	My first introduction to databases w	"My first introduction to databases was with PHP/MySQL, where normalization was the name of the game. The whole point of normalization is that there is no duplication of data anywhere. If it's possible for duplicate data to exist, that's a symptom of a design flaw in the schema.I've been using Mongo recently, and every time I raise criticism of it, the counterargument I hear is ""forget about normalization! Duplication is okay.""Like the author, I really cannot wrap my head around this. While I understand that duplicating documents across collections may make querying faster, what about when you want to change the document? You need to propagate the change across every duplicate of the document in every collection where it exists. This means that any ""de-duplication"" logic needs to happen at "	chatmasta	13.606509	-5.3638234	comment	14.0	97.0	1471273754	9.86901
23285768	In the circles I run in, MongoDB is 	In the circles I run in, MongoDB is regarded as a joke and the company behind it as basically duplicitous. For example, they still list Facebook as their first user of MongoDB on their website, for example, but there is no MongoDB use in Facebook hasn't been for years (it came in only via a startup acquisition).I had the misfortune to use MongoDB at a previous job. The replication protocol wasn't atomic. You would find partial records that were never fixed in replicas. They claimed they fixed that in several releases, but never did. The right answer turned out to be to abandon MongoDB.	madhadron	13.74547	-5.3471417	comment	14.0	153.0	1590263076	9.8741665
34068384	WordPress to support SQLite back end	WordPress to support SQLite back end	eamann	13.604379	-5.569126	story	14.0	164.0	1671554530	9.896686
15125984	100% of my friends who have used Mon	100% of my friends who have used Mongo/similar NoSQL have given up and had a nasty rewrite back to pgSQL.This seems to be the journey:1. Lack of migrations is awesome! We can iterate so quickly for MVP2. Get users3. Add features, still enjoying the speed of iteration4. Get more users5. Start building reporting features for enterprise/customer support/product metrics (ie: when the real potential success starts)6. Realise you desperately need joins, transactions and other SQL features7. Pause product dev for 1-3+ months to migrate back to SQL, or do some weird parallel development process to move it piecemeal back.I think the most interesting question though is would they be able to get MVP and initial customers that set off this if they were moving (slightly) slower due to SQL and slight ov	martinald	13.644909	-5.3139677	comment	14.0	137.0	1504027808	-9.619699
15252740	Migrating from RethinkDB to Postgres	Migrating from RethinkDB to Postgres – An Experience Report	okket	13.597746	-5.3173065	story	14.0	135.0	1505425180	-12.788236
15510369	If they had done so by presenting a 	If they had done so by presenting a product that was picked up due to it's merit and continued to gain traction based on that then I'd be rather impressed.  Instead the story of MongoDB seems to be how extremely well targeted marketing and sales can build a so-so product into a huge IPO, there have been performance comparisons showing it isn't even the best at what it does so this IPO is riding on the network effect of those early stages of marketing alone.In our economy this is sadly an entirely valid route to making money but their mindshare is going to continue to collapse as the warts on their product show more and more.So the admiration you have should probably be directed at the wool the marketers behind MongoDB managed to pull over your eyes.	munk-a	13.721744	-5.282058	comment	14.0	90.0	1508437827	9.908163
23663071	How Does Sqlite Work? (2014)	How Does Sqlite Work? (2014)	_tw9j	13.613773	-5.579748	story	15.0	480.0	1593278238	9.848066
20367679	Ask HN: Who uses SQLite database in 	Ask HN: Who uses SQLite database in production?	thunderbong	13.57354	-5.5147195	story	15.0	25.0	1562384880	9.798534
13660987	CockroachDB beta-20161013	CockroachDB beta-20161013	aphyr	13.684136	-5.197247	story	15.0	309.0	1487261273	9.969877
14139402	Live Migrations, Queryable Backups a	Live Migrations, Queryable Backups and More AWS Regions in MongoDB Atlas	francesca	13.591097	-5.2330446	story	15.0	39.0	1492527968	9.815111
30875837	Postgres wire compatible SQLite prox	Postgres wire compatible SQLite proxy	ithkuil	13.584578	-5.4984455	story	15.0	288.0	1648796282	9.8416815
31038614	Migrating from SQLite to PostgreSQL	Migrating from SQLite to PostgreSQL	cloudsql	13.569315	-5.5018644	story	15.0	112.0	1650019351	9.858786
31214131	How to Corrupt an SQLite Database Fi	How to Corrupt an SQLite Database File	segfaultbuserr	13.603665	-5.5630484	story	15.0	225.0	1651304175	9.732932
31319133	> SQLite isn't just on the same mach	> SQLite isn't just on the same machine as your application, but actually built into your application process. When you put your data right next to your application, you can see per-query latency drop to 10-20 microseconds. That's micro, with a μ. A 50-100x improvement over an intra-region Postgres query.This is the #1 reason my exuberant technical mind likes that we use SQLite for all the things. Latency is the exact reason you would have a problem scaling any large system in the first place. Forcing it all into one cache-coherent domain is a really good way to begin eliminating entire universes of bugs.Do we all appreciate just how much more throughput you can get in the case described above? A 100x latency improvement doesn't translate directly into the same # of transactions per second	bob1029	13.565069	-5.491659	comment	15.0	185.0	1652127240	9.760888
25871605	Rqlite: The lightweight, distributed	Rqlite: The lightweight, distributed relational database built on SQLite	pavanyara	13.548527	-5.518017	story	15.0	231.0	1611323333	9.804678
26217930	Can anyone share some cool applicati	Can anyone share some cool applications or bigger production systems built with sqlite? I love virtually everything I read about it, but I have never encountered a single use case where I am not better served by storing the data in some flat file (parquet, csv, etc.) and running a pandas program or simple Spark program to analyze it (locally on my laptop, or through a managed service like Dataproc or Databricks - it’s exceedingly cheap for any data size conceivably processable with sqlite).I am asking sincerely, what is the comparative advantage of sqlite or some example scenarios or trade off circumstances where sqlite is a comparatively more effective solution?	mlthoughts2018	13.579235	-5.5198774	comment	15.0	85.0	1613946477	9.828743
36475081	Mycelite: SQLite extension to synchr	Mycelite: SQLite extension to synchronize changes across SQLite instances	thunderbong	13.578055	-5.5019345	story	15.0	248.0	1687746986	9.789919
29448906	FerretDB: A truly open-source MongoD	FerretDB: A truly open-source MongoDB alternative	kiyanwang	13.627621	-5.324036	story	15.0	136.0	1638708915	9.862061
34175639	ULIDs and Primary Keys	ULIDs and Primary Keys	s4i	13.943627	-5.2416816	story	15.0	133.0	1672336810	-13.654553
34258858	Why SQLite succeeded as a database (	Why SQLite succeeded as a database (2016)	Tomte	13.623309	-5.593436	story	15.0	128.0	1672922222	9.843536
34559814	There’s an industry wide fad (like C	There’s an industry wide fad (like ChatGPT) and then there’s a hacker news wide fad which is SQLite :-). Not sure how it all started. Last few months (or my be even an year) there has been an unprecedented number of SQLite posts. What gives?	posharma	13.614855	-5.568977	comment	15.0	57.0	1674928776	9.853507
34813140	This sentiment pops up regularly on 	"This sentiment pops up regularly on HN, and I've seen at least one article per month for the past few months, but the trouble is, none of them seem to help you actually deploy it. They assume you're comfortable spinning up public web servers.If you want to use a PaaS to deploy an app, because you don't want to spend your time learning to be a sysadmin, then all the tutorials are going to put you on the Postgres path, because that's what's supported. (Of course, you'll then end up paying $15+/mo for Postgres, which is hilarious for most hobby projects storing 50MB of data.) But in reality, you could just scale vertically on one machine and be completely fine. No need for ""distributed"" anything, in theory.I took a shot at productionizing SQLite here as an experiment: https://cheapo.onrender."	irskep	13.564845	-5.4940243	comment	15.0	180.0	1676507216	9.755726
39416986	> It is generally a good practice to	"> It is generally a good practice to not expose your primary keys to the external world. This is especially important when you use sequential auto-incrementing identifiers with type integer or bigint since they are guessable.What value would there be in preventing guessing?  How would that even be possible if requests have to be authenticated in the first place?I see this ""best practice"" advocated often, but to me it reeks of security theater.  If an attacker is able to do anything useful with a guessed ID without being authenticated and authorized to do so, then something else has gone horribly, horribly, horribly wrong and that should be the focus of one's energy instead of adding needless complexity to the schema.The only case I know of where this might be valuable is from a business in"	yellowapple	13.950265	-5.2246547	comment	15.0	73.0	1708241568	-13.643825
39417503	Wddbfs – Mount a SQLite database as 	Wddbfs – Mount a SQLite database as a filesystem	vitplister	13.582295	-5.555584	story	15.0	290.0	1708247733	9.806642
36884806	WordPress Core to start using SQLite	WordPress Core to start using SQLite	JPLeRouzic	13.648261	-5.594893	story	15.0	134.0	1690404597	9.85818
25216530	Everything You Know About MongoDB Is	Everything You Know About MongoDB Is Wrong	scapbi	13.699955	-5.3216195	story	15.0	41.0	1606360824	9.901672
38626698	I benchmarked six Go SQLite drivers	I benchmarked six Go SQLite drivers	cvilsmeier	13.620647	-5.615939	story	15.0	192.0	1702472435	-5.7932534
32367982	Google Trying to Solve a UUID	Google Trying to Solve a UUID	delduca	13.998821	-5.214036	story	15.0	307.0	1659793104	-13.650357
16561022	Migrating Our Django App from MariaD	Migrating Our Django App from MariaDB Galera to PostgreSQL and Patroni	_rami_	13.523427	-5.3857994	story	15.0	81.0	1520729351	9.909388
17041591	SQLite Query Language: upsert	SQLite Query Language: upsert	coleifer	13.598517	-5.586479	story	15.0	248.0	1525976410	9.815706
21516322	CockroachDB 19.2	CockroachDB 19.2	irfansharif	13.686226	-5.2	story	15.0	141.0	1573581584	10.008852
18044380	100% naive question: why is mysql an	100% naive question: why is mysql and their similars so popular then?Spanner and AWS Aurora base off of more mysql than postregsql from what I can tell.  Why?	mrep	13.529449	-5.3320146	comment	15.0	89.0	1537588890	-6.0897574
18273390	SQLite Code of Conduct	SQLite Code of Conduct	lazyloop	13.651935	-5.5982842	story	15.0	157.0	1540202358	9.872086
12642060	Slava @ RethinkDB here. I am not abl	Slava @ RethinkDB here. I am not able to get into details yet, but the short version is that the commercial entity behind RethinkDB is shutting down. We're working on continuity for the open-source project. Full announcement (and details) coming in a day or two.	coffeemug	13.674985	-5.281997	comment	15.0	46.0	1475651967	-12.810098
13317045	Unsecured MongoDBs taken hostage	Unsecured MongoDBs taken hostage	xyunknown	13.709946	-5.2785387	story	15.0	83.0	1483525338	9.917956
33083259	> The few core developers they have 	"> The few core developers they have do not work with modern tools like git and collaboration tools like Github, and don’t accept contributions, although they may or may not accept your suggestion for a new feature request.The funny thing about this comment is that SQLite is as close to the gold standard of software quality that we have in the open source world. SQLite is the only program that I've ever used that reliably gets better with every release and never regresses. Could it be that this is precisely because they don't use ""modern tools"" and accept outside contributions?"	diffxx	13.609807	-5.581406	comment	15.0	115.0	1664902891	9.860909
33272824	Quirks, Caveats, and Gotchas in SQLi	Quirks, Caveats, and Gotchas in SQLite	thefilmore	13.612321	-5.583115	story	15.0	124.0	1666262909	9.860765
14804757	Startup Engineers and Our Mistakes w	Startup Engineers and Our Mistakes with MongoDB	nemild	13.702294	-5.3058367	story	15.0	94.0	1500476408	9.901454
23517663	Performance/Avoid SQLite in Your Nex	Performance/Avoid SQLite in Your Next Firefox Feature (2014)	mpweiher	13.556345	-5.516481	story	16.0	113.0	1592143110	9.850397
14564248	CouchDB vs. MongoDB	CouchDB vs. MongoDB	yanivleven	13.620113	-5.2252893	story	16.0	88.0	1497559907	9.726794
28669703	Show HN: SQLite Playground	Show HN: SQLite Playground	nalgeon	13.590548	-5.5691175	story	16.0	213.0	1632744927	9.80367
38751835	Text Processing Practice Experiment:	Text Processing Practice Experiment: 20 SERP Types to SQLite yy084	1vuio0pswjnm7	13.565899	-5.587404	story	16.0	2.0	1703402548	9.834376
33019500	Flyweight: An ORM for SQLite	Flyweight: An ORM for SQLite	unemployable	13.602554	-5.5758157	story	16.0	90.0	1664453777	9.792943
22262339	Migrating to CockroachDB	Migrating to CockroachDB	latch	13.666775	-5.2038836	story	16.0	163.0	1581038576	9.991918
16585268	I strongly suspect this article was 	I strongly suspect this article was written as a response against C++, Java, or C#. Especially given SQLite being started in 2000, C really was undeniably the best choice, and the existing code in C is a strong argument in favor against rewrites.That being said, Rust and possibly even Go would be strong contenders to make a new SQLite-like library/program today. At least on the Rust side, the C bindings are excellent too.	chungy	13.628822	-5.672289	comment	16.0	145.0	1521040323	9.8602915
30464075	Ask HN: Is MongoDB obsolote when Pos	Ask HN: Is MongoDB obsolote when Postgres and SQLite provide JSON types?	ewuhic	13.550763	-5.412859	story	16.0	49.0	1645768110	9.860148
13030162	ArangoDB Closes 2.2M Euro Investment	ArangoDB Closes 2.2M Euro Investment Led by Target Partners	reactor	13.655229	-5.2416167	story	16.0	103.0	1479993497	9.941153
12297596	Think before you Mongo	Think before you Mongo	sundip	13.712027	-5.311795	story	16.0	124.0	1471357149	9.907034
28157350	This is funny and sad to me. We had 	"This is funny and sad to me. We had SQLite in the browser[0]. I only did a little bit of work with it but it seemed actually pretty nice.It was torpedoed because it was SQL-based (and not trendy ""key value"" and ""web scale"").There was the whole excuse that the specification was ""whatever SQLite does"" and, therefore, not suitable for being a standard. There would be worse things than SQLite upon which to base a standard, all things considered. I still believe it was torpedoed because of lack of trendiness and ""not invented here"".[0] https://www.w3.org/TR/webdatabase/"	EvanAnderson	13.582218	-5.562496	comment	16.0	122.0	1628781267	9.838067
28278859	Why Is SQLite Coded in C (2017)	Why Is SQLite Coded in C (2017)	piyushsthr	13.634915	-5.599646	story	16.0	127.0	1629738250	9.865462
23358700	SQLite Turns 20	SQLite Turns 20	marcobambini	13.628279	-5.5905204	story	16.0	186.0	1590816329	9.845965
26581170	> There is a popular opinion among d	> There is a popular opinion among developers that SQLite is not suitable for the web, because it doesn’t support concurrent access.No, the issue is it doesn't have high availability features: failover, snapshots, concurrent backups, etc. (Edit: oops, comment pointed out it does have concurrent backups.)SQLite isn't a toy DBMS, it's an extremely capable embedded DBMS. An embedded DBMS is geared towards serving a single purpose-built client, which is great for a desktop application that wants a reliable way to store user data.Once you have multiple clients being developed and running concurrently, and you have production data (customer accounts that are effectively legal documents that must be preserved at all times) you want that DBMS to be an independent component. It's not principally ab	ben509	13.571399	-5.5166945	comment	16.0	120.0	1616684789	9.794552
15427932	Ask HN: Learning NoSQL, papers and b	Ask HN: Learning NoSQL, papers and books	wareotie	13.522125	-5.4128094	story	16.0	142.0	1507464995	9.827705
15691409	Show HN: Datasette – Create and publ	Show HN: Datasette – Create and publish an API for SQLite databases	simonw	13.521564	-5.5479383	story	16.0	269.0	1510617747	9.827441
14508413	A Brief History of the UUID	A Brief History of the UUID	mrbbk	13.992942	-5.2126184	story	17.0	304.0	1496857896	-13.670336
31703874	The Winamp Skin Museum is powered by	The Winamp Skin Museum is powered by a SQLite3 database with 1.2GB of metadata	tosh	13.55707	-5.5301495	story	17.0	293.0	1654949179	7.448758
35800109	Writing a SQLite Clone from Scratch 	Writing a SQLite Clone from Scratch in C (2022)	lispybanana	13.621996	-5.599375	story	17.0	328.0	1683106842	9.849219
35992325	UUIDs are obsolete in the age of Doc	UUIDs are obsolete in the age of Docker	lshevtsov	13.994397	-5.2109137	story	17.0	20.0	1684435420	-13.664721
29363054	SQLite Release 3.37.0	SQLite Release 3.37.0	massysett	13.626277	-5.594121	story	17.0	333.0	1638044823	9.861435
36610595	Cloud Backed SQLite	Cloud Backed SQLite	nalgeon	13.5829935	-5.4942036	story	17.0	488.0	1688612996	9.815159
37040359	Show HN: Doculite – Use SQLite as a 	Show HN: Doculite – Use SQLite as a Document Database	thenorthbay	13.557383	-5.476196	story	17.0	160.0	1691439274	9.817854
32539360	Turning SQLite into a Distributed Da	Turning SQLite into a Distributed Database	losfair	13.591587	-5.5127416	story	17.0	347.0	1661083763	9.817358
32355750	Plan B for UUIDs: double AES-128	Plan B for UUIDs: double AES-128	ingve	13.989768	-5.2125154	story	17.0	91.0	1659705809	-13.669096
17438516	How to make MongoDB not suck for ana	How to make MongoDB not suck for analytics	ayw	13.714377	-5.3221903	story	17.0	94.0	1530490828	9.89582
21146356	PostgreSQL 12	PostgreSQL 12	craigkerstiens	13.534384	-5.433407	story	17.0	373.0	1570107019	-13.0811
21163359	Sqlite 3.30.0	Sqlite 3.30.0	QuadrupleA	13.645198	-5.6117306	story	17.0	393.0	1570240726	9.88134
27762201	Show HN: SQLite query inside a Bash 	Show HN: SQLite query inside a Bash function	chmaynard	13.579661	-5.581163	story	17.0	134.0	1625671703	9.821892
28015980	Hosting SQLite Databases on GitHub P	Hosting SQLite Databases on GitHub Pages	isnotchicago	13.5545435	-5.5608377	story	17.0	567.0	1627714595	-11.797674
33948588	Just a few days ago I found a seriou	Just a few days ago I found a serious security issue in SQLite: https://sqlite.org/forum/forumpost/07beac8056151b2fIt was also promptly fixed, but it makes me feel like the millions of tests sound better than they are in reality …	adius	13.667935	-5.59534	comment	17.0	89.0	1670799794	9.838874
38070473	> The entire thing is stitched toget	> The entire thing is stitched together by spreadsheets that are parsed by Python, dropped into S3, parsed by Lambdas into more S3, the S3 files are picked up by MongoDB, then MongoDB records are passed by another Lambda into S3, the S3 files are pulled into Snowflake via Snowpipe, the new Snowflake data is pivoted by a Javascript stored procedure into a relational format... and that's how you edit someone's database access. That whole process is to upload like a 2KB CSV to a database that has people's database roles in it.Sometimes it's hard to distinguish resume-driven development from iterative-StackOverflow-driven development.	neilv	13.5296545	-5.2818484	comment	17.0	106.0	1698678908	9.834
15648280	Work on SQLite4 has concluded	Work on SQLite4 has concluded	joewalnes	13.626278	-5.5912037	story	17.0	378.0	1510093689	9.858344
20398932	Sqlite to Rest	Sqlite to Rest	mooreds	13.582577	-5.5856752	story	18.0	194.0	1562728973	9.864526
25842999	Serverless SQLite	Serverless SQLite	sfeng	13.578126	-5.508478	story	18.0	396.0	1611122201	9.83583
35740683	Exciting SQLite Improvements Since 2	Exciting SQLite Improvements Since 2020	thunderbong	13.62062	-5.5871363	story	18.0	172.0	1682686367	9.846442
38798383	BCHS software stack: BSD, C, httpd, 	BCHS software stack: BSD, C, httpd, SQLite	edward	13.561019	-5.5700307	story	18.0	153.0	1703796444	9.841773
32250426	SQLite Internals: Pages and B-trees	SQLite Internals: Pages and B-trees	eatonphil	13.602678	-5.58481	story	18.0	667.0	1658930154	9.758977
32303762	Show HN: Reduce SQLite database size	Show HN: Reduce SQLite database size by up to 80% with transparent compression	phiresky	13.539963	-5.5415993	story	18.0	420.0	1659346576	-6.3703003
16421338	Ask HN: Does anyone have success sto	Ask HN: Does anyone have success stories with MongoDB?	jitix	13.677688	-5.3132963	story	18.0	9.0	1519142861	9.907861
12543342	CouchDB 2.0	CouchDB 2.0	k__	13.6125555	-5.212682	story	18.0	258.0	1474405016	9.665536
35208113	Libgsqlite: A SQLite extension which	Libgsqlite: A SQLite extension which loads a Google Sheet as a virtual table	x2bool	13.579675	-5.576298	story	18.0	266.0	1679138689	9.851621
35488980	Go port of SQLite without CGo	Go port of SQLite without CGo	cube2222	13.623271	-5.621492	story	18.0	244.0	1680913369	9.912186
33945115	I found a bug in SQLite	I found a bug in SQLite	otoolep	13.629946	-5.5955806	story	18.0	584.0	1670779107	9.865677
24176608	SQLite 3.33	SQLite 3.33	chmaynard	13.649115	-5.6136217	story	19.0	272.0	1597572647	9.893856
19991230	PostgreSQL 12 Beta 1 Released	PostgreSQL 12 Beta 1 Released	jakobegger	13.537688	-5.4260573	story	19.0	235.0	1558616089	-13.1277075
31364166	SQLite in Go, with and Without Cgo	SQLite in Go, with and Without Cgo	ngaut	13.617438	-5.6293406	story	19.0	150.0	1652424272	9.887905
29010103	Comparing SQLite, DuckDB and Arrow w	Comparing SQLite, DuckDB and Arrow with UN trade data	marcle	13.541167	-5.566566	story	19.0	246.0	1635315663	9.872225
29065438	> It turns out my day to day work do	"> It turns out my day to day work doesn’t require deep knowledge about database internals and I can mostly treat them as a black box with an API 2.Because of such attitude of the previous dev team my client ended up with DB integrity ruined. Previous guys somehow didn't know they should use transactions when updating/deleting stuff in the DB, because hey, it's just API you call, who cares of mambo-jumbo happening behind the curtains, right?I myself had a similar fuckup with MongoDB a decade ago, because I used it ""because it's fast"", but failed to read the small letters, and wasn't aware that it achieves that speed by buffering the data for async save, and so has no guarantees it will actually be saved at all. So I lost a lot of data when traffic suddenly jumped, and since those were affil"	ivanhoe	13.6435	-5.328311	comment	19.0	90.0	1635766880	9.845638
39501281	Osquery: An sqlite3 virtual table ex	Osquery: An sqlite3 virtual table exposing operating system data to SQL	signa11	13.606121	-5.545669	story	19.0	290.0	1708873131	9.840089
19085189	UUIDs in MySQL are really not random	UUIDs in MySQL are really not random	jtwaleson	13.977829	-5.2166514	story	19.0	86.0	1549374408	-13.671713
16356942	Appropriate Uses for SQLite	Appropriate Uses for SQLite	tzhenghao	13.609318	-5.5807433	story	19.0	359.0	1518416767	9.833697
16384736	MongoDB has successfully played the 	MongoDB has successfully played the 'hype first, features later' strategy. Now it is well on the way to being a decent swiss-army-knife database.The RethinkDB retrospective[0] contains a lot of insight into how MongoDB has succeeded despite being vastly inferior on a technical level back when it first launched. I have to admit them a certain respect for executing their strategy so successfully.Choice quote:Every time MongoDB shipped a new release and people congratulated them on making improvements, I felt pangs of resentment. They’d announce they fixed the BKL, but really they’d get the granularity level down from a database to a collection. They’d add more operations, but instead of a composable interface that fits with the rest of the system, they’d simply bolt on one-off commands. They	_wc0m	13.678052	-5.320459	comment	19.0	154.0	1518708373	9.89421
17387851	How SQL Database Engines Work, by th	How SQL Database Engines Work, by the Creator of SQLite (2008) [video]	zbaylin	13.617927	-5.578369	story	19.0	813.0	1529867028	9.847345
39260614	UUID v7	UUID v7	Recursing	13.99505	-5.21348	story	19.0	231.0	1707136750	-13.67083
39297776	SQLite-Web: Web-based SQLite databas	SQLite-Web: Web-based SQLite database browser written in Python	thunderbong	13.5730915	-5.560554	story	19.0	181.0	1707363811	9.847668
29988951	BCHS: OpenBSD, C, httpd and SQLite w	BCHS: OpenBSD, C, httpd and SQLite web stack	davikrr	13.57826	-5.5315847	story	19.0	217.0	1642557874	9.856844
35399905	15k inserts/s with Rust and SQLite (	15k inserts/s with Rust and SQLite (2021)	mattrighetti	13.565864	-5.6184506	story	19.0	116.0	1680353498	9.75684
28269399	BCHS stack – BSD, C, httpd, SQLite	BCHS stack – BSD, C, httpd, SQLite	cheezymoogle	13.574239	-5.5535784	story	19.0	92.0	1629664904	9.853413
34020786	WordPress testing official SQLite Su	WordPress testing official SQLite Support	ethanpil	13.651085	-5.63365	story	19.0	122.0	1671226605	9.846252
31396732	Wp-SQLite: WordPress running on an S	Wp-SQLite: WordPress running on an SQLite database	lsferreira42	13.615109	-5.576553	story	20.0	182.0	1652707147	9.873812
34559075	The Untold Story of SQLite (2021)	The Untold Story of SQLite (2021)	xrayarx	13.610979	-5.575372	story	20.0	295.0	1674924359	9.853616
32828799	Show HN: Query SQLite files stored i	Show HN: Query SQLite files stored in S3	polyrand	13.525379	-5.4834895	story	20.0	160.0	1663095788	9.77599
32412905	How SQLite Helps You Do ACID	How SQLite Helps You Do ACID	eatonphil	13.647966	-5.608419	story	20.0	351.0	1660142859	9.840665
16995622	We’re happy with SQLite and not urge	We’re happy with SQLite and not urgently interested in a fancier DBMS (2016)	nailer	13.611268	-5.5687337	story	20.0	136.0	1525449756	9.79542
39207570	Show HN: Stanchion – Column-oriented	Show HN: Stanchion – Column-oriented tables in SQLite	dgllghr	13.556964	-5.5110965	story	20.0	273.0	1706726333	9.839934
18179819	MLab is being acquired by MongoDB	MLab is being acquired by MongoDB	luceat	13.7317705	-5.2683043	story	20.0	157.0	1539119262	9.945922
18831470	LiteCLI – A user-friendly command-li	LiteCLI – A user-friendly command-line client for SQLite database	luord	13.605932	-5.5882835	story	20.0	316.0	1546694124	9.831312
18913955	Fedora, UUIDs, and user tracking	Fedora, UUIDs, and user tracking	tlburke	13.9885025	-5.2047563	story	20.0	132.0	1547579679	-13.645885
33624018	Who needs MLflow when you have SQLit	Who needs MLflow when you have SQLite?	edublancas	13.561488	-5.5462313	story	20.0	252.0	1668610556	9.815856
15168467	Writing a SQLite clone from scratch 	Writing a SQLite clone from scratch in C	ingve	13.629071	-5.605891	story	20.0	574.0	1504535755	9.911683
13665695	Dear MongoDB users, we welcome you i	Dear MongoDB users, we welcome you in Azure DocumentDB	jeremya	13.675793	-5.3240433	story	21.0	126.0	1487302077	9.919561
31449368	SQLite may become foundational for d	SQLite may become foundational for digital progress	alexrustic	13.614428	-5.570864	story	21.0	165.0	1653062974	9.87511
36579347	Things that surprised me while runni	Things that surprised me while running SQLite in production	joseferben	13.629746	-5.5841103	story	21.0	232.0	1688421437	9.86682
32807601	Let’s make WordPress officially supp	Let’s make WordPress officially support SQLite	sqlsite	13.611401	-5.5732255	story	21.0	152.0	1662972847	9.849968
15795377	What MongoDB got right (2015)	What MongoDB got right (2015)	wheresvic3	13.703648	-5.318662	story	21.0	89.0	1511857656	9.872567
16585120	Why Is SQLite Coded in C? (2017)	Why Is SQLite Coded in C? (2017)	jeffreyrogers	13.631657	-5.608043	story	21.0	372.0	1521039143	9.856621
12663599	RethinkDB, SageMath, Andreessen-Horo	RethinkDB, SageMath, Andreessen-Horowitz, Basecamp and Open Source Software	williamstein	13.652111	-5.287848	story	21.0	331.0	1475871237	-12.837058
12961012	CockroachDB Stability Post-Mortem: F	CockroachDB Stability Post-Mortem: From 1 Node to 100 Nodes	orangechairs	13.627872	-5.206006	story	21.0	202.0	1479236022	9.887418
23281994	SQLite 3.32	SQLite 3.32	nikbackm	13.645383	-5.612398	story	21.0	379.0	1590232386	9.86809
26881915	Show HN: Mongita is to MongoDB as SQ	Show HN: Mongita is to MongoDB as SQLite is to SQL	scottrogowski	13.598656	-5.547593	story	21.0	126.0	1618953806	9.856444
14580746	BCHS stack – BSD, C, httpd, SQLite	BCHS stack – BSD, C, httpd, SQLite	based2	13.57783	-5.5526304	story	22.0	130.0	1497795769	9.8433
34434025	HC-tree is an experimental high-conc	HC-tree is an experimental high-concurrency database back end for SQLite	nalgeon	13.549346	-5.5155454	story	22.0	524.0	1674080826	9.782086
36602970	LiteFS Cloud: Distributed SQLite wit	LiteFS Cloud: Distributed SQLite with Managed Backups	nalgeon	13.576186	-5.4850583	story	22.0	238.0	1688575310	9.7829485
32478907	SQLite is not a toy database (2021)	SQLite is not a toy database (2021)	losfair	13.615274	-5.575289	story	22.0	267.0	1660620777	9.805088
16709069	CockroachDB 2.0 Performance Makes Si	CockroachDB 2.0 Performance Makes Significant Strides	awoods187	13.63895	-5.214604	story	22.0	384.0	1522344920	9.914335
17865687	LiteTree: SQLite with Branches	LiteTree: SQLite with Branches	kroggen	13.6016655	-5.5688825	story	22.0	343.0	1535517663	-11.724537
18685296	Remote code execution vulnerability 	Remote code execution vulnerability in SQLite	LinuxBender	13.613685	-5.5830307	story	22.0	444.0	1544825251	9.884136
18754634	SQLite as an Application File Format	SQLite as an Application File Format (2014)	kjeetgill	13.56935	-5.5708394	story	22.0	211.0	1545690546	9.827703
18768909	ULID: Universally Unique Lexicograph	ULID: Universally Unique Lexicographically Sortable Identifier	brunoluiz	13.936357	-5.2310157	story	22.0	238.0	1545910763	-13.659365
29794186	Understanding UUIDs, ULIDs and strin	Understanding UUIDs, ULIDs and string representations	sudhirj	13.972315	-5.2150507	story	22.0	213.0	1641300887	-13.662692
30020288	Atlas – Terraform but for Database M	Atlas – Terraform but for Database Migrations	wg0	13.521841	-5.252271	story	22.0	237.0	1642749807	9.688195
28050198	SQLite Is Dynamically Typed (2020)	SQLite Is Dynamically Typed (2020)	zachthewf	13.642142	-5.6178403	story	22.0	135.0	1628003786	9.891421
28089498	What are the advantages of sortable 	What are the advantages of sortable UUIDs with embedded timestamps over random 128 bits and a created_at column?	jozvolskyef	13.97919	-5.214246	comment	22.0	91.0	1628267636	-13.67789
15308043	MongoDB has filed to go public	MongoDB has filed to go public	mfiguiere	13.73411	-5.240246	story	22.0	168.0	1506034749	9.902421
26420665	Goodbye MongoDB, Hello PostgreSQL (2	Goodbye MongoDB, Hello PostgreSQL (2015)	ddtaylor	13.671867	-5.334555	story	23.0	166.0	1615441232	9.912896
35539464	FerretDB: open-source MongoDB altern	FerretDB: open-source MongoDB alternative	yawnxyz	13.658672	-5.318306	story	23.0	254.0	1681306745	9.86151
36208568	Why SQLite is so great for the edge	Why SQLite is so great for the edge	thunderbong	13.60412	-5.5660167	story	23.0	286.0	1686029848	9.845721
34352935	SQLite Wasm in the browser backed by	SQLite Wasm in the browser backed by the Origin Private File System	bubblehack3r	13.594415	-5.5619316	story	23.0	372.0	1673529064	9.848898
38667596	MongoDB security notice	MongoDB security notice	ciudilo	13.727491	-5.2506366	story	23.0	269.0	1702760222	9.9163265
16617750	A picture got my PostgreSQL database	A picture got my PostgreSQL database to start mining Monero	WhiteSource1	13.557816	-5.3581133	story	23.0	459.0	1521461112	9.833324
27897427	SQLite is 35% Faster Than The Filesy	SQLite is 35% Faster Than The Filesystem (2017)	emilengler	13.556043	-5.522153	story	23.0	226.0	1626805987	9.739785
31715119	New UUID Formats	New UUID Formats	swyx	13.987313	-5.2121553	story	24.0	494.0	1655047052	-13.669339
25462814	What If OpenDocument Used SQLite? (2	What If OpenDocument Used SQLite? (2014)	timeoperator	13.602914	-5.577259	story	24.0	269.0	1608255459	9.834874
25870482	Show HN: 128-bit, roughly-ordered, U	Show HN: 128-bit, roughly-ordered, URL-safe UUIDs	amzans	13.984461	-5.214084	story	24.0	205.0	1611312543	-13.657222
22098832	How to Corrupt a SQLite Database Fil	How to Corrupt a SQLite Database File	pcr910303	13.59635	-5.5658684	story	24.0	372.0	1579528946	9.782048
27718701	The Untold Story of SQLite	The Untold Story of SQLite	signa11	13.618133	-5.581475	story	24.0	548.0	1625276977	-7.2002187
35317419	Craziest thing I ever used SQLite fo	Craziest thing I ever used SQLite for: partial file deduplication (2022)	ics	13.586668	-5.568523	story	24.0	343.0	1679853626	9.836295
33374402	SQLite in the browser with WASM/JS	SQLite in the browser with WASM/JS	hochmartinez	13.596065	-5.552764	story	24.0	547.0	1666977688	9.814483
27345837	UUID, serial or identity columns for	UUID, serial or identity columns for PostgreSQL auto-generated primary keys?	lhenk	13.962305	-5.224969	story	24.0	204.0	1622479084	-13.6610775
31386330	Cron-based backup for SQLite	Cron-based backup for SQLite	davnicwil	13.5926285	-5.5055	story	25.0	370.0	1652606098	9.767138
35618503	Lightweight SQLite Editor for Window	Lightweight SQLite Editor for Windows	bbkane	13.565801	-5.5626845	story	25.0	272.0	1681844817	9.844565
28767996	Why NoSQL	Why NoSQL	typingmonkey	13.548529	-5.4079485	story	25.0	90.0	1633483240	9.8164215
34451344	Choosing a Postgres primary key	Choosing a Postgres primary key	awalias	13.821306	-5.3023424	story	25.0	220.0	1674212130	-13.65311
34860226	A Docker footgun led to a vandal del	A Docker footgun led to a vandal deleting NewsBlur's MongoDB database (2021)	quectophoton	13.717466	-5.2764606	story	25.0	119.0	1676830583	9.925852
37063238	SQLedge: Replicate Postgres to SQLit	SQLedge: Replicate Postgres to SQLite on the Edge	clessg	13.578357	-5.5157537	story	25.0	359.0	1691591389	9.843216
16384001	MongoDB gets support for multi-docum	MongoDB gets support for multi-document ACID transactions	uptown	13.626003	-5.3330793	story	25.0	343.0	1518703316	9.843768
38171322	Bluesky migrates to single-tenant SQ	Bluesky migrates to single-tenant SQLite	HillRat	13.627606	-5.5394874	story	25.0	354.0	1699316559	9.775025
26151302	Many small queries are efficient in 	Many small queries are efficient in SQLite	ArtTimeInvestor	13.575722	-5.549828	story	26.0	542.0	1613454322	9.792119
13581375	RethinkDB joins the Linux Foundation	RethinkDB joins the Linux Foundation: What Happens Next	mglukhovsky	13.681607	-5.280898	story	26.0	733.0	1486400226	-12.776427
27030088	Sortable Collision-Free UUIDs	Sortable Collision-Free UUIDs	kpdemetriou	13.984443	-5.215482	story	26.0	94.0	1620072899	-13.666557
20836331	Dqlite – High-Availability SQLite	Dqlite – High-Availability SQLite	stubish	13.575039	-5.5090466	story	27.0	463.0	1567146154	9.796501
31518618	SQLite 3 Fiddle	SQLite 3 Fiddle	sgbeal	13.616605	-5.590839	story	27.0	765.0	1653574719	9.900687
16375503	Performance Benchmark 2018 – MongoDB	Performance Benchmark 2018 – MongoDB, PostgreSQL, OrientDB, Neo4j and ArangoDB	pluma	13.5946865	-5.346691	story	27.0	155.0	1518614428	9.866468
27613217	Hacker deleted all of NewsBlur’s Mon	Hacker deleted all of NewsBlur’s Mongo data and is now holding the data hostage	jepler	13.720257	-5.288836	story	27.0	457.0	1624502129	9.91677
28259104	Strict Tables – Column type constrai	Strict Tables – Column type constraints in SQLite - Draft	thunderbong	13.646934	-5.607427	story	27.0	331.0	1629568988	9.866476
36101544	Unnatural Keys – Nature doesn’t come	Unnatural Keys – Nature doesn’t come with identifiers	thunderbong	13.912684	-5.2288666	story	28.0	183.0	1685253246	-13.637784
17272225	OpenBSD, C, httpd and SQLite – Web A	OpenBSD, C, httpd and SQLite – Web App stack	dhruvkar	13.573545	-5.535087	story	28.0	178.0	1528536644	9.874565
30163983	MariaDB to go public at $672M valuat	MariaDB to go public at $672M valuation	ashvardanian	13.5223875	-5.3874345	story	28.0	362.0	1643730132	-4.5753036
12641936	Are RethinkDB and Horizon abandoned?	Are RethinkDB and Horizon abandoned?	jamon51	13.68571	-5.2798934	story	28.0	292.0	1475649462	-12.801065
37613747	I'm all-in on server-side SQLite (20	I'm all-in on server-side SQLite (2022)	rrampage	13.611565	-5.56015	story	28.0	214.0	1695398561	9.844082
15607316	What If OpenDocument Used SQLite?	What If OpenDocument Used SQLite?	ejstronge	13.6017475	-5.579461	story	28.0	305.0	1509589236	9.835614
26440397	What's New in SQLite 3.35	What's New in SQLite 3.35	nalgeon	13.630131	-5.592037	story	29.0	496.0	1615580386	9.871308
19388913	ArangoDB Receives $10M Series A Fund	ArangoDB Receives $10M Series A Funding	kylesellas	13.651617	-5.2428236	story	29.0	190.0	1552569412	9.859596
13579544	RethinkDB Relicensed under Apache 2.	RethinkDB Relicensed under Apache 2.0	csmajorfive	13.674329	-5.3071256	story	29.0	686.0	1486390537	-12.839336
23290844	Jepsen: MongoDB 4.2.6	Jepsen: MongoDB 4.2.6	aphyr	13.714629	-5.303641	story	29.0	604.0	1590320521	9.916711
16946557	User IDs probably shouldn't be passe	User IDs probably shouldn't be passed around as ints	weinzierl	13.829933	-5.1859417	story	30.0	46.0	1524900979	-13.609762
25990400	Never use MongoDB (2013)	Never use MongoDB (2013)	mikecarlton	13.699417	-5.3184385	story	30.0	131.0	1612198523	9.888643
